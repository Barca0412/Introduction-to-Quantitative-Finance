# LLM & Agent

大语言模型与金融智能体在量化金融中的应用

> 共收录 **41** 篇论文 | [返回索引](../README.md)

---

### [Workflow is All You Need: Escaping the "Statistical Smoothing Trap" via High-Entropy Information Foraging and Adversarial Pacing](https://arxiv.org/abs/2512.10121v1)

**日期**: 2025-12-15 | **作者**: Zhongjie Jiang

**标签**: `NLP`

---

### [Reasoning Models Ace the CFA Exams](https://arxiv.org/abs/2512.08270v1)

**日期**: 2025-12-15 | **作者**: Jaisal Patel, Yunzhe Chen, Kaiwen He et al.

**标签**: `NLP`

---

### [MedAI: Evaluating TxAgent's Therapeutic Agentic Reasoning in the NeurIPS CURE-Bench Competition](https://arxiv.org/abs/2512.11682v1)

**日期**: 2025-12-15 | **作者**: Tim Cofala, Christian Kalfar, Jingge Xiao et al.

**标签**: `Deep Learning` `Financial Agent`

---

### [TriFlow: A Progressive Multi-Agent Framework for Intelligent Trip Planning](https://arxiv.org/abs/2512.11271v1)

**日期**: 2025-12-15 | **作者**: Yuxing Chen, Basem Suleiman, Qifan Chen

**标签**: `Financial Agent`

---

### [A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation](https://arxiv.org/abs/2512.11270v1)

**日期**: 2025-12-15 | **作者**: Hong Je-Gal, Chan-Bin Yi, Hyun-Suk Lee

**标签**: `LLM` `Financial Agent`

---

### [A Hybrid Model for Stock Market Forecasting: Integrating News Sentiment and Time Series Data with Graph Neural Networks](https://arxiv.org/abs/2512.08567v1)

**日期**: 2025-12-15 | **作者**: Nader Sadek, Mirette Moawad, Christina Naguib et al.

**标签**: `Deep Learning` `Sentiment Analysis` `Graph Neural Network`

---

### [不完美的必要性：通过模拟认知有限性逆转模型崩塌](https://arxiv.org/abs/2512.01354v1)

**日期**: 2025-12-02 | **作者**: Zhongjie Jiang

**标签**: `LLM` `NLP` `Behavioral Finance` `Risk Management`

本文指出合成数据因追求统计平滑去除人类文本的认知相关不规则性，加速模型崩塌；提出Prompt驱动认知计算框架（PMCSF），含认知状态解码器（CSD）和带认知扰动算子的认知文本编码器（CTE），模拟人类认知过程生成带典型不完美的文本；验证显示CTE文本与人类文本差异小，且A股压力测试中策略最大回撤降低47.4%。

---

### [期权轮动策略决策的混合架构：用于透明交易的LLM生成贝叶斯网络](https://arxiv.org/abs/2512.01123v1)

**日期**: 2025-12-02 | **作者**: Xiaoting Kuang, Boken Lin

**标签**: `LLM` `Options` `Algorithmic Trading` `Risk Management`

论文提出LLM与贝叶斯网络结合的混合架构，用LLM构建上下文特定的贝叶斯网络（而非黑盒决策），并选择相关历史数据填充条件概率表实现透明推理；该架构通过反馈循环迭代优化，实证在期权轮动策略上获15.3%年化收益及更优风险调整表现。

---

### [基于rLoRA微调的Qwen3-8B模型的金融文本分类](https://arxiv.org/abs/2512.00630v1)

**日期**: 2025-12-02 | **作者**: Zhiming Lian

**标签**: `LLM` `NLP` `Sentiment Analysis` `Transformer`

本文针对金融文本分类（含情感分析与新闻分类）任务，采用Qwen3-8B大模型，结合带噪声嵌入的指令微调、秩稳定低秩适应（rLoRA）及FlashAttention优化方法，提升训练效率与鲁棒性；实验表明Qwen3-8B在准确率和训练epoch需求上均优于传统Transformer及其他大模型基线，验证其金融应用潜力。

---

### [ICAD-LLM：基于大语言模型上下文学习的一劳永逸异常检测](https://arxiv.org/abs/2512.01672v1)

**日期**: 2025-12-02 | **作者**: Zhongyuan Wu, Jingyuan Wang, Zexuan Cheng et al.

**标签**: `LLM` `Anomaly` `Time Series` `Deep Learning`

论文针对现有异常检测方法多聚焦单模态、泛化能力不足的问题，提出ICAD范式（将异常定义为与正常参考集的差异性），并基于大语言模型的上下文学习能力构建ICAD-LLM统一框架，可处理异质数据且泛化到未见过的任务，性能与任务特定方法相当且降低部署成本。

---

### [随机对照试验的自动化偏倚风险评估：GEPA训练的程序化提示框架初探](https://arxiv.org/abs/2512.01452v1)

**日期**: 2025-12-02 | **作者**: Lingbo Li, Anuradha Mathrani, Teo Susnjak

**标签**: `LLM` `NLP` `Risk Management` `Deep Learning`

该研究提出基于DSPy的GEPA模块构建可编程偏倚风险（RoB）评估 pipeline，替代手动提示设计，通过帕累托引导搜索优化大语言模型（LLM）推理并生成可检查轨迹；在7个RoB领域的100个随机对照试验（RCT）上验证，GEPA提示显著提升部分领域（如随机序列生成）评估准确性，整体性能优于手动设计提示。

---

### [金融援助多语言对话AI：弥合印度金融科技的语言障碍](https://arxiv.org/abs/2512.01439v1)

**日期**: 2025-12-02 | **作者**: Bharatdeep Hazarika, Arya Suneesh, Prasanna Devadiga et al.

**标签**: `NLP` `Financial Agent` `LLM`

本文针对印度语言多样性导致的金融科技语言障碍问题，提出支持印地英语等混合语言的多智能体架构对话AI系统，包含语言分类、功能管理及多语言响应生成模块；通过多语言模型对比与真实部署验证，该系统显著提升用户参与度且仅增加4-8%的低延迟开销，为新兴市场数字金融服务的语言鸿沟弥合提供有效方案。

---

### [断言条件合规：多轮工具调用Agent中的溯源感知漏洞](https://arxiv.org/abs/2512.00332v1)

**日期**: 2025-12-02 | **作者**: Daud Waqas, Aaryamaan Golthi, Erika Hayashida et al.

**标签**: `LLM` `NLP` `Financial Agent` `Benchmark`

本文针对多轮工具调用大模型的鲁棒性不足问题，提出断言条件合规（A-CC）评估范式，从用户源断言（USA）和工具源断言（FSA）两个维度评估模型应对误导性断言的行为；实验表明模型对这两类误导性断言均高度脆弱，证实A-CC是部署Agent的关键潜在漏洞。

---

### [轻量级大语言模型在异构金融文本数据情感分类中的微调研究](https://arxiv.org/abs/2512.00946v1)

**日期**: 2025-12-02 | **作者**: Alvaro Paredes Amorin, Andre Python, Christoph Weisser

**标签**: `LLM` `Sentiment Analysis` `NLP` `Transformer`

该论文对比了轻量级开源LLMs（DeepSeek-LLM 7B、Llama3 8B Instruct、Qwen3 8B）与传统金融NLP模型FinBERT在五个异构金融文本数据集上的情感分类性能，发现Qwen3 8B和Llama3 8B即使仅用5%训练数据或零/少样本也能取得竞争力表现，证明轻量级开源LLMs是经济高效的金融情感分析选择。

---

### [语义优势与取证效率：深度学习与心理语言学在商务邮件泄露检测中的比较分析](https://arxiv.org/abs/2511.20944v2)

**日期**: 2025-12-02 | **作者**: Yaw Osei Adjei, Frederick Ayivor

**标签**: `NLP` `Deep Learning` `Transformer` `Risk Management`

论文针对造成巨额经济损失的商务邮件泄露（BEC）威胁，对比了基于心理语言学的CatBoost（高可解释、低延迟）与基于深度学习的DistilBERT（高准确率）两种检测范式，在混合数据集上验证了两者性能差异及成本效益，为不同部署场景提供可行选择。

---

### [CryptoBench：加密货币领域LLM智能体专家级评估的动态基准](https://arxiv.org/abs/2512.00417v1)

**日期**: 2025-12-02 | **作者**: Jiacheng Guo, Suozhi Huang, Zixin Yao et al.

**标签**: `LLM` `Financial Agent` `Benchmark`

本文引入首个专家设计的动态基准CryptoBench，针对加密货币领域LLM智能体的真实能力评估，解决该领域时间敏感、信息对抗性强、多源数据合成等特有挑战；基准每月包含50道由加密专业人士设计的任务，按简单/复杂检索、简单/复杂预测四象限分类，可精准评估LLM的数据获取与高级分析预测能力；对10个LLM的评估揭示了其存在检索-预测失衡的失效模式。

---

### [读心还是误读？大五人格测试中的大语言模型](https://arxiv.org/abs/2511.23101v1)

**日期**: 2025-12-01 | **作者**: Francesco Di Cursi, Chiara Boldrini, Marco Conti et al.

**标签**: `LLM` `NLP` `Behavioral Finance`

该论文测试5个大语言模型（含GPT-4及开源轻量模型）在3个异构数据集和2种提示策略下的大五人格二分类预测，发现丰富提示减少无效输出但引入系统偏差，不同特质预测难度差异显著；现有开箱即用LLM暂不适合自动人格预测，需协调提示设计、特质框架与评估指标。

---

### [AI欺骗：风险、动态与控制](https://arxiv.org/abs/2511.22619v1)

**日期**: 2025-12-01 | **作者**: Boyuan Chen, Sitong Fang, Jiaming Ji et al.

**标签**: `LLM` `Risk Management` `Benchmark`

论文基于动物欺骗的信号理论提出AI欺骗的正式定义，构建包含欺骗出现（机制、激励、能力前提、触发条件）与处理（检测）的欺骗周期研究框架，梳理现有实证研究并分析AI欺骗作为社会技术安全挑战的风险。

---

### [奶牛场中基于多智能体强化学习的点对点能源交易](https://arxiv.org/abs/2511.23148v1)

**日期**: 2025-12-01 | **作者**: Mian Ibad Ali Shah, Marcos Eduardo Cruz Victorio, Maeve Duffy et al.

**标签**: `Reinforcement Learning` `Financial Agent`

论文针对农村奶牛场的分散能源管理问题，提出结合多智能体强化学习（含DQN和PPO）与P2P能源交易机制的方法，通过拍卖清结算、价格顾问代理及负荷/电池管理，显著降低爱尔兰和芬兰奶牛场的用电成本（DQN分别降14.2%和5.16%）、峰时需求（PPO在爱尔兰降55.5%）并提升售电收益，验证了MARL与P2P交易的互补优势。

---

### [解决AI智能体中的上下文窗口溢出问题](https://arxiv.org/abs/2511.22729v1)

**日期**: 2025-12-01 | **作者**: Anton Bulle Labate, Valesca Moura de Sousa, Sandro Rama Fiorini et al.

**标签**: `LLM` `Financial Agent` `NLP`

本文针对大语言模型（LLM）处理工具输出时的上下文窗口溢出问题，提出将模型交互从原始数据转向内存指针的方法，可在无信息损失下处理任意长度工具响应，且减少token使用与执行时间；该方法在材料科学真实应用中验证有效，实验中token消耗约为传统方法的1/7。

---

### [AgentShield：提升多智能体系统（MAS）的安全性与效率](https://arxiv.org/abs/2511.22924v1)

**日期**: 2025-12-01 | **作者**: Kaixiang Wang, Zhaojiacheng Zhou, Bunyod Suvonov et al.

**标签**: `LLM` `Transformer` `Anomaly` `Deep Learning`

该论文针对基于大语言模型（LLM）的多智能体系统（MAS）易受对抗攻击且现有防御存在单点故障或效率损失的问题，提出分布式防御框架AgentShield，通过关键节点审计、轻量令牌审计、两轮共识审计三层设计优化鲁棒性-效率权衡；实验表明其恢复率达92.5%，审计开销降低超70%，在多样拓扑和攻击场景下维持高协作准确率。

---

### [基于量子分布组合电路（QDisCoCirc）的金融文本情感分析](https://arxiv.org/abs/2511.18804v1)

**日期**: 2025-11-28 | **作者**: Takayuki Sakuma

**标签**: `Sentiment Analysis` `NLP` `Transformer` `Investor Sentiment`

该论文将量子分布组合电路（QDisCoCirc）应用于金融文本三分类情感分析，通过分解句子为短连续chunk并映射到浅量子电路得到Bloch向量序列；采用量子token+小Transformer编码器+CCG类型嵌入的混合设计，既保留量子语义可解释性，又能建模语序与长依赖，提升了测试macro-F1，且chunk归因显示证据集中于少数chunk、正确预测句子更可靠使用类型嵌入。

---

### [基于LLM驱动的代码进化的认知阿尔法挖掘](https://arxiv.org/abs/2511.18850v1)

**日期**: 2025-11-28 | **作者**: Fengyuan Liu, Huang Yi, Sichun Luo et al.

**标签**: `LLM` `Factor Mining` `Asset Pricing` `Algorithmic Trading`

针对现有阿尔法挖掘方法搜索空间狭窄、模型不透明或经济依据不足等问题，本文提出CogAlpha框架，融合代码级阿尔法表示、LLM驱动推理与进化搜索，通过多阶段提示和金融反馈迭代优化候选阿尔法；在A股市场的实验表明，该框架挖掘的阿尔法在预测精度、鲁棒性和泛化性上均优于现有方法。

---

### [重新思考检索：金融领域大语言模型从传统检索增强生成到智能体与非向量推理系统的演进](https://arxiv.org/abs/2511.18177v1)

**日期**: 2025-11-28 | **作者**: Elias Lumer, Matt Melich, Olivia Zino et al.

**标签**: `LLM` `NLP` `Financial Agent` `Benchmark`

本文首次系统对比金融文档的向量基智能体RAG（混合搜索+元数据过滤）与非向量层次节点基RAG架构，评估交叉编码器重排序、小到大分块检索两种增强技术的效果；基于1200份SEC文件和150题基准，测检索指标、回答质量、 latency及成本，发现向量基智能体RAG更优，两种增强技术显著提升性能。

---

### [MortgageLLM：带残差指令迁移、对齐调优和任务特定路由的领域自适应预训练](https://arxiv.org/abs/2511.21101v1)

**日期**: 2025-11-28 | **作者**: Manish Jain, Satheesh Kumar Ponnambalam, Salman Faroz et al.

**标签**: `LLM` `NLP` `Financial Agent` `Transformer`

论文提出抵押贷款领域专用大模型MortgageLLM，采用双轨特化框架从LLaMA-3.1-8B构建对话问答与结构化任务两个专家模型，通过指令残差技术恢复指令遵循能力并设计智能任务路由机制，在领域基准上显著优于基础模型。

---

### [设计制造数据交易市场的声誉系统：结合Q学习和IRL估计效用的多智能体评估](https://arxiv.org/abs/2511.19930v1)

**日期**: 2025-11-28 | **作者**: Kenta Yamamoto, Teruaki Hayashi

**标签**: `Financial Agent` `Reinforcement Learning` `Market Microstructure` `Asset Pricing`

论文针对制造数据交易市场的信息不对称问题，开发了集成强化学习（Q学习）与逆强化学习（IRL）的多智能体模拟器，评估五种声誉系统的市场效果并提出融合优势的混合机制，以提升数据价格与质量的对齐度。

---

### [论AI算法进步的起源](https://arxiv.org/abs/2511.21622v1)

**日期**: 2025-11-28 | **作者**: Hans Gundlach, Alex Fogelson, Jayson Lynch et al.

**标签**: `Transformer` `Deep Learning` `LLM` `Algorithmic Trading`

论文通过小尺度消融实验、文献调查及缩放实验发现，2012-2023年AI训练FLOP效率提升的大部分（6930倍）来自算法的尺度依赖改进（如LSTM到Transformer的compute-optimal scaling law指数差异），而非小模型算法创新；指出此前对算法进步的估计高估了小模型贡献，算法效率度量强依赖参考尺度。

---

### [专家角色大语言模型的自我透明性失败：大规模行为审计](https://arxiv.org/abs/2511.21569v1)

**日期**: 2025-11-28 | **作者**: Alex Diep

**标签**: `LLM` `Behavioral Finance` `NLP`

该研究采用common-garden设计，对16个开源LLM（4B-671B参数）开展19200次试验，审计其专家角色下的自我透明性（披露AI身份）；发现模型在不同领域披露率差异显著（如金融顾问30.8% vs神经外科医生3.5%），模型身份比参数规模更能预测行为，推理优化可能抑制透明性，强调透明性由训练因素决定而非规模，需刻意设计与实证验证。

---

### [KOM：用于膝骨关节炎（KOA）精准管理的多智能体人工智能系统](https://arxiv.org/abs/2511.19798v1)

**日期**: 2025-11-28 | **作者**: Weizhi Liu, Xi Chen, Zekun Jiang et al.

**标签**: `LLM` `Deep Learning` `Risk Management`

针对全球超6亿膝骨关节炎（KOA）患者个性化多学科干预资源不足的问题，开发多智能体系统KOM，可自动化KOA评估、风险预测与治疗处方；实验显示其在影像分析和处方生成上优于通用大模型，且与临床医生协作能提升诊疗效率（减少38.5%时间）和治疗质量。

---

### [基于远程监督的语言无关情感标注：以英语、Sepedi语和Setswana语为例](https://arxiv.org/abs/2511.19818v1)

**日期**: 2025-11-28 | **作者**: Koena Ronny Mabokela, Tim Schlippe, Mpho Raborife et al.

**标签**: `NLP` `Sentiment Analysis`

本文针对非洲低资源语言缺乏情感标注数据的问题，提出一种基于情感表情和词汇的自动语言无关情感标注方法；利用SAfriSenti南非多语言情感语料实验，英语、Sepedi语和Setswana语标注准确率分别达66%、69%和63%，平均仅需修正34%自动标注结果，有效降低手动标注成本。

---

### [MOMA-AC：连续多目标多智能体强化学习的偏好驱动演员-评论员框架](https://arxiv.org/abs/2511.18181v1)

**日期**: 2025-11-28 | **作者**: Adam Callaghan, Karl Mason, Patrick Mannion

**标签**: `Reinforcement Learning` `Deep Learning` `Financial Agent`

本文针对连续状态与动作空间的多目标多智能体强化学习（MOMARL）空白，提出首个内循环演员-评论员框架MOMA-AC，基于TD3/DDPG实例化为MOMA-TD3/DDPG，结合多头演员、集中式评论员与偏好条件架构，可编码冲突目标下最优策略的帕累托前沿；还构建连续MOMARL测试套件，在合作任务中显著提升预期效用与超体积，且随智能体数量增加可稳定扩展。

---

### [MADRA：面向风险感知具身规划的多智能体辩论框架](https://arxiv.org/abs/2511.21460v1)

**日期**: 2025-11-28 | **作者**: Junjian Wang, Lidan Zhao, Xi Sheryl Zhang

**标签**: `LLM` `Risk Management` `Benchmark`

针对具身AI任务规划中现有方法计算成本高或过度拒绝的问题，提出无训练的MADRA多智能体辩论风险评估框架，通过多个LLM代理辩论指令安全性、关键评估者打分及迭代共识投票，减少误拒并保持危险任务敏感性；还引入分层认知协作规划框架提升任务成功率，贡献SafeAware-VH基准数据集，实验验证其性能优于现有方法。

---

### [Chatty-KG：面向知识图谱的按需对话式问答多智能体AI系统](https://arxiv.org/abs/2511.20940v1)

**日期**: 2025-11-28 | **作者**: Reham Omar, Abdelghny Orogat, Ibrahim Abdelaziz et al.

**标签**: `LLM` `NLP` `Financial Agent`

论文提出模块化多智能体系统Chatty-KG，针对现有RAG序列化结构、多轮上下文处理不足及传统KGQA单轮问答等局限，通过任务专用LLM智能体协作（上下文解释、对话跟踪等）结合RAG检索与结构化执行，实现自然问题到可执行SPARQL查询的准确低延迟转换；实验在多规模多样化KG上显著优于SOTA基线，模块化设计支持动态KG无需微调预训练。

---

### [通过BREW提升语言智能体性能](https://arxiv.org/abs/2511.20297v1)

**日期**: 2025-11-28 | **作者**: Shashank Kirtania, Param Biyani, Priyanshu Gupta et al.

**标签**: `LLM` `Financial Agent` `Reinforcement Learning` `Transformer`

针对当前LLM智能体训练（如PPO等）计算开销大、策略难解释的问题，论文提出BREW框架，通过构建与优化经验环境知识的结构化记忆，结合任务评分器、行为 rubric及状态空间搜索提升智能体性能；实证在OSWorld等基准上实现10-20%精度提升、10-15%工具调用减少且计算高效。

---

### [智能制造中的混合智能体AI与多智能体系统](https://arxiv.org/abs/2511.18258v1)

**日期**: 2025-11-28 | **作者**: Mojtaba A. Farahani, Md Irfan Khan, Thorsten Wuest

**标签**: `LLM` `Anomaly` `Transformer`

本文提出面向智能制造预测性维护的混合智能体AI与多智能体框架，以LLM智能体实现战略编排与自适应推理，结合规则及SLM智能体完成边缘端高效领域任务，分层架构由LLM Planner协调工作流；该框架支持动态模型适应、成本高效维护调度及可解释决策，经工业数据集验证且模块化可扩展。

---

### [LLM能否做出（个性化）访问控制决策？](https://arxiv.org/abs/2511.20284v1)

**日期**: 2025-11-28 | **作者**: Friederike Groschupp, Daniele Lain, Aritra Dhar et al.

**标签**: `LLM` `NLP` `Behavioral Finance`

针对用户访问控制决策认知负荷过重问题，论文提出利用LLM实现动态上下文感知的访问控制决策方法；通过用户研究构建含307条隐私陈述与14682条用户决策的数据集，对比通用及个性化LLM的决策效果，发现通用LLM匹配多数用户偏好准确率达86%，且个性化存在提升个体匹配与违反安全最佳实践的权衡。

---

### [用于表格数据分析的多模态对话代理](https://arxiv.org/abs/2511.18405v1)

**日期**: 2025-11-28 | **作者**: Mohammad Nour Al Awad, Sergey Ivanov, Olga Tikhonova et al.

**标签**: `LLM` `NLP` `Financial Agent`

本文提出多模态对话代理Talk2Data，整合LLM、自动语音识别（Whisper）、文本转语音（Coqui）、代码生成（Qwen-coder）及沙盒执行工具，支持语音/文本交互与多轮上下文感知对话；实验在3个数据集48个任务上实现95.8%准确率，7B参数LLM在准确率、延迟与成本间取得最优平衡，计算过程可验证。

---

### [CostNav：具身智能体成本感知评估的导航基准](https://arxiv.org/abs/2511.20216v1)

**日期**: 2025-11-28 | **作者**: Haebin Seong, Sungmin Kim, Minchan Kim et al.

**标签**: `Benchmark` `Financial Agent` `Deep Learning`

现有导航基准忽略商业部署的经济可行性，论文提出首个成本感知导航基准CostNav，基于行业参数建模全生命周期成本（硬件、训练、能源、维护等）与收入（含服务等级协议SLA）；定量揭示任务成功优化与商业可行的差距，基线虽有43% SLA合规但亏损（碰撞维护占99.7%成本），并建立多类导航方法的评估基础。

---

### [构建与基准测试：面向基于文本的钓鱼和垃圾邮件检测框架的带标签邮件数据集](https://arxiv.org/abs/2511.21448v1)

**日期**: 2025-11-28 | **作者**: Rebeka Toth, Tamas Bisztray, Richard Dubniczky

**标签**: `LLM` `NLP` `Sentiment Analysis` `Benchmark`

本研究构建了包含钓鱼、垃圾邮件及合法邮件（明确区分人类与LLM生成内容）的综合带标签数据集，标注类别、情感诉求及动机；通过基准测试筛选可靠LLM标注全数据集，评估其在原始与重写邮件上的检测性能，发现钓鱼检测能力较强但垃圾邮件与合法邮件区分存挑战，开源相关代码与资源。

---

### [语义优势与取证效率：深度学习与心理语言学在商务邮件欺诈检测中的比较分析](https://arxiv.org/abs/2511.20944v1)

**日期**: 2025-11-28 | **作者**: Yaw Osei Adjei

**标签**: `NLP` `Deep Learning` `Transformer` `Anomaly`

论文针对每年造成超29亿美元损失的商务邮件欺诈（BEC），比较两种检测范式——基于DistilBERT的语义流（高精度需GPU）和基于CatBoost的取证心理语言流（低延迟低成本），在对抗性数据集上验证性能，为不同部署场景提供选型参考。

---

### [符号信道原理：衡量大语言模型通信中的意义容量](https://arxiv.org/abs/2511.19550v1)

**日期**: 2025-11-28 | **作者**: Davide Picca

**标签**: `LLM` `NLP` `Deep Learning` `Risk Management`

论文提出符号框架分析大语言模型（LLM），用信息论工具量化表达丰富度（源熵）与解释稳定性（消息和人类解释的互信息）的权衡，引入生成复杂度参数λ建模该权衡，定义符号信道并提出意义传输的容量约束，同时展示其在模型 profiling、提示设计等四方面的应用价值。

---

