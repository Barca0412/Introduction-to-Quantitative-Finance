[
  {
    "id": "2601.03215v1",
    "title": "Trading with market resistance and concave price impact",
    "abstract": "We consider an optimal trading problem under a market impact model with endogenous market resistance generated by a sophisticated trader who (partially) detects metaorders and trades against them to exploit price overreactions induced by the order flow. The model features a concave transient impact driven by a power-law propagator with a resistance term responding to the trader's rate via a fixed-point equation involving a general resistance function. We derive a (non)linear stochastic Fredholm equation as the first-order optimality condition satisfied by optimal trading strategies. Existence and uniqueness of the optimal control are established when the resistance function is linear, and an existence result is obtained when it is strictly convex using coercivity and weak lower semicontinuity of the associated profit-and-loss functional. We also propose an iterative scheme to solve the nonlinear stochastic Fredholm equation and prove an exponential convergence rate. Numerical experiments confirm this behavior and illustrate optimal round-trip strategies under \"buy\" signals with various decay profiles and different market resistance specifications.",
    "authors": [
      "Youssef Ouazzani Chahdi",
      "Nathan De Carvalho",
      "Grégoire Szymanski"
    ],
    "published": "2026-01-06",
    "categories": [
      "q-fin.TR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.03215v1",
    "arxiv_url": "https://arxiv.org/abs/2601.03215v1",
    "fetched_at": "2026-01-07T08:36:02.061175"
  },
  {
    "id": "2601.03175v1",
    "title": "Breaking the Dimensional Barrier: Dynamic Portfolio Choice with Parameter Uncertainty via Pontryagin Projection",
    "abstract": "We study continuous-time portfolio choice in diffusion markets with parameter $θ\\in Θ$ and uncertainty law $q(dθ)$. Nature draws latent $θ\\sim q$ at time 0; the investor cannot observe it and must deploy a single $θ$-blind feedback policy maximizing an ex-ante CRRA objective averaged over diffusion noise and $θ$. Our methods access $q$ only by sampling and assume no parametric form. We extend Pontryagin-Guided Direct Policy Optimization (PG-DPO) by sampling $θ$ inside the simulator and computing discrete-time gradients via backpropagation through time (BPTT), and we propose projected PG-DPO (P-PGDPO) that projects costate estimates to satisfy the $q$-aggregated Pontryagin first-order condition, yielding a deployable rule. We prove a BPTT-PMP correspondence uniform on compacts and a residual-based $θ$-blind policy-gap bound under local stability with explicit discretization/Monte Carlo errors; experiments show projection-driven stability and accurate decision-time benchmark recovery in high dimensions.",
    "authors": [
      "Jeonggyu Huh",
      "Hyeng Keun Koo"
    ],
    "published": "2026-01-06",
    "categories": [
      "q-fin.CP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.03175v1",
    "arxiv_url": "https://arxiv.org/abs/2601.03175v1",
    "fetched_at": "2026-01-07T08:36:02.061213"
  },
  {
    "id": "2601.02677v1",
    "title": "Uni-FinLLM: A Unified Multimodal Large Language Model with Modular Task Heads for Micro-Level Stock Prediction and Macro-Level Systemic Risk Assessment",
    "abstract": "Financial institutions and regulators require systems that integrate heterogeneous data to assess risks from stock fluctuations to systemic vulnerabilities. Existing approaches often treat these tasks in isolation, failing to capture cross-scale dependencies. We propose Uni-FinLLM, a unified multimodal large language model that uses a shared Transformer backbone and modular task heads to jointly process financial text, numerical time series, fundamentals, and visual data. Through cross-modal attention and multi-task optimization, it learns a coherent representation for micro-, meso-, and macro-level predictions. Evaluated on stock forecasting, credit-risk assessment, and systemic-risk detection, Uni-FinLLM significantly outperforms baselines. It raises stock directional accuracy to 67.4% (from 61.7%), credit-risk accuracy to 84.1% (from 79.6%), and macro early-warning accuracy to 82.3%. Results validate that a unified multimodal LLM can jointly model asset behavior and systemic vulnerabilities, offering a scalable decision-support engine for finance.",
    "authors": [
      "Gongao Zhang",
      "Haijiang Zeng",
      "Lu Jiang"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.LG",
      "q-fin.RM",
      "q-fin.ST"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.02677v1",
    "arxiv_url": "https://arxiv.org/abs/2601.02677v1",
    "fetched_at": "2026-01-07T08:36:02.061240"
  },
  {
    "id": "2601.03149v1",
    "title": "PersonaLedger: Generating Realistic Financial Transactions with Persona Conditioned LLMs and Rule Grounded Feedback",
    "abstract": "Strict privacy regulations limit access to real transaction data, slowing open research in financial AI. Synthetic data can bridge this gap, but existing generators do not jointly achieve behavioral diversity and logical groundedness. Rule-driven simulators rely on hand-crafted workflows and shallow stochasticity, which miss the richness of human behavior. Learning-based generators such as GANs capture correlations yet often violate hard financial constraints and still require training on private data. We introduce PersonaLedger, a generation engine that uses a large language model conditioned on rich user personas to produce diverse transaction streams, coupled with an expert configurable programmatic engine that maintains correctness. The LLM and engine interact in a closed loop: after each event, the engine updates the user state, enforces financial rules, and returns a context aware \"nextprompt\" that guides the LLM toward feasible next actions. With this engine, we create a public dataset of 30 million transactions from 23,000 users and a benchmark suite with two tasks, illiquidity classification and identity theft segmentation. PersonaLedger offers a realistic, privacy preserving resource that supports rigorous evaluation of forecasting and anomaly detection models. PersonaLedger offers the community a rich, realistic, and privacy preserving resource -- complete with code, rules, and generation logs -- to accelerate innovation in financial AI and enable rigorous, reproducible evaluation.",
    "authors": [
      "Dehao Yuan",
      "Tyler Farnan",
      "Stefan Tesliuc",
      "Doron L Bergman",
      "Yulun Wu",
      "Xiaoyu Liu",
      "Minghui Liu",
      "James Montgomery",
      "Nam H Nguyen",
      "C. Bayan Bruss",
      "Furong Huang"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.03149v1",
    "arxiv_url": "https://arxiv.org/abs/2601.03149v1",
    "fetched_at": "2026-01-07T08:36:15.460109"
  },
  {
    "id": "2601.03085v1",
    "title": "Real-Time Adaptive Anomaly Detection in Industrial IoT Environments",
    "abstract": "To ensure reliability and service availability, next-generation networks are expected to rely on automated anomaly detection systems powered by advanced machine learning methods with the capability of handling multi-dimensional data. Such multi-dimensional, heterogeneous data occurs mostly in today's industrial Internet of Things (IIoT), where real-time detection of anomalies is critical to prevent impending failures and resolve them in a timely manner. However, existing anomaly detection methods often fall short of effectively coping with the complexity and dynamism of multi-dimensional data streams in IIoT. In this paper, we propose an adaptive method for detecting anomalies in IIoT streaming data utilizing a multi-source prediction model and concept drift adaptation. The proposed anomaly detection algorithm merges a prediction model into a novel drift adaptation method resulting in accurate and efficient anomaly detection that exhibits improved scalability. Our trace-driven evaluations indicate that the proposed method outperforms the state-of-the-art anomaly detection methods by achieving up to an 89.71% accuracy (in terms of Area under the Curve (AUC)) while meeting the given efficiency and scalability requirements.",
    "authors": [
      "Mahsa Raeiszadeh",
      "Amin Ebrahimzadeh",
      "Roch H. Glitho",
      "Johan Eker",
      "Raquel A. F. Mini"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.03085v1",
    "arxiv_url": "https://arxiv.org/abs/2601.03085v1",
    "fetched_at": "2026-01-07T08:36:15.460145"
  },
  {
    "id": "2601.02927v1",
    "title": "PrismVAU: Prompt-Refined Inference System for Multimodal Video Anomaly Understanding",
    "abstract": "Video Anomaly Understanding (VAU) extends traditional Video Anomaly Detection (VAD) by not only localizing anomalies but also describing and reasoning about their context. Existing VAU approaches often rely on fine-tuned multimodal large language models (MLLMs) or external modules such as video captioners, which introduce costly annotations, complex training pipelines, and high inference overhead. In this work, we introduce PrismVAU, a lightweight yet effective system for real-time VAU that leverages a single off-the-shelf MLLM for anomaly scoring, explanation, and prompt optimization. PrismVAU operates in two complementary stages: (1) a coarse anomaly scoring module that computes frame-level anomaly scores via similarity to textual anchors, and (2) an MLLM-based refinement module that contextualizes anomalies through system and user prompts. Both textual anchors and prompts are optimized with a weakly supervised Automatic Prompt Engineering (APE) framework. Extensive experiments on standard VAD benchmarks demonstrate that PrismVAU delivers competitive detection performance and interpretable anomaly explanations -- without relying on instruction tuning, frame-level annotations, and external modules or dense processing -- making it an efficient and practical solution for real-world applications.",
    "authors": [
      "Iñaki Erregue",
      "Kamal Nasrollahi",
      "Sergio Escalera"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.02927v1",
    "arxiv_url": "https://arxiv.org/abs/2601.02927v1",
    "fetched_at": "2026-01-07T08:36:15.460167"
  },
  {
    "id": "2601.02736v1",
    "title": "Hypothesize-Then-Verify: Speculative Root Cause Analysis for Microservices with Pathwise Parallelism",
    "abstract": "Microservice systems have become the backbone of cloud-native enterprise applications due to their resource elasticity, loosely coupled architecture, and lightweight deployment. Yet, the intrinsic complexity and dynamic runtime interactions of such systems inevitably give rise to anomalies. Ensuring system reliability therefore hinges on effective root cause analysis (RCA), which entails not only localizing the source of anomalies but also characterizing the underlying failures in a timely and interpretable manner. Recent advances in intelligent RCA techniques, particularly those powered by large language models (LLMs), have demonstrated promising capabilities, as LLMs reduce reliance on handcrafted features while offering cross-platform adaptability, task generalization, and flexibility. However, existing LLM-based methods still suffer from two critical limitations: (a) limited exploration diversity, which undermines accuracy, and (b) heavy dependence on large-scale LLMs, which results in slow inference. To overcome these challenges, we propose SpecRCA, a speculative root cause analysis framework for microservices that adopts a \\textit{hypothesize-then-verify} paradigm. SpecRCA first leverages a hypothesis drafting module to rapidly generate candidate root causes, and then employs a parallel root cause verifier to efficiently validate them. Preliminary experiments on the AIOps 2022 dataset demonstrate that SpecRCA achieves superior accuracy and efficiency compared to existing approaches, highlighting its potential as a practical solution for scalable and interpretable RCA in complex microservice environments.",
    "authors": [
      "Lingzhe Zhang",
      "Tong Jia",
      "Yunpeng Zhai",
      "Leyi Pan",
      "Chiming Duan",
      "Minghua He",
      "Pei Xiao",
      "Ying Li"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.02736v1",
    "arxiv_url": "https://arxiv.org/abs/2601.02736v1",
    "fetched_at": "2026-01-07T08:36:15.460197"
  },
  {
    "id": "2601.02694v1",
    "title": "Which Deep Learner? A Systematic Evaluation of Advanced Deep Forecasting Models Accuracy and Efficiency for Network Traffic Prediction",
    "abstract": "Network traffic prediction is essential for automating modern network management. It is a difficult time series forecasting (TSF) problem that has been addressed by Deep Learning (DL) models due to their ability to capture complex patterns. Advances in forecasting, from sophisticated transformer architectures to simple linear models, have improved performance across diverse prediction tasks. However, given the variability of network traffic across network environments and traffic series timescales, it is essential to identify effective deployment choices and modeling directions for network traffic prediction. This study systematically identify and evaluates twelve advanced TSF models -- including transformer-based and traditional DL approaches, each with unique advantages for network traffic prediction -- against three statistical baselines on four real traffic datasets, across multiple time scales and horizons, assessing performance, robustness to anomalies, data gaps, external factors, data efficiency, and resource efficiency in terms of time, memory, and energy. Results highlight performance regimes, efficiency thresholds, and promising architectures that balance accuracy and efficiency, demonstrating robustness to traffic challenges and suggesting new directions beyond traditional RNNs.",
    "authors": [
      "Eilaf MA Babai",
      "Aalaa MA Babai",
      "Koji Okamura"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.NI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.02694v1",
    "arxiv_url": "https://arxiv.org/abs/2601.02694v1",
    "fetched_at": "2026-01-07T08:36:15.460218"
  },
  {
    "id": "2601.02511v1",
    "title": "LLM-Enhanced Reinforcement Learning for Time Series Anomaly Detection",
    "abstract": "Detecting anomalies in time series data is crucial for finance, healthcare, sensor networks, and industrial monitoring applications. However, time series anomaly detection often suffers from sparse labels, complex temporal patterns, and costly expert annotation. We propose a unified framework that integrates Large Language Model (LLM)-based potential functions for reward shaping with Reinforcement Learning (RL), Variational Autoencoder (VAE)-enhanced dynamic reward scaling, and active learning with label propagation. An LSTM-based RL agent leverages LLM-derived semantic rewards to guide exploration, while VAE reconstruction errors add unsupervised anomaly signals. Active learning selects the most uncertain samples, and label propagation efficiently expands labeled data. Evaluations on Yahoo-A1 and SMD benchmarks demonstrate that our method achieves state-of-the-art detection accuracy under limited labeling budgets and operates effectively in data-constrained settings. This study highlights the promise of combining LLMs with RL and advanced unsupervised techniques for robust, scalable anomaly detection in real-world applications.",
    "authors": [
      "Bahareh Golchin",
      "Banafsheh Rekabdar",
      "Danielle Justo"
    ],
    "published": "2026-01-05",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.02511v1",
    "arxiv_url": "https://arxiv.org/abs/2601.02511v1",
    "fetched_at": "2026-01-07T08:36:15.460239"
  },
  {
    "id": "2601.02440v1",
    "title": "Mitigating Long-Tailed Anomaly Score Distributions with Importance-Weighted Loss",
    "abstract": "Anomaly detection is crucial in industrial applications for identifying rare and unseen patterns to ensure system reliability. Traditional models, trained on a single class of normal data, struggle with real-world distributions where normal data exhibit diverse patterns, leading to class imbalance and long-tailed anomaly score distributions (LTD). This imbalance skews model training and degrades detection performance, especially for minority instances. To address this issue, we propose a novel importance-weighted loss designed specifically for anomaly detection. Compared to the previous method for LTD in classification, our method does not require prior knowledge of normal data classes. Instead, we introduce a weighted loss function that incorporates importance sampling to align the distribution of anomaly scores with a target Gaussian, ensuring a balanced representation of normal data. Extensive experiments on three benchmark image datasets and three real-world hyperspectral imaging datasets demonstrate the robustness of our approach in mitigating LTD-induced bias. Our method improves anomaly detection performance by 0.043, highlighting its effectiveness in real-world applications.",
    "authors": [
      "Jungi Lee",
      "Jungkwon Kim",
      "Chi Zhang",
      "Sangmin Kim",
      "Kwangsun Yoo",
      "Seok-Joo Byun"
    ],
    "published": "2026-01-05",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.02440v1",
    "arxiv_url": "https://arxiv.org/abs/2601.02440v1",
    "fetched_at": "2026-01-07T08:36:15.460313"
  },
  {
    "id": "2601.03217v1",
    "title": "MalruleLib: Large-Scale Executable Misconception Reasoning with Step Traces for Modeling Student Thinking in Mathematics",
    "abstract": "Student mistakes in mathematics are often systematic: a learner applies a coherent but wrong procedure and repeats it across contexts. We introduce MalruleLib, a learning-science-grounded framework that translates documented misconceptions into executable procedures, drawing on 67 learning-science and mathematics education sources, and generates step-by-step traces of malrule-consistent student work. We formalize a core student-modeling problem as Malrule Reasoning Accuracy (MRA): infer a misconception from one worked mistake and predict the student's next answer under cross-template rephrasing. Across nine language models (4B-120B), accuracy drops from 66% on direct problem solving to 40% on cross-template misconception prediction. MalruleLib encodes 101 malrules over 498 parameterized problem templates and produces paired dual-path traces for both correct reasoning and malrule-consistent student reasoning. Because malrules are executable and templates are parameterizable, MalruleLib can generate over one million instances, enabling scalable supervision and controlled evaluation. Using MalruleLib, we observe cross-template degradations of 10-21%, while providing student step traces improves prediction by 3-15%. We release MalruleLib as infrastructure for educational AI that models student procedures across contexts, enabling diagnosis and feedback that targets the underlying misconception.",
    "authors": [
      "Xinghe Chen",
      "Naiming Liu",
      "Shashank Sonkar"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.03217v1",
    "arxiv_url": "https://arxiv.org/abs/2601.03217v1",
    "fetched_at": "2026-01-07T08:36:45.402103"
  },
  {
    "id": "2601.03164v1",
    "title": "WebAnchor: Anchoring Agent Planning to Stabilize Long-Horizon Web Reasoning",
    "abstract": "Large Language Model(LLM)-based agents have shown strong capabilities in web information seeking, with reinforcement learning (RL) becoming a key optimization paradigm. However, planning remains a bottleneck, as existing methods struggle with long-horizon strategies. Our analysis reveals a critical phenomenon, plan anchor, where the first reasoning step disproportionately impacts downstream behavior in long-horizon web reasoning tasks. Current RL algorithms, fail to account for this by uniformly distributing rewards across the trajectory. To address this, we propose Anchor-GRPO, a two-stage RL framework that decouples planning and execution. In Stage 1, the agent optimizes its first-step planning using fine-grained rubrics derived from self-play experiences and human calibration. In Stage 2, execution is aligned with the initial plan through sparse rewards, ensuring stable and efficient tool usage. We evaluate Anchor-GRPO on four benchmarks: BrowseComp, BrowseComp-Zh, GAIA, and XBench-DeepSearch. Across models from 3B to 30B, Anchor-GRPO outperforms baseline GRPO and First-step GRPO, improving task success and tool efficiency. Notably, WebAnchor-30B achieves 46.0% pass@1 on BrowseComp and 76.4% on GAIA. Anchor-GRPO also demonstrates strong scalability, getting higher accuracy as model size and context length increase.",
    "authors": [
      "Yu Xinmiao",
      "Zhang Liwen",
      "Feng Xiaocheng",
      "Jiang Yong",
      "Qin Bing",
      "Xie Pengjun",
      "Zhou Jingren"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.03164v1",
    "arxiv_url": "https://arxiv.org/abs/2601.03164v1",
    "fetched_at": "2026-01-07T08:36:45.402153"
  },
  {
    "id": "2601.03132v1",
    "title": "Finite Memory Belief Approximation for Optimal Control in Partially Observable Markov Decision Processes",
    "abstract": "We study finite memory belief approximation for partially observable (PO) stochastic optimal control (SOC) problems. While belief states are sufficient for SOC in partially observable Markov decision processes (POMDPs), they are generally infinite-dimensional and impractical. We interpret truncated input-output (IO) histories as inducing a belief approximation and develop a metric-based theory that directly relates information loss to control performance. Using the Wasserstein metric, we derive policy-conditional performance bounds that quantify value degradation induced by finite memory along typical closed-loop trajectories. Our analysis proceeds via a fixed-policy comparison: we evaluate two cost functionals under the same closed-loop execution and isolate the effect of replacing the true belief by its finite memory approximation inside the belief-level cost. For linear quadratic Gaussian (LQG) systems, we provide closed-form belief mismatch evaluation and empirically validate the predicted mechanism, demonstrating that belief mismatch decays approximately exponentially with memory length and that the induced performance mismatch scales accordingly. Together, these results provide a metric-aware characterization of what finite memory belief approximation can and cannot achieve in PO settings.",
    "authors": [
      "Mintae Kim"
    ],
    "published": "2026-01-06",
    "categories": [
      "eess.SY",
      "cs.IT",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.03132v1",
    "arxiv_url": "https://arxiv.org/abs/2601.03132v1",
    "fetched_at": "2026-01-07T08:36:45.402173"
  },
  {
    "id": "2601.03127v1",
    "title": "Unified Thinker: A General Reasoning Modular Core for Image Generation",
    "abstract": "Despite impressive progress in high-fidelity image synthesis, generative models still struggle with logic-intensive instruction following, exposing a persistent reasoning--execution gap. Meanwhile, closed-source systems (e.g., Nano Banana) have demonstrated strong reasoning-driven image generation, highlighting a substantial gap to current open-source models. We argue that closing this gap requires not merely better visual generators, but executable reasoning: decomposing high-level intents into grounded, verifiable plans that directly steer the generative process. To this end, we propose Unified Thinker, a task-agnostic reasoning architecture for general image generation, designed as a unified planning core that can plug into diverse generators and workflows. Unified Thinker decouples a dedicated Thinker from the image Generator, enabling modular upgrades of reasoning without retraining the entire generative model. We further introduce a two-stage training paradigm: we first build a structured planning interface for the Thinker, then apply reinforcement learning to ground its policy in pixel-level feedback, encouraging plans that optimize visual correctness over textual plausibility. Extensive experiments on text-to-image generation and image editing show that Unified Thinker substantially improves image reasoning and generation quality.",
    "authors": [
      "Sashuai Zhou",
      "Qiang Zhou",
      "Jijin Hu",
      "Hanqing Yang",
      "Yue Cao",
      "Junpeng Ma",
      "Yinchao Ma",
      "Jun Song",
      "Tiezheng Ge",
      "Cheng Yu",
      "Bo Zheng",
      "Zhou Zhao"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.03127v1",
    "arxiv_url": "https://arxiv.org/abs/2601.03127v1",
    "fetched_at": "2026-01-07T08:36:45.402211"
  },
  {
    "id": "2601.03038v1",
    "title": "Validating Generalist Robots with Situation Calculus and STL Falsification",
    "abstract": "Generalist robots are becoming a reality, capable of interpreting natural language instructions and executing diverse operations. However, their validation remains challenging because each task induces its own operational context and correctness specification, exceeding the assumptions of traditional validation methods. We propose a two-layer validation framework that combines abstract reasoning with concrete system falsification. At the abstract layer, situation calculus models the world and derives weakest preconditions, enabling constraint-aware combinatorial testing to systematically generate diverse, semantically valid world-task configurations with controllable coverage strength. At the concrete layer, these configurations are instantiated for simulation-based falsification with STL monitoring. Experiments on tabletop manipulation tasks show that our framework effectively uncovers failure cases in the NVIDIA GR00T controller, demonstrating its promise for validating general-purpose robot autonomy.",
    "authors": [
      "Changwen Li",
      "Rongjie Yan",
      "Chih-Hong Cheng",
      "Jian Zhang"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.03038v1",
    "arxiv_url": "https://arxiv.org/abs/2601.03038v1",
    "fetched_at": "2026-01-07T08:36:45.402234"
  },
  {
    "id": "2601.02997v1",
    "title": "From Memorization to Creativity: LLM as a Designer of Novel Neural-Architectures",
    "abstract": "Large language models (LLMs) excel in program synthesis, yet their ability to autonomously navigate neural architecture design--balancing syntactic reliability, performance, and structural novelty--remains underexplored. We address this by placing a code-oriented LLM within a closed-loop synthesis framework, analyzing its evolution over 22 supervised fine-tuning cycles. The model synthesizes PyTorch convolutional networks which are validated, evaluated via low-fidelity performance signals (single-epoch accuracy), and filtered using a MinHash-Jaccard criterion to prevent structural redundancy. High-performing, novel architectures are converted into prompt-code pairs for iterative fine-tuning via parameter-efficient LoRA adaptation, initialized from the LEMUR dataset. Across cycles, the LLM internalizes empirical architectural priors, becoming a robust generator. The valid generation rate stabilizes at 50.6 percent (peaking at 74.5 percent), while mean first-epoch accuracy rises from 28.06 percent to 50.99 percent, and the fraction of candidates exceeding 40 percent accuracy grows from 2.04 percent to 96.81 percent. Analyses confirm the model moves beyond replicating existing motifs, synthesizing 455 high-performing architectures absent from the original corpus. By grounding code synthesis in execution feedback, this work provides a scalable blueprint for transforming stochastic generators into autonomous, performance-driven neural designers, establishing that LLMs can internalize empirical, non-textual rewards to transcend their training data.",
    "authors": [
      "Waleed Khalid",
      "Dmitry Ignatov",
      "Radu Timofte"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.02997v1",
    "arxiv_url": "https://arxiv.org/abs/2601.02997v1",
    "fetched_at": "2026-01-07T08:36:45.402256"
  },
  {
    "id": "2601.02778v1",
    "title": "Closing the Reality Gap: Zero-Shot Sim-to-Real Deployment for Dexterous Force-Based Grasping and Manipulation",
    "abstract": "Human-like dexterous hands with multiple fingers offer human-level manipulation capabilities, but training control policies that can directly deploy on real hardware remains difficult due to contact-rich physics and imperfect actuation. We close this gap with a practical sim-to-real reinforcement learning (RL) framework that utilizes dense tactile feedback combined with joint torque sensing to explicitly regulate physical interactions. To enable effective sim-to-real transfer, we introduce (i) a computationally fast tactile simulation that computes distances between dense virtual tactile units and the object via parallel forward kinematics, providing high-rate, high-resolution touch signals needed by RL; (ii) a current-to-torque calibration that eliminates the need for torque sensors on dexterous hands by mapping motor current to joint torque; and (iii) actuator dynamics modeling to bridge the actuation gaps with randomization of non-ideal effects such as backlash, torque-speed saturation. Using an asymmetric actor-critic PPO pipeline trained entirely in simulation, our policies deploy directly to a five-finger hand. The resulting policies demonstrated two essential skills: (1) command-based, controllable grasp force tracking, and (2) reorientation of objects in the hand, both of which were robustly executed without fine-tuning on the robot. By combining tactile and torque in the observation space with effective sensing/actuation modeling, our system provides a practical solution to achieve reliable dexterous manipulation. To our knowledge, this is the first demonstration of controllable grasping on a multi-finger dexterous hand trained entirely in simulation and transferred zero-shot on real hardware.",
    "authors": [
      "Haoyu Dong",
      "Zhengmao He",
      "Yang Li",
      "Zhibin Li",
      "Xinyu Yi",
      "Zhe Zhao"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.02778v1",
    "arxiv_url": "https://arxiv.org/abs/2601.02778v1",
    "fetched_at": "2026-01-07T08:36:45.402282"
  },
  {
    "id": "2601.02752v1",
    "title": "EComStage: Stage-wise and Orientation-specific Benchmarking for Large Language Models in E-commerce",
    "abstract": "Large Language Model (LLM)-based agents are increasingly deployed in e-commerce applications to assist customer services in tasks such as product inquiries, recommendations, and order management. Existing benchmarks primarily evaluate whether these agents successfully complete the final task, overlooking the intermediate reasoning stages that are crucial for effective decision-making. To address this gap, we propose EComStage, a unified benchmark for evaluating agent-capable LLMs across the comprehensive stage-wise reasoning process: Perception (understanding user intent), Planning (formulating an action plan), and Action (executing the decision). EComStage evaluates LLMs through seven separate representative tasks spanning diverse e-commerce scenarios, with all samples human-annotated and quality-checked. Unlike prior benchmarks that focus only on customer-oriented interactions, EComStage also evaluates merchant-oriented scenarios, including promotion management, content review, and operational support relevant to real-world applications. We evaluate a wide range of over 30 LLMs, spanning from 1B to over 200B parameters, including open-source models and closed-source APIs, revealing stage/orientation-specific strengths and weaknesses. Our results provide fine-grained, actionable insights for designing and optimizing LLM-based agents in real-world e-commerce settings.",
    "authors": [
      "Kaiyan Zhao",
      "Zijie Meng",
      "Zheyong Xie",
      "Jin Duan",
      "Yao Hu",
      "Zuozhu Liu",
      "Shaosheng Cao"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.02752v1",
    "arxiv_url": "https://arxiv.org/abs/2601.02752v1",
    "fetched_at": "2026-01-07T08:36:45.402312"
  },
  {
    "id": "2601.02749v1",
    "title": "The Path Ahead for Agentic AI: Challenges and Opportunities",
    "abstract": "The evolution of Large Language Models (LLMs) from passive text generators to autonomous, goal-driven systems represents a fundamental shift in artificial intelligence. This chapter examines the emergence of agentic AI systems that integrate planning, memory, tool use, and iterative reasoning to operate autonomously in complex environments. We trace the architectural progression from statistical models to transformer-based systems, identifying capabilities that enable agentic behavior: long-range reasoning, contextual awareness, and adaptive decision-making. The chapter provides three contributions: (1) a synthesis of how LLM capabilities extend toward agency through reasoning-action-reflection loops; (2) an integrative framework describing core components perception, memory, planning, and tool execution that bridge LLMs with autonomous behavior; (3) a critical assessment of applications and persistent challenges in safety, alignment, reliability, and sustainability. Unlike existing surveys, we focus on the architectural transition from language understanding to autonomous action, emphasizing the technical gaps that must be resolved before deployment. We identify critical research priorities, including verifiable planning, scalable multi-agent coordination, persistent memory architectures, and governance frameworks. Responsible advancement requires simultaneous progress in technical robustness, interpretability, and ethical safeguards to realize potential while mitigating risks of misalignment and unintended consequences.",
    "authors": [
      "Nadia Sibai",
      "Yara Ahmed",
      "Serry Sibaee",
      "Sawsan AlHalawani",
      "Adel Ammar",
      "Wadii Boulila"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.02749v1",
    "arxiv_url": "https://arxiv.org/abs/2601.02749v1",
    "fetched_at": "2026-01-07T08:36:45.402338"
  },
  {
    "id": "2601.02720v1",
    "title": "Privacy-Preserving AI-Enabled Decentralized Learning and Employment Records System",
    "abstract": "Learning and Employment Record (LER) systems are emerging as critical infrastructure for securely compiling and sharing educational and work achievements. Existing blockchain-based platforms leverage verifiable credentials but typically lack automated skill-credential generation and the ability to incorporate unstructured evidence of learning. In this paper,a privacy-preserving, AI-enabled decentralized LER system is proposed to address these gaps. Digitally signed transcripts from educational institutions are accepted, and verifiable self-issued skill credentials are derived inside a trusted execution environment (TEE) by a natural language processing pipeline that analyzes formal records (e.g., transcripts, syllabi) and informal artifacts. All verification and job-skill matching are performed inside the enclave with selective disclosure, so raw credentials and private keys remain enclave-confined. Job matching relies solely on attested skill vectors and is invariant to non-skill resume fields, thereby reducing opportunities for screening bias.The NLP component was evaluated on sample learner data; the mapping follows the validated Syllabus-to-O*NET methodology,and a stability test across repeated runs observed <5% variance in top-ranked skills. Formal security statements and proof sketches are provided showing that derived credentials are unforgeable and that sensitive information remains confidential. The proposed system thus supports secure education and employment credentialing, robust transcript verification,and automated, privacy-preserving skill extraction within a decentralized framework.",
    "authors": [
      "Yuqiao Xu",
      "Mina Namazi",
      "Sahith Reddy Jalapally",
      "Osama Zafar",
      "Youngjin Yoo",
      "Erman Ayday"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.02720v1",
    "arxiv_url": "https://arxiv.org/abs/2601.02720v1",
    "fetched_at": "2026-01-07T08:36:45.402366"
  },
  {
    "id": "2601.02695v1",
    "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems",
    "abstract": "Complex agentic AI systems, powered by a coordinated ensemble of Large Language Models (LLMs), tool and memory modules, have demonstrated remarkable capabilities on intricate, multi-turn tasks. However, this success is shadowed by prohibitive economic costs and severe latency, exposing a critical, yet underexplored, trade-off. We formalize this challenge as the \\textbf{Agent System Trilemma}: the inherent tension among achieving state-of-the-art performance, minimizing monetary cost, and ensuring rapid task completion. To dismantle this trilemma, we introduce EvoRoute, a self-evolving model routing paradigm that transcends static, pre-defined model assignments. Leveraging an ever-expanding knowledge base of prior experience, EvoRoute dynamically selects Pareto-optimal LLM backbones at each step, balancing accuracy, efficiency, and resource use, while continually refining its own selection policy through environment feedback. Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\\%$ and latency by over $70\\%$.",
    "authors": [
      "Guibin Zhang",
      "Haiyang Yu",
      "Kaiming Yang",
      "Bingli Wu",
      "Fei Huang",
      "Yongbin Li",
      "Shuicheng Yan"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.CL",
      "cs.MA"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.02695v1",
    "arxiv_url": "https://arxiv.org/abs/2601.02695v1",
    "fetched_at": "2026-01-07T08:36:45.402394"
  },
  {
    "id": "2601.02663v1",
    "title": "When Do Tools and Planning Help LLMs Think? A Cost- and Latency-Aware Benchmark",
    "abstract": "Modern large language models (LLMs) increasingly rely on inference-time planning and external tools to improve reasoning. We benchmark this behavior on two real-world settings: event-centric question answering over graph-structured knowledge (Event-QA) and persuasive response generation in Reddit ChangeMyView (CMV). Using LangChain and LangGraph, we compare a one-shot baseline against a plan-execute-replan agent equipped with task-specific tools (DBpedia SPARQL/lookup/schema exploration, Wikipedia-focused retrieval, and topical web search). We evaluate on 60 examples each from Event-QA and CMV (3 splits of 20), and report both mean end-to-end latency and per-example token cost estimates. We evaluate GPT-4o and GPT-4o-mini under identical workflows and report accuracy and end-to-end latency. On Event-QA, the best tool-augmented configuration improves accuracy (e.g., 47.5\\% $\\rightarrow$ 67.5\\% for GPT-4o) while increasing latency by orders of magnitude ($\\sim$8s $\\rightarrow$ $\\sim$317s per example). On CMV, one-shot prompting is strongest (e.g., GPT-4o-mini achieves 75\\% at $\\sim$6s), and planning+search increases latency substantially without consistent gains. However, complex multi-tool orchestration exposes failure modes where the smaller model degrades. Overall, the findings highlight the need for task-specific, cost-aware choices of both model size and agent/tooling complexity.",
    "authors": [
      "Subha Ghoshal",
      "Ali Al-Bustami"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.02663v1",
    "arxiv_url": "https://arxiv.org/abs/2601.02663v1",
    "fetched_at": "2026-01-07T08:36:45.402413"
  },
  {
    "id": "2601.02632v1",
    "title": "TAAF: A Trace Abstraction and Analysis Framework Synergizing Knowledge Graphs and LLMs",
    "abstract": "Execution traces are a critical source of information for understanding, debugging, and optimizing complex software systems. However, traces from OS kernels or large-scale applications like Chrome or MySQL are massive and difficult to analyze. Existing tools rely on predefined analyses, and custom insights often require writing domain-specific scripts, which is an error-prone and time-consuming task. This paper introduces TAAF (Trace Abstraction and Analysis Framework), a novel approach that combines time-indexing, knowledge graphs (KGs), and large language models (LLMs) to transform raw trace data into actionable insights. TAAF constructs a time-indexed KG from trace events to capture relationships among entities such as threads, CPUs, and system resources. An LLM then interprets query-specific subgraphs to answer natural-language questions, reducing the need for manual inspection and deep system expertise. To evaluate TAAF, we introduce TraceQA-100, a benchmark of 100 questions grounded in real kernel traces. Experiments across three LLMs and multiple temporal settings show that TAAF improves answer accuracy by up to 31.2%, particularly in multi-hop and causal reasoning tasks. We further analyze where graph-grounded reasoning helps and where limitations remain, offering a foundation for next-generation trace analysis tools.",
    "authors": [
      "Alireza Ezaz",
      "Ghazal Khodabandeh",
      "Majid Babaei",
      "Naser Ezzati-Jivan"
    ],
    "published": "2026-01-06",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.02632v1",
    "arxiv_url": "https://arxiv.org/abs/2601.02632v1",
    "fetched_at": "2026-01-07T08:36:45.402435"
  },
  {
    "id": "2601.02598v1",
    "title": "LongDA: Benchmarking LLM Agents for Long-Document Data Analysis",
    "abstract": "We introduce LongDA, a data analysis benchmark for evaluating LLM-based agents under documentation-intensive analytical workflows. In contrast to existing benchmarks that assume well-specified schemas and inputs, LongDA targets real-world settings in which navigating long documentation and complex data is the primary bottleneck. To this end, we manually curate raw data files, long and heterogeneous documentation, and expert-written publications from 17 publicly available U.S. national surveys, from which we extract 505 analytical queries grounded in real analytical practice. Solving these queries requires agents to first retrieve and integrate key information from multiple unstructured documents, before performing multi-step computations and writing executable code, which remains challenging for existing data analysis agents. To support the systematic evaluation under this setting, we develop LongTA, a tool-augmented agent framework that enables document access, retrieval, and code execution, and evaluate a range of proprietary and open-source models. Our experiments reveal substantial performance gaps even among state-of-the-art models, highlighting the challenges researchers should consider before applying LLM agents for decision support in real-world, high-stakes analytical settings.",
    "authors": [
      "Yiyang Li",
      "Zheyuan Zhang",
      "Tianyi Ma",
      "Zehong Wang",
      "Keerthiram Murugesan",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "published": "2026-01-05",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.02598v1",
    "arxiv_url": "https://arxiv.org/abs/2601.02598v1",
    "fetched_at": "2026-01-07T08:36:45.402462"
  },
  {
    "id": "2601.02578v1",
    "title": "DataParasite Enables Scalable and Repurposable Online Data Curation",
    "abstract": "Many questions in computational social science rely on datasets assembled from heterogeneous online sources, a process that is often labor-intensive, costly, and difficult to reproduce. Recent advances in large language models enable agentic search and structured extraction from the web, but existing systems are frequently opaque, inflexible, or poorly suited to scientific data curation. Here we introduce DataParasite, an open-source, modular pipeline for scalable online data collection. DataParasite decomposes tabular curation tasks into independent, entity-level searches defined through lightweight configuration files and executed through a shared, task-agnostic python script. Crucially, the same pipeline can be repurposed to new tasks, including those without predefined entity lists, using only natural-language instructions. We evaluate the pipeline on multiple canonical tasks in computational social science, including faculty hiring histories, elite death events, and political career trajectories. Across tasks, DataParasite achieves high accuracy while reducing data-collection costs by an order of magnitude relative to manual curation. By lowering the technical and labor barriers to online data assembly, DataParasite provides a practical foundation for scalable, transparent, and reusable data curation in computational social science and beyond.",
    "authors": [
      "Mengyi Sun"
    ],
    "published": "2026-01-05",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.02578v1",
    "arxiv_url": "https://arxiv.org/abs/2601.02578v1",
    "fetched_at": "2026-01-07T08:36:45.402479"
  }
]