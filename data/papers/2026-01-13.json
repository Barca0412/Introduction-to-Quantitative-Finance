[
  {
    "id": "2601.07792v1",
    "title": "Non-Convex Portfolio Optimization via Energy-Based Models: A Comparative Analysis Using the Thermodynamic HypergRaphical Model Library (THRML) for Index Tracking",
    "abstract": "Portfolio optimization under cardinality constraints transforms the classical Markowitz mean-variance problem from a convex quadratic problem into an NP-hard combinatorial optimization problem. This paper introduces a novel approach using THRML (Thermodynamic HypergRaphical Model Library), a JAX-based library for building and sampling probabilistic graphical models that reformulates index tracking as probabilistic inference on an Ising Hamiltonian. Unlike traditional methods that seek a single optimal solution, THRML samples from the Boltzmann distribution of high-quality portfolios using GPU-accelerated block Gibbs sampling, providing natural regularization against overfitting.   We implement three key innovations: (1) dynamic coupling strength that scales inversely with market volatility (VIX), adapting diversification pressure to market regimes; (2) rebalanced bias weights prioritizing tracking quality over momentum for index replication; and (3) sector-aware post-processing ensuring institutional-grade diversification. Backtesting on a 100-stock S and P 500 universe from 2023 to 2025 demonstrates that THRML achieves 4.31 percent annualized tracking error versus 5.66 to 6.30 percent for baselines, while simultaneously generating 128.63 percent total return against the index total return of 79.61 percent. The Diebold-Mariano test confirms statistical significance with p less than 0.0001 across all comparisons. These results position energy-based models as a promising paradigm for portfolio construction, bridging statistical mechanics and quantitative finance.",
    "authors": [
      "Javier Mancilla",
      "Theodoros D. Bouloumis",
      "Frederic Goguikian"
    ],
    "published": "2026-01-12",
    "categories": [
      "q-fin.CP",
      "q-fin.PM",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07792v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07792v1",
    "fetched_at": "2026-01-13T08:35:57.347491"
  },
  {
    "id": "2601.07687v1",
    "title": "Physics-Informed Singular-Value Learning for Cross-Covariances Forecasting in Financial Markets",
    "abstract": "A new wave of work on covariance cleaning and nonlinear shrinkage has delivered asymptotically optimal analytical solutions for large covariance matrices. Building on this progress, these ideas have been generalized to empirical cross-covariance matrices, whose singular-value shrinkage characterizes comovements between one set of assets and another. Existing analytical cross-covariance cleaners are derived under strong stationarity and large-sample assumptions, and they typically rely on mesoscopic regularity conditions such as bounded spectra; macroscopic common modes (e.g., a global market factor) violate these conditions. When applied to real equity returns, where dependence structures drift over time and global modes are prominent, we find that these theoretically optimal formulas do not translate into robust out-of-sample performance. We address this gap by designing a random-matrix-inspired neural architecture that operates in the empirical singular-vector basis and learns a nonlinear mapping from empirical singular values to their corresponding cleaned values. By construction, the network can recover the analytical solution as a special case, yet it remains flexible enough to adapt to non-stationary dynamics and mode-driven distortions. Trained on a long history of equity returns, the proposed method achieves a more favorable bias-variance trade-off than purely analytical cleaners and delivers systematically lower out-of-sample cross-covariance prediction errors. Our results demonstrate that combining random-matrix theory with machine learning makes asymptotic theories practically effective in realistic time-varying markets.",
    "authors": [
      "Efstratios Manolakis",
      "Christian Bongiorno",
      "Rosario Nunzio Mantegna"
    ],
    "published": "2026-01-12",
    "categories": [
      "q-fin.ST",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07687v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07687v1",
    "fetched_at": "2026-01-13T08:35:57.347527"
  },
  {
    "id": "2601.07675v1",
    "title": "Tab-TRM: Tiny Recursive Model for Insurance Pricing on Tabular Data",
    "abstract": "We introduce Tab-TRM (Tabular-Tiny Recursive Model), a network architecture that adapts the recursive latent reasoning paradigm of Tiny Recursive Models (TRMs) to insurance modeling. Drawing inspiration from both the Hierarchical Reasoning Model (HRM) and its simplified successor TRM, the Tab-TRM model makes predictions by reasoning over the input features. It maintains two learnable latent tokens - an answer token and a reasoning state - that are iteratively refined by a compact, parameter-efficient recursive network. The recursive processing layer repeatedly updates the reasoning state given the full token sequence and then refines the answer token, in close analogy with iterative insurance pricing schemes. Conceptually, Tab-TRM bridges classical actuarial workflows - iterative generalized linear model fitting and minimum-bias calibration - on the one hand, and modern machine learning, in terms of Gradient Boosting Machines, on the other.",
    "authors": [
      "Kishan Padayachy",
      "Ronald Richman",
      "Mario V. Wüthrich"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.LG",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07675v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07675v1",
    "fetched_at": "2026-01-13T08:35:57.347550"
  },
  {
    "id": "2601.07664v1",
    "title": "Crypto Pricing with Hidden Factors",
    "abstract": "We estimate risk premia in the cross-section of cryptocurrency returns using the Giglio-Xiu (2021) three-pass approach, allowing for omitted latent factors alongside observed stock-market and crypto-market factors. Using weekly data on a broad universe of large cryptocurrencies, we find that crypto expected returns load on both crypto-specific factors and selected equity-industry factors associated with technology and profitability, consistent with increased integration between crypto and traditional markets. In addition, we study non-tradable state variables capturing investor sentiment (Fear and Greed), speculative rotation (Altcoin Season Index), and security shocks (hacked value scaled by market capitalization), which are new to the literature. Relative to conventional Fama-MacBeth estimates, the latent-factor approach yields materially different premia for key factors, highlighting the importance of controlling for unobserved risks in crypto asset pricing.",
    "authors": [
      "Matthew Brigida"
    ],
    "published": "2026-01-12",
    "categories": [
      "q-fin.PR",
      "econ.EM",
      "q-fin.GN"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07664v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07664v1",
    "fetched_at": "2026-01-13T08:35:57.347568"
  },
  {
    "id": "2601.07637v1",
    "title": "Reinforcement Learning for Micro-Level Claims Reserving",
    "abstract": "Outstanding claim liabilities are revised repeatedly as claims develop, yet most modern reserving models are trained as one-shot predictors and typically learn only from settled claims. We formulate individual claims reserving as a claim-level Markov decision process in which an agent sequentially updates outstanding claim liability (OCL) estimates over development, using continuous actions and a reward design that balances accuracy with stable reserve revisions. A key advantage of this reinforcement learning (RL) approach is that it can learn from all observed claim trajectories, including claims that remain open at valuation, thereby avoiding the reduced sample size and selection effects inherent in supervised methods trained on ultimate outcomes only. We also introduce practical components needed for actuarial use -- initialisation of new claims, temporally consistent tuning via a rolling-settlement scheme, and an importance-weighting mechanism to mitigate portfolio-level underestimation driven by the rarity of large claims. On CAS and SPLICE synthetic general insurance datasets, the proposed Soft Actor-Critic implementation delivers competitive claim-level accuracy and strong aggregate OCL performance, particularly for the immature claim segments that drive most of the liability.",
    "authors": [
      "Benjamin Avanzi",
      "Ronald Richman",
      "Bernard Wong",
      "Mario Wüthrich",
      "Yagebu Xie"
    ],
    "published": "2026-01-12",
    "categories": [
      "q-fin.RM",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07637v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07637v1",
    "fetched_at": "2026-01-13T08:35:57.347591"
  },
  {
    "id": "2601.07626v1",
    "title": "Universal basic income in a financial equilibrium",
    "abstract": "Universal basic income (UBI) is a tax scheme that uniformly redistributes aggregate income amongst the entire population of an economy. We prove the existence of an equilibrium in a model that implements universal basic income. The economic agents choose the proportion of their time to work and earn wages that can be used towards consumption and investment in a financial market with a traded stock and annuity. A proportion of the earned wages is uniformly distributed amongst all agents, leading to interconnectedness of the agents' decision problems, which are already dependent on one another through the financial market. The decision problems are further entangled by Nash perceptions of labor; the agents respond to the labor choices of others and act upon their perceived income in their decision problems. The equilibrium is constructed and proven to exist using a backward stochastic differential equation (BSDE) approach for a BSDE system with a quadratic structure that decouples. We analyze the effects of a universal basic income policy on labor market participation, the stock market, and welfare. While universal basic income policies affect labor market participation and welfare monotonically, its effects on the stock market are nontrivial and nonmonotone.",
    "authors": [
      "Kim Weston"
    ],
    "published": "2026-01-12",
    "categories": [
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07626v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07626v1",
    "fetched_at": "2026-01-13T08:35:57.347609"
  },
  {
    "id": "2601.07588v1",
    "title": "Temporal-Aligned Meta-Learning for Risk Management: A Stacking Approach for Multi-Source Credit Scoring",
    "abstract": "This paper presents a meta-learning framework for credit risk assessment of Italian Small and Medium Enterprises (SMEs) that explicitly addresses the temporal misalignment of credit scoring models.   The approach aligns financial statement reference dates with evaluation dates, mitigating bias arising from publication delays and asynchronous data sources. It is based on a two-step temporal decomposition that at first estimates annual probabilities of default (PDs) anchored to balance-sheet reference dates (December 31st) through a static model. Then it models the monthly evolution of PDs using higher-frequency behavioral data. Finally, we employ stacking-based architecture to aggregate multiple scoring systems, each capturing complementary aspects of default risk, into a unified predictive model. In this way, first level model outputs are treated as learned representations that encode non-linear relationships in financial and behavioral indicators, allowing integration of new expert-based features without retraining base models. This design provides a coherent and interpretable solution to challenges typical of low-default environments, including heterogeneous default definitions and reporting delays. Empirical validation shows that the framework effectively captures credit risk evolution over time, improving temporal consistency and predictive stability relative to standard ensemble methods.",
    "authors": [
      "O. Didkovskyi",
      "A. Vidali",
      "N. Jean",
      "G. Le Pera"
    ],
    "published": "2026-01-12",
    "categories": [
      "q-fin.RM",
      "cs.LG",
      "q-fin.ST"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07588v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07588v1",
    "fetched_at": "2026-01-13T08:35:57.347632"
  },
  {
    "id": "2601.07131v1",
    "title": "The Limits of Complexity: Why Feature Engineering Beats Deep Learning in Investor Flow Prediction",
    "abstract": "The application of machine learning to financial prediction has accelerated dramatically, yet the conditions under which complex models outperform simple alternatives remain poorly understood. This paper investigates whether advanced signal processing and deep learning techniques can extract predictive value from investor order flows beyond what simple feature engineering achieves. Using a comprehensive dataset of 2.79 million observations spanning 2,439 Korean equities from 2020--2024, we apply three methodologies: \\textit{Independent Component Analysis} (ICA) to recover latent market drivers, \\textit{Wavelet Coherence} analysis to characterize multi-scale correlation structure, and \\textit{Long Short-Term Memory} (LSTM) networks with attention mechanisms for non-linear prediction. Our results reveal a striking finding: a parsimonious linear model using market capitalization-normalized flows (``Matched Filter'' preprocessing) achieves a Sharpe ratio of 1.30 and cumulative return of 272.6\\%, while the full ICA-Wavelet-LSTM pipeline generates a Sharpe ratio of only 0.07 with a cumulative return of $-5.1\\%$. The raw LSTM model collapsed to predicting the unconditional mean, achieving a hit rate of 47.5\\% -- worse than random. We conclude that in low signal-to-noise financial environments, domain-specific feature engineering yields substantially higher marginal returns than algorithmic complexity. These findings establish important boundary conditions for the application of deep learning to financial prediction.",
    "authors": [
      "Sungwoo Kang"
    ],
    "published": "2026-01-12",
    "categories": [
      "q-fin.CP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07131v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07131v1",
    "fetched_at": "2026-01-13T08:35:57.347648"
  },
  {
    "id": "2601.06507v1",
    "title": "Emissions-Robust Portfolios",
    "abstract": "We study portfolio choice when firm-level emissions intensities are measured with error. We introduce a scope-specific penalty operator that rescales asset payoffs as a smooth function of revenue-normalized emissions intensity. Under payoff homogeneity, unit-scale invariance, mixture linearity, and a curvature semigroup axiom, the operator is unique and has the closed form $P^{(m)}_j(r,λ)=\\bigl(1-λ/λ_{\\max,j}\\bigr)^m r$. Combining this operator with norm- and moment-constrained ambiguity sets yields robust mean--variance and CVaR programs with exact linear and second-order cone reformulations and economically interpretable dual variables. In a U.S. large-cap equity universe with monthly rebalancing and uniform transaction costs, the resulting strategy reduces average Scope~1 emissions intensity by roughly 92\\% relative to equal weight while exhibiting no statistically detectable reduction in the Sharpe ratio under block-bootstrap inference and no statistically detectable change in average returns under HAC inference. We report the return--emissions Pareto frontier, sensitivity to robustness and turnover constraints, and uncertainty propagation from multiple imputation of emissions disclosures.",
    "authors": [
      "Khizar Qureshi",
      "H. Oliver Gao"
    ],
    "published": "2026-01-10",
    "categories": [
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.06507v1",
    "arxiv_url": "https://arxiv.org/abs/2601.06507v1",
    "fetched_at": "2026-01-13T08:35:57.347667"
  },
  {
    "id": "2601.06499v1",
    "title": "Cross-Market Alpha: Testing Short-Term Trading Factors in the U.S. Market via Double-Selection LASSO",
    "abstract": "Current asset pricing research exhibits a significant gap: a lack of sufficient cross-market validation regarding short-term trading-based factors. Against this backdrop, the development of the Chinese A-share market which is characterized by its retail-investor dominance, policy sensitivity, and high-frequency active trading -- has given rise to specific short-term trading-based factors. This study systematically examines the universality of factors from the Alpha191 library in the U.S. market, addressing the challenge of high-dimensional factor screening through the double-selection LASSO algorithm an established method for cross-market, high-dimensional research. After controlling for 151 fundamental factors from the U.S. equity factor zoo, 17 Alpha191 factors selected by this procedure exhibit significant incremental explanatory power for the cross-section of U.S. stock returns at the 5% level. Together these findings demonstrate that short-term trading-based factors, originating from the unique structure of the Chinese A-share market, provide incremental information not captured by existing mainstream pricing models, thereby enhancing the explanation of cross-sectional return differences.",
    "authors": [
      "Jin Du",
      "Alexander Walter",
      "Maxim Ulrich"
    ],
    "published": "2026-01-10",
    "categories": [
      "q-fin.ST"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.06499v1",
    "arxiv_url": "https://arxiv.org/abs/2601.06499v1",
    "fetched_at": "2026-01-13T08:35:57.347686"
  },
  {
    "id": "2601.06271v1",
    "title": "A Three--Dimensional Efficient Surface for Portfolio Optimization",
    "abstract": "The classical mean-variance framework characterizes portfolio risk solely through return variance and the covariance matrix, implicitly assuming that all relevant sources of risk are captured by second moments. In modern financial markets, however, shocks often propagate through complex networks of interconnections, giving rise to systemic and spillover risks that variance alone does not reflect.   This paper develops a unified portfolio optimization framework that incorporates connectedness risk alongside expected return and variance. Using a quadratic measure of network spillovers derived from a connectedness matrix, we formulate a three-objective optimization problem and characterize the resulting three-dimensional efficient surface. We establish existence, uniqueness, and continuity of optimal portfolios under mild regularity conditions and derive closed-form solutions when short-selling is allowed. The trade-off between variance and connectedness is shown to be strictly monotone except in degenerate cases, yielding a well-defined risk-risk frontier.   Under simultaneous diagonalizability of the covariance and connectedness matrices, we prove a three-fund separation theorem: all efficient portfolios can be expressed as affine combinations of a minimum-variance portfolio, a minimum-connectedness portfolio, and the tangency portfolio. The framework clarifies how network-based risk alters classical diversification results and provides a transparent theoretical foundation for incorporating systemic connectedness into portfolio choice.",
    "authors": [
      "Yimeng Qiu"
    ],
    "published": "2026-01-09",
    "categories": [
      "q-fin.PM",
      "q-fin.MF",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.06271v1",
    "arxiv_url": "https://arxiv.org/abs/2601.06271v1",
    "fetched_at": "2026-01-13T08:35:57.347704"
  },
  {
    "id": "2601.04896v2",
    "title": "Deep Reinforcement Learning for Optimum Order Execution: Mitigating Risk and Maximizing Returns",
    "abstract": "Optimal Order Execution is a well-established problem in finance that pertains to the flawless execution of a trade (buy or sell) for a given volume within a specified time frame. This problem revolves around optimizing returns while minimizing risk, yet recent research predominantly focuses on addressing one aspect of this challenge. In this paper, we introduce an innovative approach to Optimal Order Execution within the US market, leveraging Deep Reinforcement Learning (DRL) to effectively address this optimization problem holistically. Our study assesses the performance of our model in comparison to two widely employed execution strategies: Volume Weighted Average Price (VWAP) and Time Weighted Average Price (TWAP). Our experimental findings clearly demonstrate that our DRL-based approach outperforms both VWAP and TWAP in terms of return on investment and risk management. The model's ability to adapt dynamically to market conditions, even during periods of market stress, underscores its promise as a robust solution.",
    "authors": [
      "Khabbab Zakaria",
      "Jayapaulraj Jerinsh",
      "Andreas Maier",
      "Patrick Krauss",
      "Stefano Pasquali",
      "Dhagash Mehta"
    ],
    "published": "2026-01-08",
    "categories": [
      "q-fin.CP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.04896v2",
    "arxiv_url": "https://arxiv.org/abs/2601.04896v2",
    "fetched_at": "2026-01-13T08:35:57.347889"
  },
  {
    "id": "2601.04062v3",
    "title": "Smart Predict--then--Optimize Paradigm for Portfolio Optimization in Real Markets",
    "abstract": "Improvements in return forecast accuracy do not always lead to proportional improvements in portfolio decision quality, especially under realistic trading frictions and constraints. This paper adopts the Smart Predict--then--Optimize (SPO) paradigm for portfolio optimization in real markets, which explicitly aligns the learning objective with downstream portfolio decision quality rather than pointwise prediction accuracy. Within this paradigm, predictive models are trained using an SPO-based surrogate loss that directly reflects the performance of the resulting investment decisions. To preserve interpretability and robustness, we employ linear predictors built on return-based and technical-indicator features and integrate them with portfolio optimization models that incorporate transaction costs, turnover control, and regularization. We evaluate the proposed approach on U.S. ETF data (2015--2025) using a rolling-window backtest with monthly rebalancing. Empirical results show that decision-focused training consistently improves risk-adjusted performance over predict--then--optimize baselines and classical optimization benchmarks, and yields strong robustness during adverse market regimes (e.g., the 2020 COVID-19). These findings highlight the practical value of the Smart Predict--then--Optimize paradigm for portfolio optimization in realistic and non-stationary financial environments.",
    "authors": [
      "Wang Yi",
      "Takashi Hasuike"
    ],
    "published": "2026-01-07",
    "categories": [
      "q-fin.PM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.04062v3",
    "arxiv_url": "https://arxiv.org/abs/2601.04062v3",
    "fetched_at": "2026-01-13T08:35:57.348040"
  },
  {
    "id": "2601.06672v1",
    "title": "Will it Merge? On The Causes of Model Mergeability",
    "abstract": "Model merging has emerged as a promising technique for combining multiple fine-tuned models into a single multitask model without retraining. However, the factors that determine whether merging will succeed or fail remain poorly understood. In this work, we investigate why specific models are merged better than others. To do so, we propose a concrete, measurable definition of mergeability. We investigate several potential causes for high or low mergeability, highlighting the base model knowledge as a dominant factor: Models fine-tuned on instances that the base model knows better are more mergeable than models fine-tuned on instances that the base model struggles with. Based on our mergeability definition, we explore a simple weighted merging technique that better preserves weak knowledge in the base model.",
    "authors": [
      "Adir Rahamim",
      "Asaf Yehudai",
      "Boaz Carmeli",
      "Leshem Choshen",
      "Yosi Mass",
      "Yonatan Belinkov"
    ],
    "published": "2026-01-10",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.06672v1",
    "arxiv_url": "https://arxiv.org/abs/2601.06672v1",
    "fetched_at": "2026-01-13T08:36:03.496000"
  },
  {
    "id": "2601.07548v1",
    "title": "Contextual Discrepancy-Aware Contrastive Learning for Robust Medical Time Series Diagnosis in Small-Sample Scenarios",
    "abstract": "Medical time series data, such as EEG and ECG, are vital for diagnosing neurological and cardiovascular diseases. However, their precise interpretation faces significant challenges due to high annotation costs, leading to data scarcity, and the limitations of traditional contrastive learning in capturing complex temporal patterns. To address these issues, we propose CoDAC (Contextual Discrepancy-Aware Contrastive learning), a novel framework that enhances diagnostic accuracy and generalization, particularly in small-sample settings. CoDAC leverages external healthy data and introduces a Contextual Discrepancy Estimator (CDE), built upon a Transformer-based Autoencoder, to precisely quantify abnormal signals through context-aware anomaly scores. These scores dynamically inform a Dynamic Multi-views Contrastive Framework (DMCF), which adaptively weights different temporal views to focus contrastive learning on diagnostically relevant, discrepant regions. Our encoder combines dilated convolutions with multi-head attention for robust feature extraction. Comprehensive experiments on Alzheimer's Disease EEG, Parkinson's Disease EEG, and Myocardial Infarction ECG datasets demonstrate CoDAC's superior performance across all metrics, consistently outperforming state-of-the-art baselines, especially under low label availability. Ablation studies further validate the critical contributions of CDE and DMCF. CoDAC offers a robust and interpretable solution for medical time series diagnosis, effectively mitigating data scarcity challenges.",
    "authors": [
      "Kaito Tanaka",
      "Aya Nakayama",
      "Masato Ito",
      "Yuji Nishimura",
      "Keisuke Matsuda"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07548v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07548v1",
    "fetched_at": "2026-01-13T08:36:09.629733"
  },
  {
    "id": "2601.06940v1",
    "title": "VISTA: Knowledge-Driven Interpretable Vessel Trajectory Imputation via Large Language Models",
    "abstract": "The Automatic Identification System provides critical information for maritime navigation and safety, yet its trajectories are often incomplete due to signal loss or deliberate tampering. Existing imputation methods emphasize trajectory recovery, paying limited attention to interpretability and failing to provide underlying knowledge that benefits downstream tasks such as anomaly detection and route planning. We propose knowledge-driven interpretable vessel trajectory imputation (VISTA), the first trajectory imputation framework that offers interpretability while simultaneously providing underlying knowledge to support downstream analysis. Specifically, we first define underlying knowledge as a combination of Structured Data-derived Knowledge (SDK) distilled from AIS data and Implicit LLM Knowledge acquired from large-scale Internet corpora. Second, to manage and leverage the SDK effectively at scale, we develop a data-knowledge-data loop that employs a Structured Data-derived Knowledge Graph for SDK extraction and knowledge-driven trajectory imputation. Third, to efficiently process large-scale AIS data, we introduce a workflow management layer that coordinates the end-to-end pipeline, enabling parallel knowledge extraction and trajectory imputation with anomaly handling and redundancy elimination. Experiments on two large AIS datasets show that VISTA is capable of state-of-the-art imputation accuracy and computational efficiency, improving over state-of-the-art baselines by 5%-94% and reducing time cost by 51%-93%, while producing interpretable knowledge cues that benefit downstream tasks. The source code and implementation details of VISTA are publicly available.",
    "authors": [
      "Hengyu Liu",
      "Tianyi Li",
      "Haoyu Wang",
      "Kristian Torp",
      "Tiancheng Zhang",
      "Yushuai Li",
      "Christian S. Jensen"
    ],
    "published": "2026-01-11",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.06940v1",
    "arxiv_url": "https://arxiv.org/abs/2601.06940v1",
    "fetched_at": "2026-01-13T08:36:09.629804"
  },
  {
    "id": "2601.06186v1",
    "title": "Time-Series Anomaly Classification for Launch Vehicle Propulsion Systems: Fast Statistical Detectors Enhancing LSTM Accuracy and Data Quality",
    "abstract": "Supporting Go/No-Go decisions prior to launch requires assessing real-time telemetry data against redline limits established during the design qualification phase. Family data from ground testing or previous flights is commonly used to detect initiating failure modes and their timing; however, this approach relies heavily on engineering judgment and is more error-prone for new launch vehicles. To address these limitations, we utilize Long-Term Short-Term Memory (LSTM) networks for supervised classification of time-series anomalies. Although, initial training labels derived from simulated anomaly data may be suboptimal due to variations in anomaly strength, anomaly settling times, and other factors. In this work, we propose a novel statistical detector based on the Mahalanobis distance and forward-backward detection fractions to adjust the supervised training labels. We demonstrate our method on digital twin simulations of a ground-stage propulsion system with 20.8 minutes of operation per trial and O(10^8) training timesteps. The statistical data relabeling improved precision and recall of the LSTM classifier by 7% and 22% respectively.",
    "authors": [
      "Sean P. Engelstad",
      "Sameul R. Darr",
      "Matthew Taliaferro",
      "Vinay K. Goyal"
    ],
    "published": "2026-01-07",
    "categories": [
      "cs.LG",
      "stat.AP",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.06186v1",
    "arxiv_url": "https://arxiv.org/abs/2601.06186v1",
    "fetched_at": "2026-01-13T08:36:09.629957"
  },
  {
    "id": "2601.07782v1",
    "title": "Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning",
    "abstract": "LLM agents operating over massive, dynamic tool libraries rely on effective retrieval, yet standard single-shot dense retrievers struggle with complex requests. These failures primarily stem from the disconnect between abstract user goals and technical documentation, and the limited capacity of fixed-size embeddings to model combinatorial tool compositions. To address these challenges, we propose TOOLQP, a lightweight framework that models retrieval as iterative query planning. Instead of single-shot matching, TOOLQP decomposes instructions into sub-tasks and dynamically generates queries to interact with the retriever, effectively bridging the semantic gap by targeting the specific sub-tasks required for composition. We train TOOLQP using synthetic query trajectories followed by optimization via Reinforcement Learning with Verifiable Rewards (RLVR). Experiments demonstrate that TOOLQP achieves state-of-the-art performance, exhibiting superior zero-shot generalization, robustness across diverse retrievers, and significant improvements in downstream agentic execution.",
    "authors": [
      "Wei Fang",
      "James Glass"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07782v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07782v1",
    "fetched_at": "2026-01-13T08:36:37.221099"
  },
  {
    "id": "2601.07754v1",
    "title": "Structure First, Reason Next: Enhancing a Large Language Model using Knowledge Graph for Numerical Reasoning in Financial Documents",
    "abstract": "Numerical reasoning is an important task in the analysis of financial documents. It helps in understanding and performing numerical predictions with logical conclusions for the given query seeking answers from financial texts. Recently, Large Language Models (LLMs) have shown promising results in multiple Question-Answering (Q-A) systems with the capability of logical reasoning. As documents related to finance often consist of long and complex financial contexts, LLMs appear well-suited for building high-quality automated financial question-answering systems. However, LLMs often face challenges in accurately processing the various numbers within financial reports. Extracting numerical data from unstructured text and semi-structured tables, and reliably performing accurate calculations, remains a significant bottleneck for numerical reasoning in most state-of-the-art LLMs. Recent studies have shown that structured data augmentations, such as Knowledge Graphs (KGs), have notably improved the predictions of LLMs along with logical explanations. Thus, it is an important requirement to consider inherent structured information in financial reports while using LLMs for various financial analytics. This paper proposes a framework to incorporate structured information using KGs along with LLM predictions for numerical reasoning tasks. The KGs are extracted using a proposed schema inherently from the document under processing. We evaluated our proposed framework over the benchmark data FinQA, using an open-source LLM, namely Llama 3.1 8B Instruct. We observed that the proposed framework improved execution accuracy by approximately 12% relative to the vanilla LLM.",
    "authors": [
      "Aryan Mishra",
      "Akash Anil"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07754v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07754v1",
    "fetched_at": "2026-01-13T08:36:37.221129"
  },
  {
    "id": "2601.07696v1",
    "title": "Exploring the Meta-level Reasoning of Large Language Models via a Tool-based Multi-hop Tabular Question Answering Task",
    "abstract": "Recent advancements in Large Language Models (LLMs) are increasingly focused on \"reasoning\" ability, a concept with many overlapping definitions in the LLM discourse. We take a more structured approach, distinguishing meta-level reasoning (denoting the process of reasoning about intermediate steps required to solve a task) from object-level reasoning (which concerns the low-level execution of the aforementioned steps.) We design a novel question answering task, which is based around the values of geopolitical indicators for various countries over various years. Questions require breaking down into intermediate steps, retrieval of data, and mathematical operations over that data. The meta-level reasoning ability of LLMs is analysed by examining the selection of appropriate tools for answering questions. To bring greater depth to the analysis of LLMs beyond final answer accuracy, our task contains 'essential actions' against which we can compare the tool call output of LLMs to infer the strength of reasoning ability. We find that LLMs demonstrate good meta-level reasoning on our task, yet are flawed in some aspects of task understanding. We find that n-shot prompting has little effect on accuracy; error messages encountered do not often deteriorate performance; and provide additional evidence for the poor numeracy of LLMs. Finally, we discuss the generalisation and limitation of our findings to other task domains.",
    "authors": [
      "Nick Ferguson",
      "Alan Bundy",
      "Kwabena Nuamah"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07696v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07696v1",
    "fetched_at": "2026-01-13T08:36:37.221149"
  },
  {
    "id": "2601.07641v1",
    "title": "Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning",
    "abstract": "The central challenge of AI for Science is not reasoning alone, but the ability to create computational methods in an open-ended scientific world. Existing LLM-based agents rely on static, pre-defined tool libraries, a paradigm that fundamentally fails in scientific domains where tools are sparse, heterogeneous, and intrinsically incomplete. In this paper, we propose Test-Time Tool Evolution (TTE), a new paradigm that enables agents to synthesize, verify, and evolve executable tools during inference. By transforming tools from fixed resources into problem-driven artifacts, TTE overcomes the rigidity and long-tail limitations of static tool libraries. To facilitate rigorous evaluation, we introduce SciEvo, a benchmark comprising 1,590 scientific reasoning tasks supported by 925 automatically evolved tools. Extensive experiments show that TTE achieves state-of-the-art performance in both accuracy and tool efficiency, while enabling effective cross-domain adaptation of computational tools. The code and benchmark have been released at https://github.com/lujiaxuan0520/Test-Time-Tool-Evol.",
    "authors": [
      "Jiaxuan Lu",
      "Ziyu Kong",
      "Yemin Wang",
      "Rong Fu",
      "Haiyuan Wan",
      "Cheng Yang",
      "Wenjie Lou",
      "Haoran Sun",
      "Lilong Wang",
      "Yankai Jiang",
      "Xiaosong Wang",
      "Xiao Sun",
      "Dongzhan Zhou"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07641v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07641v1",
    "fetched_at": "2026-01-13T08:36:37.221184"
  },
  {
    "id": "2601.07593v1",
    "title": "GRPO with State Mutations: Improving LLM-Based Hardware Test Plan Generation",
    "abstract": "RTL design often relies heavily on ad-hoc testbench creation early in the design cycle. While large language models (LLMs) show promise for RTL code generation, their ability to reason about hardware specifications and generate targeted test plans remains largely unexplored. We present the first systematic study of LLM reasoning capabilities for RTL verification stimuli generation, establishing a two-stage framework that decomposes test plan generation from testbench execution. Our benchmark reveals that state-of-the-art models, including DeepSeek-R1 and Claude-4.0-Sonnet, achieve only 15.7-21.7% success rates on generating stimuli that pass golden RTL designs. To improve LLM generated stimuli, we develop a comprehensive training methodology combining supervised fine-tuning with a novel reinforcement learning approach, GRPO with State Mutation (GRPO-SMu), which enhances exploration by varying input mutations. Our approach leverages a tree-based branching mutation strategy to construct training data comprising equivalent and mutated trees, moving beyond linear mutation approaches to provide rich learning signals. Training on this curated dataset, our 7B parameter model achieves a 33.3% golden test pass rate and a 13.9% mutation detection rate, representing a 17.6% absolute improvement over baseline and outperforming much larger general-purpose models. These results demonstrate that specialized training methodologies can significantly enhance LLM reasoning capabilities for hardware verification tasks, establishing a foundation for automated sub-unit testing in semiconductor design workflows.",
    "authors": [
      "Dimple Vijay Kochar",
      "Nathaniel Pinckney",
      "Guan-Ting Liu",
      "Chia-Tung Ho",
      "Chenhui Deng",
      "Haoxing Ren",
      "Brucek Khailany"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.AR",
      "cs.CL",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07593v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07593v1",
    "fetched_at": "2026-01-13T08:36:37.221210"
  },
  {
    "id": "2601.07577v1",
    "title": "Beyond Entangled Planning: Task-Decoupled Planning for Long-Horizon Agents",
    "abstract": "Recent advances in large language models (LLMs) have enabled agents to autonomously execute complex, long-horizon tasks, yet planning remains a primary bottleneck for reliable task execution. Existing methods typically fall into two paradigms: step-wise planning, which is reactive but often short-sighted; and one-shot planning, which generates a complete plan upfront yet is brittle to execution errors. Crucially, both paradigms suffer from entangled contexts, where the agent must reason over a monolithic history spanning multiple sub-tasks. This entanglement increases cognitive load and lets local errors propagate across otherwise independent decisions, making recovery computationally expensive. To address this, we propose Task-Decoupled Planning (TDP), a training-free framework that replaces entangled reasoning with task decoupling. TDP decomposes tasks into a directed acyclic graph (DAG) of sub-goals via a Supervisor. Using a Planner and Executor with scoped contexts, TDP confines reasoning and replanning to the active sub-task. This isolation prevents error propagation and corrects deviations locally without disrupting the workflow. Results on TravelPlanner, ScienceWorld, and HotpotQA show that TDP outperforms strong baselines while reducing token consumption by up to 82%, demonstrating that sub-task decoupling improves both robustness and efficiency for long-horizon agents.",
    "authors": [
      "Yunfan Li",
      "Bingbing Xu",
      "Xueyun Tian",
      "Xiucheng Xu",
      "Huawei Shen"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07577v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07577v1",
    "fetched_at": "2026-01-13T08:36:37.221231"
  },
  {
    "id": "2601.07477v1",
    "title": "JudgeFlow: Agentic Workflow Optimization via Block Judge",
    "abstract": "Optimizing LLM-based agentic workflows is challenging for scaling AI capabilities. Current methods rely on coarse, end-to-end evaluation signals and lack fine-grained signals on where to refine, often resulting in inefficient or low-impact modifications. To address these limitations, we propose {\\our{}}, an Evaluation-Judge-Optimization-Update pipeline. We incorporate reusable, configurable logic blocks into agentic workflows to capture fundamental forms of logic. On top of this abstraction, we design a dedicated Judge module that inspects execution traces -- particularly failed runs -- and assigns rank-based responsibility scores to problematic blocks. These fine-grained diagnostic signals are then leveraged by an LLM-based optimizer, which focuses modifications on the most problematic block in the workflow. Our approach improves sample efficiency, enhances interpretability through block-level diagnostics, and provides a scalable foundation for automating increasingly complex agentic workflows. We evaluate {\\our{}} on mathematical reasoning and code generation benchmarks, where {\\our{}} achieves superior performance and efficiency compared to existing methods. The source code is publicly available at https://github.com/ma-zihan/JudgeFlow.",
    "authors": [
      "Zihan Ma",
      "Zhikai Zhao",
      "Chuanbo Hua",
      "Federico Berto",
      "Jinkyoo Park"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07477v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07477v1",
    "fetched_at": "2026-01-13T08:36:37.221253"
  },
  {
    "id": "2601.07470v1",
    "title": "Learning How to Remember: A Meta-Cognitive Management Method for Structured and Transferable Agent Memory",
    "abstract": "Large language model (LLM) agents increasingly rely on accumulated memory to solve long-horizon decision-making tasks. However, most existing approaches store memory in fixed representations and reuse it at a single or implicit level of abstraction, which limits generalization and often leads to negative transfer when distribution shift. This paper proposes the Meta-Cognitive Memory Abstraction method (MCMA), which treats memory abstraction as a learnable cognitive skill rather than a fixed design choice. MCMA decouples task execution from memory management by combining a frozen task model with a learned memory copilot. The memory copilot is trained using direct preference optimization, it determines how memories should be structured, abstracted, and reused. Memories are further organized into a hierarchy of abstraction levels, enabling selective reuse based on task similarity. When no memory is transferable, MCMA transfers the ability to abstract and manage memory by transferring the memory copilot. Experiments on ALFWorld, ScienceWorld, and BabyAI demonstrate substantial improvements in performance, out-of-distribution generalization, and cross-task transfer over several baselines.",
    "authors": [
      "Sirui Liang",
      "Pengfei Cao",
      "Jian Zhao",
      "Wenhao Teng",
      "Xiangwen Liao",
      "Jun Zhao",
      "Kang Liu"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07470v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07470v1",
    "fetched_at": "2026-01-13T08:36:37.221278"
  },
  {
    "id": "2601.07376v1",
    "title": "OpenTinker: Separating Concerns in Agentic Reinforcement Learning",
    "abstract": "We introduce OpenTinker, an infrastructure for reinforcement learning (RL) of large language model (LLM) agents built around a separation of concerns across algorithm design, execution, and agent-environment interaction. Rather than relying on monolithic, end-to-end RL pipelines, OpenTinker decomposes agentic learning systems into lightweight, composable components with clearly defined abstraction boundaries. Users specify agents, environments, and interaction protocols, while inference and training are delegated to a managed execution runtime. OpenTinker introduces a centralized scheduler for managing training and inference workloads, including LoRA-based and full-parameter RL, supervised fine-tuning, and inference, over shared resources. We further discuss design principles for extending OpenTinker to multi-agent training. Finally, we present a set of RL use cases that demonstrate the effectiveness of the framework in practical agentic learning scenarios.",
    "authors": [
      "Siqi Zhu",
      "Jiaxuan You"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.AI",
      "cs.DC"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07376v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07376v1",
    "fetched_at": "2026-01-13T08:36:37.221296"
  },
  {
    "id": "2601.07375v1",
    "title": "GROKE: Vision-Free Navigation Instruction Evaluation via Graph Reasoning on OpenStreetMap",
    "abstract": "The evaluation of navigation instructions remains a persistent challenge in Vision-and-Language Navigation (VLN) research. Traditional reference-based metrics such as BLEU and ROUGE fail to capture the functional utility of spatial directives, specifically whether an instruction successfully guides a navigator to the intended destination. Although existing VLN agents could serve as evaluators, their reliance on high-fidelity visual simulators introduces licensing constraints and computational costs, and perception errors further confound linguistic quality assessment. This paper introduces GROKE(Graph-based Reasoning over OSM Knowledge for instruction Evaluation), a vision-free training-free hierarchical LLM-based framework for evaluating navigation instructions using OpenStreetMap data. Through systematic ablation studies, we demonstrate that structured JSON and textual formats for spatial information substantially outperform grid-based and visual graph representations. Our hierarchical architecture combines sub-instruction planning with topological graph navigation, reducing navigation error by 68.5% compared to heuristic and sampling baselines on the Map2Seq dataset. The agent's execution success, trajectory fidelity, and decision patterns serve as proxy metrics for functional navigability given OSM-visible landmarks and topology, establishing a scalable and interpretable evaluation paradigm without visual dependencies. Code and data are available at https://anonymous.4open.science/r/groke.",
    "authors": [
      "Farzad Shami",
      "Subhrasankha Dey",
      "Nico Van de Weghe",
      "Henrikki Tenkanen"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07375v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07375v1",
    "fetched_at": "2026-01-13T08:36:37.221316"
  },
  {
    "id": "2601.07342v1",
    "title": "Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure",
    "abstract": "Large-scale telecom and datacenter infrastructures rely on multi-layered service and resource models, where failures propagate across physical and logical components and affect multiple customers. Traditional approaches to root cause analysis(RCA) rely on hard-coded graph traversal algorithms or rule-based correlation engines, which are costly to maintain and tightly coupled to the infrastructure model.   In this work, we introduce an agentic diagnostic framework where a Large Language Model (LLM) performs step-wise investigation using a constrained tool space exposed through the Model Context Protocol (MCP). Instead of embedding causal logic or traversal algorithms into the application, the agent autonomously navigates the infrastructure model by invoking tools for service lookup, dependency retrieval, structured and unstructured data, and event analysis, and impact discovery. We define an investigation protocol that structures the agent's reasoning and ensures grounding, reproducibility, and safe handling of missing or ambiguous information.   This work lays the foundation for autonomous incident resolution and change impact mitigation. Future systems will not only diagnose and remediate infrastructure failures, but also predict the impact of planned changes on services and customers, enabling operators to mitigate risks before executing maintenance operations.",
    "authors": [
      "Nicolas Tacheny"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07342v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07342v1",
    "fetched_at": "2026-01-13T08:36:37.221335"
  },
  {
    "id": "2601.07315v1",
    "title": "VLM-CAD: VLM-Optimized Collaborative Agent Design Workflow for Analog Circuit Sizing",
    "abstract": "Analog mixed-signal circuit sizing involves complex trade-offs within high-dimensional design spaces. Existing automatic analog circuit sizing approaches often underutilize circuit schematics and lack the explainability required for industry adoption. To tackle these challenges, we propose a Vision Language Model-optimized collaborative agent design workflow (VLM-CAD), which analyzes circuits, optimizes DC operating points, performs inference-based sizing and executes external sizing optimization. We integrate Image2Net to annotate circuit schematics and generate a structured JSON description for precise interpretation by Vision Language Models. Furthermore, we propose an Explainable Trust Region Bayesian Optimization method (ExTuRBO) that employs collaborative warm-starting from agent-generated seeds and offers dual-granularity sensitivity analysis for external sizing optimization, supporting a comprehensive final design report. Experiment results on amplifier sizing tasks using 180nm, 90nm, and 45nm Predictive Technology Models demonstrate that VLM-CAD effectively balances power and performance, achieving a 100% success rate in optimizing an amplifier with a complementary input and a class-AB output stage, while maintaining total runtime under 43 minutes across all experiments.",
    "authors": [
      "Guanyuan Pan",
      "Yugui Lin",
      "Tiansheng Zhou",
      "Pietro Liò",
      "Shuai Wang",
      "Yaqi Wang"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.AR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07315v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07315v1",
    "fetched_at": "2026-01-13T08:36:37.221359"
  },
  {
    "id": "2601.07304v1",
    "title": "Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts",
    "abstract": "Autonomous mobile manipulation in unstructured warehouses requires a balance between efficient large-scale navigation and high-precision object interaction. Traditional end-to-end learning approaches often struggle to handle the conflicting demands of these distinct phases. Navigation relies on robust decision-making over large spaces, while manipulation needs high sensitivity to fine local details. Forcing a single network to learn these different objectives simultaneously often causes optimization interference, where improving one task degrades the other. To address these limitations, we propose a Heterogeneous Multi-Expert Reinforcement Learning (HMER) framework tailored for autonomous forklifts. HMER decomposes long-horizon tasks into specialized sub-policies controlled by a Semantic Task Planner. This structure separates macro-level navigation from micro-level manipulation, allowing each expert to focus on its specific action space without interference. The planner coordinates the sequential execution of these experts, bridging the gap between task planning and continuous control. Furthermore, to solve the problem of sparse exploration, we introduce a Hybrid Imitation-Reinforcement Training Strategy. This method uses expert demonstrations to initialize the policy and Reinforcement Learning for fine-tuning. Experiments in Gazebo simulations show that HMER significantly outperforms sequential and end-to-end baselines. Our method achieves a task success rate of 94.2\\% (compared to 62.5\\% for baselines), reduces operation time by 21.4\\%, and maintains placement error within 1.5 cm, validating its efficacy for precise material handling.",
    "authors": [
      "Yun Chen",
      "Bowei Huang",
      "Fan Guo",
      "Kang Song"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07304v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07304v1",
    "fetched_at": "2026-01-13T08:36:37.221380"
  },
  {
    "id": "2601.07263v1",
    "title": "When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering Attack in Web Automation Agent",
    "abstract": "Web agents, powered by large language models (LLMs), are increasingly deployed to automate complex web interactions. The rise of open-source frameworks (e.g., Browser Use, Skyvern-AI) has accelerated adoption, but also broadened the attack surface. While prior research has focused on model threats such as prompt injection and backdoors, the risks of social engineering remain largely unexplored. We present the first systematic study of social engineering attacks against web automation agents and design a pluggable runtime mitigation solution. On the attack side, we introduce the AgentBait paradigm, which exploits intrinsic weaknesses in agent execution: inducement contexts can distort the agent's reasoning and steer it toward malicious objectives misaligned with the intended task. On the defense side, we propose SUPERVISOR, a lightweight runtime module that enforces environment and intention consistency alignment between webpage context and intended goals to mitigate unsafe operations before execution.   Empirical results show that mainstream frameworks are highly vulnerable to AgentBait, with an average attack success rate of 67.5% and peaks above 80% under specific strategies (e.g., trusted identity forgery). Compared with existing lightweight defenses, our module can be seamlessly integrated across different web automation frameworks and reduces attack success rates by up to 78.1% on average while incurring only a 7.7% runtime overhead and preserving usability. This work reveals AgentBait as a critical new threat surface for web agents and establishes a practical, generalizable defense, advancing the security of this rapidly emerging ecosystem. We reported the details of this attack to the framework developers and received acknowledgment before submission.",
    "authors": [
      "Xinyi Wu",
      "Geng Hong",
      "Yueyue Chen",
      "MingXuan Liu",
      "Feier Jin",
      "Xudong Pan",
      "Jiarun Dai",
      "Baojun Liu"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07263v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07263v1",
    "fetched_at": "2026-01-13T08:36:37.221408"
  },
  {
    "id": "2601.07160v1",
    "title": "AscendKernelGen: A Systematic Study of LLM-Based Kernel Generation for Neural Processing Units",
    "abstract": "To meet the ever-increasing demand for computational efficiency, Neural Processing Units (NPUs) have become critical in modern AI infrastructure. However, unlocking their full potential requires developing high-performance compute kernels using vendor-specific Domain-Specific Languages (DSLs), a task that demands deep hardware expertise and is labor-intensive. While Large Language Models (LLMs) have shown promise in general code generation, they struggle with the strict constraints and scarcity of training data in the NPU domain. Our preliminary study reveals that state-of-the-art general-purpose LLMs fail to generate functional complex kernels for Ascend NPUs, yielding a near-zero success rate. To address these challenges, we propose AscendKernelGen, a generation-evaluation integrated framework for NPU kernel development. We introduce Ascend-CoT, a high-quality dataset incorporating chain-of-thought reasoning derived from real-world kernel implementations, and KernelGen-LM, a domain-adaptive model trained via supervised fine-tuning and reinforcement learning with execution feedback. Furthermore, we design NPUKernelBench, a comprehensive benchmark for assessing compilation, correctness, and performance across varying complexity levels. Experimental results demonstrate that our approach significantly bridges the gap between general LLMs and hardware-specific coding. Specifically, the compilation success rate on complex Level-2 kernels improves from 0% to 95.5% (Pass@10), while functional correctness achieves 64.3% compared to the baseline's complete failure. These results highlight the critical role of domain-specific reasoning and rigorous evaluation in automating accelerator-aware code generation.",
    "authors": [
      "Xinzi Cao",
      "Jianyang Zhai",
      "Pengfei Li",
      "Zhiheng Hu",
      "Cen Yan",
      "Bingxu Mu",
      "Guanghuan Fang",
      "Bin She",
      "Jiayu Li",
      "Yihan Su",
      "Dongyang Tao",
      "Xiansong Huang",
      "Fan Xu",
      "Feidiao Yang",
      "Yao Lu",
      "Chang-Dong Wang",
      "Yutong Lu",
      "Weicheng Xue",
      "Bin Zhou",
      "Yonghong Tian"
    ],
    "published": "2026-01-12",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.07160v1",
    "arxiv_url": "https://arxiv.org/abs/2601.07160v1",
    "fetched_at": "2026-01-13T08:36:37.221453"
  },
  {
    "id": "2601.06747v1",
    "title": "FinForge: Semi-Synthetic Financial Benchmark Generation",
    "abstract": "Evaluating Language Models (LMs) in specialized, high-stakes domains such as finance remains a significant challenge due to the scarcity of open, high-quality, and domain-specific datasets. Existing general-purpose benchmarks provide broad coverage but lack the depth and domain fidelity needed to assess LMs' capabilities for real-world financial reasoning, which requires both conceptual understanding and quantitative rigor. To address this gap, we introduce FinForge, a scalable, semi-synthetic pipeline for constructing finance-specific evaluation benchmarks through a hybrid of expert-guided data curation and controlled LM-based synthesis. FinForge combines manual and programmatic corpus construction from authoritative financial sources with structured question generation and validation using Gemini 2.5 Flash. To demonstrate the pipeline's efficacy, we produce FinForge-5k, a snapshot benchmark comprising over 5,000 human-validated question-answer pairs across 11 finance subdomains, derived from a curated corpus of 100,000 verified documents totaling 143M tokens. Evaluation of state-of-the-art open-source and closed-source models on FinForge-5k reveals significant differences in financial reasoning, with leading models achieving accuracy levels near 80%. These findings underscore the framework's utility for diagnosing current model limitations and guiding future improvements in financial domain competence. All code and data are available at https://github.com/gtfintechlab/FinForge.",
    "authors": [
      "Glenn Matlin",
      "Akhil Theerthala",
      "Anant Gupta",
      "Anirudh JM",
      "Rayan Castilla",
      "Yi Mei Ng",
      "Sudheer Chava"
    ],
    "published": "2026-01-11",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.06747v1",
    "arxiv_url": "https://arxiv.org/abs/2601.06747v1",
    "fetched_at": "2026-01-13T08:37:26.226902"
  }
]