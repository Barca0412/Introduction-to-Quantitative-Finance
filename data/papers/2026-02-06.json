[
  {
    "id": "2602.05898v1",
    "title": "Universal approximation with signatures of non-geometric rough paths",
    "abstract": "We establish a universal approximation theorem for signatures of rough paths that are not necessarily weakly geometric. By extending the path with time and its rough path bracket terms, we prove that linear functionals of the signature of the resulting rough paths approximate continuous functionals on rough path spaces uniformly on compact sets. Moreover, we construct the signature of a path extended by its pathwise quadratic variation terms based on general pathwise stochastic integration à la Föllmer, in particular, allowing for pathwise Itô, Stratonovich, and backward Itô integration. In a probabilistic setting, we obtain a universal approximation result for linear functionals of the signature of continuous semimartingales extended by the quadratic variation terms, defined via stochastic Itô integration. Numerical examples illustrate the use of signatures when the path is extended by time and quadratic variation in the context of model calibration and option pricing in mathematical finance.",
    "authors": [
      "Mihriban Ceylan",
      "Anna P. Kwossek",
      "David J. Prömel"
    ],
    "published": "2026-02-05",
    "categories": [
      "math.PR",
      "cs.LG",
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05898v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05898v1",
    "fetched_at": "2026-02-06T08:50:14.864349"
  },
  {
    "id": "2602.05241v1",
    "title": "On the Skew Stickiness Ratio",
    "abstract": "The skew stickiness ratio is a statistic that captures the joint dynamics of an asset price and its volatility. We derive a representation formula for this quantity using the Itô-Wentzell and Clark-Ocone formulae, and we apply it to analyze its asymptotics under Bergomi-type stochastic volatility models.",
    "authors": [
      "Masaaki Fukasawa"
    ],
    "published": "2026-02-05",
    "categories": [
      "q-fin.MF",
      "math.PR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05241v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05241v1",
    "fetched_at": "2026-02-06T08:50:14.864389"
  },
  {
    "id": "2602.05155v1",
    "title": "Optimal Risk-Sharing Rules in Network-based Decentralized Insurance",
    "abstract": "This paper studies decentralized risk-sharing on networks. In particular, we consider a model where agents are nodes in a given network structure. Agents directly connected by edges in the network are referred to as friends. We study actuarially fair risk-sharing under the assumption that only friends can share risk, and we characterize the optimal signed linear risk-sharing rule in this network setting. Subsequently, we consider a special case of this model where all the friends of an agent take on an equal share of the agent's risk, and establish a connection to the graph Laplacian. Our results are illustrated with several examples.",
    "authors": [
      "Heather N. Fogarty",
      "Sooie-Hoe Loke",
      "Nicholas F. Marshall",
      "Enrique A. Thomann"
    ],
    "published": "2026-02-05",
    "categories": [
      "math.OC",
      "math.PR",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05155v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05155v1",
    "fetched_at": "2026-02-06T08:50:14.864418"
  },
  {
    "id": "2602.05007v1",
    "title": "Music as an Asset Class",
    "abstract": "In the streaming era, music revenues distributed to rights holders have become more transparent. However, it is not yet clear how to quantify the risk and return characteristics of music royalty assets, as is done with equities. In this paper, we fit three discounted cashflow models to transactions on the Royalty Exchange platform. We use our best model to backtest the one year and five year performance of music royalty assets, after transaction costs. We find that Life of Rights (LOR) music assets had risk and return characteristics comparable to stocks in the S\\&P500, when held over 5 years. Since the performance of stocks and music assets are likely to be uncorrelated, this result may help investors assess this asset class within the context of a more traditional stock and bond portfolio.",
    "authors": [
      "Sasha Stoikov",
      "Aadityaa Singla",
      "Umu Cetin",
      "Luis Alonso Cendra Villalobos"
    ],
    "published": "2026-02-04",
    "categories": [
      "q-fin.PR",
      "q-fin.PM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05007v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05007v1",
    "fetched_at": "2026-02-06T08:50:14.864444"
  },
  {
    "id": "2602.05646v1",
    "title": "Empowering Time Series Analysis with Large-Scale Multimodal Pretraining",
    "abstract": "While existing time series foundation models primarily rely on large-scale unimodal pretraining, they lack complementary modalities to enhance time series understanding. Building multimodal foundation models is a natural next step, but it faces key challenges: 1) lack of a unified multimodal pretraining paradigm and large-scale multimodal corpora for time series analysis; 2) how to effectively integrate heterogeneous modalities and enhance model generalization. To address these challenges, we take an early step toward multimodal foundation models for time series analysis. We first propose a multimodal pretraining paradigm that leverages time series with endogenous modalities (derived images and text) and exogenous knowledge (real-world news), providing a comprehensive multi-view perspective for time series analysis. To support this, we develop an automated data construction pipeline to curate MM-TS, the first large-scale multimodal time series dataset spanning six domains, with up to one billion points. Then we propose HORAI, a frequency-enhanced multimodal foundation model. It integrates two core components: the Frequency-enhanced Cross-Modality Encoder and the Time-Frequency Decoder, designed to effectively fuse multimodal features and enhance model generalization across modalities and domains. After pretraining on MM-TS, HORAI achieves state-of-the-art zero-shot performance on time series forecasting and anomaly detection tasks, demonstrating strong generalization.",
    "authors": [
      "Peng Chen",
      "Siyuan Wang",
      "Shiyan Hu",
      "Xingjian Wu",
      "Yang Shu",
      "Zhongwen Rao",
      "Meng Wang",
      "Yijie Li",
      "Bin Yang",
      "Chenjuan Guo"
    ],
    "published": "2026-02-05",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05646v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05646v1",
    "fetched_at": "2026-02-06T08:50:27.194709"
  },
  {
    "id": "2602.05639v1",
    "title": "Joint Embedding Variational Bayes",
    "abstract": "We introduce Variational Joint Embedding (VJE), a framework that synthesizes joint embedding and variational inference to enable self-supervised learning of probabilistic representations in a reconstruction-free, non-contrastive setting. Compared to energy-based predictive objectives that optimize pointwise discrepancies, VJE maximizes a symmetric conditional evidence lower bound (ELBO) for a latent-variable model defined directly on encoder embeddings. We instantiate the conditional likelihood with a heavy-tailed Student-$t$ model using a polar decomposition that explicitly decouples directional and radial factors to prevent norm-induced instabilities during training. VJE employs an amortized inference network to parameterize a diagonal Gaussian variational posterior whose feature-wise variances are shared with the likelihood scale to capture anisotropic uncertainty without auxiliary projection heads. Across ImageNet-1K, CIFAR-10/100, and STL-10, VJE achieves performance comparable to standard non-contrastive baselines under linear and k-NN evaluation. We further validate these probabilistic semantics through one-class CIFAR-10 anomaly detection, where likelihood-based scoring under the proposed model outperforms comparable self-supervised baselines.",
    "authors": [
      "Amin Oji",
      "Paul Fieguth"
    ],
    "published": "2026-02-05",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05639v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05639v1",
    "fetched_at": "2026-02-06T08:50:27.194735"
  },
  {
    "id": "2602.05238v1",
    "title": "PatchFlow: Leveraging a Flow-Based Model with Patch Features",
    "abstract": "Die casting plays a crucial role across various industries due to its ability to craft intricate shapes with high precision and smooth surfaces. However, surface defects remain a major issue that impedes die casting quality control. Recently, computer vision techniques have been explored to automate and improve defect detection. In this work, we combine local neighbor-aware patch features with a normalizing flow model and bridge the gap between the generic pretrained feature extractor and industrial product images by introducing an adapter module to increase the efficiency and accuracy of automated anomaly detection. Compared to state-of-the-art methods, our approach reduces the error rate by 20\\% on the MVTec AD dataset, achieving an image-level AUROC of 99.28\\%. Our approach has also enhanced performance on the VisA dataset , achieving an image-level AUROC of 96.48\\%. Compared to the state-of-the-art models, this represents a 28.2\\% reduction in error. Additionally, experiments on a proprietary die casting dataset yield an accuracy of 95.77\\% for anomaly detection, without requiring any anomalous samples for training. Our method illustrates the potential of leveraging computer vision and deep learning techniques to advance inspection capabilities for the die casting industry",
    "authors": [
      "Boxiang Zhang",
      "Baijian Yang",
      "Xiaoming Wang",
      "Corey Vian"
    ],
    "published": "2026-02-05",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05238v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05238v1",
    "fetched_at": "2026-02-06T08:50:27.194759"
  },
  {
    "id": "2602.05232v1",
    "title": "Balanced Anomaly-guided Ego-graph Diffusion Model for Inductive Graph Anomaly Detection",
    "abstract": "Graph anomaly detection (GAD) is crucial in applications like fraud detection and cybersecurity. Despite recent advancements using graph neural networks (GNNs), two major challenges persist. At the model level, most methods adopt a transductive learning paradigm, which assumes static graph structures, making them unsuitable for dynamic, evolving networks. At the data level, the extreme class imbalance, where anomalous nodes are rare, leads to biased models that fail to generalize to unseen anomalies. These challenges are interdependent: static transductive frameworks limit effective data augmentation, while imbalance exacerbates model distortion in inductive learning settings. To address these challenges, we propose a novel data-centric framework that integrates dynamic graph modeling with balanced anomaly synthesis. Our framework features: (1) a discrete ego-graph diffusion model, which captures the local topology of anomalies to generate ego-graphs aligned with anomalous structural distribution, and (2) a curriculum anomaly augmentation mechanism, which dynamically adjusts synthetic data generation during training, focusing on underrepresented anomaly patterns to improve detection and generalization. Experiments on five datasets demonstrate that the effectiveness of our framework.",
    "authors": [
      "Chunyu Wei",
      "Siyuan He",
      "Yu Wang",
      "Yueguo Chen",
      "Yunhai Wang",
      "Bing Bai",
      "Yidong Zhang",
      "Yong Xie",
      "Shunming Zhang",
      "Fei Wang"
    ],
    "published": "2026-02-05",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05232v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05232v1",
    "fetched_at": "2026-02-06T08:50:27.194835"
  },
  {
    "id": "2602.04917v1",
    "title": "Multi-Aspect Mining and Anomaly Detection for Heterogeneous Tensor Streams",
    "abstract": "Analysis and anomaly detection in event tensor streams consisting of timestamps and multiple attributes - such as communication logs(time, IP address, packet length)- are essential tasks in data mining. While existing tensor decomposition and anomaly detection methods provide useful insights, they face the following two limitations. (i) They cannot handle heterogeneous tensor streams, which comprises both categorical attributes(e.g., IP address) and continuous attributes(e.g., packet length). They typically require either discretizing continuous attributes or treating categorical attributes as continuous, both of which distort the underlying statistical properties of the data.Furthermore, incorrect assumptions about the distribution family of continuous attributes often degrade the model's performance. (ii) They discretize timestamps, failing to track the temporal dynamics of streams(e.g., trends, abnormal events), which makes them ineffective for detecting anomalies at the group level, referred to as 'group anomalies' (e.g, DoS attacks). To address these challenges, we propose HeteroComp, a method for continuously summarizing heterogeneous tensor streams into 'components' representing latent groups in each attribute and their temporal dynamics, and detecting group anomalies. Our method employs Gaussian process priors to model unknown distributions of continuous attributes, and temporal dynamics, which directly estimate probability densities from data. Extracted components give concise but effective summarization, enabling accurate group anomaly detection. Extensive experiments on real datasets demonstrate that HeteroComp outperforms the state-of-the-art algorithms for group anomaly detection accuracy, and its computational time does not depend on the data stream length.",
    "authors": [
      "Soshi Kakio",
      "Yasuko Matsubara",
      "Ren Fujiwara",
      "Yasushi Sakurai"
    ],
    "published": "2026-02-04",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.04917v1",
    "arxiv_url": "https://arxiv.org/abs/2602.04917v1",
    "fetched_at": "2026-02-06T08:50:27.194905"
  },
  {
    "id": "2602.05965v1",
    "title": "Learning to Share: Selective Memory for Efficient Parallel Agentic Systems",
    "abstract": "Agentic systems solve complex tasks by coordinating multiple agents that iteratively reason, invoke tools, and exchange intermediate results. To improve robustness and solution quality, recent approaches deploy multiple agent teams running in parallel to explore diverse reasoning trajectories. However, parallel execution comes at a significant computational cost: when different teams independently reason about similar sub-problems or execute analogous steps, they repeatedly perform substantial overlapping computation. To address these limitations, in this paper, we propose Learning to Share (LTS), a learned shared-memory mechanism for parallel agentic frameworks that enables selective cross-team information reuse while controlling context growth. LTS introduces a global memory bank accessible to all teams and a lightweight controller that decides whether intermediate agent steps should be added to memory or not. The controller is trained using stepwise reinforcement learning with usage-aware credit assignment, allowing it to identify information that is globally useful across parallel executions. Experiments on the AssistantBench and GAIA benchmarks show that LTS significantly reduces overall runtime while matching or improving task performance compared to memory-free parallel baselines, demonstrating that learned memory admission is an effective strategy for improving the efficiency of parallel agentic systems. Project page: https://joefioresi718.github.io/LTS_webpage/",
    "authors": [
      "Joseph Fioresi",
      "Parth Parag Kulkarni",
      "Ashmal Vayani",
      "Song Wang",
      "Mubarak Shah"
    ],
    "published": "2026-02-05",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05965v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05965v1",
    "fetched_at": "2026-02-06T08:50:54.911632"
  },
  {
    "id": "2602.05843v1",
    "title": "OdysseyArena: Benchmarking Large Language Models For Long-Horizon, Active and Inductive Interactions",
    "abstract": "The rapid advancement of Large Language Models (LLMs) has catalyzed the development of autonomous agents capable of navigating complex environments. However, existing evaluations primarily adopt a deductive paradigm, where agents execute tasks based on explicitly provided rules and static goals, often within limited planning horizons. Crucially, this neglects the inductive necessity for agents to discover latent transition laws from experience autonomously, which is the cornerstone for enabling agentic foresight and sustaining strategic coherence. To bridge this gap, we introduce OdysseyArena, which re-centers agent evaluation on long-horizon, active, and inductive interactions. We formalize and instantiate four primitives, translating abstract transition dynamics into concrete interactive environments. Building upon this, we establish OdysseyArena-Lite for standardized benchmarking, providing a set of 120 tasks to measure an agent's inductive efficiency and long-horizon discovery. Pushing further, we introduce OdysseyArena-Challenge to stress-test agent stability across extreme interaction horizons (e.g., > 200 steps). Extensive experiments on 15+ leading LLMs reveal that even frontier models exhibit a deficiency in inductive scenarios, identifying a critical bottleneck in the pursuit of autonomous discovery in complex environments. Our code and data are available at https://github.com/xufangzhi/Odyssey-Arena",
    "authors": [
      "Fangzhi Xu",
      "Hang Yan",
      "Qiushi Sun",
      "Jinyang Wu",
      "Zixian Huang",
      "Muye Huang",
      "Jingyang Gong",
      "Zichen Ding",
      "Kanzhi Cheng",
      "Yian Wang",
      "Xinyu Che",
      "Zeyi Sun",
      "Jian Zhang",
      "Zhangyue Yin",
      "Haoran Luo",
      "Xuanjing Huang",
      "Ben Kao",
      "Jun Liu",
      "Qika Lin"
    ],
    "published": "2026-02-05",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05843v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05843v1",
    "fetched_at": "2026-02-06T08:50:54.911694"
  },
  {
    "id": "2602.05765v1",
    "title": "RL-VLA$^3$: Reinforcement Learning VLA Accelerating via Full Asynchronism",
    "abstract": "In recent years, Vision-Language-Action (VLA) models have emerged as a crucial pathway towards general embodied intelligence, yet their training efficiency has become a key bottleneck. Although existing reinforcement learning (RL)-based training frameworks like RLinf can enhance model generalization, they still rely on synchronous execution, leading to severe resource underutilization and throughput limitations during environment interaction, policy generation (rollout), and model update phases (actor). To overcome this challenge, this paper, for the first time, proposes and implements a fully-asynchronous policy training framework encompassing the entire pipeline from environment interaction, rollout generation, to actor policy updates. Systematically drawing inspiration from asynchronous optimization ideas in large model RL, our framework designs a multi-level decoupled architecture. This includes asynchronous parallelization of environment interaction and trajectory collection, streaming execution for policy generation, and decoupled scheduling for training updates. We validated the effectiveness of our method across diverse VLA models and environments. On the LIBERO benchmark, the framework achieves throughput improvements of up to 59.25\\% compared to existing synchronous strategies. When deeply optimizing separation strategies, throughput can be increased by as much as 126.67\\%. We verified the effectiveness of each asynchronous component via ablation studies. Scaling law validation across 8 to 256 GPUs demonstrates our method's excellent scalability under most conditions.",
    "authors": [
      "Zhong Guan",
      "Haoran Sun",
      "Yongjian Guo",
      "Shuai Di",
      "Xiaodong Bai",
      "Jing Long",
      "Tianyun Zhao",
      "Mingxi Luo",
      "Chen Zhou",
      "Yucheng Guo",
      "Qiming Yang",
      "Wanting Xu",
      "Wen Huang",
      "Yunxuan Ma",
      "Hongke Zhao",
      "Likang Wu",
      "Xiaotie Deng",
      "Xi Xiao",
      "Sheng Wen",
      "Yicheng Gong",
      "Junwu Xiong"
    ],
    "published": "2026-02-05",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05765v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05765v1",
    "fetched_at": "2026-02-06T08:50:54.911747"
  },
  {
    "id": "2602.05754v1",
    "title": "TimelyFreeze: Adaptive Parameter Freezing Mechanism for Pipeline Parallelism",
    "abstract": "Pipeline parallelism enables training models that exceed single-device memory, but practical throughput remains limited by pipeline bubbles. Although parameter freezing can improve training throughput by adaptively skipping backward computation, existing methods often over-freeze parameters, resulting in unnecessary accuracy degradation. To address this issue, we propose TimelyFreeze, which models the pipeline schedule as a directed acyclic graph and solves a linear program to compute optimal freeze ratios that minimize batch execution time under accuracy constraints. Experiments show that TimelyFreeze achieves up to 40% training throughput improvement on LLaMA-8B with comparable accuracy. Overall, it enables faster large-scale model training without compromising convergence and generalizes across diverse pipeline-parallel settings.",
    "authors": [
      "Seonghye Cho",
      "Jaemin Han",
      "Hyunjin Kim",
      "Euisoo Jung",
      "Jae-Gil Lee"
    ],
    "published": "2026-02-05",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05754v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05754v1",
    "fetched_at": "2026-02-06T08:50:54.911772"
  },
  {
    "id": "2602.05711v1",
    "title": "OmniMoE: An Efficient MoE by Orchestrating Atomic Experts at Scale",
    "abstract": "Mixture-of-Experts (MoE) architectures are evolving towards finer granularity to improve parameter efficiency. However, existing MoE designs face an inherent trade-off between the granularity of expert specialization and hardware execution efficiency. We propose OmniMoE, a system-algorithm co-designed framework that pushes expert granularity to its logical extreme. OmniMoE introduces vector-level Atomic Experts, enabling scalable routing and execution within a single MoE layer, while retaining a shared dense MLP branch for general-purpose processing. Although this atomic design maximizes capacity, it poses severe challenges for routing complexity and memory access. To address these, OmniMoE adopts a system-algorithm co-design: (i) a Cartesian Product Router that decomposes the massive index space to reduce routing complexity from O(N) to O(sqrt(N)); and (ii) Expert-Centric Scheduling that inverts the execution order to turn scattered, memory-bound lookups into efficient dense matrix operations. Validated on seven benchmarks, OmniMoE (with 1.7B active parameters) achieves 50.9% zero-shot accuracy across seven benchmarks, outperforming coarse-grained (e.g., DeepSeekMoE) and fine-grained (e.g., PEER) baselines. Crucially, OmniMoE reduces inference latency from 73ms to 6.7ms (a 10.9-fold speedup) compared to PEER, demonstrating that massive-scale fine-grained MoE can be fast and accurate. Our code is open-sourced at https://github.com/flash-algo/omni-moe.",
    "authors": [
      "Jingze Shi",
      "Zhangyang Peng",
      "Yizhang Zhu",
      "Yifan Wu",
      "Guang Liu",
      "Yuyu Luo"
    ],
    "published": "2026-02-05",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05711v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05711v1",
    "fetched_at": "2026-02-06T08:50:54.911798"
  },
  {
    "id": "2602.05636v1",
    "title": "Generative Ontology: When Structured Knowledge Learns to Create",
    "abstract": "Traditional ontologies excel at describing domain structure but cannot generate novel artifacts. Large language models generate fluently but produce outputs that lack structural validity, hallucinating mechanisms without components, goals without end conditions. We introduce Generative Ontology, a framework that synthesizes these complementary strengths: ontology provides the grammar; the LLM provides the creativity.   Generative Ontology encodes domain knowledge as executable Pydantic schemas that constrain LLM generation via DSPy signatures. A multi-agent pipeline assigns specialized roles to different ontology domains: a Mechanics Architect designs game systems, a Theme Weaver integrates narrative, a Balance Critic identifies exploits. Each agent carrying a professional \"anxiety\" that prevents shallow, agreeable outputs. Retrieval-augmented generation grounds novel designs in precedents from existing exemplars, while iterative validation ensures coherence between mechanisms and components.   We demonstrate the framework through GameGrammar, a system for generating complete tabletop game designs. Given a thematic prompt (\"bioluminescent fungi competing in a cave ecosystem\"), the pipeline produces structurally complete, playable game specifications with mechanisms, components, victory conditions, and setup instructions. These outputs satisfy ontological constraints while remaining genuinely creative.   The pattern generalizes beyond games. Any domain with expert vocabulary, validity constraints, and accumulated exemplars (music composition, software architecture, culinary arts) is a candidate for Generative Ontology. We argue that constraints do not limit creativity but enable it: just as grammar makes poetry possible, ontology makes structured generation possible.",
    "authors": [
      "Benny Cheung"
    ],
    "published": "2026-02-05",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05636v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05636v1",
    "fetched_at": "2026-02-06T08:50:54.911818"
  },
  {
    "id": "2602.05467v1",
    "title": "MerNav: A Highly Generalizable Memory-Execute-Review Framework for Zero-Shot Object Goal Navigation",
    "abstract": "Visual Language Navigation (VLN) is one of the fundamental capabilities for embodied intelligence and a critical challenge that urgently needs to be addressed. However, existing methods are still unsatisfactory in terms of both success rate (SR) and generalization: Supervised Fine-Tuning (SFT) approaches typically achieve higher SR, while Training-Free (TF) approaches often generalize better, but it is difficult to obtain both simultaneously. To this end, we propose a Memory-Execute-Review framework. It consists of three parts: a hierarchical memory module for providing information support, an execute module for routine decision-making and actions, and a review module for handling abnormal situations and correcting behavior. We validated the effectiveness of this framework on the Object Goal Navigation task. Across 4 datasets, our average SR achieved absolute improvements of 7% and 5% compared to all baseline methods under TF and Zero-Shot (ZS) settings, respectively. On the most commonly used HM3D_v0.1 and the more challenging open vocabulary dataset HM3D_OVON, the SR improved by 8% and 6%, under ZS settings. Furthermore, on the MP3D and HM3D_OVON datasets, our method not only outperformed all TF methods but also surpassed all SFT methods, achieving comprehensive leadership in both SR (5% and 2%) and generalization.",
    "authors": [
      "Dekang Qi",
      "Shuang Zeng",
      "Xinyuan Chang",
      "Feng Xiong",
      "Shichao Xie",
      "Xiaolong Wu",
      "Mu Xu"
    ],
    "published": "2026-02-05",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.RO"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05467v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05467v1",
    "fetched_at": "2026-02-06T08:50:54.911847"
  },
  {
    "id": "2602.05456v1",
    "title": "Ontology-Driven Robotic Specification Synthesis",
    "abstract": "This paper addresses robotic system engineering for safety- and mission-critical applications by bridging the gap between high-level objectives and formal, executable specifications. The proposed method, Robotic System Task to Model Transformation Methodology (RSTM2) is an ontology-driven, hierarchical approach using stochastic timed Petri nets with resources, enabling Monte Carlo simulations at mission, system, and subsystem levels. A hypothetical case study demonstrates how the RSTM2 method supports architectural trades, resource allocation, and performance analysis under uncertainty. Ontological concepts further enable explainable AI-based assistants, facilitating fully autonomous specification synthesis. The methodology offers particular benefits to complex multi-robot systems, such as the NASA CADRE mission, representing decentralized, resource-aware, and adaptive autonomous systems of the future.",
    "authors": [
      "Maksym Figat",
      "Ryan M. Mackey",
      "Michel D. Ingham"
    ],
    "published": "2026-02-05",
    "categories": [
      "cs.RO",
      "cs.AI",
      "eess.SY"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05456v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05456v1",
    "fetched_at": "2026-02-06T08:50:54.911868"
  },
  {
    "id": "2602.05386v1",
    "title": "Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening",
    "abstract": "As large language models (LLMs) evolve into autonomous agents, their real-world applicability has expanded significantly, accompanied by new security challenges. Most existing agent defense mechanisms adopt a mandatory checking paradigm, in which security validation is forcibly triggered at predefined stages of the agent lifecycle. In this work, we argue that effective agent security should be intrinsic and selective rather than architecturally decoupled and mandatory. We propose Spider-Sense framework, an event-driven defense framework based on Intrinsic Risk Sensing (IRS), which allows agents to maintain latent vigilance and trigger defenses only upon risk perception. Once triggered, the Spider-Sense invokes a hierarchical defence mechanism that trades off efficiency and precision: it resolves known patterns via lightweight similarity matching while escalating ambiguous cases to deep internal reasoning, thereby eliminating reliance on external models. To facilitate rigorous evaluation, we introduce S$^2$Bench, a lifecycle-aware benchmark featuring realistic tool execution and multi-stage attacks. Extensive experiments demonstrate that Spider-Sense achieves competitive or superior defense performance, attaining the lowest Attack Success Rate (ASR) and False Positive Rate (FPR), with only a marginal latency overhead of 8.3\\%.",
    "authors": [
      "Zhenxiong Yu",
      "Zhi Yang",
      "Zhiheng Jin",
      "Shuhe Wang",
      "Heng Zhang",
      "Yanlin Fei",
      "Lingfeng Zeng",
      "Fangqi Lou",
      "Shuo Zhang",
      "Tu Hu",
      "Jingping Liu",
      "Rongze Chen",
      "Xingyu Zhu",
      "Kunyi Wang",
      "Chaofa Yuan",
      "Xin Guo",
      "Zhaowei Liu",
      "Feipeng Zhang",
      "Jie Huang",
      "Huacan Wang",
      "Ronghao Chen",
      "Liwen Zhang"
    ],
    "published": "2026-02-05",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05386v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05386v1",
    "fetched_at": "2026-02-06T08:50:54.911926"
  },
  {
    "id": "2602.05249v1",
    "title": "Automatic Cognitive Task Generation for In-Situ Evaluation of Embodied Agents",
    "abstract": "As general intelligent agents are poised for widespread deployment in diverse households, evaluation tailored to each unique unseen 3D environment has become a critical prerequisite. However, existing benchmarks suffer from severe data contamination and a lack of scene specificity, inadequate for assessing agent capabilities in unseen settings. To address this, we propose a dynamic in-situ task generation method for unseen environments inspired by human cognition. We define tasks through a structured graph representation and construct a two-stage interaction-evolution task generation system for embodied agents (TEA). In the interaction stage, the agent actively interacts with the environment, creating a loop between task execution and generation that allows for continuous task generation. In the evolution stage, task graph modeling allows us to recombine and reuse existing tasks to generate new ones without external data. Experiments across 10 unseen scenes demonstrate that TEA automatically generated 87,876 tasks in two cycles, which human verification confirmed to be physically reasonable and encompassing essential daily cognitive capabilities. Benchmarking SOTA models against humans on our in-situ tasks reveals that models, despite excelling on public benchmarks, perform surprisingly poorly on basic perception tasks, severely lack 3D interaction awareness and show high sensitivity to task types in reasoning. These sobering findings highlight the necessity of in-situ evaluation before deploying agents into real-world human environments.",
    "authors": [
      "Xinyi He",
      "Ying Yang",
      "Chuanjian Fu",
      "Sihan Guo",
      "Songchun Zhu",
      "Lifeng Fan",
      "Zhenliang Zhang",
      "Yujia Peng"
    ],
    "published": "2026-02-05",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05249v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05249v1",
    "fetched_at": "2026-02-06T08:50:54.911956"
  },
  {
    "id": "2602.05220v1",
    "title": "Bagpiper: Solving Open-Ended Audio Tasks via Rich Captions",
    "abstract": "Current audio foundation models typically rely on rigid, task-specific supervision, addressing isolated factors of audio rather than the whole. In contrast, human intelligence processes audio holistically, seamlessly bridging physical signals with abstract cognitive concepts to execute complex tasks. Grounded in this philosophy, we introduce Bagpiper, an 8B audio foundation model that interprets physical audio via rich captions, i.e., comprehensive natural language descriptions that encapsulate the critical cognitive concepts inherent in the signal (e.g., transcription, audio events). By pre-training on a massive corpus of 600B tokens, the model establishes a robust bidirectional mapping between raw audio and this high-level conceptual space. During fine-tuning, Bagpiper adopts a caption-then-process workflow, simulating an intermediate cognitive reasoning step to solve diverse tasks without task-specific priors. Experimentally, Bagpiper outperforms Qwen-2.5-Omni on MMAU and AIRBench for audio understanding and surpasses CosyVoice3 and TangoFlux in generation quality, capable of synthesizing arbitrary compositions of speech, music, and sound effects. To the best of our knowledge, Bagpiper is among the first works that achieve unified understanding generation for general audio. Model, data, and code are available at Bagpiper Home Page.",
    "authors": [
      "Jinchuan Tian",
      "Haoran Wang",
      "Bo-Hao Su",
      "Chien-yu Huang",
      "Qingzheng Wang",
      "Jiatong Shi",
      "William Chen",
      "Xun Gong",
      "Siddhant Arora",
      "Chin-Jou Li",
      "Masao Someki",
      "Takashi Maekaku",
      "Yusuke Shinohara",
      "Jin Sakuma",
      "Chao-Han Huck Yang",
      "Shinji Watanabe"
    ],
    "published": "2026-02-05",
    "categories": [
      "cs.CL",
      "cs.SD"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05220v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05220v1",
    "fetched_at": "2026-02-06T08:50:54.912000"
  },
  {
    "id": "2602.05134v1",
    "title": "SemPipes -- Optimizable Semantic Data Operators for Tabular Machine Learning Pipelines",
    "abstract": "Real-world machine learning on tabular data relies on complex data preparation pipelines for prediction, data integration, augmentation, and debugging. Designing these pipelines requires substantial domain expertise and engineering effort, motivating the question of how large language models (LLMs) can support tabular ML through code synthesis. We introduce SemPipes, a novel declarative programming model that integrates LLM-powered semantic data operators into tabular ML pipelines. Semantic operators specify data transformations in natural language while delegating execution to a runtime system. During training, SemPipes synthesizes custom operator implementations based on data characteristics, operator instructions, and pipeline context. This design enables the automatic optimization of data operations in a pipeline via LLM-based code synthesis guided by evolutionary search. We evaluate SemPipes across diverse tabular ML tasks and show that semantic operators substantially improve end-to-end predictive performance for both expert-designed and agent-generated pipelines, while reducing pipeline complexity. We implement SemPipes in Python and release it at https://github.com/deem-data/sempipes/tree/v1.",
    "authors": [
      "Olga Ovcharenko",
      "Matthias Boehm",
      "Sebastian Schelter"
    ],
    "published": "2026-02-04",
    "categories": [
      "cs.LG",
      "cs.DB"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05134v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05134v1",
    "fetched_at": "2026-02-06T08:50:54.912021"
  },
  {
    "id": "2602.05004v1",
    "title": "CoWork-X: Experience-Optimized Co-Evolution for Multi-Agent Collaboration System",
    "abstract": "Large language models are enabling language-conditioned agents in interactive environments, but highly cooperative tasks often impose two simultaneous constraints: sub-second real-time coordination and sustained multi-episode adaptation under a strict online token budget. Existing approaches either rely on frequent in-episode reasoning that induces latency and timing jitter, or deliver post-episode improvements through unstructured text that is difficult to compile into reliable low-cost execution. We propose CoWork-X, an active co-evolution framework that casts peer collaboration as a closed-loop optimization problem across episodes, inspired by fast--slow memory separation. CoWork-X instantiates a Skill-Agent that executes via HTN (hierarchical task network)-based skill retrieval from a structured, interpretable, and compositional skill library, and a post-episode Co-Optimizer that performs patch-style skill consolidation with explicit budget constraints and drift regularization. Experiments in challenging Overcooked-AI-like realtime collaboration benchmarks demonstrate that CoWork-X achieves stable, cumulative performance gains while steadily reducing online latency and token usage.",
    "authors": [
      "Zexin Lin",
      "Jiachen Yu",
      "Haoyang Zhang",
      "Yuzhao Li",
      "Zhonghang Li",
      "Yujiu Yang",
      "Junjie Wang",
      "Xiaoqiang Ji"
    ],
    "published": "2026-02-04",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.05004v1",
    "arxiv_url": "https://arxiv.org/abs/2602.05004v1",
    "fetched_at": "2026-02-06T08:50:54.912050"
  },
  {
    "id": "2602.04816v2",
    "title": "Horizon-LM: A RAM-Centric Architecture for LLM Training",
    "abstract": "The rapid growth of large language models (LLMs) has outpaced the evolution of single-GPU hardware, making model scale increasingly constrained by memory capacity rather than computation. While modern training systems extend GPU memory through distributed parallelism and offloading across CPU and storage tiers, they fundamentally retain a GPU-centric execution paradigm in which GPUs host persistent model replicas and full autograd graphs. As a result, scaling large models remains tightly coupled to multi-GPU clusters, complex distributed runtimes, and unpredictable host memory consumption, creating substantial barriers for node-scale post-training workloads such as instruction tuning, alignment, and domain adaptation. We present Horizon-LM, a memory-centric training system that redefines the roles of CPU and GPU for large-model optimization. Horizon-LM treats host memory as the authoritative parameter store and uses GPUs solely as transient compute engines through a CPU-master, GPU-template execution model. By eliminating persistent GPU-resident modules and autograd graphs, employing explicit recomputation with manual gradient propagation, and introducing a pipelined double-buffered execution engine, Horizon-LM decouples model scale from GPU count and bounds memory usage to the theoretical parameter footprint. On a single H200 GPU with 1.5\\,TB host RAM, Horizon-LM reliably trains models up to 120B parameters. On a standard single A100 machine, Horizon-LM achieves up to 12.2$\\times$ higher training throughput than DeepSpeed ZeRO-3 with CPU offloading while preserving numerical correctness. Across platforms and scales, Horizon-LM sustains high device utilization and predictable memory growth, demonstrating that host memory, not GPU memory, defines the true feasibility boundary for node-scale large-model training.",
    "authors": [
      "Zhengqing Yuan",
      "Lichao Sun",
      "Yanfang Ye"
    ],
    "published": "2026-02-04",
    "categories": [
      "cs.OS",
      "cs.CL",
      "cs.DC"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.04816v2",
    "arxiv_url": "https://arxiv.org/abs/2602.04816v2",
    "fetched_at": "2026-02-06T08:50:54.912127"
  },
  {
    "id": "2602.01388v2",
    "title": "The Enhanced Physics-Informed Kolmogorov-Arnold Networks: Applications of Newton's Laws in Financial Deep Reinforcement Learning (RL) Algorithms",
    "abstract": "Deep Reinforcement Learning (DRL), a subset of machine learning focused on sequential decision-making, has emerged as a powerful approach for tackling financial trading problems. In finance, DRL is commonly used either to generate discrete trade signals or to determine continuous portfolio allocations. In this work, we propose a novel reinforcement learning framework for portfolio optimization that incorporates Physics-Informed Kolmogorov-Arnold Networks (PIKANs) into several DRL algorithms. The approach replaces conventional multilayer perceptrons with Kolmogorov-Arnold Networks (KANs) in both actor and critic components-utilizing learnable B-spline univariate functions to achieve parameter-efficient and more interpretable function approximation. During actor updates, we introduce a physics-informed regularization loss that promotes second-order temporal consistency between observed return dynamics and the action-induced portfolio adjustments. The proposed framework is evaluated across three equity markets-China, Vietnam, and the United States, covering both emerging and developed economies. Across all three markets, PIKAN-based agents consistently deliver higher cumulative and annualized returns, superior Sharpe and Calmar ratios, and more favorable drawdown characteristics compared to both standard DRL baselines and classical online portfolio-selection methods. This yields more stable training, higher Sharpe ratios, and superior performance compared to traditional DRL counterparts. The approach is particularly valuable in highly dynamic and noisy financial markets, where conventional DRL often suffers from instability and poor generalization.",
    "authors": [
      "Trang Thoi",
      "Hung Tran",
      "Tram Thoi",
      "Huaiyang Zhong"
    ],
    "published": "2026-02-01",
    "categories": [
      "cs.CE",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.01388v2",
    "arxiv_url": "https://arxiv.org/abs/2602.01388v2",
    "fetched_at": "2026-02-06T08:52:42.589157"
  }
]