[
  {
    "id": "2601.23172v1",
    "title": "A unified theory of order flow, market impact, and volatility",
    "abstract": "We propose a microstructural model for the order flow in financial markets that distinguishes between {\\it core orders} and {\\it reaction flow}, both modeled as Hawkes processes. This model has a natural scaling limit that reconciles a number of salient empirical properties: persistent signed order flow, rough trading volume and volatility, and power-law market impact. In our framework, all these quantities are pinned down by a single statistic $H_0$, which measures the persistence of the core flow. Specifically, the signed flow converges to the sum of a fractional process with Hurst index $H_0$ and a martingale, while the limiting traded volume is a rough process with Hurst index $H_0-1/2$. No-arbitrage constraints imply that volatility is rough, with Hurst parameter $2H_0-3/2$, and that the price impact of trades follows a power law with exponent $2-2H_0$. The analysis of signed order flow data yields an estimate $H_0 \\approx 3/4$. This is not only consistent with the square-root law of market impact, but also turns out to match estimates for the roughness of traded volumes and volatilities remarkably well.",
    "authors": [
      "Johannes Muhle-Karbe",
      "Youssef Ouazzani Chahd",
      "Mathieu Rosenbaum",
      "Grégoire Szymanski"
    ],
    "published": "2026-01-30",
    "categories": [
      "q-fin.ST",
      "math.PR",
      "q-fin.MF",
      "q-fin.TR",
      "stat.AP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.23172v1",
    "arxiv_url": "https://arxiv.org/abs/2601.23172v1",
    "fetched_at": "2026-02-02T08:50:43.975778"
  },
  {
    "id": "2601.22113v2",
    "title": "Diverse Approaches to Optimal Execution Schedule Generation",
    "abstract": "We present the first application of MAP-Elites, a quality-diversity algorithm, to trade execution. Rather than searching for a single optimal policy, MAP-Elites generates a diverse portfolio of regime-specialist strategies indexed by liquidity and volatility conditions. Individual specialists achieve 8-10% performance improvements within their behavioural niches, while other cells show degradation, suggesting opportunities for ensemble approaches that combine improved specialists with the baseline PPO policy. Results indicate that quality-diversity methods offer promise for regime-adaptive execution, though substantial computational resources per behavioural cell may be required for robust specialist development across all market conditions.   To ensure experimental integrity, we develop a calibrated Gymnasium environment focused on order scheduling rather than tactical placement decisions. The simulator features a transient impact model with exponential decay and square-root volume scaling, fit to 400+ U.S. equities with $R^2>0.02$ out-of-sample. Within this environment, two Proximal Policy Optimization architectures - both MLP and CNN feature extractors - demonstrate substantial improvements over industry baselines, with the CNN variant achieving 2.13 bps arrival slippage versus 5.23 bps for VWAP on 4,900 out-of-sample orders ($21B notional). These results validate both the simulation realism and provide strong single-policy baselines for quality-diversity methods.",
    "authors": [
      "Robert de Witt",
      "Mikko S. Pakkanen"
    ],
    "published": "2026-01-29",
    "categories": [
      "q-fin.TR",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22113v2",
    "arxiv_url": "https://arxiv.org/abs/2601.22113v2",
    "fetched_at": "2026-02-02T08:50:43.975844"
  },
  {
    "id": "2601.22200v1",
    "title": "Adaptive Benign Overfitting (ABO): Overparameterized RLS for Online Learning in Non-stationary Time-series",
    "abstract": "Overparameterized models have recently challenged conventional learning theory by exhibiting improved generalization beyond the interpolation limit, a phenomenon known as benign overfitting. This work introduces Adaptive Benign Overfitting (ABO), extending the recursive least-squares (RLS) framework to this regime through a numerically stable formulation based on orthogonal-triangular updates. A QR-based exponentially weighted RLS (QR-EWRLS) algorithm is introduced, combining random Fourier feature mappings with forgetting-factor regularization to enable online adaptation under non-stationary conditions. The orthogonal decomposition prevents the numerical divergence associated with covariance-form RLS while retaining adaptability to evolving data distributions. Experiments on nonlinear synthetic time series confirm that the proposed approach maintains bounded residuals and stable condition numbers while reproducing the double-descent behavior characteristic of overparameterized models. Applications to forecasting foreign exchange and electricity demand show that ABO is highly accurate (comparable to baseline kernel methods) while achieving speed improvements of between 20 and 40 percent. The results provide a unified view linking adaptive filtering, kernel approximation, and benign overfitting within a stable online learning framework.",
    "authors": [
      "Luis Ontaneda Mijares",
      "Nick Firoozye"
    ],
    "published": "2026-01-29",
    "categories": [
      "q-fin.ST",
      "cs.LG",
      "cs.MS",
      "math.NA",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22200v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22200v1",
    "fetched_at": "2026-02-02T08:50:43.975866"
  },
  {
    "id": "2601.23220v1",
    "title": "Med-Scout: Curing MLLMs' Geometric Blindness in Medical Perception via Geometry-Aware RL Post-Training",
    "abstract": "Despite recent Multimodal Large Language Models (MLLMs)' linguistic prowess in medical diagnosis, we find even state-of-the-art MLLMs suffer from a critical perceptual deficit: geometric blindness. This failure to ground outputs in objective geometric constraints leads to plausible yet factually incorrect hallucinations, rooted in training paradigms that prioritize linguistic fluency over geometric fidelity. This paper introduces Med-Scout, a novel framework that \"cures\" this blindness via Reinforcement Learning (RL) that leverages the intrinsic geometric logic latent within unlabeled medical images. Instead of relying on costly expert annotations, Med-Scout derives verifiable supervision signals through three strategic proxy tasks: Hierarchical Scale Localization, Topological Jigsaw Reconstruction, and Anomaly Consistency Detection. To rigorously quantify this deficit, we present Med-Scout-Bench, a new benchmark specifically designed to evaluate geometric perception. Extensive evaluations show that Med-Scout significantly mitigates geometric blindness, outperforming leading proprietary and open-source MLLMs by over 40% on our benchmark. Furthermore, this enhanced geometric perception generalizes to broader medical understanding, achieving superior results on radiological and comprehensive medical VQA tasks.",
    "authors": [
      "Anglin Liu",
      "Ruichao Chen",
      "Yi Lu",
      "Hongxia Xu",
      "Jintai Chen"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.23220v1",
    "arxiv_url": "https://arxiv.org/abs/2601.23220v1",
    "fetched_at": "2026-02-02T08:50:56.634402"
  },
  {
    "id": "2601.23204v1",
    "title": "TSAQA: Time Series Analysis Question And Answering Benchmark",
    "abstract": "Time series data are integral to critical applications across domains such as finance, healthcare, transportation, and environmental science. While recent work has begun to explore multi-task time series question answering (QA), current benchmarks remain limited to forecasting and anomaly detection tasks. We introduce TSAQA, a novel unified benchmark designed to broaden task coverage and evaluate diverse temporal analysis capabilities. TSAQA integrates six diverse tasks under a single framework ranging from conventional analysis, including anomaly detection and classification, to advanced analysis, such as characterization, comparison, data transformation, and temporal relationship analysis. Spanning 210k samples across 13 domains, the dataset employs diverse formats, including true-or-false (TF), multiple-choice (MC), and a novel puzzling (PZ), to comprehensively assess time series analysis. Zero-shot evaluation demonstrates that these tasks are challenging for current Large Language Models (LLMs): the best-performing commercial LLM, Gemini-2.5-Flash, achieves an average score of only 65.08. Although instruction tuning boosts open-source performance: the best-performing open-source model, LLaMA-3.1-8B, shows significant room for improvement, highlighting the complexity of temporal analysis for LLMs.",
    "authors": [
      "Baoyu Jing",
      "Sanhorn Chen",
      "Lecheng Zheng",
      "Boyu Liu",
      "Zihao Li",
      "Jiaru Zou",
      "Tianxin Wei",
      "Zhining Liu",
      "Zhichen Zeng",
      "Ruizhong Qiu",
      "Xiao Lin",
      "Yuchen Yan",
      "Dongqi Fu",
      "Jingchao Ni",
      "Jingrui He",
      "Hanghang Tong"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.23204v1",
    "arxiv_url": "https://arxiv.org/abs/2601.23204v1",
    "fetched_at": "2026-02-02T08:50:56.634458"
  },
  {
    "id": "2601.23188v1",
    "title": "Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience",
    "abstract": "Deep search agents powered by large language models have demonstrated strong capabilities in multi-step retrieval, reasoning, and long-horizon task execution. However, their practical failures often stem from the lack of mechanisms to monitor and regulate reasoning and retrieval states as tasks evolve under uncertainty. Insights from cognitive neuroscience suggest that human metacognition is hierarchically organized, integrating fast anomaly detection with selectively triggered, experience-driven reflection. In this work, we propose Deep Search with Meta-Cognitive Monitoring (DS-MCM), a deep search framework augmented with an explicit hierarchical metacognitive monitoring mechanism. DS-MCM integrates a Fast Consistency Monitor, which performs lightweight checks on the alignment between external evidence and internal reasoning confidence, and a Slow Experience-Driven Monitor, which is selectively activated to guide corrective intervention based on experience memory from historical agent trajectories. By embedding monitoring directly into the reasoning-retrieval loop, DS-MCM determines both when intervention is warranted and how corrective actions should be informed by prior experience. Experiments across multiple deep search benchmarks and backbone models demonstrate that DS-MCM consistently improves performance and robustness.",
    "authors": [
      "Zhongxiang Sun",
      "Qipeng Wang",
      "Weijie Yu",
      "Jingxuan Yang",
      "Haolang Lu",
      "Jun Xu"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.23188v1",
    "arxiv_url": "https://arxiv.org/abs/2601.23188v1",
    "fetched_at": "2026-02-02T08:50:56.634485"
  },
  {
    "id": "2601.23147v1",
    "title": "Securing Time in Energy IoT: A Clock-Dynamics-Aware Spatio-Temporal Graph Attention Network for Clock Drift Attacks and Y2K38 Failures",
    "abstract": "The integrity of time in distributed Internet of Things (IoT) devices is crucial for reliable operation in energy cyber-physical systems, such as smart grids and microgrids. However, IoT systems are vulnerable to clock drift, time-synchronization manipulation, and timestamp discontinuities, such as the Year 2038 (Y2K38) Unix overflow, all of which disrupt temporal ordering. Conventional anomaly-detection models, which assume reliable timestamps, fail to capture temporal inconsistencies. This paper introduces STGAT (Spatio-Temporal Graph Attention Network), a framework that models both temporal distortion and inter-device consistency in energy IoT systems. STGAT combines drift-aware temporal embeddings and temporal self-attention to capture corrupted time evolution at individual devices, and uses graph attention to model spatial propagation of timing errors. A curvature-regularized latent representation geometrically separates normal clock evolution from anomalies caused by drift, synchronization offsets, and overflow events. Experimental results on energy IoT telemetry with controlled timing perturbations show that STGAT achieves 95.7% accuracy, outperforming recurrent, transformer, and graph-based baselines with significant improvements (d > 1.8, p < 0.001). Additionally, STGAT reduces detection delay by 26%, achieving a 2.3-time-step delay while maintaining stable performance under overflow, drift, and physical inconsistencies.",
    "authors": [
      "Saeid Jamshidi",
      "Omar Abdul Wahab",
      "Rolando Herrero",
      "Foutse Khomh"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.23147v1",
    "arxiv_url": "https://arxiv.org/abs/2601.23147v1",
    "fetched_at": "2026-02-02T08:50:56.634510"
  },
  {
    "id": "2601.23114v1",
    "title": "To See Far, Look Close: Evolutionary Forecasting for Long-term Time Series",
    "abstract": "The prevailing Direct Forecasting (DF) paradigm dominates Long-term Time Series Forecasting (LTSF) by forcing models to predict the entire future horizon in a single forward pass. While efficient, this rigid coupling of output and evaluation horizons necessitates computationally prohibitive re-training for every target horizon. In this work, we uncover a counter-intuitive optimization anomaly: models trained on short horizons-when coupled with our proposed Evolutionary Forecasting (EF) paradigm-significantly outperform those trained directly on long horizons. We attribute this success to the mitigation of a fundamental optimization pathology inherent in DF, where conflicting gradients from distant futures cripple the learning of local dynamics. We establish EF as a unified generative framework, proving that DF is merely a degenerate special case of EF. Extensive experiments demonstrate that a singular EF model surpasses task-specific DF ensembles across standard benchmarks and exhibits robust asymptotic stability in extreme extrapolation. This work propels a paradigm shift in LTSF: moving from passive Static Mapping to autonomous Evolutionary Reasoning.",
    "authors": [
      "Jiaming Ma",
      "Siyuan Mu",
      "Ruilin Tang",
      "Haofeng Ma",
      "Qihe Huang",
      "Zhengyang Zhou",
      "Pengkun Wang",
      "Binwu Wang",
      "Yang Wang"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.23114v1",
    "arxiv_url": "https://arxiv.org/abs/2601.23114v1",
    "fetched_at": "2026-02-02T08:50:56.634542"
  },
  {
    "id": "2601.23066v1",
    "title": "Towards Explicit Acoustic Evidence Perception in Audio LLMs for Speech Deepfake Detection",
    "abstract": "Speech deepfake detection (SDD) focuses on identifying whether a given speech signal is genuine or has been synthetically generated. Existing audio large language model (LLM)-based methods excel in content understanding; however, their predictions are often biased toward semantically correlated cues, which results in fine-grained acoustic artifacts being overlooked during the decisionmaking process. Consequently, fake speech with natural semantics can bypass detectors despite harboring subtle acoustic anomalies; this suggests that the challenge stems not from the absence of acoustic data, but from its inadequate accessibility when semantic-dominant reasoning prevails. To address this issue, we investigate SDD within the audio LLM paradigm and introduce SDD with Auditory Perception-enhanced Audio Large Language Model (SDD-APALLM), an acoustically enhanced framework designed to explicitly expose fine-grained time-frequency evidence as accessible acoustic cues. By combining raw audio with structured spectrograms, the proposed framework empowers audio LLMs to more effectively capture subtle acoustic inconsistencies without compromising their semantic understanding. Experimental results indicate consistent gains in detection accuracy and robustness, especially in cases where semantic cues are misleading. Further analysis reveals that these improvements stem from a coordinated utilization of semantic and acoustic information, as opposed to simple modality aggregation.",
    "authors": [
      "Xiaoxuan Guo",
      "Yuankun Xie",
      "Haonan Cheng",
      "Jiayi Zhou",
      "Jian Liu",
      "Hengyan Huang",
      "Long Ye",
      "Qin Zhang"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.23066v1",
    "arxiv_url": "https://arxiv.org/abs/2601.23066v1",
    "fetched_at": "2026-02-02T08:50:56.634572"
  },
  {
    "id": "2601.23026v1",
    "title": "Causal Characterization of Measurement and Mechanistic Anomalies",
    "abstract": "Root cause analysis of anomalies aims to identify those features that cause the deviation from the normal process. Existing methods ignore, however, that anomalies can arise through two fundamentally different processes: measurement errors, where data was generated normally but one or more values were recorded incorrectly, and mechanism shifts, where the causal process generating the data changed. While measurement errors can often be safely corrected, mechanistic anomalies require careful consideration. We define a causal model that explicitly captures both types by treating outliers as latent interventions on latent (\"true\") and observed (\"measured\") variables. We show that they are identifiable, and propose a maximum likelihood estimation approach to put this to practice. Experiments show that our method matches state-of-the-art performance in root cause localization, while it additionally enables accurate classification of anomaly types, and remains robust even when the causal DAG is unknown.",
    "authors": [
      "Hendrik Suhr",
      "David Kaltenpoth",
      "Jilles Vreeken"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.23026v1",
    "arxiv_url": "https://arxiv.org/abs/2601.23026v1",
    "fetched_at": "2026-02-02T08:50:56.634593"
  },
  {
    "id": "2601.22997v1",
    "title": "TriCEGAR: A Trace-Driven Abstraction Mechanism for Agentic AI",
    "abstract": "Agentic AI systems act through tools and evolve their behavior over long, stochastic interaction traces. This setting complicates assurance, because behavior depends on nondeterministic environments and probabilistic model outputs. Prior work introduced runtime verification for agentic AI via Dynamic Probabilistic Assurance (DPA), learning an MDP online and model checking quantitative properties. A key limitation is that developers must manually define the state abstraction, which couples verification to application-specific heuristics and increases adoption friction. This paper proposes TriCEGAR, a trace-driven abstraction mechanism that automates state construction from execution logs and supports online construction of an agent behavioral MDP. TriCEGAR represents abstractions as predicate trees learned from traces and refined using counterexamples. We describe a framework-native implementation that (i) captures typed agent lifecycle events, (ii) builds abstractions from traces, (iii) constructs an MDP, and (iv) performs probabilistic model checking to compute bounds such as Pmax(success) and Pmin(failure). We also show how run likelihoods enable anomaly detection as a guardrailing signal.",
    "authors": [
      "Roham Koohestani",
      "Ateş Görpelioğlu",
      "Egor Klimov",
      "Burcu Kulahcioglu Ozkan",
      "Maliheh Izadi"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22997v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22997v1",
    "fetched_at": "2026-02-02T08:50:56.634617"
  },
  {
    "id": "2601.22868v1",
    "title": "When Anomalies Depend on Context: Learning Conditional Compatibility for Anomaly Detection",
    "abstract": "Anomaly detection is often formulated under the assumption that abnormality is an intrinsic property of an observation, independent of context. This assumption breaks down in many real-world settings, where the same object or action may be normal or anomalous depending on latent contextual factors (e.g., running on a track versus on a highway). We revisit \\emph{contextual anomaly detection}, classically defined as context-dependent abnormality, and operationalize it in the visual domain, where anomaly labels depend on subject--context compatibility rather than intrinsic appearance. To enable systematic study of this setting, we introduce CAAD-3K, a benchmark that isolates contextual anomalies by controlling subject identity while varying context. We further propose a conditional compatibility learning framework that leverages vision--language representations to model subject--context relationships under limited supervision. Our method substantially outperforms existing approaches on CAAD-3K and achieves state-of-the-art performance on MVTec-AD and VisA, demonstrating that modeling context dependence complements traditional structural anomaly detection. Our code and dataset will be publicly released.",
    "authors": [
      "Shashank Mishra",
      "Didier Stricker",
      "Jason Rambach"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22868v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22868v1",
    "fetched_at": "2026-02-02T08:50:56.634638"
  },
  {
    "id": "2601.22806v1",
    "title": "Aligning the Unseen in Attributed Graphs: Interplay between Graph Geometry and Node Attributes Manifold",
    "abstract": "The standard approach to representation learning on attributed graphs -- i.e., simultaneously reconstructing node attributes and graph structure -- is geometrically flawed, as it merges two potentially incompatible metric spaces. This forces a destructive alignment that erodes information about the graph's underlying generative process. To recover this lost signal, we introduce a custom variational autoencoder that separates manifold learning from structural alignment. By quantifying the metric distortion needed to map the attribute manifold onto the graph's Heat Kernel, we transform geometric conflict into an interpretable structural descriptor. Experiments show our method uncovers connectivity patterns and anomalies undetectable by conventional approaches, proving both their theoretical inadequacy and practical limitations.",
    "authors": [
      "Aldric Labarthe",
      "Roland Bouffanais",
      "Julien Randon-Furling"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.AI",
      "math.DG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22806v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22806v1",
    "fetched_at": "2026-02-02T08:50:56.634660"
  },
  {
    "id": "2601.22800v1",
    "title": "Trackly: A Unified SaaS Platform for User Behavior Analytics and Real Time Rule Based Anomaly Detection",
    "abstract": "Understanding user behavior is essential for improving digital experiences, optimizing business conversions, and mitigating threats like account takeovers, fraud, and bot attacks. Most platforms separate product analytics and security, creating fragmented visibility and delayed threat detection. Trackly, a scalable SaaS platform, unifies comprehensive user behavior analytics with real time, rule based anomaly detection. It tracks sessions, IP based geo location, device browser fingerprints, and granular events such as page views, add to cart, and checkouts. Suspicious activities logins from new devices or locations, impossible travel (Haversine formula), rapid bot like actions, VPN proxy usage, or multiple accounts per IP are flagged via configurable rules with weighted risk scoring, enabling transparent, explainable decisions. A real time dashboard provides global session maps, DAU MAU, bounce rates, and session durations. Integration is simplified with a lightweight JavaScript SDK and secure REST APIs. Implemented on a multi tenant microservices stack (ASP.NET Core, MongoDB, RabbitMQ, Next.js), Trackly achieved 98.1% accuracy, 97.7% precision, and 2.25% false positives on synthetic datasets, proving its efficiency for SMEs and ecommerce.",
    "authors": [
      "Md Zahurul Haque",
      "Md. Hafizur Rahman",
      "Yeahyea Sarker"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22800v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22800v1",
    "fetched_at": "2026-02-02T08:50:56.634681"
  },
  {
    "id": "2601.22742v1",
    "title": "AR-BENCH: Benchmarking Legal Reasoning with Judgment Error Detection, Classification and Correction",
    "abstract": "Legal judgments may contain errors due to the complexity of case circumstances and the abstract nature of legal concepts, while existing appellate review mechanisms face efficiency pressures from a surge in case volumes. Although current legal AI research focuses on tasks like judgment prediction and legal document generation, the task of judgment review differs fundamentally in its objectives and paradigm: it centers on detecting, classifying, and correcting errors after a judgment is issued, constituting anomaly detection rather than prediction or generation. To address this research gap, we introduce a novel task APPELLATE REVIEW, aiming to assess models' diagnostic reasoning and reliability in legal practice. We also construct a novel dataset benchmark AR-BENCH, which comprises 8,700 finely annotated decisions and 34,617 supplementary corpora. By evaluating 14 large language models, we reveal critical limitations in existing models' ability to identify legal application errors, providing empirical evidence for future improvements.",
    "authors": [
      "Yifei Li",
      "Richong Zhang",
      "Wanyu Tu",
      "Zhijie Nie",
      "Haokun Luo",
      "Chuantao Yin",
      "Pengchong Li"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22742v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22742v1",
    "fetched_at": "2026-02-02T08:50:56.634709"
  },
  {
    "id": "2601.22675v1",
    "title": "Fire on Motion: Optimizing Video Pass-bands for Efficient Spiking Action Recognition",
    "abstract": "Spiking neural networks (SNNs) have gained traction in vision due to their energy efficiency, bio-plausibility, and inherent temporal processing. Yet, despite this temporal capacity, most progress concentrates on static image benchmarks, and SNNs still underperform on dynamic video tasks compared to artificial neural networks (ANNs). In this work, we diagnose a fundamental pass-band mismatch: Standard spiking dynamics behave as a temporal low pass that emphasizes static content while attenuating motion bearing bands, where task relevant information concentrates in dynamic tasks. This phenomenon explains why SNNs can approach ANNs on static tasks yet fall behind on tasks that demand richer temporal understanding.To remedy this, we propose the Pass-Bands Optimizer (PBO), a plug-and-play module that optimizes the temporal pass-band toward task-relevant motion bands. PBO introduces only two learnable parameters, and a lightweight consistency constraint that preserves semantics and boundaries, incurring negligible computational overhead and requires no architectural changes. PBO deliberately suppresses static components that contribute little to discrimination, effectively high passing the stream so that spiking activity concentrates on motion bearing content. On UCF101, PBO yields over ten percentage points improvement. On more complex multi-modal action recognition and weakly supervised video anomaly detection, PBO delivers consistent and significant gains, offering a new perspective for SNN based video processing and understanding.",
    "authors": [
      "Shuhan Ye",
      "Yuanbin Qian",
      "Yi Yu",
      "Chong Wang",
      "Yuqi Xie",
      "Jiazhen Xu",
      "Kun Wang",
      "Xudong Jiang"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22675v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22675v1",
    "fetched_at": "2026-02-02T08:50:56.634738"
  },
  {
    "id": "2601.22399v1",
    "title": "Score-based Integrated Gradient for Root Cause Explanations of Outliers",
    "abstract": "Identifying the root causes of outliers is a fundamental problem in causal inference and anomaly detection. Traditional approaches based on heuristics or counterfactual reasoning often struggle under uncertainty and high-dimensional dependencies. We introduce SIREN, a novel and scalable method that attributes the root causes of outliers by estimating the score functions of the data likelihood. Attribution is computed via integrated gradients that accumulate score contributions along paths from the outlier toward the normal data distribution. Our method satisfies three of the four classic Shapley value axioms - dummy, efficiency, and linearity - as well as an asymmetry axiom derived from the underlying causal structure. Unlike prior work, SIREN operates directly on the score function, enabling tractable and uncertainty-aware root cause attribution in nonlinear, high-dimensional, and heteroscedastic causal models. Extensive experiments on synthetic random graphs and real-world cloud service and supply chain datasets show that SIREN outperforms state-of-the-art baselines in both attribution accuracy and computational efficiency.",
    "authors": [
      "Phuoc Nguyen",
      "Truyen Tran",
      "Sunil Gupta",
      "Svetha Venkatesh"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22399v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22399v1",
    "fetched_at": "2026-02-02T08:50:56.634760"
  },
  {
    "id": "2601.23252v1",
    "title": "Nested Slice Sampling: Vectorized Nested Sampling for GPU-Accelerated Inference",
    "abstract": "Model comparison and calibrated uncertainty quantification often require integrating over parameters, but scalable inference can be challenging for complex, multimodal targets. Nested Sampling is a robust alternative to standard MCMC, yet its typically sequential structure and hard constraints make efficient accelerator implementations difficult. This paper introduces Nested Slice Sampling (NSS), a GPU-friendly, vectorized formulation of Nested Sampling that uses Hit-and-Run Slice Sampling for constrained updates. A tuning analysis yields a simple near-optimal rule for setting the slice width, improving high-dimensional behavior and making per-step compute more predictable for parallel execution. Experiments on challenging synthetic targets, high dimensional Bayesian inference, and Gaussian process hyperparameter marginalization show that NSS maintains accurate evidence estimates and high-quality posterior samples, and is particularly robust on difficult multimodal problems where current state-of-the-art methods such as tempered SMC baselines can struggle. An open-source implementation is released to facilitate adoption and reproducibility.",
    "authors": [
      "David Yallup",
      "Namu Kroupa",
      "Will Handley"
    ],
    "published": "2026-01-30",
    "categories": [
      "stat.CO",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.23252v1",
    "arxiv_url": "https://arxiv.org/abs/2601.23252v1",
    "fetched_at": "2026-02-02T08:51:25.177410"
  },
  {
    "id": "2601.23207v1",
    "title": "Learning to Execute Graph Algorithms Exactly with Graph Neural Networks",
    "abstract": "Understanding what graph neural networks can learn, especially their ability to learn to execute algorithms, remains a central theoretical challenge. In this work, we prove exact learnability results for graph algorithms under bounded-degree and finite-precision constraints. Our approach follows a two-step process. First, we train an ensemble of multi-layer perceptrons (MLPs) to execute the local instructions of a single node. Second, during inference, we use the trained MLP ensemble as the update function within a graph neural network (GNN). Leveraging Neural Tangent Kernel (NTK) theory, we show that local instructions can be learned from a small training set, enabling the complete graph algorithm to be executed during inference without error and with high probability. To illustrate the learning power of our setting, we establish a rigorous learnability result for the LOCAL model of distributed computation. We further demonstrate positive learnability results for widely studied algorithms such as message flooding, breadth-first and depth-first search, and Bellman-Ford.",
    "authors": [
      "Muhammad Fetrat Qharabagh",
      "Artur Back de Luca",
      "George Giapitzakis",
      "Kimon Fountoulakis"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.23207v1",
    "arxiv_url": "https://arxiv.org/abs/2601.23207v1",
    "fetched_at": "2026-02-02T08:51:25.177444"
  },
  {
    "id": "2601.23132v1",
    "title": "Secure Tool Manifest and Digital Signing Solution for Verifiable MCP and LLM Pipelines",
    "abstract": "Large Language Models (LLMs) are increasingly adopted in sensitive domains such as healthcare and financial institutions' data analytics; however, their execution pipelines remain vulnerable to manipulation and unverifiable behavior. Existing control mechanisms, such as the Model Context Protocol (MCP), define compliance policies for tool invocation but lack verifiable enforcement and transparent validation of model actions. To address this gap, we propose a novel Secure Tool Manifest and Digital Signing Framework, a structured and security-aware extension of Model Context Protocols. The framework enforces cryptographically signed manifests, integrates transparent verification logs, and isolates model-internal execution metadata from user-visible components to ensure verifiable execution integrity. Furthermore, the evaluation demonstrates that the framework scales nearly linearly (R-squared = 0.998), achieves near-perfect acceptance of valid executions while consistently rejecting invalid ones, and maintains balanced model utilization across execution pipelines.",
    "authors": [
      "Saeid Jamshidi",
      "Kawser Wazed Nafi",
      "Arghavan Moradi Dakhel",
      "Foutse Khomh",
      "Amin Nikanjam",
      "Mohammad Adnan Hamdaqa"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.23132v1",
    "arxiv_url": "https://arxiv.org/abs/2601.23132v1",
    "fetched_at": "2026-02-02T08:51:25.177501"
  },
  {
    "id": "2601.23092v1",
    "title": "WiFiPenTester: Advancing Wireless Ethical Hacking with Governed GenAI",
    "abstract": "Wireless ethical hacking relies heavily on skilled practitioners manually interpreting reconnaissance results and executing complex, time-sensitive sequences of commands to identify vulnerable targets, capture authentication handshakes, and assess password resilience; a process that is inherently labour-intensive, difficult to scale, and prone to subjective judgement and human error. To help address these limitations, we propose WiFiPenTester, an experimental, governed, and reproducible system for GenAI-enabled wireless ethical hacking. The system integrates large language models into the reconnaissance and decision-support phases of wireless security assessment, enabling intelligent target ranking, attack feasibility estimation, and strategy recommendation, while preserving strict human-in-the-loop control and budget-aware execution. We describe the system architecture, threat model, governance mechanisms, and prompt-engineering methodology, and empirical experiments conducted across multiple wireless environments. The results demonstrate that GenAI assistance improves target selection accuracy and overall assessment efficiency, while maintaining auditability and ethical safeguards. This indicates that WiFiPenTester is a meaningful step toward practical, safe, and scalable GenAI-assisted wireless penetration testing, while reinforcing the necessity of bounded autonomy, human oversight, and rigorous governance mechanisms when deploying GenAI in ethical hacking.",
    "authors": [
      "Haitham S. Al-Sinani",
      "Chris J. Mitchell"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.23092v1",
    "arxiv_url": "https://arxiv.org/abs/2601.23092v1",
    "fetched_at": "2026-02-02T08:51:25.177522"
  },
  {
    "id": "2601.23027v1",
    "title": "Divide-and-Conquer CoT: RL for Reducing Latency via Parallel Reasoning",
    "abstract": "Long chain-of-thought reasoning (Long CoT) is now fundamental to state-of-the-art LLMs, especially in mathematical reasoning. However, LLM generation is highly sequential, and long CoTs lead to a high latency. We propose to train Divide-and-Conquer CoT (DC-CoT) to reduce the latency. With DC-CoT, the model can act as a director that identifies distinct subtasks that can be performed in parallel in its reasoning process, and then spawns workers to execute the subtasks. Our goal is to achieve high accuracy, with a low longest path length, which is a theoretical measure of the latency needed for the response. We start with a long CoT base model (DeepScaleR-1.5B-Preview), and first use SFT with a small curated demonstration set to initialize its ability to spawn workers in a certain format. Because SFT degrades the accuracy significantly, we design a multi-stage RL algorithm, with various data filtering strategies, to recover the accuracy while decreasing the longest path length. Across several benchmarks including AIME 2024 and HMMT 2025, DC-CoT achieves similar accuracy as DeepScaleR-1.5B-Preview while decreasing longest path length by 35-40%. Our code, SFT dataset and models are publicly available at https://github.com/amahankali10/DC_CoT_RL_for_Low_Latency_CoT_with_Parallel_Reasoning.",
    "authors": [
      "Arvind Mahankali",
      "Kaiyue Wen",
      "Tengyu Ma"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.23027v1",
    "arxiv_url": "https://arxiv.org/abs/2601.23027v1",
    "fetched_at": "2026-02-02T08:51:25.177544"
  },
  {
    "id": "2601.22948v1",
    "title": "Alignment among Language, Vision and Action Representations",
    "abstract": "A fundamental question in cognitive science and AI concerns whether different learning modalities: language, vision, and action, give rise to distinct or shared internal representations. Traditional views assume that models trained on different data types develop specialized, non-transferable representations. However, recent evidence suggests unexpected convergence: models optimized for distinct tasks may develop similar representational geometries. We investigate whether this convergence extends to embodied action learning by training a transformer-based agent to execute goal-directed behaviors in response to natural language instructions. Using behavioral cloning on the BabyAI platform, we generated action-grounded language embeddings shaped exclusively by sensorimotor control requirements. We then compared these representations with those extracted from state-of-the-art large language models (LLaMA, Qwen, DeepSeek, BERT) and vision-language models (CLIP, BLIP). Despite substantial differences in training data, modality, and objectives, we observed robust cross-modal alignment. Action representations aligned strongly with decoder-only language models and BLIP (precision@15: 0.70-0.73), approaching the alignment observed among language models themselves. Alignment with CLIP and BERT was significantly weaker. These findings indicate that linguistic, visual, and action representations converge toward partially shared semantic structures, supporting modality-independent semantic organization and highlighting potential for cross-domain transfer in embodied AI systems.",
    "authors": [
      "Nicola Milano",
      "Stefano Nolfi"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22948v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22948v1",
    "fetched_at": "2026-02-02T08:51:25.177595"
  },
  {
    "id": "2601.22859v1",
    "title": "MEnvAgent: Scalable Polyglot Environment Construction for Verifiable Software Engineering",
    "abstract": "The evolution of Large Language Model (LLM) agents for software engineering (SWE) is constrained by the scarcity of verifiable datasets, a bottleneck stemming from the complexity of constructing executable environments across diverse languages. To address this, we introduce MEnvAgent, a Multi-language framework for automated Environment construction that facilitates scalable generation of verifiable task instances. MEnvAgent employs a multi-agent Planning-Execution-Verification architecture to autonomously resolve construction failures and integrates a novel Environment Reuse Mechanism that reduces computational overhead by incrementally patching historical environments. Evaluations on MEnvBench, a new benchmark comprising 1,000 tasks across 10 languages, demonstrate that MEnvAgent outperforms baselines, improving Fail-to-Pass (F2P) rates by 8.6% while reducing time costs by 43%. Additionally, we demonstrate the utility of MEnvAgent by constructing MEnvData-SWE, the largest open-source polyglot dataset of realistic verifiable Docker environments to date, alongside solution trajectories that enable consistent performance gains on SWE tasks across a wide range of models. Our code, benchmark, and dataset are available at https://github.com/ernie-research/MEnvAgent.",
    "authors": [
      "Chuanzhe Guo",
      "Jingjing Wu",
      "Sijun He",
      "Yang Chen",
      "Zhaoqi Kuang",
      "Shilong Fan",
      "Bingjin Chen",
      "Siqi Bao",
      "Jing Liu",
      "Hua Wu",
      "Qingfu Zhu",
      "Wanxiang Che",
      "Haifeng Wang"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22859v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22859v1",
    "fetched_at": "2026-02-02T08:51:25.177638"
  },
  {
    "id": "2601.22813v1",
    "title": "Quartet II: Accurate LLM Pre-Training in NVFP4 by Improved Unbiased Gradient Estimation",
    "abstract": "The NVFP4 lower-precision format, supported in hardware by NVIDIA Blackwell GPUs, promises to allow, for the first time, end-to-end fully-quantized pre-training of massive models such as LLMs. Yet, existing quantized training methods still sacrifice some of the representation capacity of this format in favor of more accurate unbiased quantized gradient estimation by stochastic rounding (SR), losing noticeable accuracy relative to standard FP16 and FP8 training. In this paper, improve the state of the art for quantized training in NVFP4 via a novel unbiased quantization routine for micro-scaled formats, called MS-EDEN, that has more than 2x lower quantization error than SR. We integrate it into a novel fully-NVFP4 quantization scheme for linear layers, called Quartet II. We show analytically that Quartet II achieves consistently better gradient estimation across all major matrix multiplications, both on the forward and on the backward passes. In addition, our proposal synergizes well with recent training improvements aimed specifically at NVFP4. We further validate Quartet II on end-to-end LLM training with up to 1.9B parameters on 38B tokens. We provide kernels for execution on NVIDIA Blackwell GPUs with up to 4.2x speedup over BF16. Our code is available at https://github.com/IST-DASLab/Quartet-II .",
    "authors": [
      "Andrei Panferov",
      "Erik Schultheis",
      "Soroush Tabesh",
      "Dan Alistarh"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22813v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22813v1",
    "fetched_at": "2026-02-02T08:51:25.177662"
  },
  {
    "id": "2601.22803v1",
    "title": "CVeDRL: An Efficient Code Verifier via Difficulty-aware Reinforcement Learning",
    "abstract": "Code verifiers play a critical role in post-verification for LLM-based code generation, yet existing supervised fine-tuning methods suffer from data scarcity, high failure rates, and poor inference efficiency. While reinforcement learning (RL) offers a promising alternative by optimizing models through execution-driven rewards without labeled supervision, our preliminary results show that naive RL with only functionality rewards fails to generate effective unit tests for difficult branches and samples. We first theoretically analyze showing that branch coverage, sample difficulty, syntactic and functional correctness can be jointly modeled as RL rewards, where optimizing these signals can improve the reliability of unit-test-based verification. Guided by this analysis, we design syntax- and functionality-aware rewards and further propose branch- and sample-difficulty--aware RL using exponential reward shaping and static analysis metrics. With this formulation, CVeDRL achieves state-of-the-art performance with only 0.6B parameters, yielding up to 28.97% higher pass rate and 15.08% higher branch coverage than GPT-3.5, while delivering over $20\\times$ faster inference than competitive baselines. Code is available at https://github.com/LIGHTCHASER1/CVeDRL.git",
    "authors": [
      "Ji Shi",
      "Peiming Guo",
      "Meishan Zhang",
      "Miao Zhang",
      "Xuebo Liu",
      "Min Zhang",
      "Weili Guan"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22803v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22803v1",
    "fetched_at": "2026-02-02T08:51:25.177693"
  },
  {
    "id": "2601.22760v1",
    "title": "AscendCraft: Automatic Ascend NPU Kernel Generation via DSL-Guided Transcompilation",
    "abstract": "The performance of deep learning models critically depends on efficient kernel implementations, yet developing high-performance kernels for specialized accelerators remains time-consuming and expertise-intensive. While recent work demonstrates that large language models (LLMs) can generate correct and performant GPU kernels, kernel generation for neural processing units (NPUs) remains largely underexplored due to domain-specific programming models, limited public examples, and sparse documentation. Consequently, directly generating AscendC kernels with LLMs yields extremely low correctness, highlighting a substantial gap between GPU and NPU kernel generation.   We present AscendCraft, a DSL-guided approach for automatic AscendC kernel generation. AscendCraft introduces a lightweight DSL that abstracts non-essential complexity while explicitly modeling Ascend-specific execution semantics. Kernels are first generated in the DSL using category-specific expert examples and then transcompiled into AscendC through structured, constraint-driven LLM lowering passes. Evaluated on MultiKernelBench across seven operator categories, AscendCraft achieves 98.1% compilation success and 90.4% functional correctness. Moreover, 46.2% of generated kernels match or exceed PyTorch eager execution performance, demonstrating that DSL-guided transcompilation can enable LLMs to generate both correct and competitive NPU kernels. Beyond benchmarks, AscendCraft further demonstrates its generality by successfully generating two correct kernels for newly proposed mHC architecture, achieving performance that substantially surpasses PyTorch eager execution.",
    "authors": [
      "Zhongzhen Wen",
      "Shudi Shao",
      "Zhong Li",
      "Yu Ge",
      "Tongtong Xu",
      "Yuanyi Lin",
      "Tian Zhang"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.DC",
      "cs.LG",
      "cs.PF",
      "cs.SE"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22760v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22760v1",
    "fetched_at": "2026-02-02T08:51:25.177725"
  },
  {
    "id": "2601.22758v1",
    "title": "AutoRefine: From Trajectories to Reusable Expertise for Continual LLM Agent Refinement",
    "abstract": "Large language model agents often fail to accumulate knowledge from experience, treating each task as an independent challenge. Recent methods extract experience as flattened textual knowledge, which cannot capture procedural logic of complex subtasks. They also lack maintenance mechanisms, causing repository degradation as experience accumulates. We introduce AutoRefine, a framework that extracts and maintains dual-form Experience Patterns from agent execution histories. For procedural subtasks, we extract specialized subagents with independent reasoning and memory. For static knowledge, we extract skill patterns as guidelines or code snippets. A continuous maintenance mechanism scores, prunes, and merges patterns to prevent repository degradation. Evaluated on ALFWorld, ScienceWorld, and TravelPlanner, AutoRefine achieves 98.4%, 70.4%, and 27.1% respectively, with 20-73% step reductions. On TravelPlanner, automatic extraction exceeds manually designed systems (27.1% vs 12.1%), demonstrating its ability to capture procedural coordination.",
    "authors": [
      "Libin Qiu",
      "Zhirong Gao",
      "Junfu Chen",
      "Yuhang Ye",
      "Weizhi Huang",
      "Xiaobo Xue",
      "Wenkai Qiu",
      "Shuo Tang"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22758v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22758v1",
    "fetched_at": "2026-02-02T08:51:25.177757"
  },
  {
    "id": "2601.22720v1",
    "title": "AEGIS: White-Box Attack Path Generation using LLMs and Training Effectiveness Evaluation for Large-Scale Cyber Defence Exercises",
    "abstract": "Creating attack paths for cyber defence exercises requires substantial expert effort. Existing automation requires vulnerability graphs or exploit sets curated in advance, limiting where it can be applied. We present AEGIS, a system that generates attack paths using LLMs, white-box access, and Monte Carlo Tree Search over real exploit execution. LLM-based search discovers exploits dynamically without pre-existing vulnerability graphs, while white-box access enables validating exploits in isolation before committing to attack paths. Evaluation at CIDeX 2025, a large-scale exercise spanning 46 IT hosts, showed that AEGIS-generated paths are comparable to human-authored scenarios across four dimensions of training experience (perceived learning, engagement, believability, challenge). Results were measured with a validated questionnaire extensible to general simulation-based training. By automating exploit chain discovery and validation, AEGIS reduces scenario development from months to days, shifting expert effort from technical validation to scenario design.",
    "authors": [
      "Ivan K. Tung",
      "Yu Xiang Shi",
      "Alex Chien",
      "Wenkai Liu",
      "Lawrence Zheng"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22720v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22720v1",
    "fetched_at": "2026-02-02T08:51:25.177783"
  },
  {
    "id": "2601.22701v1",
    "title": "Best-of-Q: Improving VLM agents with Q-function Action Ranking at Inference",
    "abstract": "Vision-Language Models (VLMs) have become powerful backbones for agents to autonomously operate in digital environments like the web and operating systems. However, these models suffer from inadaptability to fast-changing environments like the web, which can be alleviated by fine-tuning requiring expansive model training and data collection. In this work, we introduce a novel paradigm for enhancing agentic VLM policies at inference without policy retraining. Fundamentally, our approach decouples the VLM's role as a high-capacity action proposer from the final action selection mechanism. We keep the VLM policy frozen and use it to generate a set of candidate actions for a given state. Then, a lightweight, offline-trained Q-function reranks these candidates, and the agent executes the action with the highest estimated value. The main contribution is to apply the Q-function directly during inference for immediate policy improvement, and not offline to relabel data for policy retraining. We demonstrate on the academic WebVoyager benchmark that our method significantly boosts agent success rates, improving a Qwen2.5-VL-7B agent from 38.8% to 55.7% and a proprietary GPT-4.1 agent from 82.4% to 88.8%.",
    "authors": [
      "Emilien Biré",
      "María Santos",
      "Kai Yuan"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22701v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22701v1",
    "fetched_at": "2026-02-02T08:51:25.177804"
  },
  {
    "id": "2601.23088v1",
    "title": "From Similarity to Vulnerability: Key Collision Attack on LLM Semantic Caching",
    "abstract": "Semantic caching has emerged as a pivotal technique for scaling LLM applications, widely adopted by major providers including AWS and Microsoft. By utilizing semantic embedding vectors as cache keys, this mechanism effectively minimizes latency and redundant computation for semantically similar queries. In this work, we conceptualize semantic cache keys as a form of fuzzy hashes. We demonstrate that the locality required to maximize cache hit rates fundamentally conflicts with the cryptographic avalanche effect necessary for collision resistance. Our conceptual analysis formalizes this inherent trade-off between performance (locality) and security (collision resilience), revealing that semantic caching is naturally vulnerable to key collision attacks.   While prior research has focused on side-channel and privacy risks, we present the first systematic study of integrity risks arising from cache collisions. We introduce CacheAttack, an automated framework for launching black-box collision attacks. We evaluate CacheAttack in security-critical tasks and agentic workflows. It achieves a hit rate of 86\\% in LLM response hijacking and can induce malicious behaviors in LLM agent, while preserving strong transferability across different embedding models. A case study on a financial agent further illustrates the real-world impact of these vulnerabilities. Finally, we discuss mitigation strategies.",
    "authors": [
      "Zhixiang Zhang",
      "Zesen Liu",
      "Yuchong Xie",
      "Quanfeng Huang",
      "Dongdong She"
    ],
    "published": "2026-01-30",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.23088v1",
    "arxiv_url": "https://arxiv.org/abs/2601.23088v1",
    "fetched_at": "2026-02-02T08:52:03.439068"
  }
]