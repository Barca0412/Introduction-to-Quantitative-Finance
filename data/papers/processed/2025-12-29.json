[
  {
    "id": "2512.22109v1",
    "title": "Index-Tracking Portfolio Construction and Rebalancing under Bayesian Sparse Modelling and Uncertainty Quantification",
    "abstract": "We study the construction and rebalancing of sparse index-tracking portfolios from an operational research perspective, with explicit emphasis on uncertainty quantification and implementability. The decision variables are portfolio weights constrained to sum to one; the aims are to track a reference index closely while controlling the number of names and the turnover induced by rebalancing. We cast index tracking as a high-dimensional linear regression of index returns on constituent returns, and employ a sparsity-inducing Laplace prior on the weights. A single global shrinkage parameter controls the trade-off between tracking error and sparsity, and is calibrated by an empirical-Bayes stochastic approximation scheme. Conditional on this calibration, we approximate the posterior distribution of the portfolio weights using proximal Langevin-type Markov chain Monte Carlo algorithms tailored to the budget constraint. This yields posterior uncertainty on tracking error, portfolio composition and prospective rebalancing moves. Building on these posterior samples, we propose rules for rebalancing that gate trades through magnitude-based thresholds and posterior activation probabilities, thereby trading off expected tracking error against turnover and portfolio size. A case study on tracking the S&P~500 index is carried out to showcase how our tools shape the decision process from portfolio construction to rebalancing.",
    "authors": [
      "Dimitrios Roxanas"
    ],
    "published": "2025-12-26",
    "categories": [
      "q-fin.CP",
      "math.OC",
      "q-fin.PM",
      "stat.AP",
      "stat.CO"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.22109v1",
    "arxiv_url": "https://arxiv.org/abs/2512.22109v1",
    "fetched_at": "2025-12-29T08:36:34.606108",
    "chinese_title": "贝叶斯稀疏建模与不确定性量化下的指数跟踪投资组合构建与再平衡",
    "chinese_summary": "本文从运筹学视角研究稀疏指数跟踪投资组合的构建与再平衡，明确关注不确定性量化与可实施性；将指数跟踪建模为高维线性回归，采用拉普拉斯先验实现权重稀疏，通过经验贝叶斯随机近似校准收缩参数，并用近端朗之万MCMC近似权重后验分布；基于后验样本提出带阈值与激活概率的再平衡规则，平衡跟踪误差、 turnover与组合规模，以标普500为例验证方法有效性。",
    "tags": [
      "Portfolio Optimization",
      "Benchmark",
      "Risk Management"
    ],
    "key_contributions": [
      "提出结合贝叶斯稀疏建模与不确定性量化的指数跟踪组合构建框架，通过经验贝叶斯校准收缩参数，用近端朗之万MCMC近似权重后验分布，明确量化组合权重、跟踪误差等的不确定性",
      "基于后验样本设计带阈值与激活概率的再平衡规则，在平衡跟踪误差、 turnover与组合规模方面实现更优的可实施性"
    ],
    "processed_at": "2025-12-29T08:39:53.252481"
  },
  {
    "id": "2512.22001v1",
    "title": "Variational Quantum Eigensolver for Real-World Finance: Scalable Solutions for Dynamic Portfolio Optimization Problems",
    "abstract": "We present a scalable, hardware-aware methodology for extending the Variational Quantum Eigensolver (VQE) to large, realistic Dynamic Portfolio Optimization (DPO) problems. Building on the scaling strategy from our previous work, where we tailored a VQE workflow to both the DPO formulation and the target QPU, we now put forward two significant advances. The first is the implementation of the Ising Sample-based Quantum Configuration Recovery (ISQR) routine, which improves solution quality in Quadratic Unconstrained Binary Optimization problems. The second is the use of the VQE Constrained method to decompose the optimization task, enabling us to handle DPO instances with more variables than the available qubits on current hardware. These advances, which are broadly applicable to other optimization problems, allow us to address a portfolio with a size relevant to the financial industry, consisting of up to 38 assets and covering the full Spanish stock index (IBEX 35). Our results, obtained on a real Quantum Processing Unit (IBM Fez), show that this tailored workflow achieves financial performance on par with classical methods while delivering a broader set of high-quality investment strategies, demonstrating a viable path towards obtaining practical advantage from quantum optimization in real financial applications.",
    "authors": [
      "Irene De León",
      "Danel Arias",
      "Manuel Martín-Cordero",
      "María Esperanza Molina",
      "Pablo Serrano",
      "Senaida Hernández-Santana",
      "Miguel Ángel Jiménez Herrera",
      "Joana Fraxanet",
      "Ginés Carrascal",
      "Escolástico Sánchez",
      "Inmaculada Posadillo",
      "Álvaro Nodar"
    ],
    "published": "2025-12-26",
    "categories": [
      "quant-ph",
      "q-fin.CP",
      "q-fin.PM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.22001v1",
    "arxiv_url": "https://arxiv.org/abs/2512.22001v1",
    "fetched_at": "2025-12-29T08:36:34.606219",
    "chinese_title": "用于现实世界金融的变分量子本征求解器：动态投资组合优化问题的可扩展解决方案",
    "chinese_summary": "本文提出硬件感知的可扩展方法，将变分量子本征求解器（VQE）应用于大规模现实动态投资组合优化（DPO）问题；实现Ising样本基量子配置恢复（ISQR）例程提升二次无约束二进制优化解质量，并用VQE Constrained方法分解任务以处理变量多于硬件量子比特的DPO实例；在IBM Fez量子处理器上验证，可处理38资产（覆盖IBEX35），性能与经典方法相当且提供更多高质量投资策略。",
    "tags": [
      "Portfolio Optimization",
      "Risk Management"
    ],
    "key_contributions": [
      "实现Ising样本基量子配置恢复（ISQR）例程，提升二次无约束二进制优化问题的解质量",
      "采用VQE Constrained方法分解优化任务，支持处理变量数多于现有硬件量子比特的动态投资组合优化（DPO）实例"
    ],
    "processed_at": "2025-12-29T08:40:16.015884"
  },
  {
    "id": "2512.21973v1",
    "title": "When Indemnity Insurance Fails: Parametric Coverage under Binding Budget and Risk Constraints",
    "abstract": "In high-risk environments, traditional indemnity insurance is often unaffordable or ineffective, despite its well-known optimality under expected utility. This paper compares excess-of-loss indemnity insurance with parametric insurance within a common mean-variance framework, allowing for fixed costs, heterogeneous premium loadings, and binding budget constraints. We show that, once these realistic frictions are introduced, parametric insurance can yield higher welfare for risk-averse individuals, even under the same utility objective. The welfare advantage arises precisely when indemnity insurance becomes impractical, and disappears once both contracts are unconstrained. Our results help reconcile classical insurance theory with the growing use of parametric risk transfer in high-risk settings.",
    "authors": [
      "Benjamin Avanzi",
      "Debbie Kusch Falden",
      "Mogens Steffensen"
    ],
    "published": "2025-12-26",
    "categories": [
      "econ.GN",
      "math.OC",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21973v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21973v1",
    "fetched_at": "2025-12-29T08:36:34.606266",
    "chinese_title": "当赔偿保险失效时：约束性预算与风险约束下的参数化保险",
    "chinese_summary": "本文在均值-方差框架下，考虑固定成本、异质保费加载及约束性预算，比较超额损失赔偿保险与参数化保险；研究发现，引入现实摩擦后参数化保险可提升风险厌恶者福利（赔偿保险不切实际时优势显著），无约束时优势消失；结果调和经典保险理论与高风险场景下参数化风险转移的应用。",
    "tags": [
      "Risk Management",
      "Portfolio Optimization"
    ],
    "key_contributions": [
      "首次在含固定成本、异质保费加载及约束性预算的均值-方差框架下，证明参数化保险可突破传统赔偿保险的局限提升风险厌恶者福利",
      "揭示参数化保险福利优势的适用条件，调和经典保险理论与高风险场景下参数化风险转移的实际应用"
    ],
    "processed_at": "2025-12-29T08:40:43.213590"
  },
  {
    "id": "2512.21823v1",
    "title": "Investigating Conditional Restricted Boltzmann Machines in Regime Detection",
    "abstract": "This study investigates the efficacy of Conditional Restricted Boltzmann Machines (CRBMs) for modeling high-dimensional financial time series and detecting systemic risk regimes. We extend the classical application of static Restricted Boltzmann Machines (RBMs) by incorporating autoregressive conditioning and utilizing Persistent Contrastive Divergence (PCD) to incorporate complex temporal dependency structures. Comparing a discrete Bernoulli-Bernoulli architecture against a continuous Gaussian-Bernoulli variant across a multi-asset dataset spanning 2013-2025, we observe a dichotomy between generative fidelity and regime detection. While the Gaussian CRBM successfully preserves static asset correlations, it exhibits limitations in generating long-range volatility clustering. Thus, we analyze the free energy as a relative negative log-likelihood (surprisal) under a fixed, trained model. We demonstrate that the model's free energy serves as a robust, regime stability metric. By decomposing the free energy into quadratic (magnitude) and structural (correlation) components, we show that the model can distinguish between pure magnitude shocks and market regimes. Our findings suggest that the CRBM offers a valuable, interpretable diagnostic tool for monitoring systemic risk, providing a supplemental metric to implied volatility metrics like the VIX.",
    "authors": [
      "Siddhartha Srinivas Rentala"
    ],
    "published": "2025-12-26",
    "categories": [
      "q-fin.ST"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21823v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21823v1",
    "fetched_at": "2025-12-29T08:36:34.606286",
    "chinese_title": "条件限制玻尔兹曼机在机制检测中的研究",
    "chinese_summary": "本研究扩展经典限制玻尔兹曼机（RBM），引入自回归条件和持久对比散度（PCD）构建条件限制玻尔兹曼机（CRBM），用于高维金融时间序列建模与系统风险机制检测；通过比较离散与连续架构，发现模型自由能可作为稳健的机制稳定性指标，分解后能区分纯幅度冲击与市场机制，补充VIX等隐含波动率指标。",
    "tags": [
      "Deep Learning",
      "Time Series",
      "Risk Management",
      "Volatility"
    ],
    "key_contributions": [
      "扩展经典RBM，结合自回归条件与PCD构建CRBM，适配高维金融时间序列的时序依赖建模",
      "证明模型自由能可作为稳健的机制稳定性指标，分解后能区分纯幅度冲击与市场机制，补充VIX等风险度量"
    ],
    "processed_at": "2025-12-29T08:40:55.732839"
  },
  {
    "id": "2512.21798v1",
    "title": "Applications of synthetic financial data in portfolio and risk modeling",
    "abstract": "Synthetic financial data offers a practical way to address the privacy and accessibility challenges that limit research in quantitative finance. This paper examines the use of generative models, in particular TimeGAN and Variational Autoencoders (VAEs), for creating synthetic return series that support portfolio construction, trading analysis, and risk modeling. Using historical daily returns from the S and P 500 as a benchmark, we generate synthetic datasets under comparable market conditions and evaluate them using statistical similarity metrics, temporal structure tests, and downstream financial tasks. The study shows that TimeGAN produces synthetic data with distributional shapes, volatility patterns, and autocorrelation behaviour that are close to those observed in real returns. When applied to mean-variance portfolio optimization, the resulting synthetic datasets lead to portfolio weights, Sharpe ratios, and risk levels that remain close to those obtained from real data. The VAE provides more stable training but tends to smooth extreme market movements, which affects risk estimation. Finally, the analysis supports the use of synthetic datasets as substitutes for real financial data in portfolio analysis and risk simulation, particularly when models are able to capture temporal dynamics. Synthetic data therefore provides a privacy-preserving, cost-effective, and reproducible tool for financial experimentation and model development.",
    "authors": [
      "Christophe D. Hounwanou",
      "Yae Ulrich Gaba"
    ],
    "published": "2025-12-25",
    "categories": [
      "q-fin.ST",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21798v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21798v1",
    "fetched_at": "2025-12-29T08:36:34.606306",
    "chinese_title": "合成金融数据在投资组合与风险建模中的应用",
    "chinese_summary": "论文研究了TimeGAN和变分自编码器（VAE）生成合成金融收益序列的应用，通过S&P500历史日收益验证：TimeGAN生成的数据在分布、波动率等特征上接近真实数据，支持投资组合优化与风险建模；VAE训练稳定但平滑极端波动影响风险估计，合成数据可作为隐私保护的金融实验工具。",
    "tags": [
      "Deep Learning",
      "Time Series",
      "Portfolio Optimization",
      "Risk Management"
    ],
    "key_contributions": [
      "验证TimeGAN生成的合成金融收益序列能较好匹配真实数据的分布、波动率等特征，支持投资组合与风险建模任务",
      "对比TimeGAN与VAE的表现，明确TimeGAN更适合捕捉时间动态，VAE训练稳定但存在极端波动平滑问题，为合成金融数据应用提供方法参考"
    ],
    "processed_at": "2025-12-29T08:41:06.594078"
  },
  {
    "id": "2512.21791v1",
    "title": "Synthetic Financial Data Generation for Enhanced Financial Modelling",
    "abstract": "Data scarcity and confidentiality in finance often impede model development and robust testing. This paper presents a unified multi-criteria evaluation framework for synthetic financial data and applies it to three representative generative paradigms: the statistical ARIMA-GARCH baseline, Variational Autoencoders (VAEs), and Time-series Generative Adversarial Networks (TimeGAN). Using historical S and P 500 daily data, we evaluate fidelity (Maximum Mean Discrepancy, MMD), temporal structure (autocorrelation and volatility clustering), and practical utility in downstream tasks, specifically mean-variance portfolio optimization and volatility forecasting. Empirical results indicate that ARIMA-GARCH captures linear trends and conditional volatility but fails to reproduce nonlinear dynamics; VAEs produce smooth trajectories that underestimate extreme events; and TimeGAN achieves the best trade-off between realism and temporal coherence (e.g., TimeGAN attained the lowest MMD: 1.84e-3, average over 5 seeds). Finally, we articulate practical guidelines for selecting generative models according to application needs and computational constraints. Our unified evaluation protocol and reproducible codebase aim to standardize benchmarking in synthetic financial data research.",
    "authors": [
      "Christophe D. Hounwanou",
      "Yae Ulrich Gaba",
      "Pierre Ntakirutimana"
    ],
    "published": "2025-12-25",
    "categories": [
      "cs.LG",
      "q-fin.CP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21791v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21791v1",
    "fetched_at": "2025-12-29T08:36:34.606329",
    "chinese_title": "用于增强金融建模的合成金融数据生成",
    "chinese_summary": "论文针对金融数据稀缺与机密性问题，提出统一多标准评估框架，对比ARIMA-GARCH、VAE和TimeGAN三种生成范式，以标普500日度数据评估保真度、时间结构及下游任务（均值方差组合优化、波动率预测），结果显示TimeGAN在真实感与时间一致性间平衡最优，还给出模型选择指南并提供可复现代码以标准化合成金融数据基准测试。",
    "tags": [
      "Time Series",
      "Portfolio Optimization",
      "Volatility",
      "Benchmark"
    ],
    "key_contributions": [
      "提出统一多标准评估框架用于合成金融数据的系统评估",
      "系统对比三类生成范式并给出应用选择指南，提供可复现代码标准化合成金融数据基准测试"
    ],
    "processed_at": "2025-12-29T08:41:18.027922"
  },
  {
    "id": "2512.21621v1",
    "title": "Mean-Field Price Formation on Trees with a Network of Relative Performance Concerns",
    "abstract": "Financial firms and institutional investors are routinely evaluated based on their performance relative to their peers. These relative performance concerns significantly influence risk-taking behavior and market dynamics. While the literature studying Nash equilibrium under such relative performance competitions is extensive, its effect on asset price formation remains largely unexplored. This paper investigates mean-field equilibrium price formation of a single risky stock in a discrete-time market where agents exhibit exponential utility and relative performance concerns. Unlike existing literature that typically treats asset prices as exogenous, we impose a market-clearing condition to determine the price dynamics endogenously within a relative performance equilibrium. Using a binomial tree framework, we establish the existence and uniqueness of the market-clearing mean-field equilibrium in both single- and multi-population settings. Finally, we provide illustrative numerical examples demonstrating the equilibrium price distributions and agents' optimal position sizes.",
    "authors": [
      "Masaaki Fujii"
    ],
    "published": "2025-12-25",
    "categories": [
      "q-fin.MF",
      "econ.GN",
      "q-fin.GN",
      "q-fin.PM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21621v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21621v1",
    "fetched_at": "2025-12-29T08:36:34.606348",
    "chinese_title": "具有相对业绩关注网络的树模型上的均值场价格形成",
    "chinese_summary": "本文聚焦相对业绩关注对资产价格形成的影响，在离散时间市场中结合指数效用、二叉树框架，通过市场出清条件内生确定资产价格（区别于现有外生价格假设）；建立单种群和多种群下市场出清均值场均衡的存在唯一性，并通过数值例子展示均衡价格分布与金融主体最优头寸。",
    "tags": [
      "Asset Pricing",
      "Behavioral Finance",
      "Financial Agent",
      "Benchmark"
    ],
    "key_contributions": [
      "突破现有文献将资产价格外生化的局限，通过市场出清条件内生确定相对业绩均衡下的资产价格",
      "在二叉树框架下证明单种群和多种群市场出清均值场均衡的存在唯一性，并提供数值例子展示均衡特征"
    ],
    "processed_at": "2025-12-29T08:41:40.879856"
  },
  {
    "id": "2512.21539v1",
    "title": "Chaos, Ito-Stratonovich dilemma, and topological supersymmetry",
    "abstract": "It was recently established that the formalism of the generalized transfer operator (GTO) of dynamical systems (DS) theory, applied to stochastic differential equations (SDEs) of arbitrary form, belongs to the family of cohomological topological field theories (TFT) -- a class of models at the intersection of algebraic topology and high-energy physics. This interdisciplinary approach, which can be called the supersymmetric theory of stochastic dynamics (STS), can be seen as an algebraic dual to the traditional set-theoretic framework of the DS theory, with its algebraic structure enabling the extension of some DS theory concepts to stochastic dynamics. Moreover, it reveals the presence of a topological supersymmetry (TS) in the GTOs of all SDEs. It also shows that among the various definitions of chaos, positive \"pressure\", defined as the logarithm of the GTO spectral radius, stands out as particularly meaningful from a physical perspective, as it corresponds to the spontaneous breakdown of TS on the TFT side. Via the Goldstone theorem, this definition has a potential to provide the long-sought explanation for the experimental signature of chaotic dynamics known as 1/f noise. Additionally, STS clarifies that among the various existing interpretations of SDEs, only the Stratonovich interpretation yields evolution operators that match the corresponding GTOs and, consequently, have a clear-cut mathematical meaning. Here, we discuss these and other aspects of STS from both the DS theory and TFT perspectives, focusing on links between these two fields and providing mathematical concepts with physical interpretations that may be useful in some contexts.",
    "authors": [
      "Igor V. Ovchinnikov"
    ],
    "published": "2025-12-25",
    "categories": [
      "math-ph",
      "hep-th",
      "nlin.CD",
      "q-fin.CP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21539v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21539v1",
    "fetched_at": "2025-12-29T08:36:34.606371",
    "chinese_title": "混沌、伊藤-斯特拉托诺维奇两难与拓扑超对称性",
    "chinese_summary": "论文将动力系统广义传递算子（GTO）应用于随机微分方程（SDE），发现其属于上同调拓扑场论，提出随机动力学超对称理论（STS）；STS揭示所有SDE的GTO存在拓扑超对称性，明确正“压力”（GTO谱半径对数）对应拓扑超对称性自发破缺，且仅斯特拉托诺维奇解释的SDE演化算子与GTO匹配。",
    "tags": [
      "Time Series",
      "Volatility"
    ],
    "key_contributions": [
      "证明任意形式随机微分方程的广义传递算子属于上同调拓扑场论，提出随机动力学超对称理论（STS）",
      "揭示STS下拓扑超对称性的存在及正压力对应其自发破缺，明确仅斯特拉托诺维奇解释的SDE演化算子与GTO匹配"
    ],
    "processed_at": "2025-12-29T08:42:02.010685"
  },
  {
    "id": "2512.21924v1",
    "title": "Unsupervised Anomaly Detection in Brain MRI via Disentangled Anatomy Learning",
    "abstract": "Detection of various lesions in brain MRI is clinically critical, but challenging due to the diversity of lesions and variability in imaging conditions. Current unsupervised learning methods detect anomalies mainly through reconstructing abnormal images into pseudo-healthy images (PHIs) by normal samples learning and then analyzing differences between images. However, these unsupervised models face two significant limitations: restricted generalizability to multi-modality and multi-center MRIs due to their reliance on the specific imaging information in normal training data, and constrained performance due to abnormal residuals propagated from input images to reconstructed PHIs. To address these limitations, two novel modules are proposed, forming a new PHI reconstruction framework. Firstly, the disentangled representation module is proposed to improve generalizability by decoupling brain MRI into imaging information and essential imaging-invariant anatomical images, ensuring that the reconstruction focuses on the anatomy. Specifically, brain anatomical priors and a differentiable one-hot encoding operator are introduced to constrain the disentanglement results and enhance the disentanglement stability. Secondly, the edge-to-image restoration module is designed to reconstruct high-quality PHIs by restoring the anatomical representation from the high-frequency edge information of anatomical images, and then recoupling the disentangled imaging information. This module not only suppresses abnormal residuals in PHI by reducing abnormal pixels input through edge-only input, but also effectively reconstructs normal regions using the preserved structural details in the edges. Evaluated on nine public datasets (4,443 patients' MRIs from multiple centers), our method outperforms 17 SOTA methods, achieving absolute improvements of +18.32% in AP and +13.64% in DSC.",
    "authors": [
      "Tao Yang",
      "Xiuying Wang",
      "Hao Liu",
      "Guanzhong Gong",
      "Lian-Ming Wu",
      "Yu-Ping Wang",
      "Lisheng Wang"
    ],
    "published": "2025-12-26",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21924v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21924v1",
    "fetched_at": "2025-12-29T08:36:47.978996",
    "chinese_title": "基于解纠缠解剖学习的脑MRI无监督异常检测",
    "chinese_summary": "针对现有无监督脑MRI异常检测方法泛化性差（依赖正常训练数据特定成像信息）和重建残差问题，论文提出解纠缠表示模块（解耦成像与解剖信息，引入解剖先验约束）和边到图像恢复模块（从解剖边缘恢复表示并耦合成像信息重建高质量伪健康图像），提升泛化性与检测性能。",
    "tags": [
      "Anomaly",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出解纠缠表示模块，解耦MRI成像与解剖信息，引入解剖先验和可微one-hot编码提升多模态/多中心泛化性",
      "设计边到图像恢复模块，从解剖边缘恢复表示并耦合成像信息，重建高质量伪健康图像以缓解异常残差影响"
    ],
    "processed_at": "2025-12-29T08:42:14.468491"
  },
  {
    "id": "2512.21650v1",
    "title": "Causal-HM: Restoring Physical Generative Logic in Multimodal Anomaly Detection via Hierarchical Modulation",
    "abstract": "Multimodal Unsupervised Anomaly Detection (UAD) is critical for quality assurance in smart manufacturing, particularly in complex processes like robotic welding. However, existing methods often suffer from causal blindness, treating process modalities (e.g., real-time video, audio, and sensors) and result modalities (e.g., post-weld images) as equal feature sources, thereby ignoring the inherent physical generative logic. Furthermore, the heterogeneity gap between high-dimensional visual data and low-dimensional sensor signals frequently leads to critical process context being drowned out. In this paper, we propose Causal-HM, a unified multimodal UAD framework that explicitly models the physical Process to Result dependency. Specifically, our framework incorporates two key innovations: a Sensor-Guided CHM Modulation mechanism that utilizes low-dimensional sensor signals as context to guide high-dimensional audio-visual feature extraction , and a Causal-Hierarchical Architecture that enforces a unidirectional generative mapping to identify anomalies that violate physical consistency. Extensive experiments on our newly constructed Weld-4M benchmark across four modalities demonstrate that Causal-HM achieves a state-of-the-art (SOTA) I-AUROC of 90.7%. Code will be released after the paper is accepted.",
    "authors": [
      "Xiao Liu",
      "Junchen Jin",
      "Yanjie Zhao",
      "Zhixuan Xing"
    ],
    "published": "2025-12-25",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21650v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21650v1",
    "fetched_at": "2025-12-29T08:36:47.979030",
    "chinese_title": "Causal-HM：通过分层调制恢复多模态异常检测中的物理生成逻辑",
    "chinese_summary": "针对智能制造中多模态无监督异常检测（UAD）存在的因果盲视（忽略过程-结果物理生成逻辑）与异质性差距问题，论文提出Causal-HM框架，通过传感器引导的CHM调制机制（以低维传感器信号引导高维音视频特征提取）和因果分层架构（强制单向生成映射识别违反物理一致性的异常），在自建的Weld-4M多模态基准上实现SOTA的I-AUROC 90.7%。",
    "tags": [
      "Anomaly",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "显式建模多模态无监督异常检测中的过程-结果物理依赖，提出Causal-HM统一框架；",
      "提出传感器引导的CHM调制机制与因果分层架构，缓解异质性差距并识别物理一致性异常，在自建Weld-4M基准上达SOTA性能。"
    ],
    "processed_at": "2025-12-29T08:42:36.212875"
  },
  {
    "id": "2512.21459v1",
    "title": "CCAD: Compressed Global Feature Conditioned Anomaly Detection",
    "abstract": "Anomaly detection holds considerable industrial significance, especially in scenarios with limited anomalous data. Currently, reconstruction-based and unsupervised representation-based approaches are the primary focus. However, unsupervised representation-based methods struggle to extract robust features under domain shift, whereas reconstruction-based methods often suffer from low training efficiency and performance degradation due to insufficient constraints. To address these challenges, we propose a novel method named Compressed Global Feature Conditioned Anomaly Detection (CCAD). CCAD synergizes the strengths of both paradigms by adapting global features as a new modality condition for the reconstruction model. Furthermore, we design an adaptive compression mechanism to enhance both generalization and training efficiency. Extensive experiments demonstrate that CCAD consistently outperforms state-of-the-art methods in terms of AUC while achieving faster convergence. In addition, we contribute a reorganized and re-annotated version of the DAGM 2007 dataset with new annotations to further validate our method's effectiveness. The code for reproducing main results is available at https://github.com/chloeqxq/CCAD.",
    "authors": [
      "Xiao Jin",
      "Liang Diao",
      "Qixin Xiao",
      "Yifan Hu",
      "Ziqi Zhang",
      "Yuchen Liu",
      "Haisong Gu"
    ],
    "published": "2025-12-25",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21459v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21459v1",
    "fetched_at": "2025-12-29T08:36:47.979059",
    "chinese_title": "CCAD：压缩全局特征条件异常检测",
    "chinese_summary": "针对现有重建类和无监督表示类异常检测方法的不足（无监督表示法抗域偏移能力弱，重建法训练效率低、约束不足导致性能下降），本文提出CCAD方法，结合两者优势，以全局特征为重建模型的新模态条件并设计自适应压缩机制提升泛化性与训练效率；实验表明其AUC优于现有方法且收敛更快，还整理了带新标注的DAGM2007数据集。",
    "tags": [
      "Anomaly",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出CCAD方法，结合重建类与无监督表示类方法优势，以全局特征为条件并设计自适应压缩机制，提升异常检测泛化性与训练效率",
      "整理并重新标注DAGM2007数据集以验证方法有效性，公开代码可复现结果"
    ],
    "processed_at": "2025-12-29T08:42:48.739771"
  },
  {
    "id": "2512.21804v1",
    "title": "S&P 500 Stock's Movement Prediction using CNN",
    "abstract": "This paper is about predicting the movement of stock consist of S&P 500 index. Historically there are many approaches have been tried using various methods to predict the stock movement and being used in the market currently for algorithm trading and alpha generating systems using traditional mathematical approaches [1, 2].   The success of artificial neural network recently created a lot of interest and paved the way to enable prediction using cutting-edge research in the machine learning and deep learning. Some of these papers have done a great job in implementing and explaining benefits of these new technologies. Although most these papers do not go into the complexity of the financial data and mostly utilize single dimension data, still most of these papers were successful in creating the ground for future research in this comparatively new phenomenon. In this paper, I am trying to use multivariate raw data including stock split/dividend events (as-is) present in real-world market data instead of engineered financial data. Convolution Neural Network (CNN), the best-known tool so far for image classification, is used on the multi-dimensional stock numbers taken from the market mimicking them as a vector of historical data matrices (read images) and the model achieves promising results. The predictions can be made stock by stock, i.e., a single stock, sector-wise or for the portfolio of stocks.",
    "authors": [
      "Rahul Gupta"
    ],
    "published": "2025-12-25",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CE"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21804v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21804v1",
    "fetched_at": "2025-12-29T08:37:08.228495",
    "chinese_title": "基于CNN的标普500指数成分股走势预测",
    "chinese_summary": "论文针对标普500成分股走势预测，采用包含股票拆分、分红等真实市场原始多变量数据（而非工程化金融数据），将多维历史数据模拟为图像矩阵，使用卷积神经网络（CNN）实现单只股票、行业或投资组合层面的预测，取得有前景的结果。",
    "tags": [
      "Deep Learning",
      "Algorithmic Trading",
      "Time Series",
      "Portfolio Optimization"
    ],
    "key_contributions": [
      "采用真实市场原始多变量数据（含拆分、分红事件）替代工程化金融数据进行预测",
      "将多维历史股票数据模拟为图像矩阵，用CNN实现多层面（单股、行业、组合）走势预测并取得有前景结果"
    ],
    "processed_at": "2025-12-29T08:43:00.873904"
  },
  {
    "id": "2512.22101v1",
    "title": "A2P-Vis: an Analyzer-to-Presenter Agentic Pipeline for Visual Insights Generation and Reporting",
    "abstract": "Automating end-to-end data science pipeline with AI agents still stalls on two gaps: generating insightful, diverse visual evidence and assembling it into a coherent, professional report. We present A2P-Vis, a two-part, multi-agent pipeline that turns raw datasets into a high-quality data-visualization report. The Data Analyzer orchestrates profiling, proposes diverse visualization directions, generates and executes plotting code, filters low-quality figures with a legibility checker, and elicits candidate insights that are automatically scored for depth, correctness, specificity, depth and actionability. The Presenter then orders topics, composes chart-grounded narratives from the top-ranked insights, writes justified transitions, and revises the document for clarity and consistency, yielding a coherent, publication-ready report. Together, these agents convert raw data into curated materials (charts + vetted insights) and into a readable narrative without manual glue work. We claim that by coupling a quality-assured Analyzer with a narrative Presenter, A2P-Vis operationalizes co-analysis end-to-end, improving the real-world usefulness of automated data analysis for practitioners. For the complete dataset report, please see: https://www.visagent.org/api/output/f2a3486d-2c3b-4825-98d4-5af25a819f56.",
    "authors": [
      "Shuyu Gan",
      "Renxiang Wang",
      "James Mooney",
      "Dongyeop Kang"
    ],
    "published": "2025-12-26",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.22101v1",
    "arxiv_url": "https://arxiv.org/abs/2512.22101v1",
    "fetched_at": "2025-12-29T08:37:18.103148",
    "chinese_title": "A2P-Vis：用于视觉洞察生成与报告的Analyzer-to-Presenter智能体管道",
    "chinese_summary": "论文针对端到端数据科学管道中生成有洞察的可视化及组装专业报告的两大缺口，提出A2P-Vis多智能体管道；其中Data Analyzer负责数据 profiling、可视化方向生成与代码执行、质量过滤及洞察评分，Presenter负责主题组织、叙事构建与文档修订，实现原始数据到高质量报告的自动化无人工衔接，提升自动化分析实用性。",
    "tags": [
      "LLM",
      "Financial Agent",
      "NLP"
    ],
    "key_contributions": [
      "提出A2P-Vis多智能体管道，解决端到端数据科学中可视化洞察生成与专业报告组装的两大核心缺口",
      "构建含质量过滤与洞察评分的Analyzer模块及叙事构建的Presenter模块，实现原始数据到高质量报告的自动化无人工衔接流程，提升自动化分析的实用价值"
    ],
    "processed_at": "2025-12-29T08:43:21.373061"
  },
  {
    "id": "2512.22066v1",
    "title": "Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling",
    "abstract": "Energy consumption dictates the cost and environmental impact of deploying Large Language Models. This paper investigates the impact of on-chip SRAM size and operating frequency on the energy efficiency and performance of LLM inference, focusing on the distinct behaviors of the compute-bound prefill and memory-bound decode phases. Our simulation methodology combines OpenRAM for energy modeling, LLMCompass for latency simulation, and ScaleSIM for systolic array operational intensity. Our findings show that total energy use is predominantly determined by SRAM size in both phases, with larger buffers significantly increasing static energy due to leakage, which is not offset by corresponding latency benefits. We quantitatively explore the memory-bandwidth bottleneck, demonstrating that while high operating frequencies reduce prefill latency, their positive impact on memory-bound decode latency is capped by the external memory bandwidth. Counter-intuitively, high compute frequency can reduce total energy by reducing execution time and consequently decreasing static energy consumption more than the resulting dynamic power increase. We identify an optimal hardware configuration for the simulated workload: high operating frequencies (1200MHz-1400MHz) and a small local buffer size of 32KB to 64KB. This combination achieves the best energy-delay product, balancing low latency with high energy efficiency. Furthermore, we demonstrate how memory bandwidth acts as a performance ceiling, and that increasing compute frequency only yields performance gains up to the point where the workload becomes memory-bound. This analysis provides concrete architectural insights for designing energy-efficient LLM accelerators, especially for datacenters aiming to minimize their energy overhead.",
    "authors": [
      "Hannah Atmer",
      "Yuan Yao",
      "Thiemo Voigt",
      "Stefanos Kaxiras"
    ],
    "published": "2025-12-26",
    "categories": [
      "cs.AR",
      "cs.LG",
      "cs.PF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.22066v1",
    "arxiv_url": "https://arxiv.org/abs/2512.22066v1",
    "fetched_at": "2025-12-29T08:37:18.103184",
    "chinese_title": "Prefill与Decode瓶颈：SRAM-频率权衡及内存带宽上限",
    "chinese_summary": "论文聚焦大语言模型（LLM）推理的计算密集型prefill和内存密集型decode阶段，结合OpenRAM、LLMCompass、ScaleSIM等工具模拟分析，发现总能耗主要由片上SRAM大小决定，高频率虽降低prefill延迟但受内存带宽限制decode延迟，提出最优配置（1200-1400MHz+32-64KB本地缓存）实现最佳能效延迟乘积。",
    "tags": [
      "LLM",
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出LLM推理的最优硬件配置（1200-1400MHz+32-64KB本地缓存），实现能效与延迟的最优平衡"
    ],
    "processed_at": "2025-12-29T08:43:34.506534"
  },
  {
    "id": "2512.22029v1",
    "title": "LibContinual: A Comprehensive Library towards Realistic Continual Learning",
    "abstract": "A fundamental challenge in Continual Learning (CL) is catastrophic forgetting, where adapting to new tasks degrades the performance on previous ones. While the field has evolved with diverse methods, this rapid surge in diverse methodologies has culminated in a fragmented research landscape. The lack of a unified framework, including inconsistent implementations, conflicting dependencies, and varying evaluation protocols, makes fair comparison and reproducible research increasingly difficult. To address this challenge, we propose LibContinual, a comprehensive and reproducible library designed to serve as a foundational platform for realistic CL. Built upon a high-cohesion, low-coupling modular architecture, LibContinual integrates 19 representative algorithms across five major methodological categories, providing a standardized execution environment. Meanwhile, leveraging this unified framework, we systematically identify and investigate three implicit assumptions prevalent in mainstream evaluation: (1) offline data accessibility, (2) unregulated memory resources, and (3) intra-task semantic homogeneity. We argue that these assumptions often overestimate the real-world applicability of CL methods. Through our comprehensive analysis using strict online CL settings, a novel unified memory budget protocol, and a proposed category-randomized setting, we reveal significant performance drops in many representative CL methods when subjected to these real-world constraints. Our study underscores the necessity of resource-aware and semantically robust CL strategies, and offers LibContinual as a foundational toolkit for future research in realistic continual learning. The source code is available from \\href{https://github.com/RL-VIG/LibContinual}{https://github.com/RL-VIG/LibContinual}.",
    "authors": [
      "Wenbin Li",
      "Shangge Liu",
      "Borui Kang",
      "Yiyang Chen",
      "KaXuan Lew",
      "Yang Chen",
      "Yinghuan Shi",
      "Lei Wang",
      "Yang Gao",
      "Jiebo Luo"
    ],
    "published": "2025-12-26",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.22029v1",
    "arxiv_url": "https://arxiv.org/abs/2512.22029v1",
    "fetched_at": "2025-12-29T08:37:18.103235",
    "chinese_title": "LibContinual：面向现实持续学习的综合库",
    "chinese_summary": "针对持续学习领域研究碎片化、缺乏统一框架的问题，论文提出LibContinual库——基于高内聚低耦合模块化架构的可复现平台，集成19种覆盖5类方法的代表性算法；同时利用该框架分析主流评估的三个隐含假设，通过真实约束实验揭示多数方法在现实场景下性能显著下降，指出其适用性被高估。",
    "tags": [
      "Benchmark",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出LibContinual综合库，基于高内聚低耦合架构集成19种5类代表性持续学习算法，提供标准化执行环境",
      "系统识别主流评估的3个隐含假设，通过真实约束实验揭示多数方法性能显著下降，指出其现实适用性被高估"
    ],
    "processed_at": "2025-12-29T08:43:54.796369"
  },
  {
    "id": "2512.22022v1",
    "title": "Meta-Learning-Based Handover Management in NextG O-RAN",
    "abstract": "While traditional handovers (THOs) have served as a backbone for mobile connectivity, they increasingly suffer from failures and delays, especially in dense deployments and high-frequency bands. To address these limitations, 3GPP introduced Conditional Handovers (CHOs) that enable proactive cell reservations and user-driven execution. However, both handover (HO) types present intricate trade-offs in signaling, resource usage, and reliability. This paper presents unique, countrywide mobility management datasets from a top-tier mobile network operator (MNO) that offer fresh insights into these issues and call for adaptive and robust HO control in next-generation networks. Motivated by these findings, we propose CONTRA, a framework that, for the first time, jointly optimizes THOs and CHOs within the O-RAN architecture. We study two variants of CONTRA: one where users are a priori assigned to one of the HO types, reflecting distinct service or user-specific requirements, as well as a more dynamic formulation where the controller decides on-the-fly the HO type, based on system conditions and needs. To this end, it relies on a practical meta-learning algorithm that adapts to runtime observations and guarantees performance comparable to an oracle with perfect future information (universal no-regret). CONTRA is specifically designed for near-real-time deployment as an O-RAN xApp and aligns with the 6G goals of flexible and intelligent control. Extensive evaluations leveraging crowdsourced datasets show that CONTRA improves user throughput and reduces both THO and CHO switching costs, outperforming 3GPP-compliant and Reinforcement Learning (RL) baselines in dynamic and real-world scenarios.",
    "authors": [
      "Michail Kalntis",
      "George Iosifidis",
      "José Suárez-Varela",
      "Andra Lutu",
      "Fernando A. Kuipers"
    ],
    "published": "2025-12-26",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.22022v1",
    "arxiv_url": "https://arxiv.org/abs/2512.22022v1",
    "fetched_at": "2025-12-29T08:37:18.103270",
    "chinese_title": "基于元学习的下一代O-RAN切换管理",
    "chinese_summary": "论文针对移动网络切换中传统切换（THOs）与条件切换（CHOs）的信令、资源及可靠性权衡问题，提出CONTRA框架，首次在O-RAN架构下联合优化两类切换，含用户预分配和动态决策变体，采用元学习算法适配运行时并保证类先知性能，设计为O-RAN xApp支持近实时部署。",
    "tags": [
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "利用全国性移动管理数据集揭示切换权衡问题的新见解"
    ],
    "processed_at": "2025-12-29T08:44:17.190702"
  },
  {
    "id": "2512.21919v1",
    "title": "SWE-RM: Execution-free Feedback For Software Engineering Agents",
    "abstract": "Execution-based feedback like unit testing is widely used in the development of coding agents through test-time scaling (TTS) and reinforcement learning (RL). This paradigm requires scalable and reliable collection of unit test cases to provide accurate feedback, and the resulting feedback is often sparse and cannot effectively distinguish between trajectories that are both successful or both unsuccessful. In contrast, execution-free feedback from reward models can provide more fine-grained signals without depending on unit test cases. Despite this potential, execution-free feedback for realistic software engineering (SWE) agents remains underexplored. Aiming to develop versatile reward models that are effective across TTS and RL, however, we observe that two verifiers with nearly identical TTS performance can nevertheless yield very different results in RL. Intuitively, TTS primarily reflects the model's ability to select the best trajectory, but this ability does not necessarily generalize to RL. To address this limitation, we identify two additional aspects that are crucial for RL training: classification accuracy and calibration. We then conduct comprehensive controlled experiments to investigate how to train a robust reward model that performs well across these metrics. In particular, we analyze the impact of various factors such as training data scale, policy mixtures, and data source composition. Guided by these investigations, we introduce SWE-RM, an accurate and robust reward model adopting a mixture-of-experts architecture with 30B total parameters and 3B activated during inference. SWE-RM substantially improves SWE agents on both TTS and RL performance. For example, it increases the accuracy of Qwen3-Coder-Flash from 51.6% to 62.0%, and Qwen3-Coder-Max from 67.0% to 74.6% on SWE-Bench Verified using TTS, achieving new state-of-the-art performance among open-source models.",
    "authors": [
      "KaShun Shum",
      "Binyuan Hui",
      "Jiawei Chen",
      "Lei Zhang",
      "X. W.",
      "Jiaxi Yang",
      "Yuzhen Huang",
      "Junyang Lin",
      "Junxian He"
    ],
    "published": "2025-12-26",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21919v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21919v1",
    "fetched_at": "2025-12-29T08:37:18.103301",
    "chinese_title": "SWE-RM：面向软件工程代理的无执行反馈方法",
    "chinese_summary": "针对执行反馈（如单元测试）用于编码代理时存在的稀疏性等问题，论文指出TTS性能优异的验证器未必适配RL训练，需关注分类准确率与校准；通过分析训练数据规模、策略混合等因素，提出SWE-RM——一种兼顾TTS和RL性能的准确鲁棒无执行反馈奖励模型。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning",
      "LLM",
      "Execution"
    ],
    "key_contributions": [
      "揭示TTS性能与RL训练适配性的差异，明确分类准确率和校准是RL训练中奖励模型的关键评估维度",
      "提出SWE-RM，一种兼顾TTS选择能力与RL训练适配性的无执行反馈奖励模型，通过多因素优化训练实现鲁棒性"
    ],
    "processed_at": "2025-12-29T08:44:33.688248"
  },
  {
    "id": "2512.21907v1",
    "title": "SpatialBench: Can Agents Analyze Real-World Spatial Biology Data?",
    "abstract": "Spatial transcriptomics assays are rapidly increasing in scale and complexity, making computational analysis a major bottleneck in biological discovery. Although frontier AI agents have improved dramatically at software engineering and general data analysis, it remains unclear whether they can extract biological insight from messy, real-world spatial datasets. We introduce SpatialBench, a benchmark of 146 verifiable problems derived from practical spatial analysis workflows spanning five spatial technologies and seven task categories. Each problem provides a snapshot of experimental data immediately prior to an analysis step and a deterministic grader that evaluates recovery of a key biological result. Benchmark data on frontier models shows that base model accuracy remains low (20-38% across model families), with strong model-task and model-platform interactions. Harness design has a large empirical effect on performance, indicating that tools, prompts, control flow, and execution environment should be evaluated and improved as first-class objects. SpatialBench serves both as a measurement tool and a diagnostic lens for developing agents that can interact with real spatial datasets faithfully, transparently, and reproducibly.",
    "authors": [
      "Kenny Workman",
      "Zhen Yang",
      "Harihara Muralidharan",
      "Hannah Le"
    ],
    "published": "2025-12-26",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21907v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21907v1",
    "fetched_at": "2025-12-29T08:37:18.103325",
    "chinese_title": "SpatialBench：智能体能否分析真实世界空间生物学数据？",
    "chinese_summary": "论文引入SpatialBench基准，包含146个来自实际空间分析流程的可验证问题（覆盖5种空间技术和7类任务），每个问题提供分析前数据快照与生物结果恢复的确定性评分器；测试显示基础模型准确率仅20%-38%，工具设计对性能影响显著，该基准可作为开发忠实交互真实空间数据集智能体的测量与诊断工具。",
    "tags": [
      "Benchmark"
    ],
    "key_contributions": [
      "构建了覆盖多空间技术与任务的SpatialBench基准，含146个可验证的空间生物学分析问题",
      "揭示基础模型在空间生物学数据分析中的低准确率及工具设计对性能的关键影响，为智能体开发提供诊断视角"
    ],
    "processed_at": "2025-12-29T08:44:45.787581"
  },
  {
    "id": "2512.21859v1",
    "title": "TimeBill: Time-Budgeted Inference for Large Language Models",
    "abstract": "Large Language Models (LLMs) are increasingly deployed in time-critical systems, such as robotics, autonomous driving, embodied intelligence, and industrial automation, where generating accurate responses within a given time budget is crucial for decision-making, control, or safety-critical tasks. However, the auto-regressive generation process of LLMs makes it challenging to model and estimate the end-to-end execution time. Furthermore, existing efficient inference methods based on a fixed key-value (KV) cache eviction ratio struggle to adapt to varying tasks with diverse time budgets, where an improper eviction ratio may lead to incomplete inference or a drop in response performance. In this paper, we propose TimeBill, a novel time-budgeted inference framework for LLMs that balances the inference efficiency and response performance. To be more specific, we propose a fine-grained response length predictor (RLP) and an execution time estimator (ETE) to accurately predict the end-to-end execution time of LLMs. Following this, we develop a time-budgeted efficient inference approach that adaptively adjusts the KV cache eviction ratio based on execution time prediction and the given time budget. Finally, through extensive experiments, we demonstrate the advantages of TimeBill in improving task completion rate and maintaining response performance under various overrun strategies.",
    "authors": [
      "Qi Fan",
      "An Zou",
      "Yehan Ma"
    ],
    "published": "2025-12-26",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21859v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21859v1",
    "fetched_at": "2025-12-29T08:37:18.103346",
    "chinese_title": "TimeBill：大语言模型的时间预算推理框架",
    "chinese_summary": "针对大语言模型（LLM）在时间关键系统中需按时生成响应的需求，现有固定KV缓存驱逐率方法难适配不同时间预算，论文提出TimeBill框架，包含细粒度响应长度预测器（RLP）和执行时间估计器（ETE）以准确预测端到端执行时间，进而自适应调整KV缓存驱逐率平衡推理效率与响应性能，实验验证其提升任务完成率并保持响应质量的优势。",
    "tags": [
      "LLM",
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出TimeBill时间预算推理框架，解决LLM在时间关键系统中执行时间难预测及KV缓存驱逐率难适配不同时间预算的问题",
      "设计细粒度响应长度预测器（RLP）和执行时间估计器（ETE），并基于此自适应调整KV缓存驱逐率，平衡推理效率与响应性能"
    ],
    "processed_at": "2025-12-29T08:45:00.603596"
  },
  {
    "id": "2512.21853v1",
    "title": "MoonBot: Modular and On-Demand Reconfigurable Robot Toward Moon Base Construction",
    "abstract": "The allure of lunar surface exploration and development has recently captured widespread global attention. Robots have proved to be indispensable for exploring uncharted terrains, uncovering and leveraging local resources, and facilitating the construction of future human habitats. In this article, we introduce the modular and on-demand reconfigurable robot (MoonBot), a modular and reconfigurable robotic system engineered to maximize functionality while operating within the stringent mass constraints of lunar payloads and adapting to varying environmental conditions and task requirements. This article details the design and development of MoonBot and presents a preliminary field demonstration that validates the proof of concept through the execution of milestone tasks simulating the establishment of lunar infrastructure. These tasks include essential civil engineering operations, infrastructural component transportation and deployment, and assistive operations with inflatable modules. Furthermore, we systematically summarize the lessons learned during testing, focusing on the connector design and providing valuable insights for the advancement of modular robotic systems in future lunar missions.",
    "authors": [
      "Kentaro Uno",
      "Elian Neppel",
      "Gustavo H. Diaz",
      "Ashutosh Mishra",
      "Shamistan Karimov",
      "A. Sejal Jain",
      "Ayesha Habib",
      "Pascal Pama",
      "Hazal Gozbasi",
      "Shreya Santra",
      "Kazuya Yoshida"
    ],
    "published": "2025-12-26",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21853v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21853v1",
    "fetched_at": "2025-12-29T08:37:18.103381",
    "chinese_title": "MoonBot：面向月球基地建设的模块化按需可重构机器人",
    "chinese_summary": "本文介绍了面向月球基地建设的模块化按需可重构机器人MoonBot，其设计兼顾功能最大化与月球载荷的严格质量约束，可适应不同环境与任务需求；通过模拟月球基础设施建设关键任务完成初步现场验证，并总结连接器设计等测试经验，为未来月球任务模块化机器人系统提供参考。",
    "tags": [
      "Deep Learning"
    ],
    "key_contributions": [
      "设计并开发了兼顾功能最大化与月球载荷质量约束的模块化按需可重构机器人MoonBot",
      "通过模拟月球基础设施建设关键任务验证概念，总结连接器设计等测试经验，为未来月球任务模块化机器人系统提供参考"
    ],
    "processed_at": "2025-12-29T08:45:16.843789"
  },
  {
    "id": "2512.21817v1",
    "title": "Method Decoration (DeMe): A Framework for LLM-Driven Adaptive Method Generation in Dynamic IoT Environments",
    "abstract": "Intelligent IoT systems increasingly rely on large language models (LLMs) to generate task-execution methods for dynamic environments. However, existing approaches lack the ability to systematically produce new methods when facing previously unseen situations, and they often depend on fixed, device-specific logic that cannot adapt to changing environmental conditions.In this paper, we propose Method Decoration (DeMe), a general framework that modifies the method-generation path of an LLM using explicit decorations derived from hidden goals, accumulated learned methods, and environmental feedback. Unlike traditional rule augmentation, decorations in DeMe are not hardcoded; instead, they are extracted from universal behavioral principles, experience, and observed environmental differences. DeMe enables the agent to reshuffle the structure of its method path-through pre-decoration, post-decoration, intermediate-step modification, and step insertion-thereby producing context-aware, safety-aligned, and environment-adaptive methods. Experimental results show that method decoration allows IoT devices to derive ore appropriate methods when confronting unknown or faulty operating conditions.",
    "authors": [
      "Hong Su"
    ],
    "published": "2025-12-26",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21817v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21817v1",
    "fetched_at": "2025-12-29T08:37:18.103398",
    "chinese_title": "方法装饰（DeMe）：动态物联网环境中LLM驱动的自适应方法生成框架",
    "chinese_summary": "针对现有LLM驱动的物联网系统方法生成缺乏应对未知情况的能力且依赖固定设备逻辑的问题，本文提出方法装饰（DeMe）框架，通过从隐藏目标、积累方法及环境反馈中提取的显式装饰（非硬编码）修改LLM方法生成路径，实现方法路径重组以生成上下文感知、安全对齐且环境自适应的方法；实验验证该框架能让物联网设备在未知或故障工况下生成更合适的方法。",
    "tags": [
      "LLM",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出非硬编码的显式装饰机制，基于隐藏目标、积累方法及环境反馈修改LLM方法生成路径，解决现有方法应对未知情况能力不足的问题",
      "实现方法路径的多维度重组（预装饰、后装饰等），生成上下文感知、安全对齐且环境自适应的方法，实验证明其在物联网未知/故障工况下的有效性"
    ],
    "processed_at": "2025-12-29T08:45:38.846866"
  },
  {
    "id": "2512.21708v1",
    "title": "MoRAgent: Parameter Efficient Agent Tuning with Mixture-of-Roles",
    "abstract": "Despite recent advancements of fine-tuning large language models (LLMs) to facilitate agent tasks, parameter-efficient fine-tuning (PEFT) methodologies for agent remain largely unexplored. In this paper, we introduce three key strategies for PEFT in agent tasks: 1) Inspired by the increasingly dominant Reason+Action paradigm, we first decompose the capabilities necessary for the agent tasks into three distinct roles: reasoner, executor, and summarizer. The reasoner is responsible for comprehending the user's query and determining the next role based on the execution trajectory. The executor is tasked with identifying the appropriate functions and parameters to invoke. The summarizer conveys the distilled information from conversations back to the user. 2) We then propose the Mixture-of-Roles (MoR) framework, which comprises three specialized Low-Rank Adaptation (LoRA) groups, each designated to fulfill a distinct role. By focusing on their respective specialized capabilities and engaging in collaborative interactions, these LoRAs collectively accomplish the agent task. 3) To effectively fine-tune the framework, we develop a multi-role data generation pipeline based on publicly available datasets, incorporating role-specific content completion and reliability verification. We conduct extensive experiments and thorough ablation studies on various LLMs and agent benchmarks, demonstrating the effectiveness of the proposed method. This project is publicly available at https://mor-agent.github.io.",
    "authors": [
      "Jing Han",
      "Binwei Yan",
      "Tianyu Guo",
      "Zheyuan Bai",
      "Mengyu Zheng",
      "Hanting Chen",
      "Ying Nie"
    ],
    "published": "2025-12-25",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21708v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21708v1",
    "fetched_at": "2025-12-29T08:37:18.103426",
    "chinese_title": "MoRAgent：基于角色混合的参数高效智能体调优",
    "chinese_summary": "本文针对智能体任务的参数高效微调（PEFT）问题，提出将能力分解为推理者、执行者、总结者三类角色，设计含三个LoRA组的角色混合（MoR）框架，并开发多角色数据生成 pipeline；实验验证了该方法在不同大模型和智能体基准上的有效性。",
    "tags": [
      "LLM",
      "Financial Agent",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "将智能体任务所需能力分解为推理者、执行者、总结者三类角色",
      "提出角色混合（MoR）框架，包含三个专注不同角色的LoRA组",
      "构建基于公开数据集的多角色数据生成 pipeline"
    ],
    "processed_at": "2025-12-29T08:46:00.824618"
  },
  {
    "id": "2512.21699v1",
    "title": "Towards Responsible and Explainable AI Agents with Consensus-Driven Reasoning",
    "abstract": "Agentic AI represents a major shift in how autonomous systems reason, plan, and execute multi-step tasks through the coordination of Large Language Models (LLMs), Vision Language Models (VLMs), tools, and external services. While these systems enable powerful new capabilities, increasing autonomy introduces critical challenges related to explainability, accountability, robustness, and governance, especially when agent outputs influence downstream actions or decisions. Existing agentic AI implementations often emphasize functionality and scalability, yet provide limited mechanisms for understanding decision rationale or enforcing responsibility across agent interactions. This paper presents a Responsible(RAI) and Explainable(XAI) AI Agent Architecture for production-grade agentic workflows based on multi-model consensus and reasoning-layer governance. In the proposed design, a consortium of heterogeneous LLM and VLM agents independently generates candidate outputs from a shared input context, explicitly exposing uncertainty, disagreement, and alternative interpretations. A dedicated reasoning agent then performs structured consolidation across these outputs, enforcing safety and policy constraints, mitigating hallucinations and bias, and producing auditable, evidence-backed decisions. Explainability is achieved through explicit cross-model comparison and preserved intermediate outputs, while responsibility is enforced through centralized reasoning-layer control and agent-level constraints. We evaluate the architecture across multiple real-world agentic AI workflows, demonstrating that consensus-driven reasoning improves robustness, transparency, and operational trust across diverse application domains. This work provides practical guidance for designing agentic AI systems that are autonomous and scalable, yet responsible and explainable by construction.",
    "authors": [
      "Eranga Bandara",
      "Tharaka Hewa",
      "Ross Gore",
      "Sachin Shetty",
      "Ravi Mukkamala",
      "Peter Foytik",
      "Abdul Rahman",
      "Safdar H. Bouk",
      "Xueping Liang",
      "Amin Hass",
      "Sachini Rajapakse",
      "Ng Wee Keong",
      "Kasun De Zoysa",
      "Aruna Withanage",
      "Nilaan Loganathan"
    ],
    "published": "2025-12-25",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21699v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21699v1",
    "fetched_at": "2025-12-29T08:37:18.103467",
    "chinese_title": "面向负责任与可解释AI智能体的共识驱动推理方法",
    "chinese_summary": "本文针对现有智能体AI在可解释性、问责制等方面的不足，提出一种基于多模型共识与推理层治理的负责任可解释AI智能体架构；异构LLM/VLM智能体独立生成候选输出以暴露不确定性，专用推理智能体整合输出并约束安全政策，实现可审计的证据化决策，同时通过跨模型对比与中间输出保留实现可解释性，通过集中推理层控制强化责任性。",
    "tags": [
      "LLM",
      "Financial Agent",
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出基于多模型共识与推理层治理的负责任可解释（RAI-XAI）AI智能体架构，解决现有智能体可解释性、问责制不足问题",
      "通过异构LLM/VLM独立输出暴露不确定性，专用推理智能体整合并约束安全政策，实现可审计证据化决策，同时以跨模型对比和中间输出保留实现可解释性、集中推理层控制强化责任性"
    ],
    "processed_at": "2025-12-29T08:46:26.880564"
  },
  {
    "id": "2512.21623v1",
    "title": "Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design",
    "abstract": "Therapeutic discovery remains a formidable challenge, impeded by the fragmentation of specialized domains and the execution gap between computational design and physiological validation. Although generative AI offers promise, current models often function as passive assistants rather than as autonomous executors. Here, we introduce OrchestRA, a human-in-the-loop multi-agent platform that unifies biology, chemistry, and pharmacology into an autonomous discovery engine. Unlike static code generators, our agents actively execute simulations and reason the results to drive iterative optimization. Governed by an Orchestrator, a Biologist Agent leverages deep reasoning over a massive knowledge graph (>10 million associations) to pinpoint high-confidence targets; a Chemist Agent autonomously detects structural pockets for de novo design or drug repositioning; and a Pharmacologist Agent evaluates candidates via rigorous physiologically based pharmacokinetic (PBPK) simulations. This architecture establishes a dynamic feedback loop where pharmacokinetic and toxicity profiles directly trigger structural reoptimization. By seamlessly integrating autonomous execution with human guidance, OrchestRA democratizes therapeutic design, transforming drug discovery from a stochastic search to a programmable evidence-based engineering discipline.",
    "authors": [
      "Takahide Suzuki",
      "Kazuki Nakanishi",
      "Takashi Fujiwara",
      "Hideyuki Shimizu"
    ],
    "published": "2025-12-25",
    "categories": [
      "cs.AI",
      "cs.MA",
      "q-bio.QM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21623v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21623v1",
    "fetched_at": "2025-12-29T08:37:18.103492",
    "chinese_title": "用编排式知识驱动多智能体团队实现用户引导治疗设计的药物发现民主化",
    "chinese_summary": "论文提出OrchestRA人在环多智能体平台，整合生物、化学、药理学领域，通过生物智能体基于大规模知识图谱定位靶点、化学智能体自主设计药物结构、药理智能体开展生理药代动力学模拟，建立动态反馈循环，将药物发现从随机搜索转为循证工程，民主化治疗设计。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Graph Neural Network",
      "Financial Agent"
    ],
    "key_contributions": [
      "提出OrchestRA多智能体平台，整合多领域专业能力与自主执行推理，解决药物发现的领域碎片化与计算-生理验证执行gap",
      "建立药代动力学/毒性与结构优化的动态反馈循环，将药物发现转为循证可编程工程，实现治疗设计民主化"
    ],
    "processed_at": "2025-12-29T08:46:48.584044"
  },
  {
    "id": "2512.21596v1",
    "title": "Quantitative Verification of Omega-regular Properties in Probabilistic Programming",
    "abstract": "Probabilistic programming provides a high-level framework for specifying statistical models as executable programs with built-in randomness and conditioning. Existing inference techniques, however, typically compute posterior distributions over program states at fixed time points, most often at termination, thereby failing to capture the temporal evolution of probabilistic behaviors. We introduce temporal posterior inference (TPI), a new framework that unifies probabilistic programming with temporal logic by computing posterior distributions over execution traces that satisfy omega-regular specifications, conditioned on possibly temporal observations. To obtain rigorous quantitative guarantees, we develop a new method for computing upper and lower bounds on the satisfaction probabilities of omega-regular properties. Our approach decomposes Rabin acceptance conditions into persistence and recurrence components and constructs stochastic barrier certificates that soundly bound each component. We implement our approach in a prototype tool, TPInfer, and evaluate it on a suite of benchmarks, demonstrating effective and efficient inference over rich temporal properties in probabilistic models.",
    "authors": [
      "Peixin Wang",
      "Jianhao Bai",
      "Min Zhang",
      "C. -H. Luke Ong"
    ],
    "published": "2025-12-25",
    "categories": [
      "cs.PL",
      "cs.FL",
      "cs.LG",
      "cs.LO",
      "cs.SC"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21596v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21596v1",
    "fetched_at": "2025-12-29T08:37:18.103516",
    "chinese_title": "概率编程中Omega-正则性质的定量验证",
    "chinese_summary": "现有概率编程推理多聚焦固定时间点的后验分布，无法捕捉概率行为的时态演化；本文提出时间后验推理（TPI）框架，统一概率编程与时态逻辑，计算满足Omega-正则规范的执行轨迹后验，还开发了基于Rabin条件分解和随机障碍证书的满足概率上下界计算方法，实现原型工具TPInfer并验证有效。",
    "tags": [
      "Risk Management",
      "Benchmark",
      "Time Series"
    ],
    "key_contributions": [
      "提出时间后验推理（TPI）框架，统一概率编程与时态逻辑，可计算满足Omega-正则规范的执行轨迹后验（条件于时态观测）",
      "开发基于Rabin接受条件分解和随机障碍证书的Omega-正则性质满足概率上下界计算方法，实现原型工具TPInfer并验证有效"
    ],
    "processed_at": "2025-12-29T08:47:17.622475"
  },
  {
    "id": "2512.21450v1",
    "title": "RLLaVA: An RL-central Framework for Language and Vision Assistants",
    "abstract": "We present an RL-central framework for Language and Vision Assistants (RLLaVA) with its formulation of Markov decision process (MDP). RLLaVA decouples RL algorithmic logic from model architecture and distributed execution, supporting researchers in implementing new RL algorithms with minimal code, and to plug in a broad family of RL methods and vision-language models (VLMs) while remaining agnostic to specific training and inference engines. RLLaVA makes resource-efficient training of 1B--7B models feasible on common GPUs; notably, 4B-scale models can be trained end-to-end with full-parameter updates on a single 24GB GPU. Experiments on multi-modal and agentic tasks demonstrate that RLLaVA has task extensibility, and the models trained with it consistently improve performance over base models, competitive with other specially engineered RL frameworks. The code is available at https://github.com/TinyLoopX/RLLaVA.",
    "authors": [
      "Lei Zhao",
      "Zihao Ma",
      "Boyu Lin",
      "Yuhe Liu",
      "Wenjun Wu",
      "Lei Huang"
    ],
    "published": "2025-12-25",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21450v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21450v1",
    "fetched_at": "2025-12-29T08:37:18.103542",
    "chinese_title": "RLLaVA：面向语言与视觉助手的强化学习核心框架",
    "chinese_summary": "本文提出基于马尔可夫决策过程（MDP）的强化学习核心框架RLLaVA，解耦RL算法逻辑与模型架构/分布式执行，支持快速实现新RL算法并兼容多种RL方法与视觉语言模型（VLM）；该框架可在普通GPU上高效训练1B-7B模型（如4B模型可单24GB GPU全参数端到端训练），实验验证其任务可扩展性，训练模型性能优于基础模型且与专用RL框架相当。",
    "tags": [
      "LLM",
      "Reinforcement Learning",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出RLLaVA框架，基于MDP解耦RL算法逻辑与模型架构/分布式执行，支持快速实现新RL算法并兼容多种RL方法与视觉语言模型",
      "实现资源高效训练，使1B-7B模型可在普通GPU（如单24GB GPU）上训练，且训练模型性能优于基础模型"
    ],
    "processed_at": "2025-12-29T08:47:34.961075"
  },
  {
    "id": "2512.21440v1",
    "title": "Fuzzwise: Intelligent Initial Corpus Generation for Fuzzing",
    "abstract": "In mutation-based greybox fuzzing, generating high-quality input seeds for the initial corpus is essential for effective fuzzing. Rather than conducting separate phases for generating a large corpus and subsequently minimizing it, we propose FuzzWise which integrates them into one process to generate the optimal initial corpus of seeds (ICS). FuzzWise leverages a multi-agent framework based on Large Language Models (LLMs). The first LLM agent generates test cases for the target program. The second LLM agent, which functions as a predictive code coverage module, assesses whether each generated test case will enhance the overall coverage of the current corpus. The streamlined process allows each newly generated test seed to be immediately evaluated for its contribution to the overall coverage. FuzzWise employs a predictive approach using an LLM and eliminates the need for actual execution, saving computational resources and time, particularly in scenarios where the execution is not desirable or even impossible. Our empirical evaluation demonstrates that FuzzWise generates significantly fewer test cases than baseline methods. Despite the lower number of test cases, FuzzWise achieves high code coverage and triggers more runtime errors compared to the baselines. Moreover, it is more time-efficient and coverage-efficient in producing an initial corpus catching more errors.",
    "authors": [
      "Hridya Dhulipala",
      "Xiaokai Rong",
      "Aashish Yadavally",
      "Tien N. Nguyen"
    ],
    "published": "2025-12-24",
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21440v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21440v1",
    "fetched_at": "2025-12-29T08:37:18.103564",
    "chinese_title": "Fuzzwise：面向模糊测试的智能初始语料生成方法",
    "chinese_summary": "Fuzzwise针对灰盒模糊测试中高质量初始种子语料（ICS）生成问题，提出基于大语言模型（LLM）的多代理框架——第一个LLM生成测试用例，第二个LLM作为预测性代码覆盖模块评估其贡献，无需实际执行节省资源；实证显示其生成更少测试用例但覆盖更高、触发更多运行时错误，且效率更优。",
    "tags": [
      "LLM",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出整合测试用例生成与覆盖评估的多代理LLM框架，通过预测性评估替代实际执行，节省计算资源与时间",
      "实证表明Fuzzwise生成更少测试用例但实现更高代码覆盖、触发更多运行时错误，且初始语料生成效率更优"
    ],
    "processed_at": "2025-12-29T08:47:50.789880"
  },
  {
    "id": "2512.21572v1",
    "title": "RefineBridge: Generative Bridge Models Improve Financial Forecasting by Foundation Models",
    "abstract": "Financial time series forecasting is particularly challenging for transformer-based time series foundation models (TSFMs) due to non-stationarity, heavy-tailed distributions, and high-frequency noise present in data. Low-rank adaptation (LoRA) has become a popular parameter-efficient method for adapting pre-trained TSFMs to downstream data domains. However, it still underperforms in financial data, as it preserves the network architecture and training objective of TSFMs rather than complementing the foundation model. To further enhance TSFMs, we propose a novel refinement module, RefineBridge, built upon a tractable Schrödinger Bridge (SB) generative framework. Given the forecasts of TSFM as generative prior and the observed ground truths as targets, RefineBridge learns context-conditioned stochastic transport maps to improve TSFM predictions, iteratively approaching the ground-truth target from even a low-quality prior. Simulations on multiple financial benchmarks demonstrate that RefineBridge consistently improves the performance of state-of-the-art TSFMs across different prediction horizons.",
    "authors": [
      "Anthony Bolton",
      "Wuyang Zhou",
      "Zehua Chen",
      "Giorgos Iacovides",
      "Danilo Mandic"
    ],
    "published": "2025-12-25",
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21572v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21572v1",
    "fetched_at": "2025-12-29T08:38:10.530273",
    "chinese_title": "RefineBridge：生成桥模型通过基础模型提升金融预测",
    "chinese_summary": "针对金融时间序列预测中基于Transformer的时间序列基础模型（TSFM）面临的非平稳性、重尾分布及高频噪声等挑战，论文提出RefineBridge模块——基于薛定谔桥生成框架，以TSFM预测为生成先验、观测真实值为目标，学习上下文条件随机传输映射迭代优化预测；实验表明其在多个金融基准上持续提升SOTA TSFM的不同预测 horizon性能。",
    "tags": [
      "Time Series",
      "Transformer",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "提出基于薛定谔桥的RefineBridge模块，补充而非仅适配时间序列基础模型，解决金融时间序列预测的核心挑战",
      "实验验证RefineBridge能显著提升SOTA时间序列基础模型在多个金融基准和不同预测 horizon的性能"
    ],
    "processed_at": "2025-12-29T08:48:06.011574"
  },
  {
    "id": "2512.21878v1",
    "title": "MASFIN: A Multi-Agent System for Decomposed Financial Reasoning and Forecasting",
    "abstract": "Recent advances in large language models (LLMs) are transforming data-intensive domains, with finance representing a high-stakes environment where transparent and reproducible analysis of heterogeneous signals is essential. Traditional quantitative methods remain vulnerable to survivorship bias, while many AI-driven approaches struggle with signal integration, reproducibility, and computational efficiency. We introduce MASFIN, a modular multi-agent framework that integrates LLMs with structured financial metrics and unstructured news, while embedding explicit bias-mitigation protocols. The system leverages GPT-4.1-nano for reproducability and cost-efficient inference and generates weekly portfolios of 15-30 equities with allocation weights optimized for short-term performance. In an eight-week evaluation, MASFIN delivered a 7.33% cumulative return, outperforming the S&P 500, NASDAQ-100, and Dow Jones benchmarks in six of eight weeks, albeit with higher volatility. These findings demonstrate the promise of bias-aware, generative AI frameworks for financial forecasting and highlight opportunities for modular multi-agent design to advance practical, transparent, and reproducible approaches in quantitative finance.",
    "authors": [
      "Marc S. Montalvo",
      "Hamed Yaghoobian"
    ],
    "published": "2025-12-26",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.21878v1",
    "arxiv_url": "https://arxiv.org/abs/2512.21878v1",
    "fetched_at": "2025-12-29T08:39:11.047782",
    "chinese_title": "MASFIN：用于分解金融推理与预测的多智能体系统",
    "chinese_summary": "论文提出MASFIN模块化多智能体框架，整合LLM（采用GPT-4.1-nano）、结构化金融指标与非结构化新闻，嵌入显式偏差缓解协议；在8周评估中实现7.33%累计收益，优于标普500、纳斯达克100及道琼斯三大基准（虽波动更高），验证了偏差感知生成AI框架在金融预测的潜力。",
    "tags": [
      "LLM",
      "Financial Agent",
      "Portfolio Optimization",
      "Benchmark"
    ],
    "key_contributions": [
      "提出嵌入显式偏差缓解协议的MASFIN多智能体框架，整合LLM与异质金融信号（结构化指标+非结构化新闻）",
      "8周实证显示该框架累计收益优于三大主流基准，展示了模块化多智能体设计在量化金融的实用价值"
    ],
    "processed_at": "2025-12-29T08:48:20.209918"
  }
]