[
  {
    "id": "2512.05011v1",
    "title": "Risk aversion of insider and dynamic asymmetric information",
    "abstract": "This paper studies a Kyle-Back model with a risk-averse insider possessing exponential utility and a dynamic stochastic signal about the asset's terminal fundamental value. While the existing literature considers either risk-neutral insiders with dynamic signals or risk-averse insiders with static signals, we establish equilibrium when both features are present. Our approach imposes no restrictions on the magnitude of the risk aversion parameter, extending beyond previous work that requires sufficiently small risk aversion. We employ a weak conditioning methodology to construct a Schrödinger bridge between the insider's signal and the asset price process, an approach that naturally accommodates stochastic signal evolution and removes risk aversion constraints.   We derive necessary conditions for equilibrium, showing that the optimal insider strategy must be continuous with bounded variation. Under these conditions, we characterize the market-maker pricing rule and insider strategy that achieve equilibrium. We obtain explicit closed-form solutions for important cases including deterministic and quadratic signal volatilities, demonstrating the tractability of our framework.",
    "authors": [
      "Albina Danilova",
      "Valentin Lizhdvoy"
    ],
    "published": "2025-12-04",
    "categories": [
      "q-fin.MF",
      "q-fin.TR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.05011v1",
    "arxiv_url": "https://arxiv.org/abs/2512.05011v1",
    "fetched_at": "2025-12-05T08:32:28.411399",
    "chinese_title": "内幕交易者的风险厌恶与动态非对称信息",
    "chinese_summary": "本文在Kyle-Back模型框架下，同时纳入风险厌恶内幕交易者与动态随机信号，填补现有文献仅考虑单一特征的空白；采用弱条件化方法构造薛定谔桥连接信号与价格过程，无需限制风险厌恶参数大小，且推导均衡必要条件并得到重要情形的显式闭式解。",
    "tags": [
      "Asset Pricing",
      "Market Microstructure",
      "Risk Management",
      "Market Making"
    ],
    "key_contributions": [
      "首次在Kyle-Back模型中同时考虑风险厌恶内幕交易者与动态随机信号，突破此前需限制风险厌恶参数足够小的约束",
      "采用弱条件化方法构造薛定谔桥适配随机信号演化，推导均衡必要条件并得到重要情形的显式闭式解"
    ],
    "processed_at": "2025-12-05T08:35:51.248406"
  },
  {
    "id": "2512.04704v1",
    "title": "Coordinated Mean-Field Control for Systemic Risk",
    "abstract": "We develop a robust linear-quadratic mean-field control framework for systemic risk under model uncertainty, in which a central bank jointly optimizes interest rate policy and supervisory monitoring intensity against adversarial distortions. Our model features multiple policy instruments with interactive dynamics, implemented via a variance weight that depends on the policy rate, generating coupling effects absent in single-instrument models. We establish viscosity solutions for the associated HJB--Isaacs equation, prove uniqueness via comparison principles, and provide verification theorems. The linear-quadratic structure yields explicit feedback controls derived from a coupled Riccati system, preserving analytical tractability despite adversarial uncertainty. Simulations reveal distinct loss-of-control regimes driven by robustness-breakdown and control saturation, alongside a pronounced asymmetry in sensitivity between the mean and variance channels. These findings demonstrate the importance of instrument complementarity in systemic risk modeling and control.",
    "authors": [
      "Toshiaki Yamanaka"
    ],
    "published": "2025-12-04",
    "categories": [
      "math.OC",
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04704v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04704v1",
    "fetched_at": "2025-12-05T08:32:28.411435",
    "chinese_title": "系统性风险的协调平均场控制",
    "chinese_summary": "本文构建了含模型不确定性的鲁棒线性二次平均场控制框架，用于系统性风险管控，央行联合优化利率政策与监管监控强度对抗对抗性扰动；模型通过依赖政策利率的方差权重刻画多工具互动耦合，推导得到耦合Riccati系统的显式反馈控制，并通过模拟揭示失控机制与渠道敏感度不对称性，凸显工具互补性的重要性。",
    "tags": [
      "Risk Management",
      "Volatility"
    ],
    "key_contributions": [
      "构建含模型不确定性的鲁棒线性二次平均场控制框架，央行联合优化利率政策与监管监控强度对抗对抗性扰动",
      "推导耦合Riccati系统的显式反馈控制，模拟揭示失控机制与渠道敏感度不对称性，凸显工具互补性"
    ],
    "processed_at": "2025-12-05T08:36:21.941815"
  },
  {
    "id": "2512.04697v1",
    "title": "Continuous-time reinforcement learning for optimal switching over multiple regimes",
    "abstract": "This paper studies the continuous-time reinforcement learning (RL) for optimal switching problems across multiple regimes. We consider a type of exploratory formulation under entropy regularization where the agent randomizes both the timing of switches and the selection of regimes through the generator matrix of an associated continuous-time finite-state Markov chain. We establish the well-posedness of the associated system of Hamilton-Jacobi-Bellman (HJB) equations and provide a characterization of the optimal policy. The policy improvement and the convergence of the policy iterations are rigorously established by analyzing the system of equations. We also show the convergence of the value function in the exploratory formulation towards the value function in the classical formulation as the temperature parameter vanishes. Finally, a reinforcement learning algorithm is devised and implemented by invoking the policy evaluation based on the martingale characterization. Our numerical examples with the aid of neural networks illustrate the effectiveness of the proposed RL algorithm.",
    "authors": [
      "Yijie Huang",
      "Mengge Li",
      "Xiang Yu",
      "Zhou Zhou"
    ],
    "published": "2025-12-04",
    "categories": [
      "math.OC",
      "cs.LG",
      "q-fin.CP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04697v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04697v1",
    "fetched_at": "2025-12-05T08:32:28.411464",
    "chinese_title": "多机制最优切换的连续时间强化学习",
    "chinese_summary": "本文研究多机制最优切换的连续时间强化学习问题，采用熵正则化的探索性公式，通过连续时间有限状态马尔可夫链生成矩阵随机化切换时机与机制选择；建立HJB方程组适定性并刻画最优策略，严格证明策略改进及迭代收敛，同时证明温度参数趋近0时探索性价值函数收敛到经典值；设计基于鞅刻画的RL算法，数值实验验证其有效性。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出熵正则化的探索性连续时间RL框架，建立HJB方程组适定性并刻画多机制最优切换的最优策略",
      "严格证明策略改进与迭代收敛性，设计基于鞅刻画的RL算法并通过神经网络验证有效性"
    ],
    "processed_at": "2025-12-05T08:36:48.535687"
  },
  {
    "id": "2512.04603v1",
    "title": "FX Market Making with Internal Liquidity",
    "abstract": "As the FX markets continue to evolve, many institutions have started offering passive access to their internal liquidity pools. Market makers act as principal and have the opportunity to fill those orders as part of their risk management, or they may choose to adjust pricing to their external OTC franchise to facilitate the matching flow. It is, a priori, unclear how the strategies managing internal liquidity should depend on market condions, the market maker's risk appetite, and the placement algorithms deployed by participating clients. The market maker's actions in the presence of passive orders are relevant not only for their own objectives, but also for those liquidity providers who have certain expectations of the execution speed. In this work, we investigate the optimal multi-objective strategy of a market maker with an option to take liquidity on an internal exchange, and draw important qualitative insights for real-world trading.",
    "authors": [
      "Alexander Barzykin",
      "Robert Boyce",
      "Eyal Neuman"
    ],
    "published": "2025-12-04",
    "categories": [
      "q-fin.TR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04603v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04603v1",
    "fetched_at": "2025-12-05T08:32:28.411487",
    "chinese_title": "含内部流动性的外汇做市",
    "chinese_summary": "针对外汇市场中机构提供内部流动性池被动访问的场景，论文构建了做市商在具备内部交易所流动性选择权下的最优多目标策略模型，揭示了策略与市场条件、做市商风险偏好及客户订单算法的依赖关系，为现实交易提供定性指导。",
    "tags": [
      "Market Making",
      "Risk Management",
      "Market Microstructure",
      "Algorithmic Trading"
    ],
    "key_contributions": [
      "提出含内部流动性选择权的做市商最优多目标策略框架",
      "明确策略对市场条件、风险偏好及客户算法的依赖关系，给出现实交易定性见解"
    ],
    "processed_at": "2025-12-05T08:37:02.460911"
  },
  {
    "id": "2512.02352v2",
    "title": "Visibility-Graph Asymmetry as a Structural Indicator of Volatility Clustering",
    "abstract": "Volatility clustering is one of the most robust stylized facts of financial markets, yet it is typically detected using moment-based diagnostics or parametric models such as GARCH. This paper shows that clustered volatility also leaves a clear imprint on the time-reversal symmetry of horizontal visibility graphs (HVGs) constructed on absolute returns in physical time. For each time point, we compute the maximal forward and backward visibility distances, $L^{+}(t)$ and $L^{-}(t)$, and use their empirical distributions to build a visibility-asymmetry fingerprint comprising the Kolmogorov--Smirnov distance, variance difference, entropy difference, and a ratio of extreme visibility spans. In a Monte Carlo study, these HVG asymmetry features sharply separate volatility-clustered GARCH(1,1) dynamics from i.i.d.\\ Gaussian noise and from randomly shuffled GARCH series that preserve the marginal distribution but destroy temporal dependence; a simple linear classifier based on the fingerprint achieves about 90\\% in-sample accuracy. Applying the method to daily S\\&P500 data reveals a pronounced forward--backward imbalance, including a variance difference $Δ\\mathrm{Var}$ that exceeds the simulated GARCH values by two orders of magnitude and vanishes after shuffling. Overall, the visibility-graph asymmetry fingerprint emerges as a simple, model-free, and geometrically interpretable indicator of volatility clustering and time irreversibility in financial time series.",
    "authors": [
      "Michał Sikorski"
    ],
    "published": "2025-12-02",
    "categories": [
      "q-fin.ST",
      "q-fin.CP",
      "q-fin.TR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.02352v2",
    "arxiv_url": "https://arxiv.org/abs/2512.02352v2",
    "fetched_at": "2025-12-05T08:32:28.411661",
    "chinese_title": "可见性图不对称性作为波动率聚类的结构指标",
    "chinese_summary": "本文发现波动率聚类会在绝对收益构建的水平可见性图（HVG）的时间反转对称性上留下明显印记；通过前向与后向最大可见距离的经验分布构建包含KS距离、方差差等的可见性不对称指纹，该指纹可有效区分波动率聚类的GARCH(1,1)、独立高斯噪声及打乱的GARCH序列（线性分类器准确率约90%），是无模型、几何可解释的波动率聚类指标。",
    "tags": [
      "Volatility",
      "Time Series",
      "Graph Neural Network"
    ],
    "key_contributions": [
      "提出可见性图不对称性指纹作为波动率聚类的无模型、几何可解释指标，可有效区分波动率聚类序列与无聚类序列",
      "通过蒙特卡洛研究与标普500数据验证该指纹能区分GARCH(1,1)、独立高斯噪声及打乱的GARCH序列，实际应用有效"
    ],
    "processed_at": "2025-12-05T08:37:25.931066"
  },
  {
    "id": "2512.05069v1",
    "title": "Hybrid Quantum-Classical Autoencoders for Unsupervised Network Intrusion Detection",
    "abstract": "Unsupervised anomaly-based intrusion detection requires models that can generalize to attack patterns not observed during training. This work presents the first large-scale evaluation of hybrid quantum-classical (HQC) autoencoders for this task. We construct a unified experimental framework that iterates over key quantum design choices, including quantum-layer placement, measurement approach, variational and non-variational formulations, and latent-space regularization. Experiments across three benchmark NIDS datasets show that HQC autoencoders can match or exceed classical performance in their best configurations, although they exhibit higher sensitivity to architectural decisions. Under zero-day evaluation, well-configured HQC models provide stronger and more stable generalization than classical and supervised baselines. Simulated gate-noise experiments reveal early performance degradation, indicating the need for noise-aware HQC designs. These results provide the first data-driven characterization of HQC autoencoder behavior for network intrusion detection and outline key factors that govern their practical viability. All experiment code and configurations are available at https://github.com/arasyi/hqcae-network-intrusion-detection.",
    "authors": [
      "Mohammad Arif Rasyidi",
      "Omar Alhussein",
      "Sami Muhaidat",
      "Ernesto Damiani"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.LG",
      "cs.CR",
      "quant-ph"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.05069v1",
    "arxiv_url": "https://arxiv.org/abs/2512.05069v1",
    "fetched_at": "2025-12-05T08:32:35.028185",
    "chinese_title": "混合量子-经典自编码器用于无监督网络入侵检测",
    "chinese_summary": "该论文首次大规模评估混合量子-经典（HQC）自编码器在无监督网络入侵检测中的表现，构建统一实验框架探索量子层放置、测量方法等关键设计选择；实验显示最优配置的HQC模型可匹配或超越经典模型，零日攻击评估中泛化能力更强更稳定，但对架构决策敏感且易受门噪声影响，需噪声感知设计。",
    "tags": [
      "Anomaly",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "首次大规模评估混合量子-经典自编码器在无监督网络入侵检测中的性能，构建包含关键量子设计选择的统一实验框架",
      "揭示最优配置HQC模型的泛化优势（零日攻击下更强更稳定），并指出其架构敏感性与噪声鲁棒性待提升的问题"
    ],
    "processed_at": "2025-12-05T08:37:39.560054"
  },
  {
    "id": "2512.04980v1",
    "title": "Learning Causality for Longitudinal Data",
    "abstract": "This thesis develops methods for causal inference and causal representation learning (CRL) in high-dimensional, time-varying data.   The first contribution introduces the Causal Dynamic Variational Autoencoder (CDVAE), a model for estimating Individual Treatment Effects (ITEs) by capturing unobserved heterogeneity in treatment response driven by latent risk factors that affect only outcomes. CDVAE comes with theoretical guarantees on valid latent adjustment and generalization bounds for ITE error. Experiments on synthetic and real datasets show that CDVAE outperforms baselines, and that state-of-the-art models greatly improve when augmented with its latent substitutes, approaching oracle performance without access to true adjustment variables.   The second contribution proposes an efficient framework for long-term counterfactual regression based on RNNs enhanced with Contrastive Predictive Coding (CPC) and InfoMax. It captures long-range dependencies under time-varying confounding while avoiding the computational cost of transformers, achieving state-of-the-art results and introducing CPC into causal inference.   The third contribution advances CRL by addressing how latent causes manifest in observed variables. We introduce a model-agnostic interpretability layer based on the geometry of the decoder Jacobian. A sparse self-expression prior induces modular, possibly overlapping groups of observed features aligned with shared latent influences. We provide recovery guarantees in both disjoint and overlapping settings and show that meaningful latent-to-observed structure can be recovered without anchor features or single-parent assumptions. Scalable Jacobian-based regularization techniques are also developed.",
    "authors": [
      "Mouad EL Bouchattaoui"
    ],
    "published": "2025-12-04",
    "categories": [
      "stat.ML",
      "cs.IT",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04980v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04980v1",
    "fetched_at": "2025-12-05T08:32:35.028218",
    "chinese_title": "纵向数据的因果学习方法研究",
    "chinese_summary": "该论文针对高维时变数据的因果推断与因果表示学习（CRL）提出三项核心贡献：一是提出因果动态变分自动编码器（CDVAE），通过捕捉潜在风险因子驱动的未观测异质性估计个体治疗效应（ITE），具备理论保证且实验优于基线；二是构建RNN结合对比预测编码（CPC）与InfoMax的长期反事实回归框架，处理时变混杂长程依赖并避免Transformer成本，引入CPC到因果推断；三是提出基于解码器雅可比矩阵几何的模型无关可解释层，结合稀疏自表达先验诱导模块化特征组，提供恢复保证。",
    "tags": [
      "Deep Learning",
      "Time Series",
      "Transformer"
    ],
    "key_contributions": [
      "提出因果动态变分自动编码器（CDVAE），估计个体治疗效应（ITE）并捕捉未观测异质性，具备有效潜在调整与ITE误差泛化界的理论保证",
      "构建RNN结合对比预测编码（CPC）与InfoMax的高效长期反事实回归框架，处理时变混杂下的长程依赖且首次将CPC引入因果推断",
      "提出基于解码器雅可比矩阵几何的模型无关可解释层，结合稀疏自表达先验推进因果表示学习的可解释性"
    ],
    "processed_at": "2025-12-05T08:38:25.176435"
  },
  {
    "id": "2512.04895v1",
    "title": "Chameleon: Adaptive Adversarial Agents for Scaling-Based Visual Prompt Injection in Multimodal AI Systems",
    "abstract": "Multimodal Artificial Intelligence (AI) systems, particularly Vision-Language Models (VLMs), have become integral to critical applications ranging from autonomous decision-making to automated document processing. As these systems scale, they rely heavily on preprocessing pipelines to handle diverse inputs efficiently. However, this dependency on standard preprocessing operations, specifically image downscaling, creates a significant yet often overlooked security vulnerability. While intended for computational optimization, scaling algorithms can be exploited to conceal malicious visual prompts that are invisible to human observers but become active semantic instructions once processed by the model. Current adversarial strategies remain largely static, failing to account for the dynamic nature of modern agentic workflows. To address this gap, we propose Chameleon, a novel, adaptive adversarial framework designed to expose and exploit scaling vulnerabilities in production VLMs. Unlike traditional static attacks, Chameleon employs an iterative, agent-based optimization mechanism that dynamically refines image perturbations based on the target model's real-time feedback. This allows the framework to craft highly robust adversarial examples that survive standard downscaling operations to hijack downstream execution. We evaluate Chameleon against Gemini 2.5 Flash model. Our experiments demonstrate that Chameleon achieves an Attack Success Rate (ASR) of 84.5% across varying scaling factors, significantly outperforming static baseline attacks which average only 32.1%. Furthermore, we show that these attacks effectively compromise agentic pipelines, reducing decision-making accuracy by over 45% in multi-step tasks. Finally, we discuss the implications of these vulnerabilities and propose multi-scale consistency checks as a necessary defense mechanism.",
    "authors": [
      "M Zeeshan",
      "Saud Satti"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04895v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04895v1",
    "fetched_at": "2025-12-05T08:32:35.028240",
    "chinese_title": "Chameleon：多模态AI系统中基于缩放的视觉提示注入的自适应对抗智能体",
    "chinese_summary": "该论文指出多模态AI系统（尤其是视觉-语言模型）因依赖图像缩放预处理存在易被忽视的安全漏洞，现有静态对抗策略无法适配动态工作流；提出Chameleon自适应对抗框架，通过迭代智能体优化结合目标模型实时反馈生成鲁棒对抗样本，能对抗标准缩放操作；实验在Gemini 2.5 Flash模型上验证其攻击成功率达84.5%。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "揭示多模态AI系统依赖图像缩放预处理带来的安全漏洞，弥补现有静态对抗策略的不足",
      "提出Chameleon自适应对抗框架，通过迭代智能体优化生成抗缩放的鲁棒对抗样本，在Gemini 2.5 Flash上实现高攻击成功率"
    ],
    "processed_at": "2025-12-05T08:38:41.257887"
  },
  {
    "id": "2512.04841v1",
    "title": "SoK: a Comprehensive Causality Analysis Framework for Large Language Model Security",
    "abstract": "Large Language Models (LLMs) exhibit remarkable capabilities but remain vulnerable to adversarial manipulations such as jailbreaking, where crafted prompts bypass safety mechanisms. Understanding the causal factors behind such vulnerabilities is essential for building reliable defenses.   In this work, we introduce a unified causality analysis framework that systematically supports all levels of causal investigation in LLMs, ranging from token-level, neuron-level, and layer-level interventions to representation-level analysis. The framework enables consistent experimentation and comparison across diverse causality-based attack and defense methods. Accompanying this implementation, we provide the first comprehensive survey of causality-driven jailbreak studies and empirically evaluate the framework on multiple open-weight models and safety-critical benchmarks including jailbreaks, hallucination detection, backdoor identification, and fairness evaluation. Our results reveal that: (1) targeted interventions on causally critical components can reliably modify safety behavior; (2) safety-related mechanisms are highly localized (i.e., concentrated in early-to-middle layers with only 1--2\\% of neurons exhibiting causal influence); and (3) causal features extracted from our framework achieve over 95\\% detection accuracy across multiple threat types.   By bridging theoretical causality analysis and practical model safety, our framework establishes a reproducible foundation for research on causality-based attacks, interpretability, and robust attack detection and mitigation in LLMs. Code is available at https://github.com/Amadeuszhao/SOK_Casuality.",
    "authors": [
      "Wei Zhao",
      "Zhe Li",
      "Jun Sun"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04841v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04841v1",
    "fetched_at": "2025-12-05T08:32:35.028264",
    "chinese_title": "SoK：大语言模型安全的综合因果分析框架",
    "chinese_summary": "论文提出统一的因果分析框架，支持大语言模型（LLM）从token、神经元、层到表示级的因果干预与分析，伴随该框架实现，还完成因果驱动越狱研究的首次全面调研，实证评估覆盖多模型及安全关键基准，揭示因果关键组件对安全行为的影响等核心发现。",
    "tags": [
      "LLM",
      "Transformer",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "提出支持多级别因果调查的统一LLM安全因果分析框架，实现跨方法实验对比"
    ],
    "processed_at": "2025-12-05T08:38:52.992185"
  },
  {
    "id": "2512.04764v1",
    "title": "Human Cognitive Biases in Explanation-Based Interaction: The Case of Within and Between Session Order Effect",
    "abstract": "Explanatory Interactive Learning (XIL) is a powerful interactive learning framework designed to enable users to customize and correct AI models by interacting with their explanations. In a nutshell, XIL algorithms select a number of items on which an AI model made a decision (e.g. images and their tags) and present them to users, together with corresponding explanations (e.g. image regions that drive the model's decision). Then, users supply corrective feedback for the explanations, which the algorithm uses to improve the model. Despite showing promise in debugging tasks, recent studies have raised concerns that explanatory interaction may trigger order effects, a well-known cognitive bias in which the sequence of presented items influences users' trust and, critically, the quality of their feedback. We argue that these studies are not entirely conclusive, as the experimental designs and tasks employed differ substantially from common XIL use cases, complicating interpretation. To clarify the interplay between order effects and explanatory interaction, we ran two larger-scale user studies (n = 713 total) designed to mimic common XIL tasks. Specifically, we assessed order effects both within and between debugging sessions by manipulating the order in which correct and wrong explanations are presented to participants. Order effects had a limited, through significant impact on users' agreement with the model (i.e., a behavioral measure of their trust), and only when examined withing debugging sessions, not between them. The quality of users' feedback was generally satisfactory, with order effects exerting only a small and inconsistent influence in both experiments. Overall, our findings suggest that order effects do not pose a significant issue for the successful employment of XIL approaches. More broadly, our work contributes to the ongoing efforts for understanding human factors in AI.",
    "authors": [
      "Dario Pesenti",
      "Alessandro Bogani",
      "Katya Tentori",
      "Stefano Teso"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04764v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04764v1",
    "fetched_at": "2025-12-05T08:32:35.028288",
    "chinese_title": "基于解释的交互中的人类认知偏差：会话内与会话间顺序效应案例",
    "chinese_summary": "针对解释性交互学习（XIL）框架中解释交互可能触发顺序效应（认知偏差）的争议，作者开展两个大规模用户研究（共713名参与者）模拟常见XIL任务，评估会话内和会话间正确/错误解释呈现顺序的影响；结果发现顺序效应对用户对模型的认同（信任行为指标）有有限但显著的作用。",
    "tags": [
      "Behavioral Finance"
    ],
    "key_contributions": [
      "通过两个大规模用户研究（n=713）模拟常见XIL任务，填补此前研究实验设计与XIL实际用例差异的空白",
      "明确会话内与会话间顺序效应对用户模型认同的有限但显著影响，澄清解释交互中顺序效应的作用"
    ],
    "processed_at": "2025-12-05T08:39:15.443743"
  },
  {
    "id": "2512.04695v1",
    "title": "TRINITY: An Evolved LLM Coordinator",
    "abstract": "Combining diverse foundation models is promising, but weight-merging is limited by mismatched architectures and closed APIs. Trinity addresses this with a lightweight coordinator that orchestrates collaboration among large language models (LLMs). The coordinator, comprising a compact language model (approximately $0.6$B parameters) and a lightweight head (approximately $10$K parameters), is optimized with an evolutionary strategy for efficient and adaptive delegation. Trinity processes queries over multiple turns, where at each turn the coordinator assigns one of three roles (Thinker, Worker, or Verifier) to a selected LLM, effectively offloading complex skill acquisition from the coordinator itself. Experiments show that Trinity consistently outperforms individual models and existing methods across coding, math, reasoning, and domain knowledge tasks, and generalizes robustly to out-of-distribution tasks. On standard benchmarks, Trinity achieves state-of-the-art results, including a score of 86.2% on LiveCodeBench. Theoretical and empirical analyses identify two main factors behind this performance: (1) the coordinator's hidden-state representations provide rich contextualization of inputs, and (2) under high dimensionality and strict budget constraints, the separable Covariance Matrix Adaptation Evolution Strategy offers advantages over reinforcement learning, imitation learning, and random search by exploiting potential block-epsilon-separability.",
    "authors": [
      "Jinglue Xu",
      "Qi Sun",
      "Peter Schwendeman",
      "Stefan Nielsen",
      "Edoardo Cetin",
      "Yujin Tang"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04695v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04695v1",
    "fetched_at": "2025-12-05T08:32:35.028315",
    "chinese_title": "TRINITY：一种进化型大语言模型协调器",
    "chinese_summary": "TRINITY提出一种轻量协调器（含约0.6B参数的紧凑语言模型和约10K参数的轻量头），通过进化策略优化多轮角色分配（Thinker/Worker/Verifier）来协调多个大语言模型（LLM）协作，解决模型架构不匹配与封闭API的融合难题；实验表明其在编码、数学、推理等任务上优于单模型与现有方法，LiveCodeBench得分达86.2%，并分析了性能提升的关键因素。",
    "tags": [
      "LLM",
      "Deep Learning",
      "NLP"
    ],
    "key_contributions": [
      "提出轻量协调器架构，通过进化策略优化多轮角色分配实现多LLM协作，解决架构不匹配与封闭API融合问题",
      "在多任务上达到SOTA，分析了性能提升的关键因素（协调器隐藏状态、进化策略优势）"
    ],
    "processed_at": "2025-12-05T08:39:36.852150"
  },
  {
    "id": "2512.04559v1",
    "title": "Diffusion Fine-Tuning via Reparameterized Policy Gradient of the Soft Q-Function",
    "abstract": "Diffusion models excel at generating high-likelihood samples but often require alignment with downstream objectives. Existing fine-tuning methods for diffusion models significantly suffer from reward over-optimization, resulting in high-reward but unnatural samples and degraded diversity. To mitigate over-optimization, we propose \\textbf{Soft Q-based Diffusion Finetuning (SQDF)}, a novel KL-regularized RL method for diffusion alignment that applies a reparameterized policy gradient of a training-free, differentiable estimation of the soft Q-function. SQDF is further enhanced with three innovations: a discount factor for proper credit assignment in the denoising process, the integration of consistency models to refine Q-function estimates, and the use of an off-policy replay buffer to improve mode coverage and manage the reward-diversity trade-off. Our experiments demonstrate that SQDF achieves superior target rewards while preserving diversity in text-to-image alignment. Furthermore, in online black-box optimization, SQDF attains high sample efficiency while maintaining naturalness and diversity.",
    "authors": [
      "Hyeongyu Kang",
      "Jaewoo Lee",
      "Woocheol Shin",
      "Kiyoung Om",
      "Jinkyoo Park"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04559v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04559v1",
    "fetched_at": "2025-12-05T08:32:35.028342",
    "chinese_title": "基于软Q函数重参数化策略梯度的扩散模型微调",
    "chinese_summary": "现有扩散模型微调方法存在奖励过度优化问题，导致样本不自然、多样性下降；论文提出软Q-based扩散微调（SQDF）方法，采用无训练可微软Q函数的重参数化策略梯度及KL正则化，结合折扣因子、一致性模型、离策略回放缓冲区等创新，在文本到图像对齐和在线黑箱优化中实现高奖励与多样性/自然性的平衡。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出软Q-based扩散微调（SQDF）方法，通过无训练可微软Q函数的重参数化策略梯度及KL正则化，缓解扩散模型微调的奖励过度优化问题",
      "引入折扣因子、一致性模型、离策略回放缓冲区三个创新，提升目标奖励同时保留样本多样性与自然性，在多任务中验证效果"
    ],
    "processed_at": "2025-12-05T08:39:56.042919"
  },
  {
    "id": "2512.04252v1",
    "title": "Fine-Tuning ChemBERTa for Predicting Inhibitory Activity Against TDP1 Using Deep Learning",
    "abstract": "Predicting the inhibitory potency of small molecules against Tyrosyl-DNA Phosphodiesterase 1 (TDP1)-a key target in overcoming cancer chemoresistance-remains a critical challenge in early drug discovery. We present a deep learning framework for the quantitative regression of pIC50 values from molecular Simplified Molecular Input Line Entry System (SMILES) strings using fine-tuned variants of ChemBERTa, a pre-trained chemical language model. Leveraging a large-scale consensus dataset of 177,092 compounds, we systematically evaluate two pre-training strategies-Masked Language Modeling (MLM) and Masked Token Regression (MTR)-under stratified data splits and sample weighting to address severe activity imbalance which only 2.1% are active. Our approach outperforms classical baselines Random Predictor in both regression accuracy and virtual screening utility, and has competitive performance compared to Random Forest, achieving high enrichment factor EF@1% 17.4 and precision Precision@1% 37.4 among top-ranked predictions. The resulting model, validated through rigorous ablation and hyperparameter studies, provides a robust, ready-to-deploy tool for prioritizing TDP1 inhibitors for experimental testing. By enabling accurate, 3D-structure-free pIC50 prediction directly from SMILES, this work demonstrates the transformative potential of chemical transformers in accelerating target-specific drug discovery.",
    "authors": [
      "Baichuan Zeng"
    ],
    "published": "2025-12-03",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04252v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04252v1",
    "fetched_at": "2025-12-05T08:32:35.028361",
    "chinese_title": "微调ChemBERTa用于预测对TDP1抑制活性的深度学习方法",
    "chinese_summary": "本文提出基于微调预训练化学语言模型ChemBERTa的框架，从分子SMILES字符串定量回归TDP1抑制剂的pIC50值；系统评估MLM和MTR两种预训练策略，处理仅2.1%活性化合物的不平衡问题，模型在回归精度和虚拟筛选效用上优于经典基线，为TDP1抑制剂实验测试优先级排序提供稳健工具。",
    "tags": [
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "构建基于微调ChemBERTa的框架，无需3D分子结构即可从SMILES直接预测TDP1抑制剂的pIC50值",
      "系统评估两种预训练策略并处理活性不平衡，模型虚拟筛选性能优异（EF@1%=17.4、Precision@1%=37.4），提供可部署的药物发现工具"
    ],
    "processed_at": "2025-12-05T08:40:21.538948"
  },
  {
    "id": "2512.04231v1",
    "title": "CRAFT-E: A Neuro-Symbolic Framework for Embodied Affordance Grounding",
    "abstract": "Assistive robots operating in unstructured environments must understand not only what objects are, but what they can be used for. This requires grounding language-based action queries to objects that both afford the requested function and can be physically retrieved. Existing approaches often rely on black-box models or fixed affordance labels, limiting transparency, controllability, and reliability for human-facing applications. We introduce CRAFT-E, a modular neuro-symbolic framework that composes a structured verb-property-object knowledge graph with visual-language alignment and energy-based grasp reasoning. The system generates interpretable grounding paths that expose the factors influencing object selection and incorporates grasp feasibility as an integral part of affordance inference. We further construct a benchmark dataset with unified annotations for verb-object compatibility, segmentation, and grasp candidates, and deploy the full pipeline on a physical robot. CRAFT-E achieves competitive performance in static scenes, ImageNet-based functional retrieval, and real-world trials involving 20 verbs and 39 objects. The framework remains robust under perceptual noise and provides transparent, component-level diagnostics. By coupling symbolic reasoning with embodied perception, CRAFT-E offers an interpretable and customizable alternative to end-to-end models for affordance-grounded object selection, supporting trustworthy decision-making in assistive robotic systems.",
    "authors": [
      "Zhou Chen",
      "Joe Lin",
      "Carson Bulgin",
      "Sathyanarayanan N. Aakur"
    ],
    "published": "2025-12-03",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04231v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04231v1",
    "fetched_at": "2025-12-05T08:32:35.028385",
    "chinese_title": "CRAFT-E：用于具身可用性接地的神经符号框架",
    "chinese_summary": "论文提出模块化神经符号框架CRAFT-E，整合结构化动词-属性-对象知识图、视觉语言对齐与基于能量的抓取推理，解决辅助机器人在非结构化环境中理解对象可用性并物理获取的问题；构建统一标注的基准数据集并部署物理机器人验证，实现可解释、鲁棒的可信决策。",
    "tags": [
      "Deep Learning",
      "Graph Neural Network",
      "Benchmark"
    ],
    "key_contributions": [
      "提出模块化神经符号框架CRAFT-E，耦合符号推理与具身感知，提供可解释、可控的可用性接地对象选择方案",
      "构建含统一标注的基准数据集，部署物理机器人验证，在多场景中表现优异且对感知噪声鲁棒"
    ],
    "processed_at": "2025-12-05T08:40:39.372336"
  },
  {
    "id": "2512.03807v2",
    "title": "Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics",
    "abstract": "Boolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. Unlike binary matrix factorization based on standard arithmetic, BMF employs the Boolean OR and AND operations for the matrix product, which improves interpretability and reduces the approximation error. It is also used in role mining and computer vision. In this paper, we first propose algorithms for BMF that perform alternating optimization (AO) of the factor matrices, where each subproblem is solved via integer programming (IP). We then design different approaches to further enhance AO-based algorithms by selecting an optimal subset of rank-one factors from multiple runs. To address the scalability limits of IP-based methods, we introduce new greedy and local-search heuristics. We also construct a new C++ data structure for Boolean vectors and matrices that is significantly faster than existing ones and is of independent interest, allowing our heuristics to scale to large datasets. We illustrate the performance of all our proposed methods and compare them with the state of the art on various real datasets, both with and without missing data, including applications in topic modeling and imaging.",
    "authors": [
      "Christos Kolomvakis",
      "Thomas Bobille",
      "Arnaud Vandaele",
      "Nicolas Gillis"
    ],
    "published": "2025-12-03",
    "categories": [
      "cs.IR",
      "eess.SP",
      "math.OC",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.03807v2",
    "arxiv_url": "https://arxiv.org/abs/2512.03807v2",
    "fetched_at": "2025-12-05T08:32:35.028475",
    "chinese_title": "基于整数规划与启发式的布尔矩阵分解算法",
    "chinese_summary": "本文提出交替优化结合整数规划的布尔矩阵分解算法，设计从多轮运行中选最优秩一因子的增强方法；为解决可扩展性问题引入贪心和局部搜索启发式，构建更快的C++布尔数据结构，在真实数据集上验证性能优于现有方法。",
    "tags": [
      "Factor Mining"
    ],
    "key_contributions": [
      "提出交替优化（AO）结合整数规划（IP）的布尔矩阵分解算法，设计多轮运行选最优秩一因子的增强策略",
      "引入贪心与局部搜索启发式提升IP方法的可扩展性，构建高效C++布尔数据结构支持大规模数据集处理"
    ],
    "processed_at": "2025-12-05T08:40:53.494027"
  },
  {
    "id": "2512.04635v1",
    "title": "Federated Learning for Anomaly Detection in Maritime Movement Data",
    "abstract": "This paper introduces M3fed, a novel solution for federated learning of movement anomaly detection models. This innovation has the potential to improve data privacy and reduce communication costs in machine learning for movement anomaly detection. We present the novel federated learning (FL) strategies employed to train M3fed, perform an example experiment with maritime AIS data, and evaluate the results with respect to communication costs and FL model quality by comparing classic centralized M3 and the new federated M3fed.",
    "authors": [
      "Anita Graser",
      "Axel Weißenfeld",
      "Clemens Heistracher",
      "Melitta Dragaschnig",
      "Peter Widhalm"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04635v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04635v1",
    "fetched_at": "2025-12-05T08:32:41.661127",
    "chinese_title": "用于海事运动数据异常检测的联邦学习",
    "chinese_summary": "本文提出用于运动异常检测的新型联邦学习模型M3fed，可提升数据隐私并降低通信成本；采用联邦学习策略训练该模型，以海事AIS数据开展实验，对比经典集中式M3评估通信成本与模型质量。",
    "tags": [
      "Anomaly",
      "Deep Learning",
      "Time Series",
      "Risk Management"
    ],
    "key_contributions": [
      "提出M3fed联邦学习解决方案，解决运动异常检测中的数据隐私与通信成本问题",
      "设计联邦学习训练策略，通过海事AIS数据实验验证模型效果并对比集中式方法"
    ],
    "processed_at": "2025-12-05T08:41:04.584712"
  },
  {
    "id": "2512.04590v1",
    "title": "Exploiting \\texttt{ftrace}'s \\texttt{function\\_graph} Tracer Features for Machine Learning: A Case Study on Encryption Detection",
    "abstract": "This paper proposes using the Linux kernel ftrace framework, particularly the function graph tracer, to generate informative system level data for machine learning (ML) applications. Experiments on a real world encryption detection task demonstrate the efficacy of the proposed features across several learning algorithms. The learner faces the problem of detecting encryption activities across a large dataset of files, using function call traces and graph based features. Empirical results highlight an outstanding accuracy of 99.28 on the task at hand, underscoring the efficacy of features derived from the function graph tracer. The results were further validated in an additional experiment targeting a multilabel classification problem, in which running programs were identified from trace data. This work provides comprehensive methodologies for preprocessing raw trace data and extracting graph based features, offering significant advancements in applying ML to system behavior analysis, program identification, and anomaly detection. By bridging the gap between system tracing and ML, this paper paves the way for innovative solutions in performance monitoring and security analytics.",
    "authors": [
      "Kenan Begovic",
      "Abdulaziz Al-Ali",
      "Qutaibah Malluhi"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04590v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04590v1",
    "fetched_at": "2025-12-05T08:32:41.661150",
    "chinese_title": "利用ftrace的function_graph追踪器特征进行机器学习：加密检测案例研究",
    "chinese_summary": "该论文提出利用Linux内核ftrace框架的函数图追踪器生成系统级数据，提取函数调用轨迹与图特征用于机器学习；在加密检测任务中实现99.28%的准确率，还验证了多标签程序识别任务，提供了追踪数据预处理与图特征提取方法，桥接系统追踪与ML，推动性能监控和安全分析。",
    "tags": [
      "Anomaly",
      "Graph Neural Network",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出利用Linux ftrace的function_graph追踪器生成系统级数据，提取函数调用轨迹与图特征，在加密检测任务中实现99.28%的高准确率",
      "提供原始追踪数据预处理与图特征提取的完整方法，验证多标签程序识别任务，桥接系统追踪与机器学习，推动性能监控和安全分析创新"
    ],
    "processed_at": "2025-12-05T08:41:23.885789"
  },
  {
    "id": "2512.04368v1",
    "title": "AutoGuard: A Self-Healing Proactive Security Layer for DevSecOps Pipelines Using Reinforcement Learning",
    "abstract": "Contemporary DevSecOps pipelines have to deal with the evolution of security in an ever-continuously integrated and deployed environment. Existing methods,such as rule-based intrusion detection and static vulnerability scanning, are inadequate and unreceptive to changes in the system, causing longer response times and organization needs exposure to emerging attack vectors. In light of the previous constraints, we introduce AutoGuard to the DevSecOps ecosystem, a reinforcement learning (RL)-powered self-healing security framework built to pre-emptively protect DevSecOps environments. AutoGuard is a self-securing security environment that continuously observes pipeline activities for potential anomalies while preemptively remediating the environment. The model observes and reacts based on a policy that is continually learned dynamically over time. The RL agent improves each action over time through reward-based learning aimed at improving the agent's ability to prevent, detect and respond to a security incident in real-time. Testing using simulated ContinuousIntegration / Continuous Deployment (CI/CD) environments showed AutoGuard to successfully improve threat detection accuracy by 22%, reduce mean time torecovery (MTTR) for incidents by 38% and increase overall resilience to incidents as compared to traditional methods.   Keywords- DevSecOps, Reinforcement Learning, Self- Healing Security, Continuous Integration, Automated Threat Mitigation",
    "authors": [
      "Praveen Anugula",
      "Avdhesh Kumar Bhardwaj",
      "Navin Chhibber",
      "Rohit Tewari",
      "Sunil Khemka",
      "Piyush Ranjan"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04368v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04368v1",
    "fetched_at": "2025-12-05T08:32:41.661180",
    "chinese_title": "AutoGuard：基于强化学习的DevSecOps管道自修复主动安全层",
    "chinese_summary": "针对现有DevSecOps管道中规则类安全方法无法适应动态变化、响应迟缓的问题，论文提出基于强化学习的自修复主动安全框架AutoGuard，通过持续观察管道活动学习动态策略，实时预防、检测并响应安全事件；实验表明其威胁检测准确率提升22%、平均恢复时间降低38%，增强了系统韧性。",
    "tags": [
      "Reinforcement Learning",
      "Anomaly",
      "Risk Management"
    ],
    "key_contributions": [
      "提出强化学习驱动的自修复主动安全框架AutoGuard，适配DevSecOps动态环境的安全需求",
      "实验验证AutoGuard显著提升威胁检测效率、降低事件恢复时间并增强系统韧性"
    ],
    "processed_at": "2025-12-05T08:41:37.384629"
  },
  {
    "id": "2512.04282v1",
    "title": "Inference-time Stochastic Refinement of GRU-Normalizing Flow for Real-time Video Motion Transfer",
    "abstract": "Real-time video motion transfer applications such as immersive gaming and vision-based anomaly detection require accurate yet diverse future predictions to support realistic synthesis and robust downstream decision making under uncertainty. To improve the diversity of such sequential forecasts we propose a novel inference-time refinement technique that combines Gated Recurrent Unit-Normalizing Flows (GRU-NF) with stochastic sampling methods. While GRU-NF can capture multimodal distributions through its integration of normalizing flows within a temporal forecasting framework, its deterministic transformation structure can limit expressivity. To address this, inspired by Stochastic Normalizing Flows (SNF), we introduce Markov Chain Monte Carlo (MCMC) steps during GRU-NF inference, enabling the model to explore a richer output space and better approximate the true data distribution without retraining. We validate our approach in a keypoint-based video motion transfer pipeline, where capturing temporally coherent and perceptually diverse future trajectories is essential for realistic samples and low bandwidth communication. Experiments show that our inference framework, Gated Recurrent Unit- Stochastic Normalizing Flows (GRU-SNF) outperforms GRU-NF in generating diverse outputs without sacrificing accuracy, even under longer prediction horizons. By injecting stochasticity during inference, our approach captures multimodal behavior more effectively. These results highlight the potential of integrating stochastic dynamics with flow-based sequence models for generative time series forecasting.",
    "authors": [
      "Tasmiah Haque",
      "Srinjoy Das"
    ],
    "published": "2025-12-03",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04282v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04282v1",
    "fetched_at": "2025-12-05T08:32:41.661201",
    "chinese_title": "用于实时视频运动迁移的GRU-归一化流推理时随机细化",
    "chinese_summary": "针对实时视频运动迁移需准确且多样的未来预测问题，论文提出推理时随机细化方法GRU-SNF：结合GRU-归一化流（GRU-NF）与MCMC采样（受随机归一化流启发），无需重训练即可提升输出多样性且不牺牲准确性，在关键点视频运动迁移 pipeline 中验证有效。",
    "tags": [
      "Deep Learning",
      "Time Series",
      "Anomaly"
    ],
    "key_contributions": [
      "提出推理时随机细化方法GRU-SNF，结合GRU-NF与MCMC采样，无需重训练提升预测多样性",
      "在实时视频运动迁移中验证，GRU-SNF兼顾准确性与多样性，适应长预测 horizon"
    ],
    "processed_at": "2025-12-05T08:41:57.248760"
  },
  {
    "id": "2512.04690v1",
    "title": "Recurrent Neural Networks with Linear Structures for Electricity Price Forecasting",
    "abstract": "We present a novel recurrent neural network architecture designed explicitly for day-ahead electricity price forecasting, aimed at improving short-term decision-making and operational management in energy systems. Our combined forecasting model embeds linear structures, such as expert models and Kalman filters, into recurrent networks, enabling efficient computation and enhanced interpretability. The design leverages the strengths of both linear and non-linear model structures, allowing it to capture all relevant stylised price characteristics in power markets, including calendar and autoregressive effects, as well as influences from load, renewable energy, and related fuel and carbon markets. For empirical testing, we use hourly data from the largest European electricity market spanning 2018 to 2025 in a comprehensive forecasting study, comparing our model against state-of-the-art approaches, particularly high-dimensional linear and neural network models. The proposed model achieves approximately 12% higher accuracy than leading benchmarks. We evaluate the contributions of the interpretable model components and conclude on the impact of combining linear and non-linear structures.",
    "authors": [
      "Souhir Ben Amor",
      "Florian Ziel"
    ],
    "published": "2025-12-04",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04690v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04690v1",
    "fetched_at": "2025-12-05T08:32:51.928358",
    "chinese_title": "带线性结构的循环神经网络用于电价预测",
    "chinese_summary": "论文提出一种嵌入线性结构（专家模型、卡尔曼滤波）的新型循环神经网络，用于日前电价预测，结合线性与非线性优势捕捉电价的日历、自回归及负荷等影响特征；实证采用欧洲最大电力市场2018-2025年小时数据，模型准确率较领先基准提升约12%，并分析了可解释组件的贡献。",
    "tags": [
      "Deep Learning",
      "Time Series",
      "Asset Pricing",
      "Benchmark"
    ],
    "key_contributions": [
      "提出嵌入线性结构（专家模型、卡尔曼滤波）的新型循环神经网络架构，融合线性与非线性优势捕捉电价关键特征",
      "实证在欧洲最大电力市场数据上，预测准确率较领先基准提升约12%，并验证可解释组件的贡献"
    ],
    "processed_at": "2025-12-05T08:42:14.745604"
  },
  {
    "id": "2512.04112v1",
    "title": "MindFuse: Towards GenAI Explainability in Marketing Strategy Co-Creation",
    "abstract": "The future of digital marketing lies in the convergence of human creativity and generative AI, where insight, strategy, and storytelling are co-authored by intelligent systems. We present MindFuse, a brave new explainable generative AI framework designed to act as a strategic partner in the marketing process. Unlike conventional LLM applications that stop at content generation, MindFuse fuses CTR-based content AI-guided co-creation with large language models to extract, interpret, and iterate on communication narratives grounded in real advertising data. MindFuse operates across the full marketing lifecycle: from distilling content pillars and customer personas from competitor campaigns to recommending in-flight optimizations based on live performance telemetry. It uses attention-based explainability to diagnose ad effectiveness and guide content iteration, while aligning messaging with strategic goals through dynamic narrative construction and storytelling. We introduce a new paradigm in GenAI for marketing, where LLMs not only generate content but reason through it, adapt campaigns in real time, and learn from audience engagement patterns. Our results, validated in agency deployments, demonstrate up to 12 times efficiency gains, setting the stage for future integration with empirical audience data (e.g., GWI, Nielsen) and full-funnel attribution modeling. MindFuse redefines AI not just as a tool, but as a collaborative agent in the creative and strategic fabric of modern marketing.",
    "authors": [
      "Aleksandr Farseev",
      "Marlo Ongpin",
      "Qi Yang",
      "Ilia Gossoudarev",
      "Yu-Yi Chu-Farseeva",
      "Sergey Nikolenko"
    ],
    "published": "2025-12-01",
    "categories": [
      "cs.MM",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04112v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04112v1",
    "fetched_at": "2025-12-05T08:32:51.928396",
    "chinese_title": "MindFuse：面向营销战略共创的生成式AI可解释性研究",
    "chinese_summary": "论文提出MindFuse可解释生成式AI框架，融合CTR导向的内容共创与大语言模型（LLM），覆盖营销全生命周期（从竞品分析到实时优化）；通过注意力可解释性诊断广告效果，实现LLM从内容生成到推理、实时适应与学习的升级；经机构部署验证效率提升12倍，为整合实证受众数据和全漏斗归因建模奠基。",
    "tags": [
      "LLM",
      "NLP",
      "Transformer"
    ],
    "key_contributions": [
      "提出MindFuse可解释生成式AI框架，融合CTR导向的内容共创与LLM，覆盖营销全生命周期，实现LLM从内容生成到推理、实时适应与学习的升级",
      "经机构部署验证框架带来12倍效率提升，为后续整合实证受众数据和全漏斗归因建模奠定基础"
    ],
    "processed_at": "2025-12-05T08:42:43.060543"
  },
  {
    "id": "2512.04139v1",
    "title": "Solving N-Queen Problem using Las Vegas Algorithm with State Pruning",
    "abstract": "The N-Queens problem, placing all N queens in a N x N chessboard where none attack the other, is a classic problem for constraint satisfaction algorithms. While complete methods like backtracking guarantee a solution, their exponential time complexity makes them impractical for large-scale instances thus, stochastic approaches, such as Las Vegas algorithm, are preferred. While it offers faster approximate solutions, it suffers from significant performance variance due to random placement of queens on the board. This research introduces a hybrid algorithm built on top of the standard Las Vegas framework through iterative pruning, dynamically eliminating invalid placements during the random assignment phase, thus this method effectively reduces the search space. The analysis results that traditional backtracking scales poorly with increasing N. In contrast, the proposed technique consistently generates valid solutions more rapidly, establishing it as a superior alternative to use where a single, timely solution is preferred over completeness. Although large N causes some performance variability, the algorithm demonstrates a highly effective trade-off between computational cost and solution fidelity, making it particularly suited for resource-constrained computing environments.",
    "authors": [
      "Susmita Sharma",
      "Aayush Shrestha",
      "Sitasma Thapa",
      "Prashant Timalsina",
      "Prakash Poudyal"
    ],
    "published": "2025-12-03",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04139v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04139v1",
    "fetched_at": "2025-12-05T08:33:02.055911",
    "chinese_title": "用带状态剪枝的拉斯维加斯算法解决N皇后问题",
    "chinese_summary": "论文针对N皇后问题，提出一种基于状态剪枝的混合拉斯维加斯算法，通过迭代剪枝动态消除随机分配阶段的无效放置以缩小搜索空间；相比传统回溯法，该算法能更快生成有效解，在资源受限环境下实现计算成本与解质量的高效权衡，适合优先需要及时单解而非完整性的场景。",
    "tags": [
      "Algorithmic Trading",
      "Reinforcement Learning"
    ],
    "key_contributions": [
      "提出基于状态剪枝的混合拉斯维加斯算法，动态剪枝随机分配中的无效放置，有效缩小搜索空间",
      "相比回溯法，算法更快生成有效解，在资源受限环境下平衡计算成本与解质量，适配优先及时单解的需求"
    ],
    "processed_at": "2025-12-05T08:43:35.220532"
  },
  {
    "id": "2512.04834v1",
    "title": "Are LLMs Truly Multilingual? Exploring Zero-Shot Multilingual Capability of LLMs for Information Retrieval: An Italian Healthcare Use Case",
    "abstract": "Large Language Models (LLMs) have become a key topic in AI and NLP, transforming sectors like healthcare, finance, education, and marketing by improving customer service, automating tasks, providing insights, improving diagnostics, and personalizing learning experiences. Information extraction from clinical records is a crucial task in digital healthcare. Although traditional NLP techniques have been used for this in the past, they often fall short due to the complexity, variability of clinical language, and high inner semantics in the free clinical text. Recently, Large Language Models (LLMs) have become a powerful tool for better understanding and generating human-like text, making them highly effective in this area. In this paper, we explore the ability of open-source multilingual LLMs to understand EHRs (Electronic Health Records) in Italian and help extract information from them in real-time. Our detailed experimental campaign on comorbidity extraction from EHR reveals that some LLMs struggle in zero-shot, on-premises settings, and others show significant variation in performance, struggling to generalize across various diseases when compared to native pattern matching and manual annotations.",
    "authors": [
      "Vignesh Kumar Kembu",
      "Pierandrea Morandini",
      "Marta Bianca Maria Ranzini",
      "Antonino Nocera"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04834v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04834v1",
    "fetched_at": "2025-12-05T08:33:06.809836",
    "chinese_title": "LLM真的多语言吗？探索LLM零样本多语言信息检索能力：意大利医疗用例",
    "chinese_summary": "本文聚焦开源多语言大语言模型（LLM）的零样本多语言能力，以意大利语电子健康记录（EHR）的合并症提取为医疗用例展开实验研究；结果表明部分LLM在零样本本地部署场景下表现欠佳，性能差异显著，且对不同疾病的泛化能力弱于原生模式匹配与人工标注。",
    "tags": [
      "LLM",
      "NLP",
      "Transformer"
    ],
    "key_contributions": [
      "针对意大利语电子健康记录（EHR）的合并症提取任务，系统验证了开源多语言LLM的零样本多语言能力",
      "揭示了部分LLM在零样本本地部署场景下的性能局限（表现不稳定、泛化能力弱于传统方法）"
    ],
    "processed_at": "2025-12-05T08:43:58.616273"
  },
  {
    "id": "2512.05049v1",
    "title": "QKAN-LSTM: Quantum-inspired Kolmogorov-Arnold Long Short-term Memory",
    "abstract": "Long short-term memory (LSTM) models are a particular type of recurrent neural networks (RNNs) that are central to sequential modeling tasks in domains such as urban telecommunication forecasting, where temporal correlations and nonlinear dependencies dominate. However, conventional LSTMs suffer from high parameter redundancy and limited nonlinear expressivity. In this work, we propose the Quantum-inspired Kolmogorov-Arnold Long Short-Term Memory (QKAN-LSTM), which integrates Data Re-Uploading Activation (DARUAN) modules into the gating structure of LSTMs. Each DARUAN acts as a quantum variational activation function (QVAF), enhancing frequency adaptability and enabling an exponentially enriched spectral representation without multi-qubit entanglement. The resulting architecture preserves quantum-level expressivity while remaining fully executable on classical hardware. Empirical evaluations on three datasets, Damped Simple Harmonic Motion, Bessel Function, and Urban Telecommunication, demonstrate that QKAN-LSTM achieves superior predictive accuracy and generalization with a 79% reduction in trainable parameters compared to classical LSTMs. We extend the framework to the Jiang-Huang-Chen-Goan Network (JHCG Net), which generalizes KAN to encoder-decoder structures, and then further use QKAN to realize the latent KAN, thereby creating a Hybrid QKAN (HQKAN) for hierarchical representation learning. The proposed HQKAN-LSTM thus provides a scalable and interpretable pathway toward quantum-inspired sequential modeling in real-world data environments.",
    "authors": [
      "Yu-Chao Hsu",
      "Jiun-Cheng Jiang",
      "Chun-Hua Lin",
      "Kuo-Chung Peng",
      "Nan-Yow Chen",
      "Samuel Yen-Chi Chen",
      "En-Jui Kuo",
      "Hsi-Sheng Goan"
    ],
    "published": "2025-12-04",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.05049v1",
    "arxiv_url": "https://arxiv.org/abs/2512.05049v1",
    "fetched_at": "2025-12-05T08:33:13.504464",
    "chinese_title": "QKAN-LSTM：量子启发的Kolmogorov-Arnold长短期记忆网络",
    "chinese_summary": "该文提出QKAN-LSTM，将量子启发的数据重上传激活模块（DARUAN）融入LSTM门控结构，增强频率适应性与谱表示且无需多量子比特纠缠，可在经典硬件运行；实证在三个数据集上预测准确率与泛化性更优，参数较经典LSTM减少79%；还扩展出JHCG Net与混合QKAN（HQKAN）用于分层表示学习。",
    "tags": [
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "提出QKAN-LSTM，融合量子启发的DARUAN模块提升LSTM非线性表达，减少79%可训练参数且可经典硬件执行",
      "扩展出JHCG Net与混合QKAN（HQKAN），实现分层表示学习，提供可扩展可解释的架构路径"
    ],
    "processed_at": "2025-12-05T08:44:21.482745"
  },
  {
    "id": "2512.04918v1",
    "title": "Multi-Agent Reinforcement Learning for Intraday Operating Rooms Scheduling under Uncertainty",
    "abstract": "Intraday surgical scheduling is a multi-objective decision problem under uncertainty-balancing elective throughput, urgent and emergency demand, delays, sequence-dependent setups, and overtime. We formulate the problem as a cooperative Markov game and propose a multi-agent reinforcement learning (MARL) framework in which each operating room (OR) is an agent trained with centralized training and decentralized execution. All agents share a policy trained via Proximal Policy Optimization (PPO), which maps rich system states to actions, while a within-epoch sequential assignment protocol constructs conflict-free joint schedules across ORs. A mixed-integer pre-schedule provides reference starting times for electives; we impose type-specific quadratic delay penalties relative to these references and a terminal overtime penalty, yielding a single reward that captures throughput, timeliness, and staff workload. In simulations reflecting a realistic hospital mix (six ORs, eight surgery types, random urgent and emergency arrivals), the learned policy outperforms six rule-based heuristics across seven metrics and three evaluation subsets, and, relative to an ex post MIP oracle, quantifies optimality gaps. Policy analytics reveal interpretable behavior-prioritizing emergencies, batching similar cases to reduce setups, and deferring lower-value electives. We also derive a suboptimality bound for the sequential decomposition under simplifying assumptions. We discuss limitations-including OR homogeneity and the omission of explicit staffing constraints-and outline extensions. Overall, the approach offers a practical, interpretable, and tunable data-driven complement to optimization for real-time OR scheduling.",
    "authors": [
      "Kailiang Liu",
      "Ying Chen",
      "Ralf Borndörfer",
      "Thorsten Koch"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04918v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04918v1",
    "fetched_at": "2025-12-05T08:33:13.504499",
    "chinese_title": "不确定环境下日内手术室调度的多智能体强化学习方法",
    "chinese_summary": "本文将不确定环境下的日内手术室调度问题建模为合作马尔可夫博弈，提出集中训练分散执行的多智能体强化学习框架，采用PPO训练共享策略并结合混合整数预调度与顺序分配协议；在模拟实验中该方法优于6种启发式规则，量化与MIP oracle的最优间隙，揭示可解释调度行为并推导顺序分解的次优边界。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出不确定环境下日内手术室调度的多智能体强化学习框架，在模拟中优于6种启发式规则并量化与MIP oracle的最优间隙",
      "揭示可解释的调度行为（优先急诊、批处理相似手术等）并推导顺序分解的次优边界"
    ],
    "processed_at": "2025-12-05T08:44:41.720143"
  },
  {
    "id": "2512.04868v1",
    "title": "SEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs",
    "abstract": "Knowledge-based conversational question answering (KBCQA) confronts persistent challenges in resolving coreference, modeling contextual dependencies, and executing complex logical reasoning. Existing approaches, whether end-to-end semantic parsing or stepwise agent-based reasoning, often suffer from structural inaccuracies and prohibitive computational costs, particularly when processing intricate queries over large knowledge graphs. To address these limitations, we introduce SEAL, a novel two-stage semantic parsing framework grounded in self-evolving agentic learning. In the first stage, a large language model (LLM) extracts a minimal S-expression core that captures the essential semantics of the input query. This core is then refined by an agentic calibration module, which corrects syntactic inconsistencies and aligns entities and relations precisely with the underlying knowledge graph. The second stage employs template-based completion, guided by question-type prediction and placeholder instantiation, to construct a fully executable S-expression. This decomposition not only simplifies logical form generation but also significantly enhances structural fidelity and linking efficiency. Crucially, SEAL incorporates a self-evolving mechanism that integrates local and global memory with a reflection module, enabling continuous adaptation from dialog history and execution feedback without explicit retraining. Extensive experiments on the SPICE benchmark demonstrate that SEAL achieves state-of-the-art performance, especially in multi-hop reasoning, comparison, and aggregation tasks. The results validate notable gains in both structural accuracy and computational efficiency, underscoring the framework's capacity for robust and scalable conversational reasoning.",
    "authors": [
      "Hao Wang",
      "Jialun Zhong",
      "Changcheng Wang",
      "Zhujun Nie",
      "Zheng Li",
      "Shunyu Yao",
      "Yanzeng Li",
      "Xinchi Li"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04868v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04868v1",
    "fetched_at": "2025-12-05T08:33:13.504549",
    "chinese_title": "SEAL：面向知识图谱对话式问答的自进化智能体学习",
    "chinese_summary": "针对知识图谱对话式问答中核心指代、上下文依赖及复杂推理的挑战，论文提出SEAL两阶段语义解析框架，第一阶段以大语言模型提取语义核心并经智能体校准模块修正，第二阶段通过模板补全生成可执行S表达式；同时融入自进化机制，无需显式重训练即可从对话历史与执行反馈持续适应，提升了结构准确性与链接效率。",
    "tags": [
      "LLM",
      "NLP",
      "Graph Neural Network"
    ],
    "key_contributions": [
      "提出SEAL两阶段语义解析框架，通过LLM提取语义核心、智能体校准及模板补全，有效提升知识图谱对话式问答的结构准确性与链接效率",
      "设计自进化机制，整合记忆与反射模块实现无需显式重训练的持续适应，增强模型对对话历史与执行反馈的利用能力"
    ],
    "processed_at": "2025-12-05T08:45:09.363157"
  },
  {
    "id": "2512.04785v1",
    "title": "ASTRIDE: A Security Threat Modeling Platform for Agentic-AI Applications",
    "abstract": "AI agent-based systems are becoming increasingly integral to modern software architectures, enabling autonomous decision-making, dynamic task execution, and multimodal interactions through large language models (LLMs). However, these systems introduce novel and evolving security challenges, including prompt injection attacks, context poisoning, model manipulation, and opaque agent-to-agent communication, that are not effectively captured by traditional threat modeling frameworks. In this paper, we introduce ASTRIDE, an automated threat modeling platform purpose-built for AI agent-based systems. ASTRIDE extends the classical STRIDE framework by introducing a new threat category, A for AI Agent-Specific Attacks, which encompasses emerging vulnerabilities such as prompt injection, unsafe tool invocation, and reasoning subversion, unique to agent-based applications. To automate threat modeling, ASTRIDE combines a consortium of fine-tuned vision-language models (VLMs) with the OpenAI-gpt-oss reasoning LLM to perform end-to-end analysis directly from visual agent architecture diagrams, such as data flow diagrams(DFDs). LLM agents orchestrate the end-to-end threat modeling automation process by coordinating interactions between the VLM consortium and the reasoning LLM. Our evaluations demonstrate that ASTRIDE provides accurate, scalable, and explainable threat modeling for next-generation intelligent systems. To the best of our knowledge, ASTRIDE is the first framework to both extend STRIDE with AI-specific threats and integrate fine-tuned VLMs with a reasoning LLM to fully automate diagram-driven threat modeling in AI agent-based applications.",
    "authors": [
      "Eranga Bandara",
      "Amin Hass",
      "Ross Gore",
      "Sachin Shetty",
      "Ravi Mukkamala",
      "Safdar H. Bouk",
      "Xueping Liang",
      "Ng Wee Keong",
      "Kasun De Zoysa",
      "Aruna Withanage",
      "Nilaan Loganathan"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04785v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04785v1",
    "fetched_at": "2025-12-05T08:33:13.504584",
    "chinese_title": "ASTRIDE：面向Agentic-AI应用的安全威胁建模平台",
    "chinese_summary": "论文针对AI agent系统存在传统威胁建模未覆盖的新安全挑战（如提示注入等），提出ASTRIDE平台扩展经典STRIDE框架新增AI Agent特定攻击（A）类别；该平台结合微调视觉语言模型（VLM）与推理LLM，从视觉架构图自动完成端到端威胁建模，通过LLM agent协调流程实现准确可扩展可解释的威胁建模。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Risk Management"
    ],
    "key_contributions": [
      "扩展经典STRIDE框架，新增AI Agent特定攻击（A）类别，覆盖传统框架未捕获的新兴安全挑战",
      "提出ASTRIDE自动化威胁建模平台，结合VLM与推理LLM从视觉架构图实现端到端威胁建模，具备准确可扩展可解释性"
    ],
    "processed_at": "2025-12-05T08:45:31.871427"
  },
  {
    "id": "2512.04752v1",
    "title": "RLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting",
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) is an important fine-tuning technique for large language models (LLMs) and comprises three stages: generation, inference, and training. The generation stage generates samples that are then used to infer learnable experiences for training. We observe that the generation stage is the bottleneck of the entire execution process and consider it a key point for optimization. Specifically, we realize the first attempt to integrate speculative decoding into the RLHF generation stage and propose RLHFSpec, an RLHF system that accelerates generation execution with adaptive speculative decoding and sample reallocation. To fully exploit the performance potential provided by speculative decoding, especially dealing with the dynamic workload of the generation stage, RLHFSpec proposes a workload-aware drafting strategy selection mechanism, which selects the near-optimal strategy by jointly considering the verification cost and the number of accepted tokens. Moreover, RLHFSpec also proposes sample reallocation to fully utilize the GPU resources, and optimizes it with an efficient sample migration mechanism. The experimental results show that the RLHFSpec can achieve higher throughput in the generation stage compared to state-of-the-art works. Moreover, due to the effective alleviation of the generation bottleneck, RLHFSpec also shows significant performance speedup in the entire RLHF execution.",
    "authors": [
      "Siqi Wang",
      "Hailong Yang",
      "Junjie Zhu",
      "Xuezhu Wang",
      "Yufan Xu",
      "Depei Qian"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04752v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04752v1",
    "fetched_at": "2025-12-05T08:33:13.504611",
    "chinese_title": "RLHFSpec：通过自适应草稿生成打破RLHF训练的效率瓶颈",
    "chinese_summary": "该论文针对RLHF训练中生成阶段的效率瓶颈，首次将推测解码整合到RLHF生成阶段并提出RLHFSpec系统；其包含工作负载感知的草稿策略选择机制（联合考虑验证成本与接受token数选最优策略）、样本重分配及高效迁移机制；实验显示RLHFSpec在生成阶段吞吐量更高，整体RLHF执行显著加速。",
    "tags": [
      "LLM",
      "Reinforcement Learning",
      "Deep Learning"
    ],
    "key_contributions": [
      "首次将推测解码整合到RLHF训练的生成阶段，提出RLHFSpec系统",
      "设计工作负载感知的草稿策略选择、样本重分配及高效迁移机制，优化生成效率并提升整体RLHF执行速度"
    ],
    "processed_at": "2025-12-05T08:45:51.572290"
  },
  {
    "id": "2512.04745v1",
    "title": "Neural Policy Composition from Free Energy Minimization",
    "abstract": "The ability to compose acquired skills to plan and execute behaviors is a hallmark of natural intelligence. Yet, despite remarkable cross-disciplinary efforts, a principled account of how task structure shapes gating and how such computations could be delivered in neural circuits, remains elusive. Here we introduce GateMod, an interpretable theoretically grounded computational model linking the emergence of gating to the underlying decision-making task, and to a neural circuit architecture. We first develop GateFrame, a normative framework casting policy gating into the minimization of the free energy. This framework, relating gating rules to task, applies broadly across neuroscience, cognitive and computational sciences. We then derive GateFlow, a continuous-time energy based dynamics that provably converges to GateFrame optimal solution. Convergence, exponential and global, follows from a contractivity property that also yields robustness and other desirable properties. Finally, we derive a neural circuit from GateFlow, GateNet. This is a soft-competitive recurrent circuit whose components perform local and contextual computations consistent with known dendritic and neural processing motifs. We evaluate GateMod across two different settings: collective behaviors in multi-agent systems and human decision-making in multi-armed bandits. In all settings, GateMod provides interpretable mechanistic explanations of gating and quantitatively matches or outperforms established models. GateMod offers a unifying framework for neural policy gating, linking task objectives, dynamical computation, and circuit-level mechanisms. It provides a framework to understand gating in natural agents beyond current explanations and to equip machines with this ability.",
    "authors": [
      "Francesca Rossi",
      "Veronica Centorrino",
      "Francesco Bullo",
      "Giovanni Russo"
    ],
    "published": "2025-12-04",
    "categories": [
      "math.OC",
      "cs.AI",
      "eess.SY",
      "nlin.AO"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04745v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04745v1",
    "fetched_at": "2025-12-05T08:33:13.504634",
    "chinese_title": "基于自由能最小化的神经策略组合",
    "chinese_summary": "该论文提出GateMod模型，通过自由能最小化框架（GateFrame）将策略门控规范化，推导全局指数收敛的连续时间能量动力学（GateFlow），进而得到符合已知神经处理机制的循环电路（GateNet）；在多智能体集体行为与人类多臂老虎机决策任务中验证，提供可解释的门控机制解释且性能优于现有模型。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning",
      "Financial Agent",
      "Behavioral Finance"
    ],
    "key_contributions": [
      "提出基于自由能最小化的GateFrame框架，实现策略门控与任务结构、神经电路的规范化关联",
      "推导全局指数收敛的GateFlow动力学及符合神经机制的GateNet电路，在多智能体和人类决策任务中验证可解释性与性能优势"
    ],
    "processed_at": "2025-12-05T08:46:09.465869"
  },
  {
    "id": "2512.04716v1",
    "title": "Towards an AI Fluid Scientist: LLM-Powered Scientific Discovery in Experimental Fluid Mechanics",
    "abstract": "The integration of artificial intelligence into experimental fluid mechanics promises to accelerate discovery, yet most AI applications remain narrowly focused on numerical studies. This work proposes an AI Fluid Scientist framework that autonomously executes the complete experimental workflow: hypothesis generation, experimental design, robotic execution, data analysis, and manuscript preparation. We validate this through investigation of vortex-induced vibration (VIV) and wake-induced vibration (WIV) in tandem cylinders. Our work has four key contributions: (1) A computer-controlled circulating water tunnel (CWT) with programmatic control of flow velocity, cylinder position, and forcing parameters (vibration frequency and amplitude) with data acquisition (displacement, force, and torque). (2) Automated experiments reproduce literature benchmarks (Khalak and Williamson [1999] and Assi et al. [2013, 2010]) with frequency lock-in within 4% and matching critical spacing trends. (3) The framework with Human-in-the-Loop (HIL) discovers more WIV amplitude response phenomena, and uses a neural network to fit physical laws from data, which is 31% higher than that of polynomial fitting. (4) The framework with multi-agent with virtual-real interaction system executes hundreds of experiments end-to-end, which automatically completes the entire process of scientific research from hypothesis generation, experimental design, experimental execution, data analysis, and manuscript preparation. It greatly liberates human researchers and improves study efficiency, providing new paradigm for the development and research of experimental fluid mechanics.",
    "authors": [
      "Haodong Feng",
      "Lugang Ye",
      "Dixia Fan"
    ],
    "published": "2025-12-04",
    "categories": [
      "physics.flu-dyn",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04716v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04716v1",
    "fetched_at": "2025-12-05T08:33:13.504655",
    "chinese_title": "迈向AI流体科学家：LLM驱动的实验流体力学科学发现",
    "chinese_summary": "本文提出AI流体科学家框架，可自主执行假设生成、实验设计、机器人执行、数据分析及手稿准备的完整实验科研流程；通过串联圆柱的涡激振动（VIV）和尾流激振动（WIV）验证，该框架实现自动复现经典文献基准，发现更多WIV现象且神经网络拟合物理规律优于多项式拟合31%，并能端到端完成数百次实验全流程。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "提出AI流体科学家框架，可自主完成从假设生成到手稿准备的完整实验科研流程",
      "构建计算机控制的循环水槽系统，自动实验复现经典文献基准并通过HIL和多智能体系统发现新WIV现象及拟合更优物理规律"
    ],
    "processed_at": "2025-12-05T08:46:24.045976"
  },
  {
    "id": "2512.04680v1",
    "title": "Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap",
    "abstract": "Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this paper aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI's within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.",
    "authors": [
      "Jialong Li",
      "Mingyue Zhang",
      "Nianyu Li",
      "Danny Weyns",
      "Zhi Jin",
      "Kenji Tei"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04680v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04680v1",
    "fetched_at": "2025-12-05T08:33:13.504685",
    "chinese_title": "生成式人工智能在自适应系统中的应用：现状与研究路线图",
    "chinese_summary": "本文聚焦生成式AI（GenAI）在自适应系统（SAS）中的应用，通过收集分析四大研究领域文献，梳理其对SAS MAPE-K反馈环自治性的增强及人机交互的改进等潜在收益与挑战，并提出整合GenAI的SAS研究路线图。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "系统梳理生成式AI在自适应系统中的潜在收益（含MAPE-K反馈环增强及人机交互改进）与挑战",
      "提出整合生成式AI的自适应系统研究路线图"
    ],
    "processed_at": "2025-12-05T08:46:38.886777"
  },
  {
    "id": "2512.04668v1",
    "title": "Topology Matters: Measuring Memory Leakage in Multi-Agent LLMs",
    "abstract": "Graph topology is a fundamental determinant of memory leakage in multi-agent LLM systems, yet its effects remain poorly quantified. We introduce MAMA (Multi-Agent Memory Attack), a framework that measures how network structure shapes leakage. MAMA operates on synthetic documents containing labeled Personally Identifiable Information (PII) entities, from which we generate sanitized task instructions. We execute a two-phase protocol: Engram (seeding private information into a target agent's memory) and Resonance (multi-round interaction where an attacker attempts extraction). Over up to 10 interaction rounds, we quantify leakage as the fraction of ground-truth PII recovered from attacking agent outputs via exact matching. We systematically evaluate six common network topologies (fully connected, ring, chain, binary tree, star, and star-ring), varying agent counts $n\\in\\{4,5,6\\}$, attacker-target placements, and base models. Our findings reveal consistent patterns: fully connected graphs exhibit maximum leakage while chains provide strongest protection; shorter attacker-target graph distance and higher target centrality significantly increase vulnerability; leakage rises sharply in early rounds before plateauing; model choice shifts absolute leakage rates but preserves topology rankings; temporal/locational PII attributes leak more readily than identity credentials or regulated identifiers. These results provide the first systematic mapping from architectural choices to measurable privacy risk, yielding actionable guidance: prefer sparse or hierarchical connectivity, maximize attacker-target separation, limit node degree and network radius, avoid shortcuts bypassing hubs, and implement topology-aware access controls.",
    "authors": [
      "Jinbo Liu",
      "Defu Cao",
      "Yifei Wei",
      "Tianyao Su",
      "Yuan Liang",
      "Yushun Dong",
      "Yue Zhao",
      "Xiyang Hu"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04668v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04668v1",
    "fetched_at": "2025-12-05T08:33:13.504731",
    "chinese_title": "拓扑结构至关重要：多智能体大语言模型中的记忆泄露度量",
    "chinese_summary": "本文提出MAMA框架，通过含标注个人身份信息（PII）的合成文档及Engram（隐私植入）、Resonance（多轮攻击提取）两阶段协议，系统评估6种网络拓扑下多智能体LLM的记忆泄露；发现全连接图泄露最大、链状结构保护最强，攻击者-目标距离和目标中心性显著影响泄露等规律，首次系统映射架构选择与可度量泄露的关系。",
    "tags": [
      "LLM",
      "Transformer",
      "Graph Neural Network"
    ],
    "key_contributions": [
      "提出MAMA框架，结合合成PII文档与两阶段攻击协议，量化多智能体LLM中网络拓扑对记忆泄露的影响",
      "系统揭示拓扑结构、攻击者-目标距离、目标中心性等因素与记忆泄露的关系规律，为多智能体LLM架构设计提供参考"
    ],
    "processed_at": "2025-12-05T08:46:54.835555"
  },
  {
    "id": "2512.04653v1",
    "title": "Semi Centralized Training Decentralized Execution Architecture for Multi Agent Deep Reinforcement Learning in Traffic Signal Control",
    "abstract": "Multi-agent reinforcement learning (MARL) has emerged as a promising paradigm for adaptive traffic signal control (ATSC) of multiple intersections. Existing approaches typically follow either a fully centralized or a fully decentralized design. Fully centralized approaches suffer from the curse of dimensionality, and reliance on a single learning server, whereas purely decentralized approaches operate under severe partial observability and lack explicit coordination resulting in suboptimal performance. These limitations motivate region-based MARL, where the network is partitioned into smaller, tightly coupled intersections that form regions, and training is organized around these regions. This paper introduces a Semi-Centralized Training, Decentralized Execution (SEMI-CTDE) architecture for multi intersection ATSC. Within each region, SEMI-CTDE performs centralized training with regional parameter sharing and employs composite state and reward formulations that jointly encode local and regional information. The architecture is highly transferable across different policy backbones and state-reward instantiations. Building on this architecture, we implement two models with distinct design objectives. A multi-perspective experimental analysis of the two implemented SEMI-CTDE-based models covering ablations of the architecture's core elements including rule based and fully decentralized baselines shows that they achieve consistently superior performance and remain effective across a wide range of traffic densities and distributions.",
    "authors": [
      "Pouria Yazdani",
      "Arash Rezaali",
      "Monireh Abdoos"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04653v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04653v1",
    "fetched_at": "2025-12-05T08:33:13.504753",
    "chinese_title": "面向交通信号控制的多智能体深度强化学习半中心化训练去中心化执行架构",
    "chinese_summary": "现有多智能体强化学习（MARL）在自适应交通信号控制（ATSC）中存在全中心化方法的维度灾难与单服务器依赖、全去中心化方法的部分可观测性与协调缺失问题；论文提出半中心化训练去中心化执行（SEMI-CTDE）架构，区域内采用中心化训练（区域参数共享、复合状态与奖励编码局部及区域信息），执行阶段去中心化，且架构可迁移至不同策略骨干与状态-奖励设置；基于该架构实现的模型经实验验证性能优于规则及全去中心化基线。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning",
      "Execution"
    ],
    "key_contributions": [
      "提出SEMI-CTDE架构，解决全中心化/去中心化MARL在ATSC中的缺陷，实现区域内中心化训练（参数共享、复合状态/奖励）与执行去中心化，且架构具有跨策略骨干与状态-奖励设置的可迁移性",
      "基于SEMI-CTDE实现两个模型，实验证明其性能优于规则及全去中心化基线，验证了架构的有效性"
    ],
    "processed_at": "2025-12-05T08:47:14.060207"
  },
  {
    "id": "2512.04580v1",
    "title": "A Light-Weight Large Language Model File Format for Highly-Secure Model Distribution",
    "abstract": "To enhance the performance of large language models (LLMs) in various domain-specific applications, sensitive data such as healthcare, law, and finance are being used to privately customize or fine-tune these models. Such privately adapted LLMs are regarded as either personal privacy assets or corporate intellectual property. Therefore, protecting model weights and maintaining strict confidentiality during deployment and distribution have become critically important. However, existing model formats and deployment frameworks provide little to no built-in support for confidentiality, access control, or secure integration with trusted hardware. Current methods for securing model deployment either rely on computationally expensive cryptographic techniques or tightly controlled private infrastructure. Although these approaches can be effective in specific scenarios, they are difficult and costly for widespread deployment.   In this paper, we introduce CryptoTensors, a secure and format-compatible file structure for confidential LLM distribution. Built as an extension to the widely adopted Safetensors format, CryptoTensors incorporates tensor-level encryption and embedded access control policies, while preserving critical features such as lazy loading and partial deserialization. It enables transparent decryption and automated key management, supporting flexible licensing and secure model execution with minimal overhead. We implement a proof-of-concept library, benchmark its performance across serialization and runtime scenarios, and validate its compatibility with existing inference frameworks, including Hugging Face Transformers and vLLM. Our results highlight CryptoTensors as a light-weight, efficient, and developer-friendly solution for safeguarding LLM weights in real-world and widespread deployments.",
    "authors": [
      "Huifeng Zhu",
      "Shijie Li",
      "Qinfeng Li",
      "Yier Jin"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04580v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04580v1",
    "fetched_at": "2025-12-05T08:33:13.504778",
    "chinese_title": "一种用于高安全模型分发的轻量级大语言模型文件格式",
    "chinese_summary": "现有大语言模型（LLM）部署分发缺乏内置机密性支持，现有安全方法成本高难普及；本文提出CryptoTensors——基于Safetensors扩展的安全文件结构，支持张量级加密、嵌入式访问控制，保留懒加载等特性，实现透明解密与自动密钥管理，开销极小。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Transformer",
      "NLP"
    ],
    "key_contributions": [
      "提出基于Safetensors扩展的CryptoTensors，支持张量级加密与嵌入式访问控制，适配LLM安全分发",
      "实现的格式保留懒加载等关键特性，透明解密与自动密钥管理开销极小"
    ],
    "processed_at": "2025-12-05T08:47:29.022333"
  },
  {
    "id": "2512.04535v1",
    "title": "GTM: Simulating the World of Tools for AI Agents",
    "abstract": "The integration of external tools is pivotal for empowering Large Language Model (LLM) agents with real-world capabilities. However, training these agents through direct, continuous interaction with diverse tools is often prohibitively expensive, slow, and introduces additional development and maintenance overhead. To address this challenge, we introduce the Generalist Tool Model (GTM), a 1.5-billion-parameter model that learns to act as a universal tool simulator. With only prompt-level configuration, GTM accesses tool functionalities along with input arguments and generates outputs that faithfully mimic real tool execution, providing a fast and cost-effective solution that eliminates development overhead. To build GTM, we propose the Context-Aware Response Generation (CARG) pipeline, which synthesizes comprehensive training data covering over 20,000 tools across 300 domains including physics, medicine, robotics, and finance. Through this pipeline, GTM learns to produce not only syntactically correct outputs but also logically coherent and contextually appropriate responses. Experiments demonstrate that GTM produces high-quality outputs with strong consistency and reliability. Besides when used in real reinforcement learning scenarios for agent training, GTM exhibits significantly faster simulation speed compared to real tools while maintaining comparable output quality, along with remarkable generalization and domain adaptability. Our results establish GTM as a foundational component for developing future AI agents, enabling efficient and scalable training of tool-augmented systems.",
    "authors": [
      "Zhenzhen Ren",
      "Xinpeng Zhang",
      "Zhenxing Qian",
      "Yan Gao",
      "Yu Shi",
      "Shuxin Zheng",
      "Jiyan He"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04535v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04535v1",
    "fetched_at": "2025-12-05T08:33:13.504805",
    "chinese_title": "GTM：为AI智能体模拟工具世界",
    "chinese_summary": "针对LLM智能体直接与真实工具交互训练成本高、效率低的问题，本文提出15亿参数的通用工具模型GTM，通过上下文感知响应生成（CARG） pipeline合成覆盖300领域20000+工具的训练数据，使GTM能模拟工具输出，在智能体强化学习训练中速度显著更快且质量相当，具备泛化性。",
    "tags": [
      "LLM",
      "Reinforcement Learning",
      "Financial Agent"
    ],
    "key_contributions": [
      "提出通用工具模型GTM，仅需提示级配置即可模拟多领域工具输出，解决真实工具交互训练的成本效率问题",
      "设计CARG pipeline合成覆盖300领域20000+工具的训练数据，使GTM输出语法正确、逻辑连贯且泛化性强"
    ],
    "processed_at": "2025-12-05T08:47:42.445270"
  },
  {
    "id": "2512.04513v1",
    "title": "BiTAgent: A Task-Aware Modular Framework for Bidirectional Coupling between Multimodal Large Language Models and World Models",
    "abstract": "Building generalist embodied agents requires a unified system that can interpret multimodal goals, model environment dynamics, and execute reliable actions across diverse real-world tasks. Multimodal large language models (MLLMs) offer strong semantic priors and cross-modal generalization, while world models (WMs) provide actionable latent dynamics for prediction and control. Their combination holds promise for open-ended embodied intelligence, yet introduces two key challenges: (1) establishing a tight coupling between the semantic intent from MLLMs and the dynamic state representations within the WM's latent space, and (2) achieving task-aware adaptability that supports multi-task learning and cross-environment generalization. To address these limitations, we propose BiTAgent, a task-aware dynamic joint framework that enables bidirectional coupling between MLLMs and WMs. BiTAgent establishes two complementary pathways: a forward path that injects MLLM representations into the WM's latent space for semantically guided imagination, and a backward path where WM-generated feedback refines the MLLM's semantic space via dense text-conditioned rewards. This bidirectional interaction is realized through three synergistic components: Task-Aware Dynamic Joint Learning, Task-Aware Behavior Learning, and MLLM-WM Joint Optimization, which together harmonize semantic reasoning and dynamic prediction. Extensive experiments across multi-task and cross-environment settings demonstrate superior stability and generalization over state-of-the-art baselines, marking a step toward open-ended embodied learning.",
    "authors": [
      "Yu-Wei Zhan",
      "Xin Wang",
      "Pengzhe Mao",
      "Tongtong Feng",
      "Ren Wang",
      "Wenwu Zhu"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04513v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04513v1",
    "fetched_at": "2025-12-05T08:33:13.504831",
    "chinese_title": "BiTAgent：面向多模态大语言模型与世界模型双向耦合的任务感知模块化框架",
    "chinese_summary": "针对多模态大语言模型（MLLM）与世界模型（WM）结合中语义意图与潜在空间耦合不足、任务感知适应性弱的问题，本文提出BiTAgent任务感知动态联合框架，通过前向注入MLLM表征引导WM想象、后向用WM反馈优化MLLM语义空间的双向路径，结合三个协同组件实现语义推理与动态预测的和谐，多任务跨环境实验验证其有效性。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Reinforcement Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出BiTAgent双向耦合框架，解决MLLM与WM结合的语义-潜在空间耦合及任务感知适应性挑战",
      "通过双向交互路径与三个协同组件实现语义推理与动态预测的和谐，实验证明多任务跨环境效果"
    ],
    "processed_at": "2025-12-05T08:47:58.820100"
  },
  {
    "id": "2512.04480v1",
    "title": "AI-Assisted Game Management Decisions: A Fuzzy Logic Approach to Real-Time Substituitions",
    "abstract": "In elite soccer, substitution decisions entail significant financial and sporting consequences yet remain heavily reliant on intuition or predictive models that merely mimic historical biases. This paper introduces a Fuzzy Logic based Decision Support System (DSS) designed for real time, prescriptive game management. Unlike traditional Machine Learning approaches that encounter a predictive ceiling by attempting to replicate human behavior, our system audits performance through an objective, rule based inference engine. We propose a methodological advancement by reformulating the PlayeRank metric into a Cumulative Mean with Role Aware Normalization, eliminating the play time exposure bias inherent in cumulative sum models to enable accurate intra match comparison. The system integrates this refined metric with physiological proxies (fatigue) and contextual variables (disciplinary risk modulated by tactical role) to calculate a dynamic Substitution Priority (P final). Validation via a case study of the 2018 FIFA World Cup match between Brazil and Belgium demonstrates the system's ecological validity: it not only aligned with expert consensus on executed substitutions (for example Gabriel Jesus) but, crucially, identified high risk scenarios ignored by human decision makers. Specifically, the model flagged the \"FAGNER Paradox\" - a maximum priority defensive risk - minutes before a critical yellow card, and detected the \"Lukaku Paradox\", where an isolated assist masked a severe drop in participation. These results confirm that Fuzzy Logic offers a transparent, explainable, and superior alternative to black box models for optimizing real time tactical decisions.",
    "authors": [
      "Pedro Passos"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.AI",
      "cs.CE",
      "eess.SY",
      "math.OC"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04480v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04480v1",
    "fetched_at": "2025-12-05T08:33:13.504849",
    "chinese_title": "AI辅助的比赛管理决策：一种用于实时换人策略的模糊逻辑方法",
    "chinese_summary": "针对精英足球换人决策依赖直觉或带历史偏见的预测模型的问题，本文提出基于模糊逻辑的决策支持系统；通过将PlayeRank重构为角色感知归一化的累积均值消除上场时间偏差，结合生理疲劳、纪律风险等变量计算动态换人优先级，验证显示其与专家共识一致且能识别人类忽略的高风险场景。",
    "tags": [
      "Risk Management",
      "Behavioral Finance",
      "Anomaly"
    ],
    "key_contributions": [
      "提出基于模糊逻辑的实时换人决策支持系统，突破传统机器学习模仿人类行为的局限，采用客观规则推理引擎",
      "重构PlayeRank指标为角色感知归一化的累积均值，消除上场时间暴露偏差，实现准确的赛中球员表现对比"
    ],
    "processed_at": "2025-12-05T08:48:16.778771"
  },
  {
    "id": "2512.04711v1",
    "title": "Large Speech Model Enabled Semantic Communication",
    "abstract": "Existing speech semantic communication systems mainly based on Joint Source-Channel Coding (JSCC) architectures have demonstrated impressive performance, but their effectiveness remains limited by model structures specifically designed for particular tasks and datasets. Recent advances indicate that generative large models pre-trained on massive datasets, can achieve outstanding performance arexhibit exceptional performance across diverse downstream tasks with minimal fine-tuning. To exploit the rich semantic knowledge embedded in large models and enable adaptive transmission over lossy channels, we propose a Large Speech Model enabled Semantic Communication (LargeSC) system. Simultaneously achieving adaptive compression and robust transmission over lossy channels remains challenging, requiring trade-offs among compression efficiency, speech quality, and latency. In this work, we employ the Mimi as a speech codec, converting speech into discrete tokens compatible with existing network architectures. We propose an adaptive controller module that enables adaptive transmission and in-band Unequal Error Protection (UEP), dynamically adjusting to both speech content and packet loss probability under bandwidth constraints. Additionally, we employ Low-Rank Adaptation (LoRA) to finetune the Moshi foundation model for generative recovery of lost speech tokens. Simulation results show that the proposed system supports bandwidths ranging from 550 bps to 2.06 kbps, outperforms conventional baselines in speech quality under high packet loss rates and achieves an end-to-end latency of approximately 460 ms, thereby demonstrating its potential for real-time deployment.",
    "authors": [
      "Yun Tian",
      "Zhijin Qin",
      "Guocheng Lv",
      "Ye Jin",
      "Kaibin Huang",
      "Zhu Han"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04711v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04711v1",
    "fetched_at": "2025-12-05T08:33:36.674956",
    "chinese_title": "基于大语音模型的语义通信",
    "chinese_summary": "现有语音语义通信系统受限于特定任务模型，本文提出基于大语音模型的LargeSC系统：用Mimi将语音转为离散token，设计自适应控制器动态调整传输与非均匀差错保护，结合LoRA微调Moshi模型恢复丢失token，支持550bps-2.06kbps带宽且性能优于传统方法。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出基于大语音模型的语义通信系统LargeSC，突破现有系统任务特定的局限",
      "设计自适应控制器与LoRA微调方案，实现低带宽下自适应传输与丢失token恢复，性能更优"
    ],
    "processed_at": "2025-12-05T08:48:27.292549"
  },
  {
    "id": "2512.04302v1",
    "title": "Towards better dense rewards in Reinforcement Learning Applications",
    "abstract": "Finding meaningful and accurate dense rewards is a fundamental task in the field of reinforcement learning (RL) that enables agents to explore environments more efficiently. In traditional RL settings, agents learn optimal policies through interactions with an environment guided by reward signals. However, when these signals are sparse, delayed, or poorly aligned with the intended task objectives, agents often struggle to learn effectively. Dense reward functions, which provide informative feedback at every step or state transition, offer a potential solution by shaping agent behavior and accelerating learning. Despite their benefits, poorly crafted reward functions can lead to unintended behaviors, reward hacking, or inefficient exploration. This problem is particularly acute in complex or high-dimensional environments where handcrafted rewards are difficult to specify and validate. To address this, recent research has explored a variety of approaches, including inverse reinforcement learning, reward modeling from human preferences, and self-supervised learning of intrinsic rewards. While these methods offer promising directions, they often involve trade-offs between generality, scalability, and alignment with human intent. This proposal explores several approaches to dealing with these unsolved problems and enhancing the effectiveness and reliability of dense reward construction in different RL applications.",
    "authors": [
      "Shuyuan Zhang"
    ],
    "published": "2025-12-03",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04302v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04302v1",
    "fetched_at": "2025-12-05T08:34:23.376633",
    "chinese_title": "强化学习应用中更优稠密奖励的探索",
    "chinese_summary": "强化学习中稠密奖励对智能体高效探索环境至关重要，但传统稀疏/设计不当的奖励存在学习困难、意外行为等问题；现有逆强化学习、人类偏好建模、自监督内在奖励等方法存在通用性、可扩展性与人类意图对齐的权衡；论文探索解决这些未解决问题，以提升不同RL应用中稠密奖励构建的有效性与可靠性。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning"
    ],
    "key_contributions": [
      "系统分析强化学习中稠密奖励设计的核心挑战（稀疏/不当奖励缺陷、现有方法权衡）",
      "提出提升不同RL应用中稠密奖励构建有效性与可靠性的研究方向"
    ],
    "processed_at": "2025-12-05T08:48:43.373893"
  },
  {
    "id": "2512.04246v1",
    "title": "Toward Virtuous Reinforcement Learning",
    "abstract": "This paper critiques common patterns in machine ethics for Reinforcement Learning (RL) and argues for a virtue focused alternative. We highlight two recurring limitations in much of the current literature: (i) rule based (deontological) methods that encode duties as constraints or shields often struggle under ambiguity and nonstationarity and do not cultivate lasting habits, and (ii) many reward based approaches, especially single objective RL, implicitly compress diverse moral considerations into a single scalar signal, which can obscure trade offs and invite proxy gaming in practice. We instead treat ethics as policy level dispositions, that is, relatively stable habits that hold up when incentives, partners, or contexts change. This shifts evaluation beyond rule checks or scalar returns toward trait summaries, durability under interventions, and explicit reporting of moral trade offs. Our roadmap combines four components: (1) social learning in multi agent RL to acquire virtue like patterns from imperfect but normatively informed exemplars; (2) multi objective and constrained formulations that preserve value conflicts and incorporate risk aware criteria to guard against harm; (3) affinity based regularization toward updateable virtue priors that support trait like stability under distribution shift while allowing norms to evolve; and (4) operationalizing diverse ethical traditions as practical control signals, making explicit the value and cultural assumptions that shape ethical RL benchmarks.",
    "authors": [
      "Majid Ghasemi",
      "Mark Crowley"
    ],
    "published": "2025-12-03",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04246v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04246v1",
    "fetched_at": "2025-12-05T08:34:23.376665",
    "chinese_title": "迈向有德性的强化学习",
    "chinese_summary": "该论文批判强化学习（RL）机器伦理中基于规则和单目标奖励方法的局限（规则难应对模糊性与非平稳性，单目标压缩道德考量致权衡模糊），提出德性导向的替代框架，将伦理视为策略层面的稳定习性；并给出包含多智能体社会学习、多目标/约束建模等在内的四组件路线图，以提升RL伦理的适应性与透明性。",
    "tags": [
      "Reinforcement Learning",
      "Risk Management"
    ],
    "key_contributions": [
      "系统批判现有RL机器伦理中规则-based（义务论）和单目标奖励方法的两大核心局限，指出其在模糊场景、非平稳环境及道德权衡表达上的不足",
      "提出德性导向的RL伦理新框架，将伦理视为策略层面的稳定习性，构建含多智能体社会学习、多目标/约束建模等四组件的实践路线图，拓展伦理评估维度至特质稳定性、干预鲁棒性及道德权衡显式报告"
    ],
    "processed_at": "2025-12-05T08:49:05.397140"
  },
  {
    "id": "2512.05033v1",
    "title": "Arbitrage: Efficient Reasoning via Advantage-Aware Speculation",
    "abstract": "Modern Large Language Models achieve impressive reasoning capabilities with long Chain of Thoughts, but they incur substantial computational cost during inference, and this motivates techniques to improve the performance-cost ratio. Among these techniques, Speculative Decoding accelerates inference by employing a fast but inaccurate draft model to autoregressively propose tokens, which are then verified in parallel by a more capable target model. However, due to unnecessary rejections caused by token mismatches in semantically equivalent steps, traditional token-level Speculative Decoding struggles in reasoning tasks. Although recent works have shifted to step-level semantic verification, which improve efficiency by accepting or rejecting entire reasoning steps, existing step-level methods still regenerate many rejected steps with little improvement, wasting valuable target compute. To address this challenge, we propose Arbitrage, a novel step-level speculative generation framework that routes generation dynamically based on the relative advantage between draft and target models. Instead of applying a fixed acceptance threshold, Arbitrage uses a lightweight router trained to predict when the target model is likely to produce a meaningfully better step. This routing approximates an ideal Arbitrage Oracle that always chooses the higher-quality step, achieving near-optimal efficiency-accuracy trade-offs. Across multiple mathematical reasoning benchmarks, Arbitrage consistently surpasses prior step-level Speculative Decoding baselines, reducing inference latency by up to $\\sim2\\times$ at matched accuracy.",
    "authors": [
      "Monishwaran Maheswaran",
      "Rishabh Tiwari",
      "Yuezhou Hu",
      "Kerem Dilmen",
      "Coleman Hooper",
      "Haocheng Xi",
      "Nicholas Lee",
      "Mehrdad Farajtabar",
      "Michael W. Mahoney",
      "Kurt Keutzer",
      "Amir Gholami"
    ],
    "published": "2025-12-04",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.05033v1",
    "arxiv_url": "https://arxiv.org/abs/2512.05033v1",
    "fetched_at": "2025-12-05T08:34:47.666836",
    "chinese_title": "Arbitrage：基于优势感知推测的高效推理",
    "chinese_summary": "针对传统推测解码在推理任务中因语义等价步骤token不匹配导致不必要拒绝、现有步骤级方法浪费目标算力的问题，提出Arbitrage框架，通过轻量级路由器动态预测目标模型是否产生更优步骤并路由生成，近似理想Oracle以实现近最优效率-准确率权衡，在数学推理基准上表现优异。",
    "tags": [
      "LLM",
      "NLP",
      "Transformer",
      "Benchmark"
    ],
    "key_contributions": [
      "提出基于优势感知动态路由的Arbitrage推测生成框架，解决传统步骤级推测解码的算力浪费问题",
      "设计轻量级路由器近似理想Oracle，实现推理任务的近最优效率-准确率权衡"
    ],
    "processed_at": "2025-12-05T08:49:16.190885"
  },
  {
    "id": "2512.04210v1",
    "title": "Balancing Safety and Helpfulness in Healthcare AI Assistants through Iterative Preference Alignment",
    "abstract": "Large Language Models (LLMs) are increasingly used in healthcare, yet ensuring their safety and trustworthiness remains a barrier to deployment. Conversational medical assistants must avoid unsafe compliance without over-refusing benign queries. We present an iterative post-deployment alignment framework that applies Kahneman-Tversky Optimization (KTO) and Direct Preference Optimization (DPO) to refine models against domain-specific safety signals. Using the CARES-18K benchmark for adversarial robustness, we evaluate four LLMs (Llama-3B/8B, Meditron-8B, Mistral-7B) across multiple cycles. Our results show up to 42% improvement in safety-related metrics for harmful query detection, alongside interesting trade-offs against erroneous refusals, thereby exposing architecture-dependent calibration biases. We also perform ablation studies to identify when self-evaluation is reliable and when external or finetuned judges are necessary to maximize performance gains. Our findings underscore the importance of adopting best practices that balance patient safety, user trust, and clinical utility in the design of conversational medical assistants.",
    "authors": [
      "Huy Nghiem",
      "Swetasudha Panda",
      "Devashish Khatwani",
      "Huy V. Nguyen",
      "Krishnaram Kenthapadi",
      "Hal Daumé"
    ],
    "published": "2025-12-03",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04210v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04210v1",
    "fetched_at": "2025-12-05T08:34:47.666874",
    "chinese_title": "通过迭代偏好对齐平衡医疗AI助手的安全性与有用性",
    "chinese_summary": "论文针对医疗AI助手安全部署问题，提出结合Kahneman-Tversky优化（KTO）与直接偏好优化（DPO）的迭代后部署对齐框架，在CARES-18K基准上评估四个大模型，提升有害查询检测安全指标达42%；并通过消融研究明确自我评估与外部/微调评判的可靠场景，揭示模型架构的校准偏差。",
    "tags": [
      "LLM",
      "Transformer",
      "Benchmark"
    ],
    "key_contributions": [
      "提出结合KTO与DPO的迭代后部署对齐框架，有效提升医疗AI助手的有害查询检测能力",
      "通过消融研究明确自我评估与外部/微调评判的可靠场景，揭示模型架构的校准偏差"
    ],
    "processed_at": "2025-12-05T08:49:24.672283"
  },
  {
    "id": "2512.04135v1",
    "title": "Decoding Large Language Diffusion Models with Foreseeing Movement",
    "abstract": "Large Language Diffusion Models (LLDMs) benefit from a flexible decoding mechanism that enables parallelized inference and controllable generations over autoregressive models. Yet such flexibility introduces a critical challenge: inference performance becomes highly sensitive to the decoding order of tokens. Existing heuristic methods, however, focus mainly on local effects while overlooking long-term impacts. To address this limitation, we propose the Foreseeing Decoding Method (FDM), a novel approach that integrates both local and global considerations to unlock the full potential, employing a search-based strategy to enable effective optimization in discrete spaces. Furthermore, by analyzing the consistency of chosen tokens in the full decoding process, we develop a variant, FDM with Acceleration (FDM-A), which restricts deep exploration to critical steps identified as the exploration and balance circumantences. Extensive experiments across diverse benchmarks and model architectures validate the scalability of FDM and demonstrate the superior efficiency-performance trade-off achieved by FDM-A. Our work might potentially provide a principled step toward more powerful decoding methods for LLDMs.",
    "authors": [
      "Yichuan Mo",
      "Quan Chen",
      "Mingjie Li",
      "Zeming Wei",
      "Yisen Wang"
    ],
    "published": "2025-12-03",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04135v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04135v1",
    "fetched_at": "2025-12-05T08:34:47.666902",
    "chinese_title": "基于预见运动的大语言扩散模型解码方法",
    "chinese_summary": "针对大语言扩散模型（LLDM）解码性能对token顺序敏感且现有方法仅关注局部效应的问题，论文提出预见解码方法（FDM），整合局部与全局考虑并采用基于搜索的策略优化离散解码空间；进一步提出加速版FDM-A，通过识别关键步骤限制深度探索，实验验证了FDM的可扩展性及FDM-A的高效性能权衡。",
    "tags": [
      "LLM",
      "NLP",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出预见解码方法（FDM），整合局部与全局考虑，采用基于搜索的策略优化大语言扩散模型的解码token顺序",
      "提出加速版FDM-A，通过识别关键步骤限制深度探索，实现解码效率与性能的高效权衡并验证方法可扩展性"
    ],
    "processed_at": "2025-12-05T08:49:43.755285"
  },
  {
    "id": "2512.04339v1",
    "title": "A Conceptual Model for AI Adoption in Financial Decision-Making: Addressing the Unique Challenges of Small and Medium-Sized Enterprises",
    "abstract": "The adoption of artificial intelligence (AI) offers transformative potential for small and medium-sized enterprises (SMEs), particularly in enhancing financial decision-making processes. However, SMEs often face significant barriers to implementing AI technologies, including limited resources, technical expertise, and data management capabilities. This paper presents a conceptual model for the adoption of AI in financial decision-making for SMEs. The proposed model addresses key challenges faced by SMEs, including limited resources, technical expertise, and data management capabilities. The model is structured into layers: data sources, data processing and integration, AI model deployment, decision support and automation, and validation and risk management. By implementing AI incrementally, SMEs can optimize financial forecasting, budgeting, investment strategies, and risk management. This paper highlights the importance of data quality and continuous model validation, providing a practical roadmap for SMEs to integrate AI into their financial operations. The study concludes with implications for SMEs adopting AI-driven financial processes and suggests areas for future research in AI applications for SME finance.",
    "authors": [
      "Manh Chien Vu",
      "Thang Le Dinh",
      "Manh Chien Vu",
      "Tran Duc Le",
      "Thi Lien Huong Nguyen"
    ],
    "published": "2025-12-03",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.04339v1",
    "arxiv_url": "https://arxiv.org/abs/2512.04339v1",
    "fetched_at": "2025-12-05T08:35:07.721976",
    "chinese_title": "金融决策中人工智能采纳的概念模型：应对中小企业独特挑战",
    "chinese_summary": "论文针对中小企业在金融决策中应用AI面临的资源有限、技术不足、数据管理能力弱等障碍，提出包含数据来源、处理集成、部署、决策支持及验证风控的分层概念模型，并给出增量实施的实用 roadmap，助力优化财务预测、预算等流程，强调数据质量与持续验证的重要性。",
    "tags": [
      "Risk Management",
      "Portfolio Optimization"
    ],
    "key_contributions": [
      "提出针对中小企业金融决策AI采纳的分层概念模型，系统解决其资源、技术、数据管理等核心障碍",
      "给出增量实施的实用 roadmap，强调数据质量与持续模型验证，为中小企业整合AI到金融运营提供可操作路径"
    ],
    "processed_at": "2025-12-05T08:50:04.866947"
  }
]