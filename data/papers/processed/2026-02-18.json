[
  {
    "id": "2602.15474v1",
    "title": "Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit",
    "abstract": "We analyze numerically the performance of Quantum Reservoir Computing (QRC) for statistical and financial problems. We use a reservoir composed of two superconducting islands coupled via their charge degrees of freedom. The key non-linear elements that provide the reservoir with rich and complex dynamics are the Josephson junctions that connect each island to the ground. We show that QRC implemented in this circuit can accurately classify complex probability distributions, including those with heavy tails, and identify regimes in correlated time series, such as periods of high volatility generated by standard econometric models. We find QRC to outperform some of the best classical methods when the amount of information is limited. This demonstrates its potential to be a noise-resilient quantum learning approach capable of tackling real-world problems within currently available superconducting platforms. We further discuss how to improve our QRC algorithm in real superconducting hardware to benefit from a much larger Hilbert space.",
    "authors": [
      "J. J. Prieto-Garcia",
      "A. G. del Pozo-Martín",
      "M. Pino"
    ],
    "published": "2026-02-17",
    "categories": [
      "quant-ph",
      "cond-mat.supr-con",
      "q-fin.ST"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15474v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15474v1",
    "fetched_at": "2026-02-18T08:52:25.773534",
    "chinese_title": "超导量子电路中用于统计分类的量子储层计算",
    "chinese_summary": "本文采用由两个电荷耦合超导岛及接地约瑟夫森结（提供非线性动态）组成的储层实现量子储层计算（QRC）；该方法能准确分类含重尾的复杂概率分布、识别经济计量模型生成的高波动时间序列状态，信息有限时优于部分经典最优方法，且在现有超导平台下具备噪声鲁棒性，还讨论了提升算法以利用更大希尔伯特空间的策略。",
    "tags": [
      "Time Series",
      "Volatility"
    ],
    "key_contributions": [
      "提出基于超导量子电路的量子储层计算方法，可准确分类复杂概率分布并识别时间序列中的高波动状态",
      "证明信息有限时该方法优于部分经典最优方法，且在现有超导平台下具备噪声鲁棒性"
    ],
    "processed_at": "2026-02-18T08:55:27.445366"
  },
  {
    "id": "2602.15385v1",
    "title": "From Chain-Ladder to Individual Claims Reserving",
    "abstract": "The chain-ladder (CL) method is the most widely used claims reserving technique in non-life insurance. This manuscript introduces a novel approach to computing the CL reserves based on a fundamental restructuring of the data utilization for the CL prediction procedure. Instead of rolling forward the cumulative claims with estimated CL factors, we estimate multi-period factors that project the latest observations directly to the ultimate claims. This alternative perspective on CL reserving creates a natural pathway for the application of machine learning techniques to individual claims reserving. As a proof of concept, we present a small-scale real data application employing neural networks for individual claims reserving.",
    "authors": [
      "Ronald Richman",
      "Mario V. Wüthrich"
    ],
    "published": "2026-02-17",
    "categories": [
      "stat.AP",
      "q-fin.RM",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15385v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15385v1",
    "fetched_at": "2026-02-18T08:52:25.773570",
    "chinese_title": "从链梯法到个体理赔准备金评估",
    "chinese_summary": "链梯法是非寿险中最常用的理赔准备金技术，论文重构其预测的数据利用方式：不滚动累计理赔及估计的链梯因子，而是用多期因子直接从最新观测投射到最终理赔；该视角为机器学习应用于个体理赔准备金评估开辟自然路径，并用小规模真实数据结合神经网络完成概念验证。",
    "tags": [
      "Risk Management",
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "提出链梯法准备金计算的新方法，通过多期因子直接投射最新观测到最终理赔，替代传统滚动累计方式",
      "为机器学习（如神经网络）应用于个体理赔准备金评估提供可行路径，并通过真实数据验证其有效性"
    ],
    "processed_at": "2026-02-18T08:55:45.374004"
  },
  {
    "id": "2602.15248v1",
    "title": "Predicting Invoice Dilution in Supply Chain Finance with Leakage Free Two Stage XGBoost, KAN (Kolmogorov Arnold Networks), and Ensemble Models",
    "abstract": "Invoice or payment dilution is the gap between the approved invoice amount and the actual collection is a significant source of non credit risk and margin loss in supply chain finance. Traditionally, this risk is managed through the buyer's irrevocable payment undertaking (IPU), which commits to full payment without deductions. However, IPUs can hinder supply chain finance adoption, particularly among sub-invested grade buyers. A newer, data-driven methods use real-time dynamic credit limits, projecting dilution for each buyer-supplier pair in real-time. This paper introduces an AI, machine learning framework and evaluates how that can supplement a deterministic algorithm to predict invoice dilution using extensive production dataset across nine key transaction fields.",
    "authors": [
      "Pavel Koptev",
      "Vishnu Kumar",
      "Konstantin Malkov",
      "George Shapiro",
      "Yury Vikhanov"
    ],
    "published": "2026-02-16",
    "categories": [
      "cs.AI",
      "math.OC",
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15248v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15248v1",
    "fetched_at": "2026-02-18T08:52:25.773598",
    "chinese_title": "基于无泄漏两阶段XGBoost、Kolmogorov-Arnold网络及集成模型的供应链金融发票稀释预测",
    "chinese_summary": "本文聚焦供应链金融中发票稀释（获批金额与实际收款差额）的风险预测问题，针对传统买方不可撤销付款承诺（IPU）的局限性，提出包含无泄漏两阶段XGBoost、Kolmogorov-Arnold网络（KAN）及集成模型的AI/ML框架，利用含9个关键交易字段的大规模生产数据集，评估该框架对确定性算法的补充预测效果。",
    "tags": [
      "Risk Management",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出融合无泄漏两阶段XGBoost、KAN及集成模型的AI/ML框架，用于供应链金融发票稀释预测",
      "基于含9个关键交易字段的大规模生产数据集，验证该框架对传统确定性算法的补充预测价值，助力解决IPU的应用局限性"
    ],
    "processed_at": "2026-02-18T08:56:04.772507"
  },
  {
    "id": "2602.15182v1",
    "title": "Autodeleveraging as Online Learning",
    "abstract": "Autodeleveraging (ADL) is a last-resort loss socialization mechanism used by perpetual futures venues when liquidation and insurance buffers are insufficient to restore solvency. Despite the scale of perpetual futures markets, ADL has received limited formal treatment as a sequential control problem. This paper provides a concise formalization of ADL as online learning on a PNL-haircut domain: at each round, the venue selects a solvency budget and a set of profitable trader accounts. The profitable accounts are liquidated to cover shortfalls up to the solvency budget, with the aim of recovering exchange-wide solvency. In this model, ADL haircuts apply to positive PNL (unrealized gains), not to posted collateral principal. Using our online learning model, we provide robustness results and theoretical upper bounds on how poorly a mechanism can perform at recovering solvency. We apply our model to the October 10, 2025 Hyperliquid stress episode. The regret caused by Hyperliquid's production ADL queue is about 50\\% of an upper bound on regret, calibrated to this event, while our optimized algorithm achieves about 2.6\\% of the same bound. In dollar terms, the production ADL model over liquidates trader profits by up to \\$51.7M. We also counterfactually evaluated algorithms inspired by our online learning framework that perform better and found that the best algorithm reduces overshoot to \\$3M. Our results provide simple, implementable mechanisms for improving ADL in live perpetuals exchanges.",
    "authors": [
      "Tarun Chitra",
      "Nagu Thogiti",
      "Mauricio Jean Pieer Trujillo Ramirez",
      "Victor Xu"
    ],
    "published": "2026-02-16",
    "categories": [
      "cs.GT",
      "q-fin.RM",
      "q-fin.TR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15182v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15182v1",
    "fetched_at": "2026-02-18T08:52:25.773624",
    "chinese_title": "自动去杠杆作为在线学习问题",
    "chinese_summary": "本文首次将永续期货的自动去杠杆（ADL）机制形式化为PNL减记域上的在线学习问题，推导了偿付能力恢复的鲁棒性结果与理论上界；通过Hyperliquid 2025年10月10日压力事件验证，优化后的在线学习算法可将过度清算损失从生产模型的约5170万美元降至300万美元，提供了可落地的ADL改进方案。",
    "tags": [
      "Risk Management",
      "Market Microstructure",
      "Algorithmic Trading"
    ],
    "key_contributions": [
      "首次将ADL形式化为在线学习问题，推导偿付能力恢复的鲁棒性与理论上界",
      "提出优化算法大幅降低ADL过度清算损失，提供可落地的改进机制"
    ],
    "processed_at": "2026-02-18T08:56:18.148815"
  },
  {
    "id": "2602.15177v1",
    "title": "Optimal investment under capital gains taxes",
    "abstract": "We generalize classical results on the existence of optimal portfolios in discrete time frictionless market models to models with capital gains taxes. We consider the realistic but mathematically challenging rule that losses do not trigger negative taxes but can only be offset against potential gains in the future. Central to the analysis is a well-known phenomenon from arbitrage-free markets with proportional transaction costs that does not exist in arbitrage-free frictionless markets: an investment in specific quantities of stocks that is completely riskless but may provide an advantage over holding money in the bank account. As a result of this phenomenon, on an infinite probability space, no-arbitrage does not imply that the set of attainable terminal wealth is closed in probability. We show closedness under the slightly stronger {\\em no unbounded non-substitutable investment with bounded risk} condition.   As a by-product, we provide a proof that in discrete time frictionless models with short-selling constraints, no-arbitrage implies that the set of attainable terminal wealth is closed in probability -- even if there are redundant stocks.",
    "authors": [
      "Alexander Dimitrov",
      "Christoph Kühn"
    ],
    "published": "2026-02-16",
    "categories": [
      "q-fin.MF",
      "math.PR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15177v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15177v1",
    "fetched_at": "2026-02-18T08:52:25.773646",
    "chinese_title": "资本利得税下的最优投资",
    "chinese_summary": "本文将离散时间无摩擦市场最优投资组合存在性的经典结果推广至含资本利得税的模型，考虑损失仅能未来抵收益的现实规则；分析了无套利市场中无风险但优于银行存款的股票投资现象，证明稍强条件下可达终端财富集在概率下封闭，还补充了无摩擦卖空约束下无套利implies可达集封闭的结论。",
    "tags": [
      "Portfolio Optimization",
      "Asset Pricing"
    ],
    "key_contributions": [
      "将离散时间无摩擦市场最优投资组合存在性推广至含资本利得税的模型，考虑损失仅能未来抵收益的现实规则",
      "证明稍强条件下可达终端财富集在概率下封闭，补充了无摩擦卖空约束下无套利implies可达集封闭的结论"
    ],
    "processed_at": "2026-02-18T08:56:41.602983"
  },
  {
    "id": "2602.14754v2",
    "title": "Market Efficiency and the Heterogeneous Impact of Financial Liberalization: Evidence from the Shanghai-Hong Kong Stock Connect",
    "abstract": "This paper investigates the impact of the Shanghai-Hong Kong Stock Connect (SHHK Stock Connect) on the A-H share price premium and examines whether the policy effect is contingent on market efficiency. Using monthly data for 67 Shanghai-listed A-H dual-listed firms from January 2011 to May 2019, we employ a dynamic panel model estimated via two-step system generalized method of moment (GMM) to account for the persistence of the premium and potential endogeneity. Market efficiency is proxied by trading-friction measures derived from daily high-low price ranges. Our findings indicate that the implementation of SHHK Stock Connect is associated with an average 18.4% increase in the A-H premium. However, this effect is heterogeneous: the marginal impact of the policy is more pronounced for firms operating in less efficient markets and weaker for those with higher efficiency, suggesting that pre-existing trading frictions shape the policy outcome. No significant response is observed at the announcement stage. Placebo tests and alternative efficiency measures confirm the robustness of the efficiency-dependent effect. Overall, the results underscore the importance of the information environment in shaping the outcomes of financial liberalization.",
    "authors": [
      "Jiaqi Liu",
      "Chen Tang"
    ],
    "published": "2026-02-16",
    "categories": [
      "q-fin.GN"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.14754v2",
    "arxiv_url": "https://arxiv.org/abs/2602.14754v2",
    "fetched_at": "2026-02-18T08:52:25.773712",
    "chinese_title": "市场效率与金融开放的异质性影响：来自沪港通的证据",
    "chinese_summary": "本文以2011年1月至2019年5月67家沪市A+H股公司月度数据为样本，采用两步系统GMM动态面板模型（控制溢价持续性与内生性），用日高低价衍生的交易摩擦指标代理市场效率，研究沪港通对A-H股溢价的影响及异质性。发现沪港通实施使A-H溢价平均提升18.4%，但异质性显著：市场效率越低（交易摩擦越大）的公司政策边际影响越强，公告阶段无显著效应，安慰剂与替代指标验证了效率依赖效应的稳健性，强调信息环境对金融开放结果的塑造作用。",
    "tags": [
      "Asset Pricing",
      "Market Microstructure",
      "Anomaly"
    ],
    "key_contributions": [
      "揭示沪港通对A-H股溢价的影响具有异质性，依赖于公司所在市场的效率（交易摩擦），效率越低政策影响越强",
      "通过动态面板GMM控制内生性，结合安慰剂与替代指标验证结果稳健性，强调信息环境对金融开放政策效果的关键作用"
    ],
    "processed_at": "2026-02-18T08:57:05.285918"
  },
  {
    "id": "2602.15532v1",
    "title": "Quantifying construct validity in large language model evaluations",
    "abstract": "The LLM community often reports benchmark results as if they are synonymous with general model capabilities. However, benchmarks can have problems that distort performance, like test set contamination and annotator error. How can we know that a benchmark is a reliable indicator of some capability that we want to measure? This question concerns the construct validity of LLM benchmarks, and it requires separating benchmark results from capabilities when we model and predict LLM performance.   Both social scientists and computer scientists propose formal models - latent factor models and scaling laws - for identifying the capabilities underlying benchmark scores. However, neither technique is satisfactory for construct validity. Latent factor models ignore scaling laws, and as a result, the capabilities they extract often proxy model size. Scaling laws ignore measurement error, and as a result, the capabilities they extract are both uninterpretable and overfit to the observed benchmarks.   This thesis presents the structured capabilities model, the first model to extract interpretable and generalisable capabilities from a large collection of LLM benchmark results. I fit this model and its two alternatives on a large sample of results from the OpenLLM Leaderboard. Structured capabilities outperform latent factor models on parsimonious fit indices, and exhibit better out-of-distribution benchmark prediction than scaling laws. These improvements are possible because neither existing approach separates model scale from capabilities in the appropriate way. Model scale should inform capabilities, as in scaling laws, and these capabilities should inform observed results up to measurement error, as in latent factor models. In combining these two insights, structured capabilities demonstrate better explanatory and predictive power for quantifying construct validity in LLM evaluations.",
    "authors": [
      "Ryan Othniel Kearns"
    ],
    "published": "2026-02-17",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15532v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15532v1",
    "fetched_at": "2026-02-18T08:52:31.935783",
    "chinese_title": "量化大语言模型评估中的构念效度",
    "chinese_summary": "现有大语言模型（LLM）基准评估的构念效度存在不足，传统潜在因子模型和缩放定律均无法有效提取可解释且泛化的模型能力；论文提出结构化能力模型，首次从大量LLM基准结果中提取可解释、可泛化的能力，在简约拟合指标上优于潜在因子模型，且分布外基准预测优于缩放定律。",
    "tags": [
      "LLM",
      "NLP",
      "Benchmark"
    ],
    "key_contributions": [
      "指出现有LLM基准评估构念效度的缺陷，分析传统潜在因子模型与缩放定律的不足",
      "提出结构化能力模型，首次从大量LLM基准结果中提取可解释且可泛化的模型能力，在拟合与预测上优于现有方法"
    ],
    "processed_at": "2026-02-18T08:57:15.525930"
  },
  {
    "id": "2602.15470v1",
    "title": "The Skeletal Trap: Mapping Spatial Inequality and Ghost Stops in Ankara's Transit Network",
    "abstract": "Ankara's public transport crisis is commonly framed as a shortage of buses or operational inefficiency. This study argues that the problem is fundamentally morphological and structural. The city's leapfrog urban expansion has produced fragmented peripheral clusters disconnected from a rigid, center-oriented bus network. As a result, demand remains intensely concentrated along the Kizilay-Ulus axis and western corridors, while peripheral districts experience either chronic under-service or enforced transfer dependency. The deficiency is therefore not merely quantitative but rooted in the misalignment between urban macroform and network architecture. The empirical analysis draws on a 173-day operational dataset derived from route-level passenger and trip reports published by EGO under the former \"Transparent Ankara\" initiative. To overcome the absence of stop-level geospatial data, a Connectivity-Based Weighted Distribution Model reallocates passenger volumes to 1 km x 1 km grid cells using network centrality. The findings reveal persistent center-periphery asymmetries, structural bottlenecks, and spatially embedded accessibility inequalities.",
    "authors": [
      "Elifnaz Kancan"
    ],
    "published": "2026-02-17",
    "categories": [
      "physics.soc-ph",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15470v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15470v1",
    "fetched_at": "2026-02-18T08:52:38.096077",
    "chinese_title": "骨架陷阱：安卡拉公交网络的空间不平等与幽灵站点映射",
    "chinese_summary": "本研究指出安卡拉公交危机本质是城市跳跃式扩张导致的外围集群与中心导向公交网络形态错配（而非单纯车辆不足或运营低效）；采用173天运营数据集，结合基于连通性的加权分布模型（弥补站点级地理数据缺失），揭示了中心-外围空间不平等、结构瓶颈等问题。",
    "tags": [
      "Time Series",
      "Graph Neural Network"
    ],
    "key_contributions": [
      "突破传统认知，指出安卡拉公交危机本质为城市形态与网络架构错配",
      "提出基于连通性的加权分布模型，解决站点级地理数据缺失的乘客量空间分配问题",
      "揭示公交网络中心-外围空间不平等、结构瓶颈等核心特征"
    ],
    "processed_at": "2026-02-18T08:57:34.800370"
  },
  {
    "id": "2602.15457v1",
    "title": "Benchmarking IoT Time-Series AD with Event-Level Augmentations",
    "abstract": "Anomaly detection (AD) for safety-critical IoT time series should be judged at the event level: reliability and earliness under realistic perturbations. Yet many studies still emphasize point-level results on curated base datasets, limiting value for model selection in practice. We introduce an evaluation protocol with unified event-level augmentations that simulate real-world issues: calibrated sensor dropout, linear and log drift, additive noise, and window shifts. We also perform sensor-level probing via mask-as-missing zeroing with per-channel influence estimation to support root-cause analysis. We evaluate 14 representative models on five public anomaly datasets (SWaT, WADI, SMD, SKAB, TEP) and two industrial datasets (steam turbine, nuclear turbogenerator) using unified splits and event aggregation. There is no universal winner: graph-structured models transfer best under dropout and long events (e.g., on SWaT under additive noise F1 drops 0.804->0.677 for a graph autoencoder, 0.759->0.680 for a graph-attention variant, and 0.762->0.756 for a hybrid graph attention model); density/flow models work well on clean stationary plants but can be fragile to monotone drift; spectral CNNs lead when periodicity is strong; reconstruction autoencoders become competitive after basic sensor vetting; predictive/hybrid dynamics help when faults break temporal dependencies but remain window-sensitive. The protocol also informs design choices: on SWaT under log drift, replacing normalizing flows with Gaussian density reduces high-stress F1 from ~0.75 to ~0.57, and fixing a learned DAG gives a small clean-set gain (~0.5-1.0 points) but increases drift sensitivity by ~8x.",
    "authors": [
      "Dmitry Zhevnenko",
      "Ilya Makarov",
      "Aleksandr Kovalenko",
      "Fedor Meshchaninov",
      "Anton Kozhukhov",
      "Vladislav Travnikov",
      "Makar Ippolitov",
      "Kirill Yashunin",
      "Iurii Katser"
    ],
    "published": "2026-02-17",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15457v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15457v1",
    "fetched_at": "2026-02-18T08:52:38.096121",
    "chinese_title": "基于事件级增强的物联网时间序列异常检测基准测试",
    "chinese_summary": "本文针对安全关键物联网时间序列异常检测（AD），提出含统一事件级增强（模拟传感器 dropout、漂移、噪声等真实扰动）的评估协议，还通过传感器级探测支持根因分析；系统评估14个代表性模型在7个数据集（5公开+2工业）上的表现，发现无通用最优，不同模型适配不同扰动场景，协议可指导模型设计。",
    "tags": [
      "Anomaly",
      "Time Series",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "提出含统一事件级增强（模拟真实扰动）和传感器级探测的物联网时间序列AD评估协议",
      "系统评估14个模型在7个数据集（含工业数据）上的表现，揭示模型适配场景并指导设计选择"
    ],
    "processed_at": "2026-02-18T08:57:46.439831"
  },
  {
    "id": "2602.15325v1",
    "title": "AgriWorld:A World Tools Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents",
    "abstract": "Foundation models for agriculture are increasingly trained on massive spatiotemporal data (e.g., multi-spectral remote sensing, soil grids, and field-level management logs) and achieve strong performance on forecasting and monitoring. However, these models lack language-based reasoning and interactive capabilities, limiting their usefulness in real-world agronomic workflows. Meanwhile, large language models (LLMs) excel at interpreting and generating text, but cannot directly reason over high-dimensional, heterogeneous agricultural datasets. We bridge this gap with an agentic framework for agricultural science. It provides a Python execution environment, AgriWorld, exposing unified tools for geospatial queries over field parcels, remote-sensing time-series analytics, crop growth simulation, and task-specific predictors (e.g., yield, stress, and disease risk). On top of this environment, we design a multi-turn LLM agent, Agro-Reflective, that iteratively writes code, observes execution results, and refines its analysis via an execute-observe-refine loop. We introduce AgroBench, with scalable data generation for diverse agricultural QA spanning lookups, forecasting, anomaly detection, and counterfactual \"what-if\" analysis. Experiments outperform text-only and direct tool-use baselines, validating execution-driven reflection for reliable agricultural reasoning.",
    "authors": [
      "Zhixing Zhang",
      "Jesen Zhang",
      "Hao Liu",
      "Qinhan Lv",
      "Jing Yang",
      "Kaitong Cai",
      "Keze Wang"
    ],
    "published": "2026-02-17",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15325v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15325v1",
    "fetched_at": "2026-02-18T08:52:38.096152",
    "chinese_title": "AgriWorld：带代码执行LLM智能体的可验证农业推理世界工具协议框架",
    "chinese_summary": "现有农业基础模型缺乏语言推理交互能力，LLM无法直接处理高维异质农业数据，论文提出AgriWorld框架（含Python执行环境与统一农业工具），设计Agro-Reflective多轮LLM智能体（执行-观察-优化循环），并引入AgroBench基准，实验验证其优于文本-only及直接工具使用基线。",
    "tags": [
      "LLM",
      "Execution",
      "Benchmark"
    ],
    "key_contributions": [
      "提出AgriWorld框架，桥接农业基础模型与LLM的能力 gap，提供统一工具与代码执行环境",
      "设计Agro-Reflective多轮LLM智能体并引入AgroBench基准，验证执行驱动反思对农业推理的有效性"
    ],
    "processed_at": "2026-02-18T08:57:58.002616"
  },
  {
    "id": "2602.15315v1",
    "title": "Training-Free Zero-Shot Anomaly Detection in 3D Brain MRI with 2D Foundation Models",
    "abstract": "Zero-shot anomaly detection (ZSAD) has gained increasing attention in medical imaging as a way to identify abnormalities without task-specific supervision, but most advances remain limited to 2D datasets. Extending ZSAD to 3D medical images has proven challenging, with existing methods relying on slice-wise features and vision-language models, which fail to capture volumetric structure. In this paper, we introduce a fully training-free framework for ZSAD in 3D brain MRI that constructs localized volumetric tokens by aggregating multi-axis slices processed by 2D foundation models. These 3D patch tokens restore cubic spatial context and integrate directly with distance-based, batch-level anomaly detection pipelines. The framework provides compact 3D representations that are practical to compute on standard GPUs and require no fine-tuning, prompts, or supervision. Our results show that training-free, batch-based ZSAD can be effectively extended from 2D encoders to full 3D MRI volumes, offering a simple and robust approach for volumetric anomaly detection.",
    "authors": [
      "Tai Le-Gia",
      "Jaehyun Ahn"
    ],
    "published": "2026-02-17",
    "categories": [
      "cs.CV",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15315v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15315v1",
    "fetched_at": "2026-02-18T08:52:38.096172",
    "chinese_title": "基于2D基础模型的3D脑MRI无训练零样本异常检测",
    "chinese_summary": "论文针对3D医学图像零样本异常检测（ZSAD）难以捕捉体积结构的问题，提出无训练框架：通过2D基础模型处理多轴切片并聚合为局部体积token恢复3D空间上下文，结合基于距离的批量异常检测管道，无需微调、提示或监督，有效扩展2D编码器到3D MRI的无训练ZSAD。",
    "tags": [
      "Anomaly",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出无训练零样本异常检测框架，解决3D脑MRI ZSAD中体积结构捕捉不足的挑战",
      "无需微调、提示或监督，通过聚合多轴切片特征恢复3D上下文，结合批量管道实现有效检测"
    ],
    "processed_at": "2026-02-18T08:58:12.030253"
  },
  {
    "id": "2602.15089v1",
    "title": "Hybrid Feature Learning with Time Series Embeddings for Equipment Anomaly Prediction",
    "abstract": "In predictive maintenance of equipment, deep learning-based time series anomaly detection has garnered significant attention; however, pure deep learning approaches often fail to achieve sufficient accuracy on real-world data. This study proposes a hybrid approach that integrates 64-dimensional time series embeddings from Granite TinyTimeMixer with 28-dimensional statistical features based on domain knowledge for HVAC equipment anomaly prediction tasks. Specifically, we combine time series embeddings extracted from a Granite TinyTimeMixer encoder fine-tuned with LoRA (Low-Rank Adaptation) and 28 types of statistical features including trend, volatility, and drawdown indicators, which are then learned using a LightGBM gradient boosting classifier. In experiments using 64 equipment units and 51,564 samples, we achieved Precision of 91--95\\% and ROC-AUC of 0.995 for anomaly prediction at 30-day, 60-day, and 90-day horizons. Furthermore, we achieved production-ready performance with a false positive rate of 1.1\\% or less and a detection rate of 88--94\\%, demonstrating the effectiveness of the system for predictive maintenance applications. This work demonstrates that practical anomaly detection systems can be realized by leveraging the complementary strengths between deep learning's representation learning capabilities and statistical feature engineering.",
    "authors": [
      "Takato Yasuno"
    ],
    "published": "2026-02-16",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15089v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15089v1",
    "fetched_at": "2026-02-18T08:52:38.096215",
    "chinese_title": "基于时间序列嵌入的混合特征学习在设备异常预测中的应用",
    "chinese_summary": "本研究针对设备预测维护中的异常预测问题，提出一种混合方法：将经LoRA微调的Granite TinyTimeMixer提取的时间序列嵌入与28维领域统计特征（含趋势、波动率等指标）结合，采用LightGBM分类器实现预测；在64台设备、51564样本上，30/60/90天预测均获高精度（Precision91-95%、ROC-AUC0.995）及生产级性能（误报率≤1.1%、检测率88-94%），验证了深度学习表示学习与统计特征工程的互补性。",
    "tags": [
      "Anomaly",
      "Time Series",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出融合LoRA微调时间序列嵌入与领域统计特征的混合方法，提升设备异常预测精度",
      "在HVAC设备预测维护中实现生产级性能，验证深度学习与统计特征工程的互补性"
    ],
    "processed_at": "2026-02-18T08:58:24.525829"
  },
  {
    "id": "2602.15828v1",
    "title": "Dex4D: Task-Agnostic Point Track Policy for Sim-to-Real Dexterous Manipulation",
    "abstract": "Learning generalist policies capable of accomplishing a plethora of everyday tasks remains an open challenge in dexterous manipulation. In particular, collecting large-scale manipulation data via real-world teleoperation is expensive and difficult to scale. While learning in simulation provides a feasible alternative, designing multiple task-specific environments and rewards for training is similarly challenging. We propose Dex4D, a framework that instead leverages simulation for learning task-agnostic dexterous skills that can be flexibly recomposed to perform diverse real-world manipulation tasks. Specifically, Dex4D learns a domain-agnostic 3D point track conditioned policy capable of manipulating any object to any desired pose. We train this 'Anypose-to-Anypose' policy in simulation across thousands of objects with diverse pose configurations, covering a broad space of robot-object interactions that can be composed at test time. At deployment, this policy can be zero-shot transferred to real-world tasks without finetuning, simply by prompting it with desired object-centric point tracks extracted from generated videos. During execution, Dex4D uses online point tracking for closed-loop perception and control. Extensive experiments in simulation and on real robots show that our method enables zero-shot deployment for diverse dexterous manipulation tasks and yields consistent improvements over prior baselines. Furthermore, we demonstrate strong generalization to novel objects, scene layouts, backgrounds, and trajectories, highlighting the robustness and scalability of the proposed framework.",
    "authors": [
      "Yuxuan Kuang",
      "Sungjae Park",
      "Katerina Fragkiadaki",
      "Shubham Tulsiani"
    ],
    "published": "2026-02-17",
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15828v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15828v1",
    "fetched_at": "2026-02-18T08:53:05.924689",
    "chinese_title": "Dex4D：面向Sim-to-Real灵巧操作的任务无关点跟踪策略",
    "chinese_summary": "论文提出Dex4D框架，通过仿真学习任务无关的3D点跟踪条件策略，实现任意物体到任意位姿的操作；该策略无需微调即可零样本迁移至真实任务，结合在线点跟踪实现闭环感知控制，泛化性及性能优于基线。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出任务无关的3D点跟踪条件策略，支持任意物体-任意位姿操作且可零样本迁移至真实场景",
      "无需任务特定环境/奖励设计，通过仿真大规模训练实现多样灵巧操作，泛化至新物体"
    ],
    "processed_at": "2026-02-18T08:58:40.718395"
  },
  {
    "id": "2602.15827v1",
    "title": "Perceptive Humanoid Parkour: Chaining Dynamic Human Skills via Motion Matching",
    "abstract": "While recent advances in humanoid locomotion have achieved stable walking on varied terrains, capturing the agility and adaptivity of highly dynamic human motions remains an open challenge. In particular, agile parkour in complex environments demands not only low-level robustness, but also human-like motion expressiveness, long-horizon skill composition, and perception-driven decision-making. In this paper, we present Perceptive Humanoid Parkour (PHP), a modular framework that enables humanoid robots to autonomously perform long-horizon, vision-based parkour across challenging obstacle courses. Our approach first leverages motion matching, formulated as nearest-neighbor search in a feature space, to compose retargeted atomic human skills into long-horizon kinematic trajectories. This framework enables the flexible composition and smooth transition of complex skill chains while preserving the elegance and fluidity of dynamic human motions. Next, we train motion-tracking reinforcement learning (RL) expert policies for these composed motions, and distill them into a single depth-based, multi-skill student policy, using a combination of DAgger and RL. Crucially, the combination of perception and skill composition enables autonomous, context-aware decision-making: using only onboard depth sensing and a discrete 2D velocity command, the robot selects and executes whether to step over, climb onto, vault or roll off obstacles of varying geometries and heights. We validate our framework with extensive real-world experiments on a Unitree G1 humanoid robot, demonstrating highly dynamic parkour skills such as climbing tall obstacles up to 1.25m (96% robot height), as well as long-horizon multi-obstacle traversal with closed-loop adaptation to real-time obstacle perturbations.",
    "authors": [
      "Zhen Wu",
      "Xiaoyu Huang",
      "Lujie Yang",
      "Yuanhang Zhang",
      "Koushil Sreenath",
      "Xi Chen",
      "Pieter Abbeel",
      "Rocky Duan",
      "Angjoo Kanazawa",
      "Carmelo Sferrazza",
      "Guanya Shi",
      "C. Karen Liu"
    ],
    "published": "2026-02-17",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "eess.SY"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15827v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15827v1",
    "fetched_at": "2026-02-18T08:53:05.924748",
    "chinese_title": "感知人形机器人跑酷：通过运动匹配链接动态人类技能",
    "chinese_summary": "论文提出感知人形机器人跑酷（PHP）模块化框架，先通过特征空间最近邻搜索的运动匹配方法组合人类原子技能成长期运动轨迹，再结合DAgger与RL将运动跟踪RL专家策略蒸馏为基于深度的多技能学生策略，实现仅用机载深度感知和离散2D速度指令的自主跑酷决策与执行。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出感知人形机器人跑酷模块化框架，通过运动匹配实现人类动态技能的灵活组合与平滑过渡",
      "结合DAgger和RL蒸馏出基于深度感知的多技能学生策略，支持仅用机载深度和离散速度指令的自主跑酷决策"
    ],
    "processed_at": "2026-02-18T08:58:52.349111"
  },
  {
    "id": "2602.15758v1",
    "title": "ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models",
    "abstract": "While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.",
    "authors": [
      "Manav Nitin Kapadnis",
      "Lawanya Baghel",
      "Atharva Naik",
      "Carolyn Rosé"
    ],
    "published": "2026-02-17",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15758v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15758v1",
    "fetched_at": "2026-02-18T08:53:05.924773",
    "chinese_title": "ChartEditBench：多模态语言模型中基于视觉的多轮图表编辑评估",
    "chinese_summary": "现有多模态大模型在单轮图表生成中表现较好，但多轮探索性图表编辑能力未被充分探索；论文提出ChartEditBench基准（含5000个难度可控的多轮修改链及人工验证子集），并构建融合执行检查、像素相似度、代码逻辑验证的评估框架；实验表明多轮编辑下模型因错误累积和上下文断裂性能下降，该基准为多模态编程提供测试床。",
    "tags": [
      "LLM",
      "Benchmark",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出ChartEditBench基准，包含5000个难度可控的多轮图表修改链及人工验证子集，填补多模态语言模型多轮视觉编辑评估的空白",
      "构建融合执行保真度检查、像素级视觉相似度、代码逻辑验证的评估框架，缓解LLM-as-a-Judge的局限性"
    ],
    "processed_at": "2026-02-18T08:59:14.508595"
  },
  {
    "id": "2602.15721v1",
    "title": "Lifelong Scalable Multi-Agent Realistic Testbed and A Comprehensive Study on Design Choices in Lifelong AGV Fleet Management Systems",
    "abstract": "We present Lifelong Scalable Multi-Agent Realistic Testbed (LSMART), an open-source simulator to evaluate any Multi-Agent Path Finding (MAPF) algorithm in a Fleet Management System (FMS) with Automated Guided Vehicles (AGVs). MAPF aims to move a group of agents from their corresponding starting locations to their goals. Lifelong MAPF (LMAPF) is a variant of MAPF that continuously assigns new goals for agents to reach. LMAPF applications, such as autonomous warehouses, often require a centralized, lifelong system to coordinate the movement of a fleet of robots, typically AGVs. However, existing works on MAPF and LMAPF often assume simplified kinodynamic models, such as pebble motion, as well as perfect execution and communication for AGVs. Prior work has presented SMART, a software capable of evaluating any MAPF algorithms while considering agent kinodynamics, communication delays, and execution uncertainties. However, SMART is designed for MAPF, not LMAPF. Generalizing SMART to an FMS requires many more design choices. First, an FMS parallelizes planning and execution, raising the question of when to plan. Second, given planners with varying optimality and differing agent-model assumptions, one must decide how to plan. Third, when the planner fails to return valid solutions, the system must determine how to recover. In this paper, we first present LSMART, an open-source simulator that incorporates all these considerations to evaluate any MAPF algorithms in an FMS. We then provide experiment results based on state-of-the-art methods for each design choice, offering guidance on how to effectively design centralized lifelong AGV Fleet Management Systems. LSMART is available at https://smart-mapf.github.io/lifelong-smart.",
    "authors": [
      "Jingtian Yan",
      "Yulun Zhang",
      "Zhenting Liu",
      "Han Zhang",
      "He Jiang",
      "Jingkai Chen",
      "Stephen F. Smith",
      "Jiaoyang Li"
    ],
    "published": "2026-02-17",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15721v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15721v1",
    "fetched_at": "2026-02-18T08:53:05.924803",
    "chinese_title": "终身可扩展多智能体真实测试床及终身AGV车队管理系统设计选择的综合研究",
    "chinese_summary": "本文提出开源模拟器LSMART，用于AGV车队管理系统中评估MAPF/LMAPF算法，纳入规划执行并行化、规划时机、故障恢复等真实场景设计选择；同时对终身AGV车队管理系统的设计选择开展综合研究。",
    "tags": [
      "Benchmark",
      "Financial Agent"
    ],
    "key_contributions": [
      "提出开源测试床LSMART，支持AGV车队管理系统中MAPF/LMAPF算法的真实场景评估，纳入多类设计选择",
      "对终身AGV车队管理系统的关键设计选择开展综合分析"
    ],
    "processed_at": "2026-02-18T08:59:34.052469"
  },
  {
    "id": "2602.15559v1",
    "title": "Fixed-Horizon Self-Normalized Inference for Adaptive Experiments via Martingale AIPW/DML with Logged Propensities",
    "abstract": "Adaptive randomized experiments update treatment probabilities as data accrue, but still require an end-of-study interval for the average treatment effect (ATE) at a prespecified horizon. Under adaptive assignment, propensities can keep changing, so the predictable quadratic variation of AIPW/DML score increments may remain random. When no deterministic variance limit exists, Wald statistics normalized by a single long-run variance target can be conditionally miscalibrated given the realized variance regime. We assume no interference, sequential randomization, i.i.d. arrivals, and executed overlap on a prespecified scored set, and we require two auditable pipeline conditions: the platform logs the executed randomization probability for each unit, and the nuisance regressions used to score unit $t$ are constructed predictably from past data only. These conditions make the centered AIPW/DML scores an exact martingale difference sequence. Using self-normalized martingale limit theory, we show that the Studentized statistic, with variance estimated by realized quadratic variation, is asymptotically N(0,1) at the prespecified horizon, even without variance stabilization. Simulations validate the theory and highlight when standard fixed-variance Wald reporting fails.",
    "authors": [
      "Gabriel Saco"
    ],
    "published": "2026-02-17",
    "categories": [
      "stat.ME",
      "econ.EM",
      "math.ST",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15559v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15559v1",
    "fetched_at": "2026-02-18T08:53:05.924821",
    "chinese_title": "固定horizon自适应实验的自归一化推断——基于带日志倾向的鞅AIPW/DML",
    "chinese_summary": "自适应随机实验中处理概率随数据累积更新，现有方法因倾向变化导致方差不稳定易校准错误；论文通过日志执行随机概率和仅用历史数据的nuisance回归使AIPW/DML分数为精确鞅差序列，利用自归一化鞅极限理论证明Studentized统计量渐近正态，模拟验证了理论及标准Wald方法的不足。",
    "tags": [
      "Execution",
      "Risk Management"
    ],
    "key_contributions": [
      "提出两个可审计的pipeline条件，使中心化AIPW/DML分数成为精确鞅差序列",
      "利用自归一化鞅极限理论证明固定horizon下Studentized统计量渐近正态，无需方差稳定假设"
    ],
    "processed_at": "2026-02-18T09:00:00.662658"
  },
  {
    "id": "2602.15549v1",
    "title": "VLM-DEWM: Dynamic External World Model for Verifiable and Resilient Vision-Language Planning in Manufacturing",
    "abstract": "Vision-language model (VLM) shows promise for high-level planning in smart manufacturing, yet their deployment in dynamic workcells faces two critical challenges: (1) stateless operation, they cannot persistently track out-of-view states, causing world-state drift; and (2) opaque reasoning, failures are difficult to diagnose, leading to costly blind retries. This paper presents VLM-DEWM, a cognitive architecture that decouples VLM reasoning from world-state management through a persistent, queryable Dynamic External World Model (DEWM). Each VLM decision is structured into an Externalizable Reasoning Trace (ERT), comprising action proposal, world belief, and causal assumption, which is validated against DEWM before execution. When failures occur, discrepancy analysis between predicted and observed states enables targeted recovery instead of global replanning. We evaluate VLM-DEWM on multi-station assembly, large-scale facility exploration, and real-robot recovery under induced failures. Compared to baseline memory-augmented VLM systems, VLM DEWM improves state-tracking accuracy from 56% to 93%, increases recovery success rate from below 5% to 95%, and significantly reduces computational overhead through structured memory. These results establish VLM-DEWM as a verifiable and resilient solution for long-horizon robotic operations in dynamic manufacturing environments.",
    "authors": [
      "Guoqin Tang",
      "Qingxuan Jia",
      "Gang Chen",
      "Tong Li",
      "Zeyuan Huang",
      "Zihang Lv",
      "Ning Ji"
    ],
    "published": "2026-02-17",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15549v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15549v1",
    "fetched_at": "2026-02-18T08:53:05.924850",
    "chinese_title": "VLM-DEWM：面向制造中可验证且弹性的视觉-语言规划的动态外部世界模型",
    "chinese_summary": "针对视觉-语言模型（VLM）在智能制造动态场景中无状态操作导致世界状态漂移、推理不透明难以诊断的问题，论文提出VLM-DEWM架构，通过持久可查询的动态外部世界模型（DEWM）解耦VLM推理与状态管理，用可外部化推理轨迹验证决策并支持故障定向恢复；实验表明该方法显著提升状态跟踪准确率、恢复成功率并降低计算开销，适用于动态制造环境的长程机器人操作。",
    "tags": [
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出VLM-DEWM认知架构，通过持久可查询的动态外部世界模型（DEWM）解耦VLM推理与世界状态管理，解决VLM无状态操作导致的状态漂移问题",
      "引入可外部化推理轨迹（ERT）实现决策验证与故障定向恢复，提升推理透明度与系统弹性，实验验证在制造场景中的显著性能优势"
    ],
    "processed_at": "2026-02-18T09:00:19.775730"
  },
  {
    "id": "2602.15485v1",
    "title": "SecCodeBench-V2 Technical Report",
    "abstract": "We introduce SecCodeBench-V2, a publicly released benchmark for evaluating Large Language Model (LLM) copilots' capabilities of generating secure code. SecCodeBench-V2 comprises 98 generation and fix scenarios derived from Alibaba Group's industrial productions, where the underlying security issues span 22 common CWE (Common Weakness Enumeration) categories across five programming languages: Java, C, Python, Go, and Node.js. SecCodeBench-V2 adopts a function-level task formulation: each scenario provides a complete project scaffold and requires the model to implement or patch a designated target function under fixed interfaces and dependencies. For each scenario, SecCodeBench-V2 provides executable proof-of-concept (PoC) test cases for both functional validation and security verification. All test cases are authored and double-reviewed by security experts, ensuring high fidelity, broad coverage, and reliable ground truth. Beyond the benchmark itself, we build a unified evaluation pipeline that assesses models primarily via dynamic execution. For most scenarios, we compile and run model-generated artifacts in isolated environments and execute PoC test cases to validate both functional correctness and security properties. For scenarios where security issues cannot be adjudicated with deterministic test cases, we additionally employ an LLM-as-a-judge oracle. To summarize performance across heterogeneous scenarios and difficulty levels, we design a Pass@K-based scoring protocol with principled aggregation over scenarios and severity, enabling holistic and comparable evaluation across models. Overall, SecCodeBench-V2 provides a rigorous and reproducible foundation for assessing the security posture of AI coding assistants, with results and artifacts released at https://alibaba.github.io/sec-code-bench. The benchmark is publicly available at https://github.com/alibaba/sec-code-bench.",
    "authors": [
      "Longfei Chen",
      "Ji Zhao",
      "Lanxiao Cui",
      "Tong Su",
      "Xingbo Pan",
      "Ziyang Li",
      "Yongxing Wu",
      "Qijiang Cao",
      "Qiyao Cai",
      "Jing Zhang",
      "Yuandong Ni",
      "Junyao He",
      "Zeyu Zhang",
      "Chao Ge",
      "Xuhuai Lu",
      "Zeyu Gao",
      "Yuxin Cui",
      "Weisen Chen",
      "Yuxuan Peng",
      "Shengping Wang",
      "Qi Li",
      "Yukai Huang",
      "Yukun Liu",
      "Tuo Zhou",
      "Terry Yue Zhuo",
      "Junyang Lin",
      "Chao Zhang"
    ],
    "published": "2026-02-17",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15485v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15485v1",
    "fetched_at": "2026-02-18T08:53:05.924918",
    "chinese_title": "SecCodeBench-V2技术报告",
    "chinese_summary": "该论文介绍公开基准SecCodeBench-V2，用于评估大语言模型（LLM）生成安全代码的能力，包含98个来自阿里工业生产的代码生成/修复场景，覆盖22种常见CWE类别及5种编程语言，每个场景配有安全专家审核的可执行PoC测试用例；还构建了动态执行+LLM-as-judge的统一评估 pipeline，并设计Pass@K评分协议汇总多场景性能。",
    "tags": [
      "LLM",
      "Benchmark",
      "Deep Learning"
    ],
    "key_contributions": [
      "发布工业级公开基准SecCodeBench-V2，覆盖多语言多CWE类别的安全代码生成/修复任务，测试用例经安全专家审核确保高保真与可靠性",
      "构建动态执行+LLM-as-judge的统一评估 pipeline，设计Pass@K评分协议，支持跨异构场景评估LLM的安全代码能力"
    ],
    "processed_at": "2026-02-18T09:00:43.246042"
  },
  {
    "id": "2602.15384v1",
    "title": "World-Model-Augmented Web Agents with Action Correction",
    "abstract": "Web agents based on large language models have demonstrated promising capability in automating web tasks. However, current web agents struggle to reason out sensible actions due to the limitations of predicting environment changes, and might not possess comprehensive awareness of execution risks, prematurely performing risky actions that cause losses and lead to task failure. To address these challenges, we propose WAC, a web agent that integrates model collaboration, consequence simulation, and feedback-driven action refinement. To overcome the cognitive isolation of individual models, we introduce a multi-agent collaboration process that enables an action model to consult a world model as a web-environment expert for strategic guidance; the action model then grounds these suggestions into executable actions, leveraging prior knowledge of environmental state transition dynamics to enhance candidate action proposal. To achieve risk-aware resilient task execution, we introduce a two-stage deduction chain. A world model, specialized in environmental state transitions, simulates action outcomes, which a judge model then scrutinizes to trigger action corrective feedback when necessary. Experiments show that WAC achieves absolute gains of 1.8% on VisualWebArena and 1.3% on Online-Mind2Web.",
    "authors": [
      "Zhouzhou Shen",
      "Xueyu Hu",
      "Xiyun Li",
      "Tianqing Fang",
      "Juncheng Li",
      "Shengyu Zhang"
    ],
    "published": "2026-02-17",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15384v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15384v1",
    "fetched_at": "2026-02-18T08:53:05.924947",
    "chinese_title": "带动作修正的世界模型增强型Web智能体",
    "chinese_summary": "针对现有Web智能体因环境变化预测不足、执行风险意识弱导致任务失败的问题，本文提出WAC智能体，整合多模型协作、结果模拟与反馈驱动的动作优化；通过多智能体协作让动作模型咨询世界模型获取策略指导，结合两阶段推理链（世界模型模拟动作结果+法官模型审查触发修正）提升风险感知与任务执行鲁棒性，实验在VisualWebArena和Online-Mind2Web上取得绝对增益。",
    "tags": [
      "LLM",
      "Risk Management",
      "Execution"
    ],
    "key_contributions": [
      "提出WAC智能体框架，整合模型协作、结果模拟与反馈驱动的动作优化，解决现有Web智能体环境变化预测不足、风险意识弱的问题",
      "引入多智能体协作机制（动作模型咨询世界模型）和两阶段推理链（世界模型模拟+法官模型审查修正），提升任务执行鲁棒性，在两个基准数据集上取得显著性能增益"
    ],
    "processed_at": "2026-02-18T09:01:07.536723"
  },
  {
    "id": "2602.15379v1",
    "title": "FlashMem: Supporting Modern DNN Workloads on Mobile with GPU Memory Hierarchy Optimizations",
    "abstract": "The increasing size and complexity of modern deep neural networks (DNNs) pose significant challenges for on-device inference on mobile GPUs, with limited memory and computational resources. Existing DNN acceleration frameworks primarily deploy a weight preloading strategy, where all model parameters are loaded into memory before execution on mobile GPUs. We posit that this approach is not adequate for modern DNN workloads that comprise very large model(s) and possibly execution of several distinct models in succession. In this work, we introduce FlashMem, a memory streaming framework designed to efficiently execute large-scale modern DNNs and multi-DNN workloads while minimizing memory consumption and reducing inference latency. Instead of fully preloading weights, FlashMem statically determines model loading schedules and dynamically streams them on demand, leveraging 2.5D texture memory to minimize data transformations and improve execution efficiency. Experimental results on 11 models demonstrate that FlashMem achieves 2.0x to 8.4x memory reduction and 1.7x to 75.0x speedup compared to existing frameworks, enabling efficient execution of large-scale models and multi-DNN support on resource-constrained mobile GPUs.",
    "authors": [
      "Zhihao Shu",
      "Md Musfiqur Rahman Sanim",
      "Hangyu Zheng",
      "Kunxiong Zhu",
      "Miao Yin",
      "Gagan Agrawal",
      "Wei Niu"
    ],
    "published": "2026-02-17",
    "categories": [
      "cs.DC",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15379v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15379v1",
    "fetched_at": "2026-02-18T08:53:05.924976",
    "chinese_title": "FlashMem：通过GPU内存层次优化支持移动设备上的现代DNN工作负载",
    "chinese_summary": "针对移动GPU内存与计算资源有限导致现代DNN难以高效推理的问题，提出FlashMem内存流框架，采用静态调度结合动态按需流加载权重（替代全预加载），并利用2.5D纹理内存减少数据转换；实验显示其内存减少2.0x-8.4x、速度提升1.7x-75.0x，支持大规模及多DNN工作负载。",
    "tags": [
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出FlashMem内存流框架，以静态调度+动态按需流加载替代传统全预加载权重策略，适配移动GPU资源限制",
      "利用2.5D纹理内存优化数据转换效率，实验验证内存与推理延迟显著优化，支持大规模和多DNN工作负载"
    ],
    "processed_at": "2026-02-18T09:01:29.922320"
  },
  {
    "id": "2602.15337v1",
    "title": "FedPSA: Modeling Behavioral Staleness in Asynchronous Federated Learning",
    "abstract": "Asynchronous Federated Learning (AFL) has emerged as a significant research area in recent years. By not waiting for slower clients and executing the training process concurrently, it achieves faster training speed compared to traditional federated learning. However, due to the staleness introduced by the asynchronous process, its performance may degrade in some scenarios. Existing methods often use the round difference between the current model and the global model as the sole measure of staleness, which is coarse-grained and lacks observation of the model itself, thereby limiting the performance ceiling of asynchronous methods. In this paper, we propose FedPSA (Parameter Sensitivity-based Asynchronous Federated Learning), a more fine-grained AFL framework that leverages parameter sensitivity to measure model obsolescence and establishes a dynamic momentum queue to assess the current training phase in real time, thereby adjusting the tolerance for outdated information dynamically. Extensive experiments on multiple datasets and comparisons with various methods demonstrate the superior performance of FedPSA, achieving up to 6.37\\% improvement over baseline methods and 1.93\\% over the current state-of-the-art method.",
    "authors": [
      "Chaoyi Lu"
    ],
    "published": "2026-02-17",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15337v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15337v1",
    "fetched_at": "2026-02-18T08:53:05.924993",
    "chinese_title": "FedPSA：异步联邦学习中的行为陈旧性建模",
    "chinese_summary": "针对异步联邦学习（AFL）因陈旧性导致性能下降且现有方法仅以轮次差度量陈旧性过于粗糙的问题，本文提出FedPSA框架，利用参数敏感性度量模型过时性并建立动态动量队列实时评估训练阶段以动态调整过时信息容忍度；实验表明该方法性能优于基线及当前最优方法。",
    "tags": [
      "Deep Learning"
    ],
    "key_contributions": [
      "提出基于参数敏感性的细粒度模型过时性度量方法，弥补现有仅用轮次差度量的粗糙性不足",
      "构建动态动量队列实时感知训练阶段，实现过时信息容忍度的动态调整，提升AFL性能"
    ],
    "processed_at": "2026-02-18T09:01:50.175881"
  },
  {
    "id": "2602.15286v1",
    "title": "AI-Paging: Lease-Based Execution Anchoring for Network-Exposed AI-as-a-Service",
    "abstract": "With AI-as-a-Service (AIaaS) now deployed across multiple providers and model tiers, selecting the appropriate model instance at run time is increasingly outside the end user's knowledge and operational control. Accordingly, the 6G service providers are envisioned to play a crucial role in exposing AIaaS in a setting where users submit only an intent while the network helps in the intent-to-model matching (resolution) and execution placement under policy, trust, and Quality of Service (QoS) constraints. The network role becomes to discover candidate execution endpoints and selects a suitable model/anchor under policy and QoS constraints in a process referred here to as AI-paging (by analogy to cellular call paging). In the proposed architecture, AI-paging is a control-plane transaction that resolves an intent into an AI service identity (AISI), a scoped session token (AIST), and an expiring admission lease (COMMIT) that authorizes user-plane steering to a selected AI execution anchor (AEXF) under a QoS binding. AI-Paging enforces two invariants: (i) lease-gated steering (without COMMIT, no steering state is installed) and (ii) make-before-break anchoring to support continuity and reliability of AIaaS services under dynamic network conditions. We prototype AI-Paging using existing control- and user-plane mechanisms (service-based control, QoS flows, and policy-based steering) with no new packet headers, ensuring compatibility with existing 3GPP-based exposure and management architectures, and evaluate transaction latency, relocation interruption, enforcement correctness under lease expiry, and audit-evidence overhead under mobility and failures.",
    "authors": [
      "Merve Saimler",
      "Mohaned Chraiti"
    ],
    "published": "2026-02-17",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15286v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15286v1",
    "fetched_at": "2026-02-18T08:53:05.925040",
    "chinese_title": "AI寻呼：面向网络暴露型AI即服务的基于租约的执行锚定",
    "chinese_summary": "本文针对AI即服务（AIaaS）跨多提供商与模型层级部署下用户难以选择合适模型实例的问题，提出AI寻呼架构——一种控制平面事务，通过解析用户意图生成AI服务身份、会话令牌和过期准入租约，授权用户平面转向符合策略与QoS约束的AI执行锚点；并实现租约门控转向和先建后断锚定两个不变式，确保服务连续性与可靠性，且原型兼容现有3GPP机制无新包头。",
    "tags": [
      "Execution",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出AI寻呼架构，作为控制平面事务实现用户意图到AI服务身份、会话令牌及过期准入租约的解析，授权符合策略与QoS约束的AI执行锚点转向",
      "实现租约门控转向和先建后断锚定两个不变式，确保动态网络下AIaaS服务连续性与可靠性，且原型兼容现有3GPP机制无新包头"
    ],
    "processed_at": "2026-02-18T09:02:14.316802"
  },
  {
    "id": "2602.15197v1",
    "title": "OpaqueToolsBench: Learning Nuances of Tool Behavior Through Interaction",
    "abstract": "Tool-calling is essential for Large Language Model (LLM) agents to complete real-world tasks. While most existing benchmarks assume simple, perfectly documented tools, real-world tools (e.g., general \"search\" APIs) are often opaque, lacking clear best practices or failure modes. Can LLM agents improve their performance in environments with opaque tools by interacting and subsequently improving documentation? To study this, we create OpaqueToolsBench, a benchmark consisting of three distinct task-oriented environments: general function calling, interactive chess playing, and long-trajectory agentic search. Each environment provides underspecified tools that models must learn to use effectively to complete the task. Results on OpaqueToolsBench suggest existing methods for automatically documenting tools are expensive and unreliable when tools are opaque. To address this, we propose a simple framework, ToolObserver, that iteratively refines tool documentation by observing execution feedback from tool-calling trajectories. Our approach outperforms existing methods on OpaqueToolsBench across datasets, even in relatively hard settings. Furthermore, for test-time tool exploration settings, our method is also efficient, consuming 3.5-7.5x fewer total tokens than the best baseline.",
    "authors": [
      "Skyler Hallinan",
      "Thejas Venkatesh",
      "Xiang Ren",
      "Sai Praneeth Karimireddy",
      "Ashwin Paranjape",
      "Yuhao Zhang",
      "Jack Hessel"
    ],
    "published": "2026-02-16",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15197v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15197v1",
    "fetched_at": "2026-02-18T08:53:05.925066",
    "chinese_title": "OpaqueToolsBench：通过交互学习工具行为的细微差别",
    "chinese_summary": "针对现有工具调用基准多假设简单明确工具、忽略现实工具不透明性的问题，论文构建了包含三个任务环境的OpaqueToolsBench基准；提出ToolObserver框架，通过观察工具调用轨迹的执行反馈迭代优化工具文档，在该基准上优于现有方法，且测试时探索效率更高（token消耗减少3.5-7.5倍）。",
    "tags": [
      "LLM",
      "Benchmark",
      "NLP"
    ],
    "key_contributions": [
      "构建OpaqueToolsBench基准，包含三个使用不透明工具的任务导向环境，填补现实工具不透明性的基准空白",
      "提出ToolObserver框架，通过迭代观察工具调用轨迹的执行反馈优化工具文档，提升性能且降低测试时token消耗"
    ],
    "processed_at": "2026-02-18T09:02:34.714683"
  },
  {
    "id": "2602.15146v1",
    "title": "Beyond Reinforcement Learning: Fast and Scalable Quantum Circuit Synthesis",
    "abstract": "Quantum unitary synthesis addresses the problem of translating abstract quantum algorithms into sequences of hardware-executable quantum gates. Solving this task exactly is infeasible in general due to the exponential growth of the underlying combinatorial search space. Existing approaches suffer from misaligned optimization objectives, substantial training costs and limited generalization across different qubit counts. We mitigate these limitations by using supervised learning to approximate the minimum description length of residual unitaries and combining this estimate with stochastic beam search to identify near optimal gate sequences. Our method relies on a lightweight model with zero-shot generalization, substantially reducing training overhead compared to prior baselines. Across multiple benchmarks, we achieve faster wall-clock synthesis times while exceeding state-of-the-art methods in terms of success rate for complex circuits.",
    "authors": [
      "Lukas Theissinger",
      "Thore Gerlach",
      "David Berghaus",
      "Christian Bauckhage"
    ],
    "published": "2026-02-16",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15146v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15146v1",
    "fetched_at": "2026-02-18T08:53:05.925089",
    "chinese_title": "超越强化学习：快速可扩展的量子电路合成",
    "chinese_summary": "该论文针对量子酉合成问题（将抽象量子算法转化为硬件可执行量子门序列），提出用监督学习近似残差酉的最小描述长度，结合随机束搜索识别近优门序列的方法；该方法采用轻量模型实现零样本泛化，大幅降低训练开销，在多基准测试中比现有方法合成速度更快且复杂电路成功率更高。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "提出监督学习结合随机束搜索的量子电路合成方法，解决现有方法优化目标错位、训练成本高、泛化有限的问题",
      "采用轻量模型实现零样本泛化，大幅降低训练开销，在基准测试中合成速度更快且复杂电路成功率更高"
    ],
    "processed_at": "2026-02-18T09:02:50.861770"
  },
  {
    "id": "2602.15112v1",
    "title": "ResearchGym: Evaluating Language Model Agents on Real-World AI Research",
    "abstract": "We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses, run experiments, and attempt to surpass strong human baselines on the paper's metrics. In a controlled evaluation of an agent powered by GPT-5, we observe a sharp capability--reliability gap. The agent improves over the provided baselines from the repository in just 1 of 15 evaluations (6.7%) by 11.5%, and completes only 26.5% of sub-tasks on average. We identify recurring long-horizon failure modes, including impatience, poor time and resource management, overconfidence in weak hypotheses, difficulty coordinating parallel experiments, and hard limits from context length. Yet in a single run, the agent surpasses the solution of an ICML 2025 Spotlight task, indicating that frontier agents can occasionally reach state-of-the-art performance, but do so unreliably. We additionally evaluate proprietary agent scaffolds including Claude Code (Opus-4.5) and Codex (GPT-5.2) which display a similar gap. ResearchGym provides infrastructure for systematic evaluation and analysis of autonomous agents on closed-loop research.",
    "authors": [
      "Aniketh Garikaparthi",
      "Manasi Patwardhan",
      "Arman Cohan"
    ],
    "published": "2026-02-16",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.15112v1",
    "arxiv_url": "https://arxiv.org/abs/2602.15112v1",
    "fetched_at": "2026-02-18T08:53:05.925109",
    "chinese_title": "ResearchGym：在真实AI研究场景下评估语言模型智能体",
    "chinese_summary": "论文引入ResearchGym基准环境，复用ICML、ICLR、ACL顶会的5篇论文仓库（保留数据、评估工具、基线但隐藏提出方法），构建5个容器化任务环境（共39子任务）以评估AI智能体端到端研究能力；实验发现前沿LLM智能体存在能力-可靠性差距，偶尔能超SOTA但不可靠，并识别长程任务常见失败模式。",
    "tags": [
      "LLM",
      "Benchmark"
    ],
    "key_contributions": [
      "提出ResearchGym基准环境，基于顶会论文仓库构建5个容器化任务环境（含39子任务），支持AI智能体端到端研究能力的系统评估",
      "揭示前沿LLM智能体存在能力-可靠性差距，识别长程任务常见失败模式，发现其偶尔能达到SOTA但不可靠"
    ],
    "processed_at": "2026-02-18T09:03:07.374554"
  }
]