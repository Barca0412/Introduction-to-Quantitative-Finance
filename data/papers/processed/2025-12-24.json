[
  {
    "id": "2512.20515v1",
    "title": "Modeling Bank Systemic Risk of Emerging Markets under Geopolitical Shocks: Empirical Evidence from BRICS Countries",
    "abstract": "The growing economic influence of the BRICS nations requires risk models that capture complex, long-term dynamics. This paper introduces the Bank Risk Interlinkage with Dynamic Graph and Event Simulations (BRIDGES) framework, which analyzes systemic risk based on the level of information complexity (zero-order, first-order, and second-order). BRIDGES utilizes the Dynamic Time Warping (DTW) distance to construct a dynamic network for 551 BRICS banks based on their strategic similarity, using zero-order information such as annual balance sheet data from 2008 to 2024. It then employs first-order information, including trends in risk ratios, to detect shifts in banks' behavior. A Temporal Graph Neural Network (TGNN), as the core of BRIDGES, is deployed to learn network evolutions and detect second-order information, such as anomalous changes in the structural relationships of the bank network. To measure the impact of anomalous changes on network stability, BRIDGES performs Agent-Based Model (ABM) simulations to assess the banking system's resilience to internal financial failure and external geopolitical shocks at the individual country level and across BRICS nations. Simulation results show that the failure of the largest institutions causes more systemic damage than the failure of the financially vulnerable or dynamically anomalous ones, driven by powerful panic effects. Compared to this \"too big to fail\" scenario, a geopolitical shock with correlated country-wide propagation causes more destructive systemic damage, leading to a near-total systemic collapse. It suggests that the primary threats to BRICS financial stability are second-order panic and large-scale geopolitical shocks, which traditional risk analysis models might not detect.",
    "authors": [
      "Haibo Wang"
    ],
    "published": "2025-12-23",
    "categories": [
      "q-fin.CP",
      "econ.EM",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20515v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20515v1",
    "fetched_at": "2025-12-24T08:34:25.218918",
    "chinese_title": "地缘政治冲击下新兴市场银行系统性风险建模：来自金砖国家的实证证据",
    "chinese_summary": "本文提出BRIDGES框架，通过动态时间规整（DTW）构建金砖国家银行动态网络，结合时序图神经网络（TGNN）学习网络演化、基于主体模型（ABM）模拟冲击，分析地缘政治冲击下的银行系统性风险；实证发现大型机构失败的恐慌效应导致的系统性损害更显著，地缘政治冲击的跨国关联传播也有重要影响。",
    "tags": [
      "Risk Management",
      "Graph Neural Network",
      "Anomaly",
      "Financial Agent"
    ],
    "key_contributions": [
      "提出整合多阶信息（零阶资产负债表、一阶风险趋势、二阶网络结构异常）的BRIDGES框架，结合动态网络构建、TGNN及ABM模拟，全面量化地缘政治冲击下的银行系统性风险",
      "实证揭示金砖国家中“太大而不能倒”机构失败的恐慌效应及地缘政治冲击跨国关联传播对系统性风险的影响规律"
    ],
    "processed_at": "2025-12-24T08:37:36.711730"
  },
  {
    "id": "2512.20477v1",
    "title": "Switching between states and the COVID-19 turbulence",
    "abstract": "In Aarab (2020), I examine U.S. stock return predictability across economic regimes and document evidence of time-varying expected returns across market states in the long run. The analysis introduces a state-switching specification in which the market state is proxied by the slope of the yield curve, and proposes an Aligned Economic Index built from the popular predictors of Welch and Goyal (2008) (augmented with bond and equity premium measures). The Aligned Economic Index under the state-switching model exhibits statistically and economically meaningful in-sample ($R^2 = 5.9\\%$) and out-of-sample ($R^2_{\\text{oos}} = 4.12\\%$) predictive power across both recessions and expansions, while outperforming a range of widely used predictors. In this work, I examine the added value for professional practitioners by computing the economic gains for a mean-variance investor and find substantial added benefit of using the new index under the state switching model across all market states. The Aligned Economic Index can thus be implemented on a consistent real-time basis. These findings are crucial for both academics and practitioners as expansions are much longer-lived than recessions. Finally, I extend the empirical exercises by incorporating data through September 2020 and document sizable gains from using the Aligned Economic Index, relative to more traditional approaches, during the COVID-19 market turbulence.",
    "authors": [
      "Ilias Aarab"
    ],
    "published": "2025-12-23",
    "categories": [
      "q-fin.ST",
      "q-fin.PM",
      "q-fin.RM",
      "stat.AP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20477v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20477v1",
    "fetched_at": "2025-12-24T08:34:25.218954",
    "chinese_title": "状态切换与新冠疫情市场动荡",
    "chinese_summary": "论文引入以收益率曲线斜率代理市场状态的状态切换模型，基于Welch和Goyal（2008）预测因子并补充债券与股权溢价构建对齐经济指数；该指数样本内外预测力显著（样本内R²=5.9%，样本外R²_oos=4.12%），优于传统预测因子，且新冠动荡期间能为均值方差投资者带来显著经济收益，可实时实施。",
    "tags": [
      "Asset Pricing",
      "Time Series",
      "Portfolio Optimization",
      "Volatility"
    ],
    "key_contributions": [
      "构建基于状态切换模型的对齐经济指数，样本内外预测力显著且优于传统预测因子，可实时实施",
      "验证该指数在新冠疫情市场动荡期间能为均值方差投资者带来显著经济收益，补充2020年9月前数据"
    ],
    "processed_at": "2025-12-24T08:37:54.992702"
  },
  {
    "id": "2512.20460v1",
    "title": "The Aligned Economic Index & The State Switching Model",
    "abstract": "A growing empirical literature suggests that equity-premium predictability is state dependent, with much of the forecasting power concentrated around recessionary periods \\parencite{Henkel2011,DanglHalling2012,Devpura2018}. I study U.S. stock return predictability across economic regimes and document strong evidence of time-varying expected returns across both expansionary and contractionary states. I contribute in two ways. First, I introduce a state-switching predictive regression in which the market state is defined in real time using the slope of the yield curve. Relative to the standard one-state predictive regression, the state-switching specification increases both in-sample and out-of-sample performance for the set of popular predictors considered by \\textcite{WelchGoyal2008}, improving the out-of-sample performance of most predictors in economically meaningful ways. Second, I propose a new aggregate predictor, the Aligned Economic Index, constructed via partial least squares (PLS). Under the state-switching model, the Aligned Economic Index exhibits statistically and economically significant predictive power in sample and out of sample, and it outperforms widely used benchmark predictors and alternative predictor-combination methods.",
    "authors": [
      "Ilias Aarab"
    ],
    "published": "2025-12-23",
    "categories": [
      "q-fin.ST",
      "cs.LG",
      "econ.EM",
      "q-fin.PM",
      "stat.AP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20460v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20460v1",
    "fetched_at": "2025-12-24T08:34:25.218979",
    "chinese_title": "对齐经济指数与状态切换模型",
    "chinese_summary": "本文研究美国股票收益的状态依赖可预测性，提出用收益率曲线斜率实时定义市场状态的状态切换预测回归，提升样本内外预测表现；同时通过偏最小二乘（PLS）构建对齐经济指数，该指数在状态切换模型下的样本内外预测能力显著优于常用基准和预测组合方法。",
    "tags": [
      "Asset Pricing",
      "Time Series",
      "Factor Mining",
      "Benchmark"
    ],
    "key_contributions": [
      "提出基于收益率曲线斜率实时定义状态的状态切换预测回归，提升样本内外预测表现",
      "通过偏最小二乘构建对齐经济指数，在状态切换模型下样本内外预测能力显著优于基准及其他预测组合方法"
    ],
    "processed_at": "2025-12-24T08:38:08.763796"
  },
  {
    "id": "2512.20216v1",
    "title": "Quantitative Financial Modeling for Sri Lankan Markets: Approach Combining NLP, Clustering and Time-Series Forecasting",
    "abstract": "This research introduces a novel quantitative methodology tailored for quantitative finance applications, enabling banks, stockbrokers, and investors to predict economic regimes and market signals in emerging markets, specifically Sri Lankan stock indices (S&P SL20 and ASPI) by integrating Environmental, Social, and Governance (ESG) sentiment analysis with macroeconomic indicators and advanced time-series forecasting. Designed to leverage quantitative techniques for enhanced risk assessment, portfolio optimization, and trading strategies in volatile environments, the architecture employs FinBERT, a transformer-based NLP model, to extract sentiment from ESG texts, followed by unsupervised clustering (UMAP/HDBSCAN) to identify 5 latent ESG regimes, validated via PCA. These regimes are mapped to economic conditions using a dense neural network and gradient boosting classifier, achieving 84.04% training and 82.0% validation accuracy. Concurrently, time-series models (SRNN, MLP, LSTM, GRU) forecast daily closing prices, with GRU attaining an R-squared of 0.801 and LSTM delivering 52.78% directional accuracy on intraday data. A strong correlation between S&P SL20 and S&P 500, observed through moving average and volatility trend plots, further bolsters forecasting precision. A rule-based fusion logic merges ESG and time-series outputs for final market signals. By addressing literature gaps that overlook emerging markets and holistic integration, this quant-driven framework combines global correlations and local sentiment analysis to offer scalable, accurate tools for quantitative finance professionals navigating complex markets like Sri Lanka.",
    "authors": [
      "Linuk Perera"
    ],
    "published": "2025-12-23",
    "categories": [
      "q-fin.CP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20216v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20216v1",
    "fetched_at": "2025-12-24T08:34:25.219000",
    "chinese_title": "斯里兰卡市场的量化金融建模：结合NLP、聚类与时序预测的方法",
    "chinese_summary": "该研究针对斯里兰卡新兴市场（S&P SL20和ASPI指数），提出整合ESG情感分析、宏观经济指标与时序预测的量化框架：用FinBERT提取ESG文本情感，UMAP/HDBSCAN聚类识别5个潜在ESG regime（经PCA验证），再通过DNN和梯度提升分类器映射到经济状况（训练/验证准确率84.04%/82.0%）；同时比较SRNN、MLP、LSTM、GRU等时序模型，GRU获0.801的R²，LSTM日内方向准确率52.78%，最终规则融合ESG和时序输出得到市场信号，填补了新兴市场量化建模的文献缺口。",
    "tags": [
      "NLP",
      "Sentiment Analysis",
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "提出针对斯里兰卡新兴市场的量化框架，整合ESG情感分析（FinBERT）、聚类（UMAP/HDBSCAN）与时序预测（GRU/LSTM等），填补新兴市场量化建模的文献缺口",
      "实现ESG regime与经济状况的有效映射（84%+准确率），并通过规则融合ESG和时序输出提升市场信号预测精度"
    ],
    "processed_at": "2025-12-24T08:38:32.446264"
  },
  {
    "id": "2512.20190v1",
    "title": "Pricing of wrapped Bitcoin and Ethereum on-chain options",
    "abstract": "This paper measures price differences between Hegic option quotes on Arbitrum and a model-based benchmark built on Black--Scholes model with regime-sensitive volatility estimated via a two-regime MS-AR-(GJR)-GARCH model. Using option-level feasible GLS, we find benchmark prices exceed Hegic quotes on average, especially for call options. The price spread rises with order size, strike, maturity, and estimated volatility, and falls with trading volume. By underlying, wrapped Bitcoin options show larger and more persistent spreads, while Ethereum options are closer to the benchmark. The framework offers a data-driven analysis for monitoring and calibrating on-chain option pricing logic.",
    "authors": [
      "Anastasiia Zbandut"
    ],
    "published": "2025-12-23",
    "categories": [
      "q-fin.PR",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20190v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20190v1",
    "fetched_at": "2025-12-24T08:34:25.219019",
    "chinese_title": "Wrapped比特币与以太坊链上期权定价研究",
    "chinese_summary": "本文以含两状态MS-AR-(GJR)-GARCH估计的 regime-sensitive波动率的Black-Scholes模型为基准，对比Arbitrum上Hegic期权报价，发现基准价平均高于Hegic报价（尤其看涨期权）；价差随订单量、行权价、到期日、波动率上升，随交易量下降，且Wrapped比特币期权价差更大更持久，以太坊更接近基准。",
    "tags": [
      "Asset Pricing",
      "Options",
      "Volatility",
      "Benchmark"
    ],
    "key_contributions": [
      "构建基于两状态MS-AR-(GJR)-GARCH波动率的Black-Scholes基准模型，揭示链上期权（Hegic）与基准的价差特征及影响因素",
      "提出可用于链上期权定价监控与校准的数据驱动分析框架，对比Wrapped比特币与以太坊期权的价差差异"
    ],
    "processed_at": "2025-12-24T08:38:44.419307"
  },
  {
    "id": "2512.20027v1",
    "title": "GIFfluence: A Visual Approach to Investor Sentiment and the Stock Market",
    "abstract": "We study dynamic visual representations as a proxy for investor sentiment about the stock market. Our sentiment index, GIFsentiment, is constructed from millions of posts in the Graphics Interchange Format (GIF) on a leading investment social media platform. GIFsentiment correlates with seasonal mood variations and the severity of COVID lockdowns. It is positively associated with contemporaneous market returns and negatively predicts returns for up to four weeks, even after controlling for other sentiment and attention measures. These effects are stronger among portfolios that are more susceptible to mispricing. GIFsentiment positively predicts trading volume, market volatility, and flows toward equity funds and away from debt funds. Our evidence suggests that GIFsentiment is a proxy for misperceptions that are later corrected.",
    "authors": [
      "Ming Gu",
      "David Hirshleifer",
      "Siew Hong Teoh",
      "Shijia Wu"
    ],
    "published": "2025-12-23",
    "categories": [
      "q-fin.PR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20027v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20027v1",
    "fetched_at": "2025-12-24T08:34:25.219043",
    "chinese_title": "GIFfluence：投资者情绪与股市的可视化方法",
    "chinese_summary": "论文提出基于投资社交平台数百万GIF构建投资者情绪指数GIFsentiment，验证其与季节情绪、新冠封锁严重程度相关；发现该指数与同期市场收益正相关、负预测未来四周收益（控制其他指标后仍显著），且对易误定价组合影响更强，还能预测交易量、波动率及资金流向，表明其反映后期纠正的认知偏差。",
    "tags": [
      "Investor Sentiment",
      "Behavioral Finance",
      "Asset Pricing",
      "Volatility"
    ],
    "key_contributions": [
      "提出基于社交平台GIF的投资者情绪指数GIFsentiment，验证其与市场情绪相关因素的关联",
      "揭示GIFsentiment对市场收益、交易量、波动率及资金流向的预测作用，且对易误定价组合影响更强，反映可纠正的认知偏差"
    ],
    "processed_at": "2025-12-24T08:38:53.673219"
  },
  {
    "id": "2512.19986v1",
    "title": "Covariance-Aware Simplex Projection for Cardinality-Constrained Portfolio Optimization",
    "abstract": "Metaheuristic algorithms for cardinality-constrained portfolio optimization require repair operators to map infeasible candidates onto the feasible region. Standard Euclidean projection treats assets as independent and can ignore the covariance structure that governs portfolio risk, potentially producing less diversified portfolios. This paper introduces Covariance-Aware Simplex Projection (CASP), a two-stage repair operator that (i) selects a target number of assets using volatility-normalized scores and (ii) projects the candidate weights using a covariance-aware geometry aligned with tracking-error risk. This provides a portfolio-theoretic foundation for using a covariance-induced distance in repair operators. On S&P 500 data (2020-2024), CASP-Basic delivers materially lower portfolio variance than standard Euclidean repair without relying on return estimates, with improvements that are robust across assets and statistically significant. Ablation results indicate that volatility-normalized selection drives most of the variance reduction, while the covariance-aware projection provides an additional, consistent improvement. We further show that optional return-aware extensions can improve Sharpe ratios, and out-of-sample tests confirm that gains transfer to realized performance. CASP integrates as a drop-in replacement for Euclidean projection in metaheuristic portfolio optimizers.",
    "authors": [
      "Nikolaos Iliopoulos"
    ],
    "published": "2025-12-23",
    "categories": [
      "q-fin.PM",
      "cs.LG",
      "cs.NE",
      "q-fin.CP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.19986v1",
    "arxiv_url": "https://arxiv.org/abs/2512.19986v1",
    "fetched_at": "2025-12-24T08:34:25.219062",
    "chinese_title": "考虑协方差的单纯形投影在基数约束投资组合优化中的应用",
    "chinese_summary": "论文针对基数约束投资组合优化中启发式算法的修复算子问题，提出考虑协方差的单纯形投影（CASP），通过波动率归一化选资产、协方差感知几何投影权重，相比标准欧氏投影显著降低组合方差且不依赖收益估计；CASP可作为启发式优化器中欧氏投影的替代，样本外表现稳健，可选扩展能提升夏普比。",
    "tags": [
      "Portfolio Optimization",
      "Risk Management",
      "Volatility"
    ],
    "key_contributions": [
      "验证CASP可无缝替代启发式优化器中的欧氏投影，不依赖收益估计且收益可转移至样本外，可选扩展提升夏普比"
    ],
    "processed_at": "2025-12-24T08:39:06.124677"
  },
  {
    "id": "2512.19838v1",
    "title": "Equilibrium Liquidity and Risk Offsetting in Decentralised Markets",
    "abstract": "We develop an economic model of decentralised exchanges (DEXs) in which risk-averse liquidity providers (LPs) manage risk in a centralised exchange (CEX) based on preferences, information, and trading costs. Rational, risk-averse LPs anticipate the frictions associated with replication and manage risk primarily by reducing the reserves supplied to the DEX. Greater aversion reduces the equilibrium viability of liquidity provision, resulting in thinner markets and lower trading volumes. Greater uninformed demand supports deeper liquidity, whereas higher fundamental price volatility erodes it. Finally, while moderate anticipated price changes can improve LP performance, larger changes require more intensive trading in the CEX, generate higher replication costs, and induce LPs to reduce liquidity supply.",
    "authors": [
      "Fayçal Drissi",
      "Xuchen Wu",
      "Sebastian Jaimungal"
    ],
    "published": "2025-12-22",
    "categories": [
      "q-fin.TR",
      "q-fin.GN",
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.19838v1",
    "arxiv_url": "https://arxiv.org/abs/2512.19838v1",
    "fetched_at": "2025-12-24T08:34:25.219084",
    "chinese_title": "去中心化市场中的均衡流动性与风险对冲",
    "chinese_summary": "本文构建了去中心化交易所（DEX）的经济模型，刻画风险厌恶的流动性提供者（LP）基于偏好、信息与交易成本在中心化交易所（CEX）管理风险的行为；分析发现，风险厌恶增强会降低流动性供给均衡可行性，非知情需求提升、基础价格波动加剧分别促进/侵蚀流动性，适度预期价格变化可改善LP表现但大幅变化会增加CEX交易成本并减少流动性供给。",
    "tags": [
      "Market Microstructure",
      "Risk Management",
      "Volatility",
      "Market Making"
    ],
    "key_contributions": [
      "构建整合DEX与CEX的经济模型，刻画风险厌恶LP的风险对冲行为及影响因素",
      "揭示风险厌恶、非知情需求、价格波动等对DEX均衡流动性的作用机制"
    ],
    "processed_at": "2025-12-24T08:39:16.891200"
  },
  {
    "id": "2512.19821v1",
    "title": "How to choose my stochastic volatility parameters? A review",
    "abstract": "Based on the existing literature, this article presents the different ways of choosing the parameters of stochastic volatility models in general, in the context of pricing financial derivative contracts. This includes the use of stochastic volatility inside stochastic local volatility models.",
    "authors": [
      "Fabien Le Floc'h"
    ],
    "published": "2025-12-22",
    "categories": [
      "q-fin.PR",
      "q-fin.CP",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.19821v1",
    "arxiv_url": "https://arxiv.org/abs/2512.19821v1",
    "fetched_at": "2025-12-24T08:34:25.219102",
    "chinese_title": "如何选择随机波动率参数？一篇综述",
    "chinese_summary": "论文基于现有文献，综述了金融衍生品定价场景下随机波动率模型参数选择的各类方法；同时涵盖了随机局部波动率模型中随机波动率参数的选择问题。",
    "tags": [
      "Volatility",
      "Options",
      "Asset Pricing",
      "Benchmark"
    ],
    "key_contributions": [
      "系统综述金融衍生品定价中随机波动率模型的参数选择方法",
      "涵盖随机局部波动率模型内随机波动率参数的选择问题"
    ],
    "processed_at": "2025-12-24T08:39:29.227970"
  },
  {
    "id": "2512.19625v1",
    "title": "Counterexamples for FX Options Interpolations -- Part II",
    "abstract": "This follow-up article analyzes the impact of foreign exchange option interpolation on the vanilla option implied volatilities. In particular different exact interpolations of broker quotes may lead to different implied volatilities at the 10$Δ$ and 25$Δ$ Puts and Calls.",
    "authors": [
      "Jherek Healy"
    ],
    "published": "2025-12-22",
    "categories": [
      "q-fin.PR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.19625v1",
    "arxiv_url": "https://arxiv.org/abs/2512.19625v1",
    "fetched_at": "2025-12-24T08:34:25.219120",
    "chinese_title": "外汇期权插值的反例——第二部分",
    "chinese_summary": "这是一篇续篇论文，分析外汇期权插值对普通期权隐含波动率的影响；研究发现不同经纪商报价的精确插值方式会导致10Δ和25Δ看跌/看涨期权的隐含波动率存在差异。",
    "tags": [
      "Options",
      "Volatility",
      "Market Microstructure",
      "Asset Pricing"
    ],
    "key_contributions": [
      "明确分析外汇期权插值对普通期权隐含波动率的影响",
      "揭示不同经纪商报价插值方式会导致特定Δ值期权隐含波动率差异"
    ],
    "processed_at": "2025-12-24T08:39:41.575722"
  },
  {
    "id": "2512.19621v1",
    "title": "Counterexamples for FX Options Interpolations -- Part I",
    "abstract": "This article provides a list of counterexamples, where some of the popular fx option interpolations break down. Interpolation of FX option prices (or equivalently volatilities), is key to risk-manage not only vanilla FX option books, but also more exotic derivatives which are typically valued with local volatility or local stochastic volatilility models.",
    "authors": [
      "Jherek Healy"
    ],
    "published": "2025-12-22",
    "categories": [
      "q-fin.PR",
      "q-fin.CP",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.19621v1",
    "arxiv_url": "https://arxiv.org/abs/2512.19621v1",
    "fetched_at": "2025-12-24T08:34:25.219142",
    "chinese_title": "外汇期权插值的反例——第一部分",
    "chinese_summary": "论文第一部分提供了若干流行外汇期权插值方法失效的反例；指出外汇期权价格（或等价波动率）插值是管理普通及奇异外汇期权组合风险的关键环节。",
    "tags": [
      "Options",
      "Volatility",
      "Risk Management"
    ],
    "key_contributions": [
      "提供流行外汇期权插值方法失效的反例",
      "强调外汇期权插值对期权组合风险管理的重要性"
    ],
    "processed_at": "2025-12-24T08:39:49.854161"
  },
  {
    "id": "2512.19611v1",
    "title": "Heston vol-of-vol and the VVIX",
    "abstract": "The Heston stochastic volatility model is arguably, the most popular stochastic volatility model used to price and risk manage exotic derivatives. In spite of this, it is not necessarily easy to calibrate to the market and obtain stable exotic option prices with this model. This paper focuses on the vol-of-vol parameter and its relation with the volatility of volatility index (VVIX) level. Four different approaches to estimate the VVIX in the Heston model are presented: two based on the known transition density of the variance, one analytical approximation, and one based on the Heston PDE which computes the value directly out of the underlying SPX500. Finally we explore their use to improve calibration stability.",
    "authors": [
      "Jherek Healy"
    ],
    "published": "2025-12-22",
    "categories": [
      "q-fin.PR",
      "q-fin.CP",
      "q-fin.MF",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.19611v1",
    "arxiv_url": "https://arxiv.org/abs/2512.19611v1",
    "fetched_at": "2025-12-24T08:34:25.219160",
    "chinese_title": "Heston波动率的波动率与VVIX指数",
    "chinese_summary": "该文聚焦Heston随机波动率模型的波动率的波动率（vol-of-vol）参数与VVIX指数的关联，提出四种估计Heston模型中VVIX的方法（含两种基于方差转移密度、一种解析近似及一种基于Heston PDE的方法），并探索这些方法对提升模型校准稳定性的作用。",
    "tags": [
      "Volatility",
      "Options",
      "Risk Management"
    ],
    "key_contributions": [
      "揭示Heston模型vol-of-vol参数与VVIX指数的关联，提出四种估计Heston模型中VVIX的方法",
      "探索上述方法对提升Heston模型校准稳定性的作用"
    ],
    "processed_at": "2025-12-24T08:40:04.505802"
  },
  {
    "id": "2512.19251v1",
    "title": "Institutional Backing and Crypto Volatility: A Hybrid Framework for DeFi Stabilization",
    "abstract": "Decentralized finance (DeFi) lacks centralized oversight, often resulting in heightened volatility. In contrast, centralized finance (CeFi) offers a more stable environment with institutional safeguards. Institutional backing can play a stabilizing role in a hybrid structure (HyFi), enhancing transparency, governance, and market discipline. This study investigates whether HyFi-like cryptocurrencies, those backed by institutions, exhibit lower price risk than fully decentralized counterparts. Using daily data for 18 major cryptocurrencies from January 2020 to November 2024, we estimate panel EGLS models with fixed, random, and dynamic specifications. Results show that HyFi-like assets consistently experience lower price risk, with this effect intensifying during periods of elevated market volatility. The negative interaction between HyFi status and market-wide volatility confirms their stabilizing role. Conversely, greater decentralization is strongly associated with increased volatility, particularly during periods of market stress. Robustness checks using quantile regressions and pre-/post-Terra Luna subsamples reinforce these findings, with stronger effects observed in high-volatility quantiles and post-crisis conditions. These results highlight the importance of institutional architecture in enhancing the resilience of digital asset markets.",
    "authors": [
      "Ihlas Sovbetov"
    ],
    "published": "2025-12-22",
    "categories": [
      "q-fin.CP",
      "q-fin.RM",
      "q-fin.TR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.19251v1",
    "arxiv_url": "https://arxiv.org/abs/2512.19251v1",
    "fetched_at": "2025-12-24T08:34:25.219178",
    "chinese_title": "机构背书与加密货币波动性：DeFi稳定的混合框架",
    "chinese_summary": "本研究对比机构背书的混合结构（HyFi）加密货币与完全去中心化加密货币的价格风险，采用2020-2024年18种主要加密货币日度数据，通过面板EGLS（固定/随机/动态）及分位数回归等方法，发现HyFi资产波动性更低且高波动期效应更显著，凸显机构架构对数字资产韧性的作用。",
    "tags": [
      "Volatility",
      "Risk Management",
      "Asset Pricing",
      "Time Series"
    ],
    "key_contributions": [
      "验证机构背书的HyFi类加密货币比完全去中心化资产具有更低价格风险，且高波动期效应更显著",
      "通过分位数回归及Terra Luna危机前后样本等稳健性检验，强化机构架构对数字资产市场稳定性的关键结论"
    ],
    "processed_at": "2025-12-24T08:40:18.831706"
  },
  {
    "id": "2512.18918v1",
    "title": "Needles in a haystack: using forensic network science to uncover insider trading",
    "abstract": "Although the automation and digitisation of anti-financial crime investigation has made significant progress in recent years, detecting insider trading remains a unique challenge, partly due to the limited availability of labelled data. To address this challenge, we propose using a data-driven networks approach that flags groups of corporate insiders who report coordinated transactions that are indicative of insider trading. Specifically, we leverage data on 2.9 million trades reported to the U.S. Securities and Exchange Commission (SEC) by company insiders (C-suite executives, board members and major shareholders) between 2014 and 2024. Our proposed algorithm constructs weighted edges between insiders based on the temporal similarity of their trades over the 10-year timeframe. Within this network we then uncover trends that indicate insider trading by focusing on central nodes and anomalous subgraphs. To highlight the validity of our approach we evaluate our findings with reference to two null models, generated by running our algorithm on synthetic empirically calibrated and shuffled datasets. The results indicate that our approach can be used to detect pairs or clusters of insiders whose behaviour suggests insider trading and/or market manipulation.",
    "authors": [
      "Gian Jaeger",
      "Wang Ngai Yeung",
      "Renaud Lambiotte"
    ],
    "published": "2025-12-21",
    "categories": [
      "cs.SI",
      "physics.data-an",
      "q-fin.CP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.18918v1",
    "arxiv_url": "https://arxiv.org/abs/2512.18918v1",
    "fetched_at": "2025-12-24T08:34:25.219199",
    "chinese_title": "大海捞针：利用法医网络科学揭露内幕交易",
    "chinese_summary": "针对内幕交易检测中标签数据有限的挑战，本文提出数据驱动的网络方法，基于美国SEC 2014-2024年290万笔内幕交易数据，通过交易时间相似性构建加权网络，聚焦中心节点与异常子图识别协调交易的内幕人士群体；并利用经验校准和打乱的合成数据集生成空模型验证方法有效性，可检测涉嫌内幕交易/市场操纵的内幕人士对或集群。",
    "tags": [
      "Anomaly",
      "Behavioral Finance",
      "Risk Management"
    ],
    "key_contributions": [
      "提出基于网络科学的数据驱动方法，解决内幕交易检测中标签数据有限的问题，通过交易时间相似性构建内幕人士网络并识别异常子图/中心节点",
      "利用经验校准和打乱的合成数据集生成空模型验证方法有效性，可检测涉嫌内幕交易/市场操纵的内幕人士群体"
    ],
    "processed_at": "2025-12-24T08:40:40.109162"
  },
  {
    "id": "2512.18790v1",
    "title": "Optimal Catastrophe Risk Pooling",
    "abstract": "Catastrophe risk has long been recognized to pose a serious threat to the insurance sector. Although natural disasters such as flooding, hurricane or severe drought are rare events, they generally lead to devastating damages that traditional insurance schemes may not be able to efficiently cover. Catastrophe risk pooling is an effective way to diversify the losses from such risks. In this paper, we improve the catastrophe risk pool by Pareto-optimally allocating the diversification benefits among participants. Finding the practical Pareto-optimal pool entails solving a high-dimensional optimization problem, for which analytical solutions are typically unavailable and numerical methods can be computationally intensive and potentially unreliable. We propose evaluating the diversification benefits at the limit case and using it to approximate the optimal pool by deriving an asymptotic optimal pool. Simulation studies are undertaken to explore the implications of the results and an empirical analysis from the U.S. National Flood Insurance Program is also carried out to illustrate how this framework can be applied in practice.",
    "authors": [
      "Minh Chau Nguyen",
      "Tony S. Wirjanto",
      "Fan Yang"
    ],
    "published": "2025-12-21",
    "categories": [
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.18790v1",
    "arxiv_url": "https://arxiv.org/abs/2512.18790v1",
    "fetched_at": "2025-12-24T08:34:25.219220",
    "chinese_title": "最优巨灾风险汇集",
    "chinese_summary": "本文针对巨灾风险对保险行业的威胁及传统保险难以有效覆盖的问题，提出通过帕累托最优分配分散化收益改进巨灾风险池；因高维优化无解析解且数值方法不可靠，推导渐近最优池近似方法，并结合模拟与美国国家洪水保险计划实证验证框架实用性。",
    "tags": [
      "Risk Management"
    ],
    "key_contributions": [
      "提出通过帕累托最优分配分散化收益改进巨灾风险池，提升巨灾损失覆盖效率",
      "推导渐近最优池近似方法解决高维优化难题，并通过模拟与实证验证框架实用性"
    ],
    "processed_at": "2025-12-24T08:40:58.307037"
  },
  {
    "id": "2512.18648v1",
    "title": "Optimal Signal Extraction from Order Flow: A Matched Filter Perspective on Normalization and Market Microstructure",
    "abstract": "We demonstrate that the choice of normalization for order flow intensity is fundamental to signal extraction in finance, not merely a technical detail. Through theoretical modeling, Monte Carlo simulation, and empirical validation using Korean market data, we prove that market capitalization normalization acts as a ``matched filter'' for informed trading signals, achieving 1.32--1.97$\\times$ higher correlation with future returns compared to traditional trading value normalization. The key insight is that informed traders scale positions by firm value (market capitalization), while noise traders respond to daily liquidity (trading volume), creating heteroskedastic corruption when normalizing by trading volume. By reframing the normalization problem using signal processing theory, we show that dividing order flow by market capitalization preserves the information signal while traditional volume normalization multiplies the signal by inverse turnover -- a highly volatile quantity. Our theoretical predictions are robust across parameter specifications and validated by empirical evidence showing 482\\% improvement in explanatory power. These findings have immediate implications for high-frequency trading algorithms, risk factor construction, and information-based trading strategies.",
    "authors": [
      "Sungwoo Kang"
    ],
    "published": "2025-12-21",
    "categories": [
      "q-fin.CP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.18648v1",
    "arxiv_url": "https://arxiv.org/abs/2512.18648v1",
    "fetched_at": "2025-12-24T08:34:25.219236",
    "chinese_title": "订单流的最优信号提取：基于匹配滤波视角的标准化与市场微观结构",
    "chinese_summary": "论文指出订单流强度的标准化选择是金融信号提取的核心而非技术细节，通过理论建模、蒙特卡洛模拟及韩国市场数据验证，发现市值标准化是知情交易信号的“匹配滤波器”，比传统交易价值标准化与未来收益相关性高1.32-1.97倍，且能保留信息信号（传统成交量标准化放大噪声），解释力提升482%，对高频交易等策略有直接意义。",
    "tags": [
      "Market Microstructure",
      "High Frequency",
      "Algorithmic Trading",
      "Factor Mining"
    ],
    "key_contributions": [
      "首次从信号处理匹配滤波视角证明市值标准化是知情交易信号的最优选择，优于传统交易价值/成交量标准化",
      "揭示知情交易者按市值 scaling、噪声按成交量响应的差异，解释传统标准化放大噪声的根源，实证验证解释力显著提升"
    ],
    "processed_at": "2025-12-24T08:41:09.645828"
  },
  {
    "id": "2512.17895v2",
    "title": "Visualization of The Content of Surah al Fiil using Marker-Based Augmented Reality",
    "abstract": "This study presents the development of a marker-based augmented reality (AR) application designed to visualize the content of Surah al-Fil as an interactive and context-rich medium for Islamic education. Using a research and development approach, the system was developed through structured stages including data collection, user requirement analysis, interface design, 3D asset creation using Blender, and integration of Unity 3D with the Vuforia SDK. The application features key visual elements such as the elephant army, the Kaaba, and the Ababil birds, which were modeled in detail and linked to high-contrast image markers to ensure accurate and stable AR tracking. Functional testing demonstrated strong technical performance, achieving a 95 percent marker detection accuracy at an optimal distance of 30-40 cm with consistent real-time rendering across multiple Android devices. User evaluations involving students and Islamic education teachers indicated high acceptance, with an overall satisfaction score of 4.7 out of 5 in terms of usability, visual appeal, interactivity, and learning effectiveness. These findings indicate that AR-based learning media can enhance learner engagement, deepen understanding of Quranic narratives, and provide immersive insights into historical and spiritual contexts. Overall, this study demonstrates that marker-based AR technology has significant potential to support innovation in digital Islamic education by enriching traditional learning with interactive and visually intuitive experiences.",
    "authors": [
      "Wisnu Uriawan",
      "Ahmad Badru Al Husaeni",
      "Dzakwanfaiq Nauval",
      "Farid Muhtar Fathir",
      "Mahesa Adlan Falah",
      "Muhammad Miftahur Rizki Awalin"
    ],
    "published": "2025-12-19",
    "categories": [
      "q-fin.CP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.17895v2",
    "arxiv_url": "https://arxiv.org/abs/2512.17895v2",
    "fetched_at": "2025-12-24T08:34:25.219262",
    "chinese_title": "基于标记的增强现实可视化《象章》内容的研究",
    "chinese_summary": "该研究采用研发方法，结合Unity 3D、Vuforia SDK及Blender建模，开发标记-based AR应用可视化《象章》关键元素；经测试标记检测准确率95%、用户满意度4.7/5，验证其提升伊斯兰教育互动性与学习效果的潜力。",
    "tags": [
      "Deep Learning"
    ],
    "key_contributions": [
      "开发整合3D建模与AR跟踪的标记-based应用，可视化《象章》核心场景（象军、克尔白等）",
      "通过技术与用户评估，证实AR技术可创新数字伊斯兰教育，增强学习互动性与效果"
    ],
    "processed_at": "2025-12-24T08:41:25.636606"
  },
  {
    "id": "2512.16251v2",
    "title": "Interpretable Deep Learning for Stock Returns: A Consensus-Bottleneck Asset Pricing Model",
    "abstract": "We introduce the Consensus-Bottleneck Asset Pricing Model (CB-APM), a partially interpretable neural network that replicates the reasoning processes of sell-side analysts by capturing how dispersed investor beliefs are compressed into asset prices through a consensus formation process. By modeling this \"bottleneck\" to summarize firm- and macro-level information, CB-APM not only predicts future risk premiums of U.S. equities but also links belief aggregation to expected returns in a structurally interpretable manner. The model improves long-horizon return forecasts and outperforms standard deep learning approaches in both predictive accuracy and explanatory power. Comprehensive portfolio analyses show that CB-APM's out-of-sample predictions translate into economically meaningful payoffs, with monotonic return differentials and stable long-short performance across regularization settings. Empirically, CB-APM leverages consensus as a regularizer to amplify long-horizon predictability and yields interpretable consensus-based components that clarify how information is priced in returns. Moreover, regression and Gibbons-Ross-Shanken (GRS)-based pricing diagnostics reveal that the learned consensus representations capture priced variation only partially spanned by traditional factor models, demonstrating that CB-APM uncovers belief-driven structure in expected returns beyond the canonical factor space. Overall, CB-APM provides an interpretable and empirically grounded framework for understanding belief-driven return dynamics.",
    "authors": [
      "Bong-Gyu Jang",
      "Younwoo Jeong",
      "Changeun Kim"
    ],
    "published": "2025-12-18",
    "categories": [
      "q-fin.PR",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.16251v2",
    "arxiv_url": "https://arxiv.org/abs/2512.16251v2",
    "fetched_at": "2025-12-24T08:34:25.219461",
    "chinese_title": "股票收益的可解释深度学习：共识瓶颈资产定价模型",
    "chinese_summary": "本文提出共识瓶颈资产定价模型（CB-APM），这是一种部分可解释神经网络，通过模拟卖方分析师推理捕捉投资者分散信念压缩为资产价格的共识形成过程；模型提升美国股票长期收益预测准确性，优于标准深度学习方法，其共识表征包含传统因子模型未覆盖的定价变异，投资组合分析显示预测具有经济意义。",
    "tags": [
      "Asset Pricing",
      "Deep Learning",
      "Behavioral Finance",
      "Factor Model"
    ],
    "key_contributions": [
      "提出CB-APM模型，通过共识瓶颈机制实现可解释的资产定价，模拟信念聚合与资产价格形成的关联",
      "实证验证模型提升长期收益预测能力，捕获传统因子未覆盖的定价变异，且投资组合表现具有经济意义"
    ],
    "processed_at": "2025-12-24T08:41:40.900698"
  },
  {
    "id": "2512.20432v1",
    "title": "High Dimensional Data Decomposition for Anomaly Detection of Textured Images",
    "abstract": "In the realm of diverse high-dimensional data, images play a significant role across various processes of manufacturing systems where efficient image anomaly detection has emerged as a core technology of utmost importance. However, when applied to textured defect images, conventional anomaly detection methods have limitations including non-negligible misidentification, low robustness, and excessive reliance on large-scale and structured datasets. This paper proposes a texture basis integrated smooth decomposition (TBSD) approach, which is targeted at efficient anomaly detection in textured images with smooth backgrounds and sparse anomalies. Mathematical formulation of quasi-periodicity and its theoretical properties are investigated for image texture estimation. TBSD method consists of two principal processes: the first process learns the texture basis functions to effectively extract quasi-periodic texture patterns; the subsequent anomaly detection process utilizes that texture basis as prior knowledge to prevent texture misidentification and capture potential anomalies with high accuracy.The proposed method surpasses benchmarks with less misidentification, smaller training dataset requirement, and superior anomaly detection performance on both simulation and real-world datasets.",
    "authors": [
      "Ji Song",
      "Xing Wang",
      "Jianguo Wu",
      "Xiaowei Yue"
    ],
    "published": "2025-12-23",
    "categories": [
      "cs.CV",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20432v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20432v1",
    "fetched_at": "2025-12-24T08:34:38.418993",
    "chinese_title": "面向纹理图像异常检测的高维数据分解方法",
    "chinese_summary": "论文针对纹理缺陷图像异常检测中误识别率高、鲁棒性低及依赖大规模结构化数据的问题，提出纹理基融合平滑分解（TBSD）方法；该方法先学习纹理基函数提取准周期纹理模式，再以其为先验准确捕获异常，在模拟和真实数据集上均优于基准方法，误识别少且训练数据需求低。",
    "tags": [
      "Anomaly",
      "Benchmark"
    ],
    "key_contributions": [
      "提出纹理基融合平滑分解（TBSD）方法，针对纹理背景平滑、异常稀疏的图像异常检测问题；",
      "学习纹理基函数提取准周期纹理模式，利用其作为先验减少误识别，且对训练数据需求低，性能优于基准方法。"
    ],
    "processed_at": "2025-12-24T08:41:58.326143"
  },
  {
    "id": "2512.20177v1",
    "title": "NeuralCrop: Combining physics and machine learning for improved crop yield predictions",
    "abstract": "Global gridded crop models (GGCMs) simulate daily crop growth by explicitly representing key biophysical processes and project end-of-season yield time series. They are a primary tool to quantify the impacts of climate change on agricultural productivity and assess associated risks for food security. Despite decades of development, state-of-the-art GGCMs still have substantial uncertainties in simulating complex biophysical processes due to limited process understanding. Recently, machine learning approaches trained on observational data have shown great potential in crop yield predictions. However, these models have not demonstrated improved performance over classical GGCMs and are not suitable for simulating crop yields under changing climate conditions due to problems in generalizing outside their training distributions. Here we introduce NeuralCrop, a hybrid GGCM that combines the strengths of an advanced process-based GGCM, resolving important processes explicitly, with data-driven machine learning components. The model is first trained to emulate a competitive GGCM before it is fine-tuned on observational data. We show that NeuralCrop outperforms state-of-the-art GGCMs across site-level and large-scale cropping regions. Across moisture conditions, NeuralCrop reproduces the interannual yield anomalies in European wheat regions and the US Corn Belt more accurately during the period from 2000 to 2019 with particularly strong improvements under drought extremes. When generalizing to conditions unseen during training, NeuralCrop continues to make robust projections, while pure machine learning models exhibit substantial performance degradation. Our results show that our hybrid crop modelling approach offers overall improved crop modeling and more reliable yield projections under climate change and intensifying extreme weather conditions.",
    "authors": [
      "Yunan Lin",
      "Sebastian Bathiany",
      "Maha Badri",
      "Maximilian Gelbrecht",
      "Philipp Hess",
      "Brian Groenke",
      "Jens Heinke",
      "Christoph Müller",
      "Niklas Boers"
    ],
    "published": "2025-12-23",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20177v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20177v1",
    "fetched_at": "2025-12-24T08:34:38.419035",
    "chinese_title": "NeuralCrop：结合物理与机器学习提升作物产量预测",
    "chinese_summary": "本文提出NeuralCrop混合模型，融合先进过程驱动全球网格化作物模型（GGCM）的物理过程显式表达与数据驱动机器学习组件；先训练模型模仿竞争GGCM，再用观测数据微调；实验表明其在站点及大区域作物产量预测上优于现有GGCM，干旱极端条件下改进更显著。",
    "tags": [
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "提出融合过程驱动GGCM与数据驱动ML的NeuralCrop混合模型，解决传统GGCM不确定性及纯ML泛化差问题",
      "实验验证NeuralCrop在站点及大区域作物产量预测（含干旱极端条件）优于现有最先进GGCM"
    ],
    "processed_at": "2025-12-24T08:42:15.335487"
  },
  {
    "id": "2512.20086v1",
    "title": "Spatio-Temporal Graphs Beyond Grids: Benchmark for Maritime Anomaly Detection",
    "abstract": "Spatio-temporal graph neural networks (ST-GNNs) have achieved notable success in structured domains such as road traffic and public transportation, where spatial entities can be naturally represented as fixed nodes. In contrast, many real-world systems including maritime traffic lack such fixed anchors, making the construction of spatio-temporal graphs a fundamental challenge. Anomaly detection in these non-grid environments is particularly difficult due to the absence of canonical reference points, the sparsity and irregularity of trajectories, and the fact that anomalies may manifest at multiple granularities. In this work, we introduce a novel benchmark dataset for anomaly detection in the maritime domain, extending the Open Maritime Traffic Analysis Dataset (OMTAD) into a benchmark tailored for graph-based anomaly detection. Our dataset enables systematic evaluation across three different granularities: node-level, edge-level, and graph-level anomalies. We plan to employ two specialized LLM-based agents: \\emph{Trajectory Synthesizer} and \\emph{Anomaly Injector} to construct richer interaction contexts and generate semantically meaningful anomalies. We expect this benchmark to promote reproducibility and to foster methodological advances in anomaly detection for non-grid spatio-temporal systems.",
    "authors": [
      "Jeehong Kim",
      "Youngseok Hwang",
      "Minchan Kim",
      "Sungho Bae",
      "Hyunwoo Park"
    ],
    "published": "2025-12-23",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20086v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20086v1",
    "fetched_at": "2025-12-24T08:34:38.419061",
    "chinese_title": "网格外的时空图：海事异常检测基准",
    "chinese_summary": "该论文针对海事等无固定锚点的非网格时空系统异常检测难题，扩展OMTAD数据集为图异常检测基准（支持节点、边、图三级粒度评估），并计划用LLM代理构建交互上下文与生成语义异常，以提升该领域研究的可复现性与方法创新。",
    "tags": [
      "Anomaly",
      "Graph Neural Network",
      "Benchmark",
      "LLM"
    ],
    "key_contributions": [
      "构建面向海事非网格时空系统的图异常检测基准数据集（扩展OMTAD，支持三级粒度评估）",
      "提出用LLM代理生成语义有意义的异常与丰富交互上下文"
    ],
    "processed_at": "2025-12-24T08:42:29.255601"
  },
  {
    "id": "2512.19383v1",
    "title": "Real-Time Machine Learning for Embedded Anomaly Detection",
    "abstract": "The spread of a resource-constrained Internet of Things (IoT) environment and embedded devices has put pressure on the real-time detection of anomalies occurring at the edge. This survey presents an overview of machine-learning methods aimed specifically at on-device anomaly detection with extremely strict constraints for latency, memory, and power consumption. Lightweight algorithms such as Isolation Forest, One-Class SVM, recurrent architectures, and statistical techniques are compared here according to the realities of embedded implementation. Our survey brings out significant trade-offs of accuracy and computational efficiency of detection, as well as how hardware constraints end up fundamentally redefining algorithm choice. The survey is completed with a set of practical recommendations on the choice of the algorithm depending on the equipment profiles and new trends in TinyML, which can help close the gap between detection capabilities and embedded reality. The paper serves as a strategic roadmap for engineers deploying anomaly detection in edge environments that are constrained by bandwidth and may be safety-critical.",
    "authors": [
      "Abdelmadjid Benmachiche",
      "Khadija Rais",
      "Hamda Slimi"
    ],
    "published": "2025-12-22",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.19383v1",
    "arxiv_url": "https://arxiv.org/abs/2512.19383v1",
    "fetched_at": "2025-12-24T08:34:38.419082",
    "chinese_title": "面向嵌入式异常检测的实时机器学习",
    "chinese_summary": "这篇综述针对资源受限的物联网边缘环境下的嵌入式异常检测，对比了隔离森林、一类支持向量机等轻量算法在延迟、内存和功耗约束下的表现，揭示了检测准确率与计算效率的权衡及硬件约束对算法选择的影响，还给出基于设备特征的算法选择建议及TinyML新趋势，为边缘环境部署异常检测提供战略路线图。",
    "tags": [
      "Anomaly",
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "系统对比轻量机器学习算法在嵌入式异常检测中准确率与计算效率的权衡及硬件约束对算法选择的影响",
      "结合设备特征和TinyML趋势给出实用算法选择建议，为边缘环境异常检测部署提供战略路线图"
    ],
    "processed_at": "2025-12-24T08:42:41.911064"
  },
  {
    "id": "2512.19228v1",
    "title": "Generation of Programmatic Rules for Document Forgery Detection Using Large Language Models",
    "abstract": "Document forgery poses a growing threat to legal, economic, and governmental processes, requiring increasingly sophisticated verification mechanisms. One approach involves the use of plausibility checks, rule-based procedures that assess the correctness and internal consistency of data, to detect anomalies or signs of manipulation. Although these verification procedures are essential for ensuring data integrity, existing plausibility checks are manually implemented by software engineers, which is time-consuming. Recent advances in code generation with large language models (LLMs) offer new potential for automating and scaling the generation of these checks. However, adapting LLMs to the specific requirements of an unknown domain remains a significant challenge. This work investigates the extent to which LLMs, adapted on domain-specific code and data through different fine-tuning strategies, can generate rule-based plausibility checks for forgery detection on constrained hardware resources. We fine-tune open-source LLMs, Llama 3.1 8B and OpenCoder 8B, on structured datasets derived from real-world application scenarios and evaluate the generated plausibility checks on previously unseen forgery patterns. The results demonstrate that the models are capable of generating executable and effective verification procedures. This also highlights the potential of LLMs as scalable tools to support human decision-making in security-sensitive contexts where comprehensibility is required.",
    "authors": [
      "Valentin Schmidberger",
      "Manuel Eberhardinger",
      "Setareh Maghsudi",
      "Johannes Maucher"
    ],
    "published": "2025-12-22",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.19228v1",
    "arxiv_url": "https://arxiv.org/abs/2512.19228v1",
    "fetched_at": "2025-12-24T08:34:38.419104",
    "chinese_title": "基于大语言模型生成文档伪造检测的程序化规则",
    "chinese_summary": "本文针对文档伪造检测中手动实现合理性检查耗时的问题，采用领域特定数据和不同微调策略适配开源大语言模型（Llama 3.1 8B、OpenCoder 8B）；实验表明模型能生成可执行且有效的验证规则，可检测 unseen 的伪造模式，凸显LLM在安全敏感场景的决策支持潜力。",
    "tags": [
      "LLM",
      "Anomaly",
      "NLP"
    ],
    "key_contributions": [
      "提出用领域适配的开源LLM自动生成文档伪造检测的合理性检查规则，解决手动实现耗时问题",
      "实验验证模型可生成可执行有效规则并检测 unseen 伪造模式，凸显LLM在安全敏感场景的决策支持潜力"
    ],
    "processed_at": "2025-12-24T08:42:58.674172"
  },
  {
    "id": "2512.18826v1",
    "title": "Hyperbolic Graph Embeddings: a Survey and an Evaluation on Anomaly Detection",
    "abstract": "This survey reviews hyperbolic graph embedding models, and evaluate them on anomaly detection, highlighting their advantages over Euclidean methods in capturing complex structures. Evaluating models like \\textit{HGCAE}, \\textit{\\(\\mathcal{P}\\)-VAE}, and \\textit{HGCN} demonstrates high performance, with \\textit{\\(\\mathcal{P}\\)-VAE} achieving an F1-score of 94\\% on the \\textit{Elliptic} dataset and \\textit{HGCAE} scoring 80\\% on \\textit{Cora}. In contrast, Euclidean methods like \\textit{DOMINANT} and \\textit{GraphSage} struggle with complex data. The study emphasizes the potential of hyperbolic spaces for improving anomaly detection, and provides an open-source library to foster further research in this field.",
    "authors": [
      "Souhail Abdelmouaiz Sadat",
      "Mohamed Yacine Touahria Miliani",
      "Khadidja Hab El Hames",
      "Hamida Seba",
      "Mohammed Haddad"
    ],
    "published": "2025-12-21",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.18826v1",
    "arxiv_url": "https://arxiv.org/abs/2512.18826v1",
    "fetched_at": "2025-12-24T08:34:38.419129",
    "chinese_title": "双曲图嵌入：综述及异常检测评估",
    "chinese_summary": "该论文综述了双曲图嵌入模型，在异常检测任务上评估了HGCAE、P-VAE等模型，对比欧氏方法验证了双曲空间捕捉复杂结构的优势（P-VAE在Elliptic数据集F1分数达94%），并提供开源库促进相关研究。",
    "tags": [
      "Anomaly",
      "Graph Neural Network",
      "Deep Learning"
    ],
    "key_contributions": [
      "系统综述双曲图嵌入模型，并在异常检测任务上评估多个代表性模型的性能",
      "验证双曲空间在捕捉复杂结构方面优于欧氏方法，同时提供开源库支持后续研究"
    ],
    "processed_at": "2025-12-24T08:43:16.801841"
  },
  {
    "id": "2512.18733v1",
    "title": "Explainable and Fine-Grained Safeguarding of LLM Multi-Agent Systems via Bi-Level Graph Anomaly Detection",
    "abstract": "Large language model (LLM)-based multi-agent systems (MAS) have shown strong capabilities in solving complex tasks. As MAS become increasingly autonomous in various safety-critical tasks, detecting malicious agents has become a critical security concern. Although existing graph anomaly detection (GAD)-based defenses can identify anomalous agents, they mainly rely on coarse sentence-level information and overlook fine-grained lexical cues, leading to suboptimal performance. Moreover, the lack of interpretability in these methods limits their reliability and real-world applicability. To address these limitations, we propose XG-Guard, an explainable and fine-grained safeguarding framework for detecting malicious agents in MAS. To incorporate both coarse and fine-grained textual information for anomalous agent identification, we utilize a bi-level agent encoder to jointly model the sentence- and token-level representations of each agent. A theme-based anomaly detector further captures the evolving discussion focus in MAS dialogues, while a bi-level score fusion mechanism quantifies token-level contributions for explanation. Extensive experiments across diverse MAS topologies and attack scenarios demonstrate robust detection performance and strong interpretability of XG-Guard.",
    "authors": [
      "Junjun Pan",
      "Yixin Liu",
      "Rui Miao",
      "Kaize Ding",
      "Yu Zheng",
      "Quoc Viet Hung Nguyen",
      "Alan Wee-Chung Liew",
      "Shirui Pan"
    ],
    "published": "2025-12-21",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.MA"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.18733v1",
    "arxiv_url": "https://arxiv.org/abs/2512.18733v1",
    "fetched_at": "2025-12-24T08:34:38.419158",
    "chinese_title": "基于双层图异常检测的LLM多智能体系统可解释细粒度防护",
    "chinese_summary": "针对现有图异常检测方法在LLM多智能体系统恶意智能体检测中依赖粗粒度句子信息、忽略细粒度词汇线索且缺乏可解释性的问题，本文提出可解释细粒度防护框架XG-Guard；该框架通过双层智能体编码器联合建模句子与token级表示，结合主题异常检测器捕捉对话焦点变化，并利用双层分数融合量化token贡献以实现解释，实验验证了其鲁棒检测性能与强可解释性。",
    "tags": [
      "LLM",
      "Anomaly",
      "Graph Neural Network",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出双层智能体编码器，联合建模智能体的句子与token级表示，弥补现有方法粗粒度信息的不足",
      "设计主题异常检测器与双层分数融合机制，实现可解释的恶意智能体检测，提升方法可靠性与实际适用性"
    ],
    "processed_at": "2025-12-24T08:43:35.908628"
  },
  {
    "id": "2512.18673v1",
    "title": "Improving Pattern Recognition of Scheduling Anomalies through Structure-Aware and Semantically-Enhanced Graphs",
    "abstract": "This paper proposes a structure-aware driven scheduling graph modeling method to improve the accuracy and representation capability of anomaly identification in scheduling behaviors of complex systems. The method first designs a structure-guided scheduling graph construction mechanism that integrates task execution stages, resource node states, and scheduling path information to build dynamically evolving scheduling behavior graphs, enhancing the model's ability to capture global scheduling relationships. On this basis, a multi-scale graph semantic aggregation module is introduced to achieve semantic consistency modeling of scheduling features through local adjacency semantic integration and global topology alignment, thereby strengthening the model's capability to capture abnormal features in complex scenarios such as multi-task concurrency, resource competition, and stage transitions. Experiments are conducted on a real scheduling dataset with multiple scheduling disturbance paths set to simulate different types of anomalies, including structural shifts, resource changes, and task delays. The proposed model demonstrates significant performance advantages across multiple metrics, showing a sensitive response to structural disturbances and semantic shifts. Further visualization analysis reveals that, under the combined effect of structure guidance and semantic aggregation, the scheduling behavior graph exhibits stronger anomaly separability and pattern representation, validating the effectiveness and adaptability of the method in scheduling anomaly detection tasks.",
    "authors": [
      "Ning Lyu",
      "Junjie Jiang",
      "Lu Chang",
      "Chihui Shao",
      "Feng Chen",
      "Chong Zhang"
    ],
    "published": "2025-12-21",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.18673v1",
    "arxiv_url": "https://arxiv.org/abs/2512.18673v1",
    "fetched_at": "2025-12-24T08:34:38.419183",
    "chinese_title": "通过结构感知和语义增强图提升调度异常的模式识别能力",
    "chinese_summary": "本文提出结构感知驱动的调度图建模方法以提升复杂系统调度行为异常识别的准确性与表征能力；该方法先设计结构引导的调度图构建机制（整合任务执行阶段、资源节点状态及调度路径），再引入多尺度图语义聚合模块实现调度特征的语义一致性建模；实验在含多类异常的真实调度数据集上验证了方法的性能优势，异常可分离性与模式表征能力更强。",
    "tags": [
      "Anomaly",
      "Graph Neural Network",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出结构引导的调度图构建机制，整合任务执行阶段、资源节点状态及调度路径信息，构建动态演化的调度行为图，提升模型对全局调度关系的捕捉能力",
      "引入多尺度图语义聚合模块，通过局部邻接语义整合与全局拓扑对齐实现调度特征的语义一致性建模，强化多任务并发、资源竞争等复杂场景下的异常特征捕捉能力"
    ],
    "processed_at": "2025-12-24T08:43:53.709459"
  },
  {
    "id": "2512.18244v1",
    "title": "Breaking Minds, Breaking Systems: Jailbreaking Large Language Models via Human-like Psychological Manipulation",
    "abstract": "Large Language Models (LLMs) have gained considerable popularity and protected by increasingly sophisticated safety mechanisms. However, jailbreak attacks continue to pose a critical security threat by inducing models to generate policy-violating behaviors. Current paradigms focus on input-level anomalies, overlooking that the model's internal psychometric state can be systematically manipulated. To address this, we introduce Psychological Jailbreak, a new jailbreak attack paradigm that exposes a stateful psychological attack surface in LLMs, where attackers exploit the manipulation of a model's psychological state across interactions. Building on this insight, we propose Human-like Psychological Manipulation (HPM), a black-box jailbreak method that dynamically profiles a target model's latent psychological vulnerabilities and synthesizes tailored multi-turn attack strategies. By leveraging the model's optimization for anthropomorphic consistency, HPM creates a psychological pressure where social compliance overrides safety constraints. To systematically measure psychological safety, we construct an evaluation framework incorporating psychometric datasets and the Policy Corruption Score (PCS). Benchmarking against various models (e.g., GPT-4o, DeepSeek-V3, Gemini-2-Flash), HPM achieves a mean Attack Success Rate (ASR) of 88.1%, outperforming state-of-the-art attack baselines. Our experiments demonstrate robust penetration against advanced defenses, including adversarial prompt optimization (e.g., RPO) and cognitive interventions (e.g., Self-Reminder). Ultimately, PCS analysis confirms HPM induces safety breakdown to satisfy manipulated contexts. Our work advocates for a fundamental paradigm shift from static content filtering to psychological safety, prioritizing the development of psychological defense mechanisms against deep cognitive manipulation.",
    "authors": [
      "Zehao Liu",
      "Xi Lin"
    ],
    "published": "2025-12-20",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.18244v1",
    "arxiv_url": "https://arxiv.org/abs/2512.18244v1",
    "fetched_at": "2025-12-24T08:34:38.419202",
    "chinese_title": "打破思维，打破系统：通过类人心理操纵越狱大语言模型",
    "chinese_summary": "论文提出**心理越狱**新范式，突破现有LLM越狱攻击仅关注输入层异常的局限，暴露模型可被系统操纵的有状态心理攻击面；设计类人心理操纵（HPM）黑盒攻击方法，动态 profiling 模型潜在心理漏洞并合成多轮策略，利用拟人一致性使社会合规压倒安全约束；实验验证HPM在多模型上攻击成功率达88.1%，优于基线且能穿透高级防御，同时构建含心理测量数据集和政策腐败分数的评估框架。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出**心理越狱**新范式，暴露LLM可被系统操纵的有状态心理攻击面，突破现有输入层异常的攻击局限",
      "设计类人心理操纵（HPM）黑盒攻击方法，动态 profiling 模型心理漏洞并合成多轮策略，实验验证其高成功率及对高级防御的穿透性"
    ],
    "processed_at": "2025-12-24T08:44:21.595881"
  },
  {
    "id": "2512.17979v1",
    "title": "Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis",
    "abstract": "Industrial symbiosis fosters circularity by enabling firms to repurpose residual resources, yet its emergence is constrained by socio-spatial frictions that shape costs, matching opportunities, and market efficiency. Existing models often overlook the interaction between spatial structure, market design, and adaptive firm behavior, limiting our understanding of where and how symbiosis arises. We develop an agent-based model where heterogeneous firms trade byproducts through a spatially embedded double-auction market, with prices and quantities emerging endogenously from local interactions. Leveraging reinforcement learning, firms adapt their bidding strategies to maximize profit while accounting for transport costs, disposal penalties, and resource scarcity. Simulation experiments reveal the economic and spatial conditions under which decentralized exchanges converge toward stable and efficient outcomes. Counterfactual regret analysis shows that sellers' strategies approach a near Nash equilibrium, while sensitivity analysis highlights how spatial structures and market parameters jointly govern circularity. Our model provides a basis for exploring policy interventions that seek to align firm incentives with sustainability goals, and more broadly demonstrates how decentralized coordination can emerge from adaptive agents in spatially constrained markets.",
    "authors": [
      "Matthieu Mastio",
      "Paul Saves",
      "Benoit Gaudou",
      "Nicolas Verstaevel"
    ],
    "published": "2025-12-19",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA",
      "econ.GN",
      "stat.AP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.17979v1",
    "arxiv_url": "https://arxiv.org/abs/2512.17979v1",
    "fetched_at": "2025-12-24T08:34:48.326457",
    "chinese_title": "空间双向拍卖市场中的自适应主体：工业共生涌现的建模",
    "chinese_summary": "论文构建了融合空间结构、市场设计与自适应企业行为的基于主体模型，利用强化学习让异质企业在空间嵌入的双向拍卖中自适应调整竞价策略（考虑运输成本、处置惩罚等），揭示工业共生涌现的经济与空间条件，为可持续政策干预提供基础。",
    "tags": [
      "Financial Agent",
      "Reinforcement Learning",
      "Market Microstructure"
    ],
    "key_contributions": [
      "构建融合空间结构、市场设计与自适应企业行为的基于主体模型，模拟工业共生涌现机制",
      "揭示经济与空间条件下分散交易收敛至稳定有效结果的规律，为可持续政策干预提供依据"
    ],
    "processed_at": "2025-12-24T08:44:31.316397"
  },
  {
    "id": "2512.18034v1",
    "title": "Conflict-Driven Clause Learning with VSIDS Heuristics for Discrete Facility Layout",
    "abstract": "This paper studies the use of Conflict-Driven Clause Learning (CDCL) with VSIDS heuristics as a computational engine for discrete facility layout problems. The facility layout problem is modeled as a combinatorial assignment problem with dense logical structure arising from adjacency, separation, and slot-availability constraints. We develop a CNF-based formulation for layout feasibility and compare CDCL-based SAT solving against CP-SAT and MILP formulations under a unified benchmarking framework. Empirical results show that CDCL exhibits near-constant runtime behavior for feasibility detection across increasing problem sizes and constraint densities, while CP-SAT and MILP display polynomial and exponential scaling respectively. To address the limitation of CDCL in objective optimization, we introduce two hybrid architectures that combine CDCL-based feasibility search with CP-SAT optimization. The first architecture rapidly enumerates feasible layouts to trade optimality for speed, while the second uses CDCL to generate warm-start solutions that accelerate exact optimization. The results demonstrate that hybrid approaches can significantly reduce time-to-solution while preserving correctness guarantees, clarifying the algorithmic trade-offs between clause-learning search and exact optimization methods in large-scale discrete layout problems.",
    "authors": [
      "Joshua Gibson",
      "Kapil Dhakal"
    ],
    "published": "2025-12-19",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.18034v1",
    "arxiv_url": "https://arxiv.org/abs/2512.18034v1",
    "fetched_at": "2025-12-24T08:34:58.147090",
    "chinese_title": "基于VSIDS启发式的冲突驱动子句学习在离散设施布局中的应用",
    "chinese_summary": "本文将离散设施布局问题建模为带邻接、分离等约束的组合分配问题，采用冲突驱动子句学习（CDCL）结合VSIDS启发式作为计算引擎，对比其与CP-SAT、MILP的性能；针对CDCL优化能力不足，提出两种混合架构，结合CDCL可行性搜索与CP-SAT优化，实验表明混合方法可显著缩短求解时间并保证正确性。",
    "tags": [
      "Algorithmic Trading",
      "Benchmark",
      "Portfolio Optimization"
    ],
    "key_contributions": [
      "对比CDCL、CP-SAT和MILP在离散设施布局可行性检测中的性能，发现CDCL具有随问题规模和约束密度增加的近常数运行时特性",
      "提出两种混合架构，分别通过快速枚举可行布局或生成热启动解，结合CDCL可行性搜索与CP-SAT优化，显著减少求解时间并保持正确性"
    ],
    "processed_at": "2025-12-24T08:45:00.569020"
  },
  {
    "id": "2512.20605v1",
    "title": "Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning",
    "abstract": "Large-scale autoregressive models pretrained on next-token prediction and finetuned with reinforcement learning (RL) have achieved unprecedented success on many problem domains. During RL, these models explore by generating new outputs, one token at a time. However, sampling actions token-by-token can result in highly inefficient learning, particularly when rewards are sparse. Here, we show that it is possible to overcome this problem by acting and exploring within the internal representations of an autoregressive model. Specifically, to discover temporally-abstract actions, we introduce a higher-order, non-causal sequence model whose outputs control the residual stream activations of a base autoregressive model. On grid world and MuJoCo-based tasks with hierarchical structure, we find that the higher-order model learns to compress long activation sequence chunks onto internal controllers. Critically, each controller executes a sequence of behaviorally meaningful actions that unfold over long timescales and are accompanied with a learned termination condition, such that composing multiple controllers over time leads to efficient exploration on novel tasks. We show that direct internal controller reinforcement, a process we term \"internal RL\", enables learning from sparse rewards in cases where standard RL finetuning fails. Our results demonstrate the benefits of latent action generation and reinforcement in autoregressive models, suggesting internal RL as a promising avenue for realizing hierarchical RL within foundation models.",
    "authors": [
      "Seijin Kobayashi",
      "Yanick Schimpf",
      "Maximilian Schlegel",
      "Angelika Steger",
      "Maciej Wolczyk",
      "Johannes von Oswald",
      "Nino Scherre",
      "Kaitlin Maile",
      "Guillaume Lajoie",
      "Blake A. Richards",
      "Rif A. Saurous",
      "James Manyika",
      "Blaise Agüera y Arcas",
      "Alexander Meulemans",
      "João Sacramento"
    ],
    "published": "2025-12-23",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20605v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20605v1",
    "fetched_at": "2025-12-24T08:35:08.154388",
    "chinese_title": "自回归模型中的涌现时间抽象使分层强化学习成为可能",
    "chinese_summary": "论文指出大规模自回归模型在强化学习（RL）中逐token采样动作效率低（尤其稀疏奖励场景），为此提出高阶非因果序列模型，通过控制基自回归模型残差流激活发现时间抽象动作；该模型将长激活序列压缩到带终止条件的内部控制器，组合控制器可高效探索新任务；还提出“内部RL”（直接强化内部控制器），能在标准RL微调失败的稀疏奖励场景下学习。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning",
      "Transformer",
      "LLM"
    ],
    "key_contributions": [
      "提出高阶非因果序列模型，通过控制残差流激活发现时间抽象动作，解决逐token采样效率低问题",
      "提出“内部RL”方法，在稀疏奖励场景下实现标准RL无法完成的学习"
    ],
    "processed_at": "2025-12-24T08:45:21.568906"
  },
  {
    "id": "2512.20595v1",
    "title": "Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs",
    "abstract": "We introduce Cube Bench, a Rubik's-cube benchmark for evaluating spatial and sequential reasoning in multimodal large language models (MLLMs). The benchmark decomposes performance into five skills: (i) reconstructing cube faces from images and text, (ii) choosing the optimal next move, (iii) predicting the outcome of a candidate move without applying it, (iv) executing multi-step plans while recovering from mistakes, and (v) detecting and revising one's own errors. Using a shared set of scrambled cube states, identical prompts and parsers, and a single distance-to-solved metric, we compare recent MLLMs side by side as a function of scramble depth. Across seven MLLMs, accuracy drops sharply with depth; once a trajectory stalls or diverges, models rarely recover, and high face-reconstruction accuracy does not guarantee competent action selection or multi-step execution. A pronounced closed- vs open-source gap emerges: the strongest closed model leads on both single-step perception tasks and multi-step control tasks, while open-weight models cluster near chance on the hardest settings; yet even the best MLLM degrades at higher cube complexity. A simple self-correction via reflective thinking yields modest gains but can also introduce overthinking. Cube Bench offers a compact, reproducible probe of sequential spatial reasoning in MLLMs.",
    "authors": [
      "Dhruv Anand",
      "Ehsan Shareghi"
    ],
    "published": "2025-12-23",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20595v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20595v1",
    "fetched_at": "2025-12-24T08:35:08.154419",
    "chinese_title": "Cube Bench：多模态大模型空间视觉推理基准",
    "chinese_summary": "论文提出Cube Bench（魔方基准），用于评估多模态大模型（MLLMs）的空间与序列推理能力，将其分解为5项核心技能；通过统一设置对比7个MLLMs，发现模型性能随魔方复杂度下降，闭源模型表现优于开源，简单自我修正可小幅提升但可能过拟合，该基准可紧凑复现地探测MLLMs的序列空间推理能力。",
    "tags": [
      "LLM",
      "Benchmark",
      "Deep Learning"
    ],
    "key_contributions": [
      "对比7个MLLMs揭示闭源vs开源性能差距、复杂度对性能的影响，验证自我修正的效果"
    ],
    "processed_at": "2025-12-24T08:45:34.191264"
  },
  {
    "id": "2512.20469v1",
    "title": "Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale",
    "abstract": "AI agents are emerging as a practical way to run multi-step scientific workflows that interleave reasoning with tool use and verification, pointing to a shift from isolated AI-assisted steps toward \\emph{agentic science at scale}. This shift is increasingly feasible, as scientific tools and models can be invoked through stable interfaces and verified with recorded execution traces, and increasingly necessary, as AI accelerates scientific output and stresses the peer-review and publication pipeline, raising the bar for traceability and credible evaluation.   However, scaling agentic science remains difficult: workflows are hard to observe and reproduce; many tools and laboratory systems are not agent-ready; execution is hard to trace and govern; and prototype AI Scientist systems are often bespoke, limiting reuse and systematic improvement from real workflow signals.   We argue that scaling agentic science requires an infrastructure-and-ecosystem approach, instantiated in Bohrium+SciMaster. Bohrium acts as a managed, traceable hub for AI4S assets -- akin to a HuggingFace of AI for Science -- that turns diverse scientific data, software, compute, and laboratory systems into agent-ready capabilities. SciMaster orchestrates these capabilities into long-horizon scientific workflows, on which scientific agents can be composed and executed. Between infrastructure and orchestration, a \\emph{scientific intelligence substrate} organizes reusable models, knowledge, and components into executable building blocks for workflow reasoning and action, enabling composition, auditability, and improvement through use.   We demonstrate this stack with eleven representative master agents in real workflows, achieving orders-of-magnitude reductions in end-to-end scientific cycle time and generating execution-grounded signals from real workloads at multi-million scale.",
    "authors": [
      "Linfeng Zhang",
      "Siheng Chen",
      "Yuzhu Cai",
      "Jingyi Chai",
      "Junhan Chang",
      "Kun Chen",
      "Zhi X. Chen",
      "Zhaohan Ding",
      "Yuwen Du",
      "Yuanpeng Gao",
      "Yuan Gao",
      "Jing Gao",
      "Zhifeng Gao",
      "Qiangqiang Gu",
      "Yanhui Hong",
      "Yuan Huang",
      "Xi Fang",
      "Xiaohong Ji",
      "Guolin Ke",
      "Zixing Lei",
      "Xinyu Li",
      "Yongge Li",
      "Ruoxue Liao",
      "Hang Lin",
      "Xiaolu Lin",
      "Yuxiang Liu",
      "Xinzijian Liu",
      "Zexi Liu",
      "Jintan Lu",
      "Tingjia Miao",
      "Haohui Que",
      "Weijie Sun",
      "Yanfeng Wang",
      "Bingyang Wu",
      "Tianju Xue",
      "Rui Ye",
      "Jinzhe Zeng",
      "Duo Zhang",
      "Jiahui Zhang",
      "Linfeng Zhang",
      "Tianhan Zhang",
      "Wenchang Zhang",
      "Yuzhi Zhang",
      "Zezhong Zhang",
      "Hang Zheng",
      "Hui Zhou",
      "Tong Zhu",
      "Xinyu Zhu",
      "Qingguo Zhou",
      "Weinan E"
    ],
    "published": "2025-12-23",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20469v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20469v1",
    "fetched_at": "2025-12-24T08:35:08.154525",
    "chinese_title": "Bohrium + SciMaster：构建规模化智能体科学的基础设施与生态系统",
    "chinese_summary": "论文指出AI智能体推动科学研究从孤立AI辅助转向规模化智能体科学，但当前存在工作流难观测复现、工具未适配智能体等挑战；为此提出Bohrium+SciMaster架构，Bohrium作为AI4S资产托管中心将多样科学资源转为智能体可用能力，SciMaster编排能力支撑长周期科学工作流。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Financial Agent"
    ],
    "key_contributions": [
      "明确规模化智能体科学面临的核心挑战（工作流可观测性/复现性不足、工具未适配智能体等）",
      "提出Bohrium+SciMaster架构，包含可追溯AI4S资产中心与工作流编排平台，构建支撑规模化智能体科学的基础设施生态"
    ],
    "processed_at": "2025-12-24T08:45:56.360859"
  },
  {
    "id": "2512.20387v1",
    "title": "Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems",
    "abstract": "We propose a Vision-Language Simulation Model (VLSM) that unifies visual and textual understanding to synthesize executable FlexScript from layout sketches and natural-language prompts, enabling cross-modal reasoning for industrial simulation systems. To support this new paradigm, the study constructs the first large-scale dataset for generative digital twins, comprising over 120,000 prompt-sketch-code triplets that enable multimodal learning between textual descriptions, spatial structures, and simulation logic. In parallel, three novel evaluation metrics, Structural Validity Rate (SVR), Parameter Match Rate (PMR), and Execution Success Rate (ESR), are proposed specifically for this task to comprehensively evaluate structural integrity, parameter fidelity, and simulator executability. Through systematic ablation across vision encoders, connectors, and code-pretrained language backbones, the proposed models achieve near-perfect structural accuracy and high execution robustness. This work establishes a foundation for generative digital twins that integrate visual reasoning and language understanding into executable industrial simulation systems.",
    "authors": [
      "YuChe Hsu",
      "AnJui Wang",
      "TsaiChing Ni",
      "YuanFu Yang"
    ],
    "published": "2025-12-23",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20387v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20387v1",
    "fetched_at": "2025-12-24T08:35:08.154549",
    "chinese_title": "生成式数字孪生：面向可执行工业系统的视觉-语言仿真模型",
    "chinese_summary": "论文提出视觉-语言仿真模型（VLSM），可从布局草图和自然语言提示合成可执行工业仿真代码，支撑跨模态推理；构建超12万提示-草图-代码三元组的大规模生成式数字孪生数据集，提出结构有效率（SVR）、参数匹配率（PMR）、执行成功率（ESR）三个评估指标；实验验证模型结构准确率高且执行鲁棒，为生成式数字孪生奠定基础。",
    "tags": [
      "Deep Learning",
      "Transformer",
      "Execution",
      "LLM"
    ],
    "key_contributions": [
      "提出视觉-语言仿真模型（VLSM），实现布局草图与自然语言到可执行工业仿真代码的跨模态合成",
      "构建首个大规模生成式数字孪生数据集并提出三个针对性评估指标"
    ],
    "processed_at": "2025-12-24T08:46:12.585247"
  },
  {
    "id": "2512.20333v1",
    "title": "SynCraft: Guiding Large Language Models to Predict Edit Sequences for Molecular Synthesizability Optimization",
    "abstract": "Generative artificial intelligence has revolutionized the exploration of chemical space, yet a critical bottleneck remains that a substantial fraction of generated molecules is synthetically inaccessible. Current solutions, such as post-hoc filtering or projection-based methods, often compromise structural novelty or disrupt key pharmacophores by forcing molecules into pre-defined synthetic templates. Herein, we introduce SynCraft, a reasoning-based framework that reframes synthesizability optimization not as a sequence translation task, but as a precise structural editing problem. Leveraging the emergent reasoning capabilities of Large Language Models, SynCraft navigates the \"synthesis cliff\" where minimal structural modifications yield significant gains in synthetic feasibility. By predicting executable sequences of atom-level edits rather than generating SMILES strings directly, SynCraft circumvents the syntactic fragility of LLMs while harnessing their chemical intuition. Extensive benchmarks demonstrate that SynCraft outperforms state-of-the-art baselines in generating synthesizable analogs with high structural fidelity. Furthermore, through interaction-aware prompting, SynCraft successfully replicates expert medicinal chemistry intuition in editing PLK1 inhibitors and rescuing high-scoring but previously discarded RIPK1 candidates in previous molecular generation literatures.",
    "authors": [
      "Junren Li",
      "Luhua Lai"
    ],
    "published": "2025-12-23",
    "categories": [
      "cs.AI",
      "q-bio.QM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20333v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20333v1",
    "fetched_at": "2025-12-24T08:35:08.154568",
    "chinese_title": "SynCraft：引导大语言模型预测编辑序列以优化分子可合成性",
    "chinese_summary": "SynCraft将分子可合成性优化重新定义为原子级结构编辑问题，而非序列翻译任务，利用大语言模型（LLM）的推理能力预测可执行的原子编辑序列，规避LLM语法脆弱性并利用其化学直觉；实验表明该框架在生成高结构保真度的可合成类似物上优于现有基线，还能通过交互提示复现专家药物化学直觉解决实际分子优化问题。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出SynCraft框架，将分子可合成性优化转化为原子级结构编辑问题，利用LLM推理能力预测可执行编辑序列，规避LLM语法脆弱性",
      "实验验证其生成的可合成类似物结构保真度高且优于现有基线，还能复现专家药物化学直觉解决实际分子优化问题"
    ],
    "processed_at": "2025-12-24T08:46:31.129615"
  },
  {
    "id": "2512.20312v1",
    "title": "TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning",
    "abstract": "Tabular data serves as the backbone of modern data analysis and scientific research. While Large Language Models (LLMs) fine-tuned via Supervised Fine-Tuning (SFT) have significantly improved natural language interaction with such structured data, they often fall short in handling the complex, multi-step reasoning and robust code execution required for real-world table tasks. Reinforcement Learning (RL) offers a promising avenue to enhance these capabilities, yet its application in the tabular domain faces three critical hurdles: the scarcity of high-quality agentic trajectories with closed-loop code execution and environment feedback on diverse table structures, the extreme heterogeneity of feedback signals ranging from rigid SQL execution to open-ended data interpretation, and the risk of catastrophic forgetting of general knowledge during vertical specialization. To overcome these challenges and unlock advanced reasoning on complex tables, we introduce \\textbf{TableGPT-R1}, a specialized tabular model built on a systematic RL framework. Our approach integrates a comprehensive data engineering pipeline that synthesizes difficulty-stratified agentic trajectories for both supervised alignment and RL rollouts, a task-adaptive reward system that combines rule-based verification with a criteria-injected reward model and incorporates process-level step reward shaping with behavioral regularization, and a multi-stage training framework that progressively stabilizes reasoning before specializing in table-specific tasks. Extensive evaluations demonstrate that TableGPT-R1 achieves state-of-the-art performance on authoritative benchmarks, significantly outperforming baseline models while retaining robust general capabilities. Our model is available at https://huggingface.co/tablegpt/TableGPT-R1.",
    "authors": [
      "Saisai Yang",
      "Qingyi Huang",
      "Jing Yuan",
      "Liangyu Zha",
      "Kai Tang",
      "Yuhang Yang",
      "Ning Wang",
      "Yucheng Wei",
      "Liyao Li",
      "Wentao Ye",
      "Hao Chen",
      "Tao Zhang",
      "Junlin Zhou",
      "Haobo Wang",
      "Gang Chen",
      "Junbo Zhao"
    ],
    "published": "2025-12-23",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20312v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20312v1",
    "fetched_at": "2025-12-24T08:35:08.154611",
    "chinese_title": "TableGPT-R1：通过强化学习推进表格推理",
    "chinese_summary": "论文指出现有微调大语言模型（LLM）在表格任务的复杂多步推理与代码执行上存在不足，强化学习（RL）应用面临轨迹稀缺、反馈异质性、灾难性遗忘三大障碍；为此提出TableGPT-R1，整合合成难度分层轨迹的数据工程、任务自适应奖励系统及多阶段训练框架，提升复杂表格推理能力。",
    "tags": [
      "LLM",
      "Reinforcement Learning",
      "NLP"
    ],
    "key_contributions": [
      "识别并解决RL在表格领域应用的三大核心障碍（轨迹稀缺、反馈异质性、灾难性遗忘）",
      "提出TableGPT-R1框架，整合数据工程、自适应奖励与多阶段训练，增强复杂表格的推理能力"
    ],
    "processed_at": "2025-12-24T08:46:46.283109"
  },
  {
    "id": "2512.20278v1",
    "title": "Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation",
    "abstract": "While CodeMem establishes executable code as the optimal representation for agentic procedural memory, the mechanism for autonomously synthesizing this memory from a blank slate remains underexplored. This paper operationalizes the transition of Large Language Models from passive tool-users to active workflow architects. Through a high-fidelity case study of a cross-service orchestration task involving Outlook and OneDrive, we identify and address four structural bottlenecks in automated skill generation: the Discovery Gap involving navigation of large tool registries, the Verification Gap regarding grounding tool response structures, the Decomposition Gap which replaces inefficient search with Linear State Anchoring, and the Scaling Gap focused on concurrency and persistence. We demonstrate that by enforcing a scientific methodology of hypothesize, probe, and code, agents can autonomously write robust, production-grade code skills.",
    "authors": [
      "Nishant Gaurav",
      "Adit Akarsh",
      "Ankit Ranjan",
      "Manoj Bajaj"
    ],
    "published": "2025-12-23",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20278v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20278v1",
    "fetched_at": "2025-12-24T08:35:08.154643",
    "chinese_title": "合成程序性记忆：自动化工作流生成中的挑战与架构",
    "chinese_summary": "本文针对大语言模型自主合成程序性记忆的空白，以Outlook与OneDrive跨服务编排任务为案例，识别并解决发现、验证、分解、扩展四个结构瓶颈，提出假设-探测-编码的方法，使模型从被动工具使用者转为主动工作流架构师，能自主编写健壮生产级代码技能。",
    "tags": [
      "LLM",
      "Financial Agent",
      "Transformer"
    ],
    "key_contributions": [
      "识别并解决自动化技能生成中的发现、验证、分解、扩展四大结构瓶颈",
      "提出假设-探测-编码方法，实现LLM从被动工具使用者到主动工作流架构师的转变，可自主编写健壮生产级代码技能"
    ],
    "processed_at": "2025-12-24T08:47:06.590601"
  },
  {
    "id": "2512.20276v1",
    "title": "ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge",
    "abstract": "Vision-Language-Action (VLA) models have emerged as a unified paradigm for robotic perception and control, enabling emergent generalization and long-horizon task execution. However, their deployment in dynamic, real-world environments is severely hin dered by high inference latency. While smooth robotic interaction requires control frequencies of 20 to 30 Hz, current VLA models typi cally operate at only 3-5 Hz on edge devices due to the memory bound nature of autoregressive decoding. Existing optimizations often require extensive retraining or compromise model accuracy. To bridge this gap, we introduce ActionFlow, a system-level inference framework tailored for resource-constrained edge plat forms. At the core of ActionFlow is a Cross-Request Pipelin ing strategy, a novel scheduler that redefines VLA inference as a macro-pipeline of micro-requests. The strategy intelligently batches memory-bound Decode phases with compute-bound Prefill phases across continuous time steps to maximize hardware utilization. Furthermore, to support this scheduling, we propose a Cross Request State Packed Forward operator and a Unified KV Ring Buffer, which fuse fragmented memory operations into efficient dense computations. Experimental results demonstrate that ActionFlow achieves a 2.55x improvement in FPS on the OpenVLA-7B model without retraining, enabling real-time dy namic manipulation on edge hardware. Our work is available at https://anonymous.4open.science/r/ActionFlow-1D47.",
    "authors": [
      "Yuntao Dai",
      "Hang Gu",
      "Teng Wang",
      "Qianyu Cheng",
      "Yifei Zheng",
      "Zhiyong Qiu",
      "Lei Gong",
      "Wenqi Lou",
      "Xuehai Zhou"
    ],
    "published": "2025-12-23",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20276v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20276v1",
    "fetched_at": "2025-12-24T08:35:08.154674",
    "chinese_title": "ActionFlow：边缘视觉语言模型的流水线动作加速",
    "chinese_summary": "针对视觉语言动作（VLA）模型在边缘部署延迟高的问题，论文提出ActionFlow系统级推理框架，核心是跨请求流水线调度策略，结合跨请求状态打包前向算子与统一KV环形缓冲区，在OpenVLA-7B模型上实现2.55x FPS提升且无需重训练，支持边缘实时动态操作。",
    "tags": [
      "Transformer",
      "Deep Learning",
      "LLM"
    ],
    "key_contributions": [
      "提出针对边缘资源约束的VLA模型加速系统ActionFlow，无需模型重训练"
    ],
    "processed_at": "2025-12-24T08:47:21.189709"
  },
  {
    "id": "2512.20188v1",
    "title": "Asynchronous Fast-Slow Vision-Language-Action Policies for Whole-Body Robotic Manipulation",
    "abstract": "Most Vision-Language-Action (VLA) systems integrate a Vision-Language Model (VLM) for semantic reasoning with an action expert generating continuous action signals, yet both typically run at a single unified frequency. As a result, policy performance is constrained by the low inference speed of large VLMs. This mandatory synchronous execution severely limits control stability and real-time performance in whole-body robotic manipulation, which involves more joints, larger motion spaces, and dynamically changing views. We introduce a truly asynchronous Fast-Slow VLA framework (DuoCore-FS), organizing the system into a fast pathway for high-frequency action generation and a slow pathway for rich VLM reasoning. The system is characterized by two key features. First, a latent representation buffer bridges the slow and fast systems. It stores instruction semantics and action-reasoning representation aligned with the scene-instruction context, providing high-level guidance to the fast pathway. Second, a whole-body action tokenizer provides a compact, unified representation of whole-body actions. Importantly, the VLM and action expert are still jointly trained end-to-end, preserving unified policy learning while enabling asynchronous execution. DuoCore-FS supports a 3B-parameter VLM while achieving 30 Hz whole-body action-chunk generation, approximately three times as fast as prior VLA models with comparable model sizes. Real-world whole-body manipulation experiments demonstrate improved task success rates and significantly enhanced responsiveness compared to synchronous Fast-Slow VLA baselines. The implementation of DuoCore-FS, including training, inference, and deployment, is provided to commercial users by Astribot as part of the Astribot robotic platform.",
    "authors": [
      "Teqiang Zou",
      "Hongliang Zeng",
      "Yuxuan Nong",
      "Yifan Li",
      "Kehui Liu",
      "Haotian Yang",
      "Xinyang Ling",
      "Xin Li",
      "Lianyang Ma"
    ],
    "published": "2025-12-23",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20188v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20188v1",
    "fetched_at": "2025-12-24T08:35:08.154705",
    "chinese_title": "异步快慢视觉-语言-动作策略用于全身机器人操作",
    "chinese_summary": "针对现有视觉-语言-动作（VLA）系统因同步执行受限于大VLM低推理速度的问题，提出异步快慢框架DuoCore-FS，通过潜在表示缓冲区桥接快慢系统、全身动作tokenizer统一动作表示，且端到端联合训练VLM与动作专家，支持3B参数VLM并实现30Hz全身动作块生成，提升全身机器人操作的控制稳定性与实时性。",
    "tags": [
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出异步快慢VLA框架DuoCore-FS，突破同步执行对大VLM推理速度的限制，提升全身机器人操作的实时性与控制稳定性",
      "设计潜在表示缓冲区桥接快慢系统及全身动作tokenizer统一动作表示，实现端到端联合训练下的异步执行与高频全身动作生成"
    ],
    "processed_at": "2025-12-24T08:47:30.695122"
  },
  {
    "id": "2512.19980v1",
    "title": "Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?",
    "abstract": "Code language models excel on code intelligence tasks, yet their internal interpretability is underexplored. Existing neuron interpretability techniques from NLP are suboptimal for source code due to programming languages formal, hierarchical, and executable nature. We empirically investigate code LLMs at the neuron level, localizing language-specific neurons (selectively responsive to one language) and concept layers (feed-forward layers encoding language-agnostic code representations). We analyze Llama-3.1-8B and Qwen2.5-Coder-32B on multilingual inputs in C++, Java, Python, Go, and JavaScript, measuring neuron selectivity and layerwise contributions during generation. We find (1) neurons specialized for individual languages alongside a universal subset supporting general-purpose generation; and (2) lower layers mainly encode language-specific syntax, while middle layers capture semantic abstractions shared across languages, emerging as concept layers. We demonstrate utility on three tasks: neuron-guided fine-tuning for code generation, clone detection via concept-layer embeddings, and concept-layer-guided transfer for code summarization, each yielding consistent gains in multilingual settings.",
    "authors": [
      "Zhe Yin",
      "Xiaodong Gu",
      "Beijun Shen"
    ],
    "published": "2025-12-23",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.19980v1",
    "arxiv_url": "https://arxiv.org/abs/2512.19980v1",
    "fetched_at": "2025-12-24T08:35:08.154725",
    "chinese_title": "代码大语言模型的神经元引导解释：在哪里、为什么以及如何？",
    "chinese_summary": "针对现有NLP神经元解释技术不适用于代码LLM（因编程语言形式化、层次化及可执行特性）的问题，论文实证分析Llama-3.1-8B等模型的神经元，定位语言特异性神经元与跨语言语义抽象的概念层；发现单语言专用神经元与通用子集并存，低层编码语法、中层捕获语义；并在代码生成微调、克隆检测、代码摘要迁移三个任务中验证效用，多语言场景下获增益。",
    "tags": [
      "LLM",
      "Transformer",
      "Deep Learning",
      "NLP"
    ],
    "key_contributions": [
      "揭示代码LLM中语言特异性神经元与通用子集的分布，以及低层语法编码、中层跨语言语义抽象的概念层特征",
      "提出神经元/概念层引导的三个任务应用，多语言场景下性能提升"
    ],
    "processed_at": "2025-12-24T08:47:49.493759"
  },
  {
    "id": "2512.19941v1",
    "title": "Block-Recurrent Dynamics in Vision Transformers",
    "abstract": "As Vision Transformers (ViTs) become standard vision backbones, a mechanistic account of their computational phenomenology is essential. Despite architectural cues that hint at dynamical structure, there is no settled framework that interprets Transformer depth as a well-characterized flow. In this work, we introduce the Block-Recurrent Hypothesis (BRH), arguing that trained ViTs admit a block-recurrent depth structure such that the computation of the original $L$ blocks can be accurately rewritten using only $k \\ll L$ distinct blocks applied recurrently. Across diverse ViTs, between-layer representational similarity matrices suggest few contiguous phases. To determine whether these phases reflect genuinely reusable computation, we train block-recurrent surrogates of pretrained ViTs: Recurrent Approximations to Phase-structured TransfORmers (Raptor). In small-scale, we demonstrate that stochastic depth and training promote recurrent structure and subsequently correlate with our ability to accurately fit Raptor. We then provide an empirical existence proof for BRH by training a Raptor model to recover $96\\%$ of DINOv2 ImageNet-1k linear probe accuracy in only 2 blocks at equivalent computational cost. Finally, we leverage our hypothesis to develop a program of Dynamical Interpretability. We find i) directional convergence into class-dependent angular basins with self-correcting trajectories under small perturbations, ii) token-specific dynamics, where cls executes sharp late reorientations while patch tokens exhibit strong late-stage coherence toward their mean direction, and iii) a collapse to low rank updates in late depth, consistent with convergence to low-dimensional attractors. Altogether, we find a compact recurrent program emerges along ViT depth, pointing to a low-complexity normative solution that enables these models to be studied through principled dynamical systems analysis.",
    "authors": [
      "Mozes Jacobs",
      "Thomas Fel",
      "Richard Hakim",
      "Alessandra Brondetta",
      "Demba Ba",
      "T. Andy Keller"
    ],
    "published": "2025-12-23",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.19941v1",
    "arxiv_url": "https://arxiv.org/abs/2512.19941v1",
    "fetched_at": "2025-12-24T08:35:08.154754",
    "chinese_title": "视觉Transformer中的块循环动力学",
    "chinese_summary": "本文提出视觉Transformer（ViT）的块循环假设（BRH），认为训练好的ViT可通过少量循环块替代原多层结构；训练Raptor模型，在等效计算成本下用2块恢复DINOv2 96%的ImageNet-1k线性探针准确率；并开展动力学可解释性分析，揭示类相关收敛盆地等现象。",
    "tags": [
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出块循环假设（BRH），证明训练好的视觉Transformer存在块循环深度结构，可通过少量循环块替代原多层结构",
      "训练Raptor模型，在等效计算成本下用2块恢复DINOv2 96%的ImageNet-1k线性探针准确率，并开展动力学可解释性研究"
    ],
    "processed_at": "2025-12-24T08:48:06.233625"
  },
  {
    "id": "2512.19799v1",
    "title": "PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research",
    "abstract": "Advances in LLMs have produced agents with knowledge and operational capabilities comparable to human scientists, suggesting potential to assist, accelerate, and automate research. However, existing studies mainly evaluate such systems on well-defined benchmarks or general tasks like literature retrieval, limiting their end-to-end problem-solving ability in open scientific scenarios. This is particularly true in physics, which is abstract, mathematically intensive, and requires integrating analytical reasoning with code-based computation. To address this, we propose PhysMaster, an LLM-based agent functioning as an autonomous theoretical and computational physicist. PhysMaster couples absract reasoning with numerical computation and leverages LANDAU, the Layered Academic Data Universe, which preserves retrieved literature, curated prior knowledge, and validated methodological traces, enhancing decision reliability and stability. It also employs an adaptive exploration strategy balancing efficiency and open-ended exploration, enabling robust performance in ultra-long-horizon tasks. We evaluate PhysMaster on problems from high-energy theory, condensed matter theory to astrophysics, including: (i) acceleration, compressing labor-intensive research from months to hours; (ii) automation, autonomously executing hypothesis-driven loops ; and (iii) autonomous discovery, independently exploring open problems.",
    "authors": [
      "Tingjia Miao",
      "Jiawen Dai",
      "Jingkun Liu",
      "Jinxin Tan",
      "Muhua Zhang",
      "Wenkai Jin",
      "Yuwen Du",
      "Tian Jin",
      "Xianghe Pang",
      "Zexi Liu",
      "Tu Guo",
      "Zhengliang Zhang",
      "Yunjie Huang",
      "Shuo Chen",
      "Rui Ye",
      "Yuzhi Zhang",
      "Linfeng Zhang",
      "Kun Chen",
      "Wei Wang",
      "Weinan E",
      "Siheng Chen"
    ],
    "published": "2025-12-22",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.19799v1",
    "arxiv_url": "https://arxiv.org/abs/2512.19799v1",
    "fetched_at": "2025-12-24T08:35:08.154805",
    "chinese_title": "PhysMaster：构建用于理论与计算物理研究的自主AI物理学家",
    "chinese_summary": "针对现有LLM代理在物理等抽象数学密集型开放科学场景端到端问题解决能力不足的问题，本文提出PhysMaster——基于LLM的自主理论与计算物理学家代理，其耦合抽象推理与数值计算，依托LANDAU分层学术数据宇宙增强决策可靠性，并采用自适应探索策略平衡效率与开放探索；该代理在高能理论、凝聚态理论等领域问题上实现了研究加速（数月缩至数小时）、假设驱动循环自动化及开放问题自主发现。",
    "tags": [
      "LLM",
      "Transformer",
      "NLP"
    ],
    "key_contributions": [
      "提出PhysMaster——基于LLM的自主理论与计算物理学家代理，耦合抽象推理与数值计算，依托LANDAU分层学术数据宇宙增强决策可靠性，采用自适应探索策略平衡效率与开放探索",
      "验证其在多物理领域的能力，实现研究加速、假设驱动循环自动化及开放问题自主发现"
    ],
    "processed_at": "2025-12-24T08:48:23.983122"
  },
  {
    "id": "2512.19562v1",
    "title": "REALM: A Real-to-Sim Validated Benchmark for Generalization in Robotic Manipulation",
    "abstract": "Vision-Language-Action (VLA) models empower robots to understand and execute tasks described by natural language instructions. However, a key challenge lies in their ability to generalize beyond the specific environments and conditions they were trained on, which is presently difficult and expensive to evaluate in the real-world. To address this gap, we present REALM, a new simulation environment and benchmark designed to evaluate the generalization capabilities of VLA models, with a specific emphasis on establishing a strong correlation between simulated and real-world performance through high-fidelity visuals and aligned robot control. Our environment offers a suite of 15 perturbation factors, 7 manipulation skills, and more than 3,500 objects. Finally, we establish two task sets that form our benchmark and evaluate the π_{0}, π_{0}-FAST, and GR00T N1.5 VLA models, showing that generalization and robustness remain an open challenge. More broadly, we also show that simulation gives us a valuable proxy for the real-world and allows us to systematically probe for and quantify the weaknesses and failure modes of VLAs. Project page: https://martin-sedlacek.com/realm",
    "authors": [
      "Martin Sedlacek",
      "Pavlo Yefanov",
      "Georgy Ponimatkin",
      "Jai Bardhan",
      "Simon Pilc",
      "Mederic Fourmy",
      "Evangelos Kazakos",
      "Cees G. M. Snoek",
      "Josef Sivic",
      "Vladimir Petrik"
    ],
    "published": "2025-12-22",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.19562v1",
    "arxiv_url": "https://arxiv.org/abs/2512.19562v1",
    "fetched_at": "2025-12-24T08:35:08.154838",
    "chinese_title": "REALM：面向机器人操作泛化的实-虚验证基准",
    "chinese_summary": "论文提出REALM模拟环境与基准，通过高保真视觉和对齐的机器人控制建立模拟与真实性能的强关联，用于评估Vision-Language-Action（VLA）模型的泛化能力；该环境含15种扰动因素、7种操作技能及超3500个对象，评估π₀等模型后指出泛化鲁棒性仍为开放挑战，且模拟可作为真实世界的有效代理。",
    "tags": [
      "Benchmark",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出REALM模拟环境与基准，通过高保真视觉和控制对齐模拟与真实性能，支持VLA模型泛化评估",
      "构建含15扰动、7技能、超3500对象的任务集，揭示VLA模型泛化鲁棒性的开放挑战，证明模拟可作为真实世界有效代理"
    ],
    "processed_at": "2025-12-24T08:48:35.128849"
  },
  {
    "id": "2512.19524v1",
    "title": "Initialization of a Polyharmonic Cascade, Launch and Testing",
    "abstract": "This paper concludes a series of studies on the polyharmonic cascade, a deep machine learning architecture theoretically derived from indifference principles and the theory of random functions. A universal initialization procedure is proposed, based on symmetric constellations in the form of hyperoctahedra with a central point. This initialization not only ensures stable training of cascades with tens and hundreds of layers (up to 500 layers without skip connections), but also radically simplifies the computations. Scalability and robustness are demonstrated on MNIST (98.3% without convolutions or augmentations), HIGGS (AUC approximately 0.885 on 11M examples), and Epsilon (AUC approximately 0.963 with 2000 features). All linear algebra is reduced to 2D operations and is efficiently executed on GPUs. A public repository and an archived snapshot are provided for full reproducibility.",
    "authors": [
      "Yuriy N. Bakhvalov"
    ],
    "published": "2025-12-22",
    "categories": [
      "cs.LG",
      "math.NA"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.19524v1",
    "arxiv_url": "https://arxiv.org/abs/2512.19524v1",
    "fetched_at": "2025-12-24T08:35:08.154855",
    "chinese_title": "多调和级联的初始化、启动与测试",
    "chinese_summary": "本文提出基于带中心点超八面体对称星座的多调和级联通用初始化方法，可稳定训练最多500层无跳跃连接的级联并简化计算；在MNIST、HIGGS、Epsilon数据集上验证了可扩展性与鲁棒性，线性代数简化为2D操作且支持GPU高效执行，还提供公开仓库保障可复现性。",
    "tags": [
      "Deep Learning",
      "Anomaly",
      "Risk Management"
    ],
    "key_contributions": [
      "提出基于超八面体对称星座的多调和级联通用初始化方法，实现最多500层无跳跃连接级联的稳定训练并简化计算",
      "验证方法在多数据集上的可扩展性与鲁棒性，线性代数简化为2D操作且支持GPU高效执行，提供可复现的公开仓库"
    ],
    "processed_at": "2025-12-24T08:49:02.459906"
  },
  {
    "id": "2512.19475v1",
    "title": "A Large-Language-Model Framework for Automated Humanitarian Situation Reporting",
    "abstract": "Timely and accurate situational reports are essential for humanitarian decision-making, yet current workflows remain largely manual, resource intensive, and inconsistent. We present a fully automated framework that uses large language models (LLMs) to transform heterogeneous humanitarian documents into structured and evidence-grounded reports. The system integrates semantic text clustering, automatic question generation, retrieval augmented answer extraction with citations, multi-level summarization, and executive summary generation, supported by internal evaluation metrics that emulate expert reasoning. We evaluated the framework across 13 humanitarian events, including natural disasters and conflicts, using more than 1,100 documents from verified sources such as ReliefWeb. The generated questions achieved 84.7 percent relevance, 84.0 percent importance, and 76.4 percent urgency. The extracted answers reached 86.3 percent relevance, with citation precision and recall both exceeding 76 percent. Agreement between human and LLM based evaluations surpassed an F1 score of 0.80. Comparative analysis shows that the proposed framework produces reports that are more structured, interpretable, and actionable than existing baselines. By combining LLM reasoning with transparent citation linking and multi-level evaluation, this study demonstrates that generative AI can autonomously produce accurate, verifiable, and operationally useful humanitarian situation reports.",
    "authors": [
      "Ivan Decostanzi",
      "Yelena Mejova",
      "Kyriaki Kalimeri"
    ],
    "published": "2025-12-22",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.19475v1",
    "arxiv_url": "https://arxiv.org/abs/2512.19475v1",
    "fetched_at": "2025-12-24T08:35:08.154875",
    "chinese_title": "基于大语言模型的自动化人道主义情况报告框架",
    "chinese_summary": "该文提出一种整合语义聚类、自动问题生成、检索增强答案提取（带引用）、多级摘要等模块的LLM框架，结合模拟专家推理的内部评估指标；在13个人道主义事件的超1100份文档上验证，生成报告比现有基线更结构化、可操作，且问题/答案质量及人类-LLM评估一致性优异，证明生成式AI可自主生产准确可验证的人道主义情况报告。",
    "tags": [
      "LLM",
      "NLP"
    ],
    "key_contributions": [
      "提出整合多NLP模块的LLM框架，实现人道主义情况报告的自动化生成",
      "验证框架在真实事件文档上的有效性，生成报告更结构化、可操作且质量优异"
    ],
    "processed_at": "2025-12-24T08:49:15.085207"
  },
  {
    "id": "2512.20403v1",
    "title": "BRIDGE: Budget-aware Reasoning via Intermediate Distillation with Guided Examples",
    "abstract": "Distilling knowledge from large proprietary models (e.g., GPT-4) to tiny deployable models (less than 1B parameters) faces a critical capacity-budget trap: the 1000x capacity gap between teachers and students prevents effective direct transfer, while API costs prohibit extensive data collection. We introduce BRIDGE (Budget-Aware Reasoning via Intermediate Distillation), a two-phase framework that resolves these constraints through strategic intermediation and budget asymmetry. In Phase 1, a mid-sized Teacher Assistant (TA; e.g., about 7B) learns from the black-box teacher on a strictly limited subset of data (e.g., 3-5%), selected via a zero-API-cost pipeline that balances entropic difficulty and semantic diversity using only local TA inference. In Phase 2, we exploit this asymmetry-teacher queries are expensive, whereas TA inference is free to amplify supervision: the refined TA generates synthetic rationales for the full dataset to train the tiny student. Crucially, we apply an instruction-tuning curriculum to establish behavioral alignment in the tiny student before transferring reasoning. Our theoretical analysis shows that BRIDGE yields tighter generalization bounds than direct distillation when data is abundant. Experiments across medical, legal, and financial benchmarks demonstrate consistent improvements: BRIDGE delivers student performance gains of 28-41%, closing the capability gap with proprietary teachers by 12-16% while using 10x fewer teacher queries. Notably, BRIDGE defies the conventional cost-performance frontier, surpassing direct distillation baselines that use 100% of the budget while consuming only 5% of the resources.",
    "authors": [
      "Xuan-An Le",
      "Minh-Nam Tran",
      "Son Nguyen"
    ],
    "published": "2025-12-23",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.20403v1",
    "arxiv_url": "https://arxiv.org/abs/2512.20403v1",
    "fetched_at": "2025-12-24T08:36:00.566726",
    "chinese_title": "BRIDGE：基于引导示例的中间蒸馏预算感知推理",
    "chinese_summary": "该论文针对大模型（如GPT-4）蒸馏到超小模型（<1B参数）的容量-预算陷阱，提出两阶段BRIDGE框架：阶段1用中规模助教（TA，约7B）在有限数据（3-5%）上学黑盒大模型，数据选择基于本地TA推理的熵难度与语义多样性平衡；阶段2用TA生成全数据集合成理由训练小模型，结合指令微调课程对齐行为。实验在多领域（含金融）证明小模型性能提升28-41%，缩小与大模型差距12-16%，且减少10x教师API查询。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出BRIDGE两阶段框架，通过中规模助教中间蒸馏解决大模型到小模型的容量-预算约束问题",
      "实验验证在含金融等多领域显著提升小模型性能，降低教师API查询成本"
    ],
    "processed_at": "2025-12-24T08:49:28.823131"
  }
]