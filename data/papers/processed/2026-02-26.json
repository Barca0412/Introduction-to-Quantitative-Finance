[
  {
    "id": "2602.22069v1",
    "title": "Pools as Portfolios: Observed arbitrage efficiency & LVR analysis of dynamic weight AMMs",
    "abstract": "Dynamic-weight AMMs (aka Temporal Function Market Makers, TFMMs) implement algorithmic asset allocation, analogous to index or smart beta funds, by continuously updating pools' weights. A strategy updates target weights over time, and arbitrageurs trade the pool back toward those weights. This creates a sequence of small, predictable mispricings that grow until taken, effectively executing rebalances as a series of Dutch reverse auctions. Prior theoretical and simulation work (Willetts & Harrington, 2024) predicted that this mechanism could outperform CEX-style rebalancing. We test that claim on two live pools on the QuantAMM protocol, one on Ethereum mainnet and one on Base, across two short rebalancing windows six months apart (July 2025 and January 2026). We perform block-level arbitrage analysis, and then measure long term outcomes using Loss-vs-Rebalancing (LVR) and Rebalancing-vs-Rebalancing (RVR) benchmarks. On mainnet, rebalancing becomes markedly more efficient over time (more frequent arbitrage trades with lower value extracted per trade), reaching performance comparable to or better than CEX-based models. On Base, rebalancing persists even when per-trade extraction is near (or below) zero, consistent with routing-driven execution, and achieves efficiencies that meet or exceed standard \"perfect rebalancing\" LVR baselines. These results demonstrate dynamic-weight AMMs as a competitive execution layer for tokenised funds, with superior performance on L2s where routing and lower data costs compress arbitrage spreads.",
    "authors": [
      "Matthew Willetts",
      "Christian Harrington"
    ],
    "published": "2026-02-25",
    "categories": [
      "q-fin.TR",
      "q-fin.PM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.22069v1",
    "arxiv_url": "https://arxiv.org/abs/2602.22069v1",
    "fetched_at": "2026-02-26T08:53:59.519444",
    "chinese_title": "将资金池视为投资组合：动态权重自动做市商（AMMs）的套利效率观测与损失对比再平衡（LVR）分析",
    "chinese_summary": "本文针对动态权重AMMs（类似时间函数做市商），通过测试QuantAMM协议上以太坊主网和Base的两个真实资金池，采用块级套利分析及LVR、RVR基准衡量长期表现；发现主网再平衡效率随时间显著提升，Base上即使单交易套利提取接近零仍持续再平衡且效率超“完美再平衡”基准，证明动态权重AMMs是代币化基金的竞争执行层。",
    "tags": [
      "Market Making",
      "Execution",
      "Portfolio Optimization",
      "Benchmark"
    ],
    "key_contributions": [
      "首次在真实区块链网络（以太坊主网与Base）上验证动态权重AMMs的套利效率及再平衡表现，突破此前理论/模拟研究的局限",
      "证明动态权重AMMs可作为代币化基金的竞争执行层，Base网络上效率达到或超过“完美再平衡”基准，主网效率随时间提升至接近/优于中心化交易所（CEX）模式"
    ],
    "processed_at": "2026-02-26T08:57:05.975980"
  },
  {
    "id": "2602.21869v1",
    "title": "A Bayesian approach to out-of-sample network reconstruction",
    "abstract": "Networks underpin systems that range from finance to biology, yet their structure is often only partially observed. Current reconstruction methods typically fit the parameters of a model anew to each snapshot, thus offering no guidance to predict future configurations. Here, we develop a Bayesian approach that uses the information about past network snapshots to inform a prior and predict the subsequent ones, while quantifying uncertainty. Instantiated with a single-parameter fitness model, our method infers link probabilities from node strengths and carries information forward in time. When applied to the Electronic Market for Interbank Deposit across the years 1999-2012, our method accurately recovers the number of connections per bank at subsequent times, outperforming probabilistic benchmarks designed for analogous, link prediction tasks. Notably, each predicted snapshot serves as a reliable prior for the next one, thus enabling self-sustained, out-of-sample reconstruction of evolving networks with a minimal amount of additional data.",
    "authors": [
      "Mattia Marzi",
      "Tiziano Squartini"
    ],
    "published": "2026-02-25",
    "categories": [
      "physics.soc-ph",
      "physics.app-ph",
      "physics.data-an",
      "q-fin.ST"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.21869v1",
    "arxiv_url": "https://arxiv.org/abs/2602.21869v1",
    "fetched_at": "2026-02-26T08:53:59.519481",
    "chinese_title": "样本外网络重构的贝叶斯方法",
    "chinese_summary": "本文针对现有网络重构方法无法预测未来结构的问题，提出贝叶斯方法，利用过去网络快照信息构建先验以预测后续结构并量化不确定性，基于单参数适应度模型从节点强度推断链接概率并跨时间传递信息；该方法在1999-2012年银行间存款电子市场数据中，准确恢复后续各银行连接数，优于同类概率基准，且预测快照可作为下一个的可靠先验，实现最小额外数据下的自维持样本外演化网络重构。",
    "tags": [
      "Time Series",
      "Market Microstructure",
      "Benchmark"
    ],
    "key_contributions": [
      "提出贝叶斯网络重构方法，利用过去快照信息作为先验预测未来结构并量化不确定性，解决现有方法无法预测的问题",
      "在银行间市场数据中验证，准确恢复后续连接数且优于同类基准，预测快照可作为下一个先验实现自维持样本外重构，减少额外数据需求"
    ],
    "processed_at": "2026-02-26T08:57:26.222392"
  },
  {
    "id": "2602.21928v1",
    "title": "Learning Unknown Interdependencies for Decentralized Root Cause Analysis in Nonlinear Dynamical Systems",
    "abstract": "Root cause analysis (RCA) in networked industrial systems, such as supply chains and power networks, is notoriously difficult due to unknown and dynamically evolving interdependencies among geographically distributed clients. These clients represent heterogeneous physical processes and industrial assets equipped with sensors that generate large volumes of nonlinear, high-dimensional, and heterogeneous IoT data. Classical RCA methods require partial or full knowledge of the system's dependency graph, which is rarely available in these complex networks. While federated learning (FL) offers a natural framework for decentralized settings, most existing FL methods assume homogeneous feature spaces and retrainable client models. These assumptions are not compatible with our problem setting. Different clients have different data features and often run fixed, proprietary models that cannot be modified. This paper presents a federated cross-client interdependency learning methodology for feature-partitioned, nonlinear time-series data, without requiring access to raw sensor streams or modifying proprietary client models. Each proprietary local client model is augmented with a Machine Learning (ML) model that encodes cross-client interdependencies. These ML models are coordinated via a global server that enforces representation consistency while preserving privacy through calibrated differential privacy noise. RCA is performed using model residuals and anomaly flags. We establish theoretical convergence guarantees and validate our approach on extensive simulations and a real-world industrial cybersecurity dataset.",
    "authors": [
      "Ayush Mohanty",
      "Paritosh Ramanan",
      "Nagi Gebraeel"
    ],
    "published": "2026-02-25",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.21928v1",
    "arxiv_url": "https://arxiv.org/abs/2602.21928v1",
    "fetched_at": "2026-02-26T08:54:11.685788",
    "chinese_title": "非线性动力系统中去中心化根因分析的未知依赖关系学习",
    "chinese_summary": "针对非线性动力系统中去中心化根因分析（RCA）面临的未知动态依赖、客户端异构数据及固定专有模型不可修改等挑战，本文提出联邦跨客户端依赖学习方法，无需访问原始传感器数据或修改客户端模型，通过客户端本地ML模型编码跨客户端依赖、全局服务器协调表示一致性并保护隐私，基于模型残差和异常标志实现RCA。",
    "tags": [
      "Anomaly",
      "Time Series",
      "Deep Learning",
      "Risk Management"
    ],
    "key_contributions": [
      "提出适用于特征分区非线性时间序列、无需修改客户端固定专有模型且不访问原始数据的联邦跨客户端依赖学习框架",
      "设计全局服务器协调跨客户端表示一致性并通过校准差分隐私保护隐私的机制，基于模型残差和异常标志实现去中心化根因分析"
    ],
    "processed_at": "2026-02-26T08:57:51.570937"
  },
  {
    "id": "2602.21766v1",
    "title": "RAMSeS: Robust and Adaptive Model Selection for Time-Series Anomaly Detection Algorithms",
    "abstract": "Time-series data vary widely across domains, making a universal anomaly detector impractical. Methods that perform well on one dataset often fail to transfer because what counts as an anomaly is context dependent. The key challenge is to design a method that performs well in specific contexts while remaining adaptable across domains with varying data complexities. We present the Robust and Adaptive Model Selection for Time-Series Anomaly Detection RAMSeS framework. RAMSeS comprises two branches: (i) a stacking ensemble optimized with a genetic algorithm to leverage complementary detectors. (ii) An adaptive model-selection branch identifies the best single detector using techniques including Thompson sampling, robustness testing with generative adversarial networks, and Monte Carlo simulations. This dual strategy exploits the collective strength of multiple models and adapts to dataset-specific characteristics. We evaluate RAMSeS and show that it outperforms prior methods on F1.",
    "authors": [
      "Mohamed Abdelmaksoud",
      "Sheng Ding",
      "Andrey Morozov",
      "Ziawasch Abedjan"
    ],
    "published": "2026-02-25",
    "categories": [
      "cs.DB",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.21766v1",
    "arxiv_url": "https://arxiv.org/abs/2602.21766v1",
    "fetched_at": "2026-02-26T08:54:11.685821",
    "chinese_title": "RAMSeS：时间序列异常检测算法的鲁棒自适应模型选择",
    "chinese_summary": "论文针对时间序列数据跨领域差异大导致通用异常检测器失效的问题，提出RAMSeS框架：包含遗传算法优化的堆叠集成分支（利用互补检测器）和自适应模型选择分支（结合汤普森采样、GAN鲁棒性测试等识别最优单检测器），双策略结合多模型优势与数据集特性适应，实验显示其F1性能优于现有方法。",
    "tags": [
      "Anomaly",
      "Time Series",
      "Deep Learning"
    ],
    "key_contributions": [
      "通过汤普森采样、GAN鲁棒性测试等技术，实现时间序列异常检测的鲁棒性与跨领域适应性，实验F1优于现有方法"
    ],
    "processed_at": "2026-02-26T08:58:04.851898"
  },
  {
    "id": "2602.21252v1",
    "title": "INTACT: Intent-Aware Representation Learning for Cryptographic Traffic Violation Detection",
    "abstract": "Security monitoring systems typically treat anomaly detection as identifying statistical deviations from observed data distributions. In cryptographic traffic analysis, however, violations are defined not by rarity but by explicit policy constraints, including key reuse prohibition, downgrade prevention, and bounded key lifetimes. This fundamental mismatch limits the interpretability and adaptability of conventional anomaly detection methods. We introduce INTACT (INTent-Aware Cryptographic Traffic), a policy-conditioned framework that reformulates violation detection as conditional constraint learning. Instead of learning a static decision boundary over behavioral features, INTACT models the probability of violation conditioned on both observed behavior and declared security intent. The architecture factorizes representation learning into behavioral and intent encoders whose fused embeddings produce a violation score, yielding a policy-parameterized family of decision boundaries. We evaluate the framework on a real-world network flow dataset and a 210,000-trace synthetic multi-intent cryptographic dataset. INTACT matches or exceeds strong unsupervised and supervised baselines, achieving near-perfect discrimination (AUROC up to 1.0000) in the real dataset and consistent superiority in detecting relational and composite violations in the synthetic setting. These results demonstrate that explicit intent conditioning improves discrimination, interpretability, and robustness in cryptographic monitoring.",
    "authors": [
      "Rahul D Ray"
    ],
    "published": "2026-02-22",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.21252v1",
    "arxiv_url": "https://arxiv.org/abs/2602.21252v1",
    "fetched_at": "2026-02-26T08:54:11.686152",
    "chinese_title": "INTACT：用于加密流量违规检测的意图感知表示学习",
    "chinese_summary": "传统异常检测将加密流量违规视为统计偏差，但实际违规由政策约束定义，存在可解释性和适应性局限；论文提出INTACT框架，重构违规检测为条件约束学习，通过行为与意图编码器融合嵌入生成违规分数，结合政策参数化决策边界；在真实与合成数据集上评估，其性能优于基线，提升了检测的判别性、可解释性与鲁棒性。",
    "tags": [
      "Anomaly",
      "Deep Learning",
      "Risk Management"
    ],
    "key_contributions": [
      "针对传统异常检测与加密流量违规政策约束不匹配的问题，提出INTACT框架，将违规检测重构为条件约束学习",
      "设计行为与意图编码器融合的表示学习架构，结合政策参数化决策边界，在真实与合成数据集上实现优于基线的检测性能，提升判别性、可解释性与鲁棒性"
    ],
    "processed_at": "2026-02-26T08:58:20.113161"
  },
  {
    "id": "2602.22056v1",
    "title": "FlowCorrect: Efficient Interactive Correction of Generative Flow Policies for Robotic Manipulation",
    "abstract": "Generative manipulation policies can fail catastrophically under deployment-time distribution shift, yet many failures are near-misses: the robot reaches almost-correct poses and would succeed with a small corrective motion. We present FlowCorrect, a deployment-time correction framework that converts near-miss failures into successes using sparse human nudges, without full policy retraining. During execution, a human provides brief corrective pose nudges via a lightweight VR interface. FlowCorrect uses these sparse corrections to locally adapt the policy, improving actions without retraining the backbone while preserving the model performance on previously learned scenarios. We evaluate on a real-world robot across three tabletop tasks: pick-and-place, pouring, and cup uprighting. With a low correction budget, FlowCorrect improves success on hard cases by 85\\% while preserving performance on previously solved scenarios. The results demonstrate clearly that FlowCorrect learns only with very few demonstrations and enables fast and sample-efficient incremental, human-in-the-loop corrections of generative visuomotor policies at deployment time in real-world robotics.",
    "authors": [
      "Edgar Welte",
      "Yitian Shi",
      "Rosa Wolf",
      "Maximillian Gilles",
      "Rania Rayyes"
    ],
    "published": "2026-02-25",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.22056v1",
    "arxiv_url": "https://arxiv.org/abs/2602.22056v1",
    "fetched_at": "2026-02-26T08:54:40.629583",
    "chinese_title": "FlowCorrect：用于机器人操纵的生成流策略高效交互式修正",
    "chinese_summary": "针对生成式操纵策略在部署时分布偏移下的灾难性失败问题，提出FlowCorrect框架，通过VR界面的稀疏人类轻推局部适配策略，无需全量重训主干网络，在保持已学场景性能的同时以低修正成本提升困难案例成功率85%，实现部署时快速样本高效的人机环修正。",
    "tags": [
      "Deep Learning"
    ],
    "key_contributions": [
      "提出无需全量重训主干网络、仅用稀疏人类轻推即可局部适配生成式视觉运动策略的FlowCorrect部署时修正框架",
      "在真实机器人任务中验证，低修正预算下提升困难案例成功率85%且保持已学场景性能，实现快速样本高效的人机环修正"
    ],
    "processed_at": "2026-02-26T08:58:38.138210"
  },
  {
    "id": "2602.21947v1",
    "title": "Large Language Models are Algorithmically Blind",
    "abstract": "Large language models (LLMs) demonstrate remarkable breadth of knowledge, yet their ability to reason about computational processes remains poorly understood. Closing this gap matters for practitioners who rely on LLMs to guide algorithm selection and deployment. We address this limitation using causal discovery as a testbed and evaluate eight frontier LLMs against ground truth derived from large-scale algorithm executions and find systematic, near-total failure. Models produce ranges far wider than true confidence intervals yet still fail to contain the true algorithmic mean in the majority of instances; most perform worse than random guessing and the marginal above-random performance of the best model is most consistent with benchmark memorization rather than principled reasoning. We term this failure algorithmic blindness and argue it reflects a fundamental gap between declarative knowledge about algorithms and calibrated procedural prediction.",
    "authors": [
      "Sohan Venkatesh",
      "Ashish Mahendran Kurapath",
      "Tejas Melkote"
    ],
    "published": "2026-02-25",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.21947v1",
    "arxiv_url": "https://arxiv.org/abs/2602.21947v1",
    "fetched_at": "2026-02-26T08:54:40.629615",
    "chinese_title": "大语言模型存在算法盲性",
    "chinese_summary": "本文以因果发现为测试床，评估8个前沿大语言模型对算法计算过程的推理能力，发现其存在系统性几乎完全失败的“算法盲性”——预测区间远宽于真实置信区间，多数未包含真实算法均值，表现劣于随机猜测，最好模型的微弱优势更可能源于记忆而非原则性推理；该问题反映陈述性算法知识与校准过程预测的根本差距。",
    "tags": [
      "LLM",
      "Benchmark",
      "Algorithmic Trading"
    ],
    "key_contributions": [
      "系统揭示前沿大语言模型在算法计算过程推理中存在“算法盲性”的系统性缺陷",
      "指出该缺陷源于陈述性算法知识与校准过程预测的根本差距，而非随机误差或有效推理能力"
    ],
    "processed_at": "2026-02-26T08:59:00.393035"
  },
  {
    "id": "2602.21858v1",
    "title": "ProactiveMobile: A Comprehensive Benchmark for Boosting Proactive Intelligence on Mobile Devices",
    "abstract": "Multimodal large language models (MLLMs) have made significant progress in mobile agent development, yet their capabilities are predominantly confined to a reactive paradigm, where they merely execute explicit user commands. The emerging paradigm of proactive intelligence, where agents autonomously anticipate needs and initiate actions, represents the next frontier for mobile agents. However, its development is critically bottlenecked by the lack of benchmarks that can address real-world complexity and enable objective, executable evaluation. To overcome these challenges, we introduce ProactiveMobile, a comprehensive benchmark designed to systematically advance research in this domain. ProactiveMobile formalizes the proactive task as inferring latent user intent across four dimensions of on-device contextual signals and generating an executable function sequence from a comprehensive function pool of 63 APIs. The benchmark features over 3,660 instances of 14 scenarios that embrace real-world complexity through multi-answer annotations. To ensure quality, a team of 30 experts conducts a final audit of the benchmark, verifying factual accuracy, logical consistency, and action feasibility, and correcting any non-compliant entries. Extensive experiments demonstrate that our fine-tuned Qwen2.5-VL-7B-Instruct achieves a success rate of 19.15%, outperforming o1 (15.71%) and GPT-5 (7.39%). This result indicates that proactivity is a critical competency widely lacking in current MLLMs, yet it is learnable, emphasizing the importance of the proposed benchmark for proactivity evaluation.",
    "authors": [
      "Dezhi Kong",
      "Zhengzhao Feng",
      "Qiliang Liang",
      "Hao Wang",
      "Haofei Sun",
      "Changpeng Yang",
      "Yang Li",
      "Peng Zhou",
      "Shuai Nie",
      "Hongzhen Wang",
      "Linfeng Zhou",
      "Hao Jia",
      "Jiaming Xu",
      "Runyu Shi",
      "Ying Huang"
    ],
    "published": "2026-02-25",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.21858v1",
    "arxiv_url": "https://arxiv.org/abs/2602.21858v1",
    "fetched_at": "2026-02-26T08:54:40.629658",
    "chinese_title": "ProactiveMobile：提升移动设备主动智能的综合基准",
    "chinese_summary": "针对移动设备主动智能缺乏有效基准的问题，论文提出ProactiveMobile综合基准，形式化主动任务为从4维度上下文推断潜在意图并生成63个API的可执行函数序列，包含14场景3660+多答案实例且经专家审核；实验表明微调的Qwen2.5-VL-7B-Instruct主动任务成功率优于o1和GPT-5，凸显当前多模态大模型主动能力不足。",
    "tags": [
      "LLM",
      "Benchmark",
      "Transformer"
    ],
    "key_contributions": [
      "提出ProactiveMobile综合基准，填补移动设备主动智能领域缺乏可客观评估基准的空白，该基准包含14场景3660+多答案实例，经专家审核确保质量",
      "通过实验验证当前主流多模态大模型主动能力普遍不足，为后续主动智能研究提供评估标准和参考"
    ],
    "processed_at": "2026-02-26T08:59:24.633071"
  },
  {
    "id": "2602.21783v1",
    "title": "Therapist-Robot-Patient Physical Interaction is Worth a Thousand Words: Enabling Intuitive Therapist Guidance via Remote Haptic Control",
    "abstract": "Robotic systems can enhance the amount and repeatability of physically guided motor training. Yet their real-world adoption is limited, partly due to non-intuitive trainer/therapist-trainee/patient interactions. To address this gap, we present a haptic teleoperation system for trainers to remotely guide and monitor the movements of a trainee wearing an arm exoskeleton. The trainer can physically interact with the exoskeleton through a commercial handheld haptic device via virtual contact points at the exoskeleton's elbow and wrist, allowing intuitive guidance. Thirty-two participants tested the system in a trainer-trainee paradigm, comparing our haptic demonstration system with conventional visual demonstration in guiding trainees in executing arm poses. Quantitative analyses showed that haptic demonstration significantly reduced movement completion time and improved smoothness, while speech analysis using large language models for automated transcription and categorization of verbal commands revealed fewer verbal instructions. The haptic demonstration did not result in higher reported mental and physical effort by trainers compared to the visual demonstration, while trainers reported greater competence and trainees lower physical demand. These findings support the feasibility of our proposed interface for effective remote human-robot physical interaction. Future work should assess its usability and efficacy for clinical populations in restoring clinicians' sense of agency during robot-assisted therapy.",
    "authors": [
      "Beatrice Luciani",
      "Alex van den Berg",
      "Matti Lang",
      "Alexandre L. Ratschat",
      "Laura Marchal-Crespo"
    ],
    "published": "2026-02-25",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.21783v1",
    "arxiv_url": "https://arxiv.org/abs/2602.21783v1",
    "fetched_at": "2026-02-26T08:54:40.629683",
    "chinese_title": "治疗师-机器人-患者物理交互胜千言：通过远程触觉控制实现直观治疗师指导",
    "chinese_summary": "论文提出一种基于商用手持触觉设备的远程触觉遥操作系统，治疗师可通过外骨骼肘部和腕部的虚拟接触点直观引导患者运动；32名参与者测试显示，该系统显著减少运动完成时间、提升动作流畅度，减少 verbal指令，且治疗师/患者的努力感知更优，验证了临床应用可行性。",
    "tags": [
      "LLM",
      "NLP"
    ],
    "key_contributions": [
      "提出直观的触觉遥操作接口，解决传统机器人辅助训练交互不直观的问题",
      "通过实验验证该系统在提升训练效率、减少指令量及优化用户感知方面的优势，支持临床应用潜力"
    ],
    "processed_at": "2026-02-26T08:59:39.278048"
  },
  {
    "id": "2602.21680v1",
    "title": "Hierarchical Lead Critic based Multi-Agent Reinforcement Learning",
    "abstract": "Cooperative Multi-Agent Reinforcement Learning (MARL) solves complex tasks that require coordination from multiple agents, but is often limited to either local (independent learning) or global (centralized learning) perspectives. In this paper, we introduce a novel sequential training scheme and MARL architecture, which learns from multiple perspectives on different hierarchy levels. We propose the Hierarchical Lead Critic (HLC) - inspired by natural emerging distributions in team structures, where following high-level objectives combines with low-level execution. HLC demonstrates that introducing multiple hierarchies, leveraging local and global perspectives, can lead to improved performance with high sample efficiency and robust policies. Experimental results conducted on cooperative, non-communicative, and partially observable MARL benchmarks demonstrate that HLC outperforms single hierarchy baselines and scales robustly with increasing amounts of agents and difficulty.",
    "authors": [
      "David Eckel",
      "Henri Meeß"
    ],
    "published": "2026-02-25",
    "categories": [
      "cs.LG",
      "cs.MA"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.21680v1",
    "arxiv_url": "https://arxiv.org/abs/2602.21680v1",
    "fetched_at": "2026-02-26T08:54:40.629706",
    "chinese_title": "基于分层引导批评者的多智能体强化学习",
    "chinese_summary": "针对合作多智能体强化学习（MARL）常局限于局部或全局单视角的问题，论文提出分层引导批评者（HLC）架构及序贯训练方案，融合不同层次的局部与全局视角；实验表明HLC在多类MARL基准上优于单层次基线，且随智能体数量和难度增加仍保持稳健性能与高样本效率。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "提出分层引导批评者（HLC）架构及序贯训练方案，融合多层次局部与全局视角，突破传统MARL单视角局限",
      "在合作、非通信、部分可观测MARL基准上验证HLC优于单层次基线，且随智能体数量/难度增加仍保持稳健性能与高样本效率"
    ],
    "processed_at": "2026-02-26T09:00:02.081645"
  },
  {
    "id": "2602.21670v1",
    "title": "Hierarchical LLM-Based Multi-Agent Framework with Prompt Optimization for Multi-Robot Task Planning",
    "abstract": "Multi-robot task planning requires decomposing natural-language instructions into executable actions for heterogeneous robot teams. Conventional Planning Domain Definition Language (PDDL) planners provide rigorous guarantees but struggle to handle ambiguous or long-horizon missions, while large language models (LLMs) can interpret instructions and propose plans but may hallucinate or produce infeasible actions. We present a hierarchical multi-agent LLM-based planner with prompt optimization: an upper layer decomposes tasks and assigns them to lower-layer agents, which generate PDDL problems solved by a classical planner. When plans fail, the system applies TextGrad-inspired textual-gradient updates to optimize each agent's prompt and thereby improve planning accuracy. In addition, meta-prompts are learned and shared across agents within the same layer, enabling efficient prompt optimization in multi-agent settings. On the MAT-THOR benchmark, our planner achieves success rates of 0.95 on compound tasks, 0.84 on complex tasks, and 0.60 on vague tasks, improving over the previous state-of-the-art LaMMA-P by 2, 7, and 15 percentage points respectively. An ablation study shows that the hierarchical structure, prompt optimization, and meta-prompt sharing contribute roughly +59, +37, and +4 percentage points to the overall success rate.",
    "authors": [
      "Tomoya Kawabe",
      "Rin Takano"
    ],
    "published": "2026-02-25",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.21670v1",
    "arxiv_url": "https://arxiv.org/abs/2602.21670v1",
    "fetched_at": "2026-02-26T08:54:40.629727",
    "chinese_title": "带提示优化的分层LLM多智能体框架用于多机器人任务规划",
    "chinese_summary": "本文提出一种带提示优化的分层LLM多智能体框架用于多机器人任务规划，上层分解任务并分配给下层代理，下层生成PDDL问题由经典规划器求解，任务失败时通过TextGrad启发的文本梯度更新优化提示，且同层代理共享元提示以提升效率；在MAT-THOR基准上，该框架在复合、复杂、模糊任务上的成功率较之前SOTA分别提升2、7、15个百分点， ablation实验验证了各模块的贡献。",
    "tags": [
      "LLM",
      "NLP",
      "Transformer"
    ],
    "key_contributions": [
      "设计带提示优化的分层LLM多智能体规划框架，融合任务分解、PDDL生成+经典规划、TextGrad启发提示更新及元提示共享，提升规划准确性与效率；",
      "在MAT-THOR基准上显著提升多机器人任务规划成功率， ablation实验量化分层结构、提示优化、元提示共享的贡献。"
    ],
    "processed_at": "2026-02-26T09:00:25.569169"
  },
  {
    "id": "2602.21634v1",
    "title": "AgentLTV: An Agent-Based Unified Search-and-Evolution Framework for Automated Lifetime Value Prediction",
    "abstract": "Lifetime Value (LTV) prediction is critical in advertising, recommender systems, and e-commerce. In practice, LTV data patterns vary across decision scenarios. As a result, practitioners often build complex, scenario-specific pipelines and iterate over feature processing, objective design, and tuning. This process is expensive and hard to transfer. We propose AgentLTV, an agent-based unified search-and-evolution framework for automated LTV modeling. AgentLTV treats each candidate solution as an {executable pipeline program}. LLM-driven agents generate code, run and repair pipelines, and analyze execution feedback. Two decision agents coordinate a two-stage search. The Monte Carlo Tree Search (MCTS) stage explores a broad space of modeling choices under a fixed budget, guided by the Polynomial Upper Confidence bounds for Trees criterion and a Pareto-aware multi-metric value function. The Evolutionary Algorithm (EA) stage refines the best MCTS program via island-based evolution with crossover, mutation, and migration. Experiments on a large-scale proprietary dataset and a public benchmark show that AgentLTV consistently discovers strong models across ranking and error metrics. Online bucket-level analysis further indicates improved ranking consistency and value calibration, especially for high-value and negative-LTV segments. We summarize practitioner-oriented takeaways: use MCTS for rapid adaptation to new data patterns, use EA for stable refinement, and validate deployment readiness with bucket-level ranking and calibration diagnostics. The proposed AgentLTV has been successfully deployed online.",
    "authors": [
      "Chaowei Wu",
      "Huazhu Chen",
      "Congde Yuan",
      "Qirui Yang",
      "Guoqing Song",
      "Yue Gao",
      "Li Luo",
      "Frank Youhua Chen",
      "Mengzhuo Guo"
    ],
    "published": "2026-02-25",
    "categories": [
      "cs.LG",
      "cs.MA"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.21634v1",
    "arxiv_url": "https://arxiv.org/abs/2602.21634v1",
    "fetched_at": "2026-02-26T08:54:40.629758",
    "chinese_title": "AgentLTV：基于智能体的自动化客户终身价值预测统一搜索与进化框架",
    "chinese_summary": "针对客户终身价值（LTV）预测中场景特定建模 pipeline 复杂难迁移的问题，论文提出AgentLTV框架，以可执行pipeline为候选解，通过LLM驱动智能体生成、运行及修复 pipeline，结合蒙特卡洛树搜索（MCTS）探索建模空间与进化算法（EA）细化最优解；实验在私有大规模数据集和公开基准上验证了其模型效果，线上桶分析进一步表明其提升了高价值及负LTV segment的排序一致性与价值校准能力。",
    "tags": [
      "LLM",
      "Financial Agent",
      "Time Series",
      "Benchmark"
    ],
    "key_contributions": [
      "提出基于智能体的统一框架AgentLTV，将LTV建模候选解视为可执行pipeline，通过LLM驱动智能体协调MCTS探索与EA细化，实现自动化跨场景LTV建模",
      "实验验证AgentLTV在公开基准与私有大规模数据集上的有效性，线上分析显示其对高价值及负LTV segment的排序一致性和价值校准有显著改进"
    ],
    "processed_at": "2026-02-26T09:00:46.794195"
  },
  {
    "id": "2602.21597v1",
    "title": "NGDB-Zoo: Towards Efficient and Scalable Neural Graph Databases Training",
    "abstract": "Neural Graph Databases (NGDBs) facilitate complex logical reasoning over incomplete knowledge structures, yet their training efficiency and expressivity are constrained by rigid query-level batching and structure-exclusive embeddings. We present NGDB-Zoo, a unified framework that resolves these bottlenecks by synergizing operator-level training with semantic augmentation. By decoupling logical operators from query topologies, NGDB-Zoo transforms the training loop into a dynamically scheduled data-flow execution, enabling multi-stream parallelism and achieving a $1.8\\times$ - $6.8\\times$ throughput compared to baselines. Furthermore, we formalize a decoupled architecture to integrate high-dimensional semantic priors from Pre-trained Text Encoders (PTEs) without triggering I/O stalls or memory overflows. Extensive evaluations on six benchmarks, including massive graphs like ogbl-wikikg2 and ATLAS-Wiki, demonstrate that NGDB-Zoo maintains high GPU utilization across diverse logical patterns and significantly mitigates representation friction in hybrid neuro-symbolic reasoning.",
    "authors": [
      "Zhongwei Xie",
      "Jiaxin Bai",
      "Shujie Liu",
      "Haoyu Huang",
      "Yufei Li",
      "Yisen Gao",
      "Hong Ting Tsang",
      "Yangqiu Song"
    ],
    "published": "2026-02-25",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.21597v1",
    "arxiv_url": "https://arxiv.org/abs/2602.21597v1",
    "fetched_at": "2026-02-26T08:54:40.629787",
    "chinese_title": "NGDB-Zoo：面向高效可扩展的神经图数据库训练",
    "chinese_summary": "针对神经图数据库（NGDBs）训练效率与表达性受限问题，本文提出NGDB-Zoo统一框架：通过解耦逻辑算子与查询拓扑，动态调度数据流实现多流并行，吞吐量较基线提升1.8×-6.8×；同时形式化解耦架构整合预训练文本编码器的语义先验，避免I/O阻塞与内存溢出，在多基准验证其高GPU利用率与表示摩擦缓解效果。",
    "tags": [
      "Graph Neural Network",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "提出NGDB-Zoo统一框架，通过算子级训练与动态数据流调度实现多流并行，显著提升神经图数据库训练吞吐量（1.8×-6.8×）",
      "形式化解耦架构整合预训练文本编码器的高维语义先验，避免I/O阻塞与内存溢出，缓解混合神经符号推理的表示摩擦"
    ],
    "processed_at": "2026-02-26T09:01:06.413720"
  },
  {
    "id": "2602.21496v1",
    "title": "Beyond Refusal: Probing the Limits of Agentic Self-Correction for Semantic Sensitive Information",
    "abstract": "While defenses for structured PII are mature, Large Language Models (LLMs) pose a new threat: Semantic Sensitive Information (SemSI), where models infer sensitive identity attributes, generate reputation-harmful content, or hallucinate potentially wrong information. The capacity of LLMs to self-regulate these complex, context-dependent sensitive information leaks without destroying utility remains an open scientific question. To address this, we introduce SemSIEdit, an inference-time framework where an agentic \"Editor\" iteratively critiques and rewrites sensitive spans to preserve narrative flow rather than simply refusing to answer. Our analysis reveals a Privacy-Utility Pareto Frontier, where this agentic rewriting reduces leakage by 34.6% across all three SemSI categories while incurring a marginal utility loss of 9.8%. We also uncover a Scale-Dependent Safety Divergence: large reasoning models (e.g., GPT-5) achieve safety through constructive expansion (adding nuance), whereas capacity-constrained models revert to destructive truncation (deleting text). Finally, we identify a Reasoning Paradox: while inference-time reasoning increases baseline risk by enabling the model to make deeper sensitive inferences, it simultaneously empowers the defense to execute safe rewrites.",
    "authors": [
      "Umid Suleymanov",
      "Zaur Rajabov",
      "Emil Mirzazada",
      "Murat Kantarcioglu"
    ],
    "published": "2026-02-25",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.21496v1",
    "arxiv_url": "https://arxiv.org/abs/2602.21496v1",
    "fetched_at": "2026-02-26T08:54:40.629809",
    "chinese_title": "超越拒绝：探究智能体自我修正语义敏感信息的边界",
    "chinese_summary": "该论文针对大语言模型（LLM）的语义敏感信息（SemSI）泄露问题，提出推理时框架SemSIEdit，通过智能体“编辑者”迭代批判改写敏感片段以保留叙事流畅性；分析发现隐私-效用帕累托前沿、规模依赖安全差异及推理悖论等关键结论。",
    "tags": [
      "LLM",
      "NLP"
    ],
    "key_contributions": [
      "提出推理时框架SemSIEdit，通过智能体迭代改写敏感片段解决LLM语义敏感信息泄露问题，实现隐私与效用的平衡",
      "揭示LLM在语义敏感信息处理中的三个核心规律：隐私-效用帕累托前沿、规模依赖安全差异、推理悖论"
    ],
    "processed_at": "2026-02-26T09:01:17.901824"
  },
  {
    "id": "2602.21480v1",
    "title": "Both Ends Count! Just How Good are LLM Agents at \"Text-to-Big SQL\"?",
    "abstract": "Text-to-SQL and Big Data are both extensively benchmarked fields, yet there is limited research that evaluates them jointly. In the real world, Text-to-SQL systems are often embedded with Big Data workflows, such as large-scale data processing or interactive data analytics. We refer to this as \"Text-to-Big SQL\". However, existing text-to-SQL benchmarks remain narrowly scoped and overlook the cost and performance implications that arise at scale. For instance, translation errors that are minor on small datasets lead to substantial cost and latency overheads as data scales, a relevant issue completely ignored by text-to-SQL metrics.   In this paper, we overcome this overlooked challenge by introducing novel and representative metrics for evaluating Text-to-Big SQL. Our study focuses on production-level LLM agents, a database-agnostic system adaptable to diverse user needs. Via an extensive evaluation of frontier models, we show that text-to-SQL metrics are insufficient for Big Data. In contrast, our proposed text-to-Big SQL metrics accurately reflect execution efficiency, cost, and the impact of data scale. Furthermore, we provide LLM-specific insights, including fine-grained, cross-model comparisons of latency and cost.",
    "authors": [
      "Germán T. Eizaguirre",
      "Lars Tissen",
      "Marc Sánchez-Artigas"
    ],
    "published": "2026-02-25",
    "categories": [
      "cs.DB",
      "cs.CL",
      "cs.IR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.21480v1",
    "arxiv_url": "https://arxiv.org/abs/2602.21480v1",
    "fetched_at": "2026-02-26T08:54:40.629833",
    "chinese_title": "两端皆重！LLM智能体在‘文本转大数据SQL’任务中的表现究竟如何？",
    "chinese_summary": "该论文针对现有文本转SQL基准未覆盖大数据场景下成本、性能等问题的不足，提出Text-to-Big SQL的新型评估指标；通过评估生产级LLM智能体发现传统指标无法适配大数据场景，新指标可准确反映执行效率、成本及数据规模影响，并给出LLM跨模型的延迟与成本对比。",
    "tags": [
      "LLM",
      "NLP",
      "Benchmark"
    ],
    "key_contributions": [
      "提出针对Text-to-Big SQL的新型代表性评估指标，弥补现有文本转SQL基准忽略大数据场景成本、性能等问题的不足",
      "评估前沿生产级LLM智能体，揭示传统文本转SQL指标无法适配大数据场景，新指标可准确反映执行效率、成本及数据规模影响，并提供LLM跨模型的延迟与成本对比"
    ],
    "processed_at": "2026-02-26T09:01:34.760979"
  },
  {
    "id": "2602.21401v1",
    "title": "The Headless Firm: How AI Reshapes Enterprise Boundaries",
    "abstract": "The boundary of the firm is determined by coordination cost. We argue that agentic AI induces a structural change in how coordination costs scale: in prior modular systems, integration cost grew with interaction topology (O(n^2) in the number of components); in protocol-mediated agentic systems, integration cost collapses to O(n) while verification scales with task throughput rather than interaction count. This shift selects for a specific organizational equilibrium -- the Headless Firm -- structured as an hourglass: a personalized generative interface at the top, a standardized protocol waist in the middle, and a competitive market of micro-specialized execution agents at the bottom. We formalize this claim as a coordination cost model with two falsifiable empirical predictions: (1) the marginal cost of adding an execution provider should be approximately constant in a mature hourglass ecosystem; (2) the ratio of total coordination cost to task throughput should remain stable as ecosystem size grows. We derive conditions for hourglass stability versus re-centralization and analyze implications for firm size distributions, labor markets, and software economics. The analysis predicts a domain-conditional Great Unbundling: in high knowledge-velocity domains, firm size distributions shift mass from large integrated incumbents toward micro-specialized agents and thin protocol orchestrators.",
    "authors": [
      "Tassilo Klein",
      "Sebastian Wieczorek"
    ],
    "published": "2026-02-24",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.SI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.21401v1",
    "arxiv_url": "https://arxiv.org/abs/2602.21401v1",
    "fetched_at": "2026-02-26T08:54:40.629852",
    "chinese_title": "无头企业：AI如何重塑企业边界",
    "chinese_summary": "该研究以协调成本为核心，指出agentic AI使企业集成成本从O(n²)降至O(n)，验证成本随任务吞吐量而非交互数变化；提出“无头企业”沙漏结构（顶部个性化生成界面、中间标准化协议、底部微专业化执行代理市场），形式化模型并给出两个可证伪预测，分析其对企业规模、劳动力市场等的影响，预测高知识速度领域的“大解绑”现象。",
    "tags": [
      "Financial Agent",
      "Deep Learning"
    ],
    "key_contributions": [
      "揭示agentic AI对企业协调成本的结构性影响（集成成本从O(n²)到O(n)，验证成本随吞吐量变化），定义“无头企业”沙漏结构",
      "形式化协调成本模型，提出两个可证伪预测，分析其对企业规模分布、劳动力市场等的影响，预测高知识速度领域的“大解绑”"
    ],
    "processed_at": "2026-02-26T09:02:02.618406"
  },
  {
    "id": "2602.21351v1",
    "title": "A Hierarchical Multi-Agent System for Autonomous Discovery in Geoscientific Data Archives",
    "abstract": "The rapid accumulation of Earth science data has created a significant scalability challenge; while repositories like PANGAEA host vast collections of datasets, citation metrics indicate that a substantial portion remains underutilized, limiting data reusability. Here we present PANGAEA-GPT, a hierarchical multi-agent framework designed for autonomous data discovery and analysis. Unlike standard Large Language Model (LLM) wrappers, our architecture implements a centralized Supervisor-Worker topology with strict data-type-aware routing, sandboxed deterministic code execution, and self-correction via execution feedback, enabling agents to diagnose and resolve runtime errors. Through use-case scenarios spanning physical oceanography and ecology, we demonstrate the system's capacity to execute complex, multi-step workflows with minimal human intervention. This framework provides a methodology for querying and analyzing heterogeneous repository data through coordinated agent workflows.",
    "authors": [
      "Dmitrii Pantiukhin",
      "Ivan Kuznetsov",
      "Boris Shapkin",
      "Antonia Anna Jost",
      "Thomas Jung",
      "Nikolay Koldunov"
    ],
    "published": "2026-02-24",
    "categories": [
      "cs.AI",
      "cs.IR",
      "cs.MA"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.21351v1",
    "arxiv_url": "https://arxiv.org/abs/2602.21351v1",
    "fetched_at": "2026-02-26T08:54:40.629878",
    "chinese_title": "用于地球科学数据档案自主发现的分层多智能体系统",
    "chinese_summary": "该论文针对地球科学数据积累的可扩展性挑战，提出PANGAEA-GPT分层多智能体框架；其采用集中式监督- worker拓扑，具备数据类型感知路由、沙盒确定性代码执行及执行反馈自纠正能力，可实现最小人工干预的复杂多步骤工作流，为异构库数据查询分析提供方法。",
    "tags": [
      "LLM",
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "验证框架可在地球科学领域实现最小人工干预的复杂多步骤工作流，提升数据可复用性"
    ],
    "processed_at": "2026-02-26T09:02:21.082773"
  }
]