[
  {
    "id": "2601.09324v1",
    "title": "Martingale expansion for stochastic volatility",
    "abstract": "The martingale expansion provides a refined approximation to the marginal distributions of martingales beyond the normal approximation implied by the martingale central limit theorem. We develop a martingale expansion framework specifically suited to continuous stochastic volatility models. Our approach accommodates both small volatility-of-volatility and fast mean-reversion models, yielding first-order perturbation expansions under essentially minimal conditions.",
    "authors": [
      "Masaaki Fukasawa"
    ],
    "published": "2026-01-14",
    "categories": [
      "math.PR",
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09324v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09324v1",
    "fetched_at": "2026-01-15T08:38:27.128019",
    "chinese_title": "随机波动率的鞅展开",
    "chinese_summary": "本文提出适用于连续随机波动率模型的鞅展开框架，超越鞅中心极限定理的正态近似以提供更精细的边际分布近似；该框架可适应小波动率-of-波动率及快速均值回复模型，在基本最小条件下得到一阶扰动展开。",
    "tags": [
      "Volatility",
      "Options",
      "Asset Pricing"
    ],
    "key_contributions": [
      "提出适用于连续随机波动率模型的鞅展开框架，超越正态近似实现更精细的鞅边际分布近似",
      "框架可同时适应小波动率-of-波动率和快速均值回复模型，且在基本最小条件下得到一阶扰动展开"
    ],
    "processed_at": "2026-01-15T08:41:31.627752"
  },
  {
    "id": "2601.09127v1",
    "title": "Robo-Advising in Motion: A Model Predictive Control Approach",
    "abstract": "Robo-advisors (RAs) are automated portfolio management systems that complement traditional financial advisors by offering lower fees and smaller initial investment requirements. While most existing RAs rely on static, one-period allocation methods, we propose a dynamic, multi-period asset-allocation framework that leverages Model Predictive Control (MPC) to generate suboptimal but practically effective strategies. Our approach combines a Hidden Markov Model with Black-Litterman (BL) methodology to forecast asset returns and covariances, and incorporates practically important constraints, including turnover limits, transaction costs, and target portfolio allocations. We study two predominant optimality criteria in wealth management: dynamic mean-variance (MV) and dynamic risk-budgeting (MRB). Numerical experiments demonstrate that MPC-based strategies consistently outperform myopic approaches, with MV providing flexible and diversified portfolios, while MRB delivers smoother allocations less sensitive to key parameters. These findings highlight the trade-offs between adaptability and stability in practical robo-advising design.",
    "authors": [
      "Tomasz R. Bielecki",
      "Igor Cialenco"
    ],
    "published": "2026-01-14",
    "categories": [
      "q-fin.PM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09127v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09127v1",
    "fetched_at": "2026-01-15T08:38:27.128057",
    "chinese_title": "动态智能投顾：一种模型预测控制方法",
    "chinese_summary": "现有智能投顾多依赖静态单期资产配置方法，本文提出基于模型预测控制（MPC）的动态多期框架，结合隐马尔可夫模型与Black-Litterman方法预测资产收益及协方差，纳入交易成本、换手率限制等实际约束；通过对比动态均值方差与风险预算策略，实验表明MPC策略优于短视方法，揭示智能投顾设计中适应性与稳定性的权衡。",
    "tags": [
      "Portfolio Optimization",
      "Risk Management",
      "Asset Pricing"
    ],
    "key_contributions": [
      "提出基于模型预测控制（MPC）的动态多期智能投顾资产配置框架，结合隐马尔可夫模型与Black-Litterman方法预测收益协方差并纳入实际约束",
      "通过实验验证MPC策略优于现有短视方法，揭示智能投顾设计中适应性与稳定性的权衡"
    ],
    "processed_at": "2026-01-15T08:41:53.350938"
  },
  {
    "id": "2601.09074v1",
    "title": "The Fourier estimator of spot volatility: Unbounded coefficients and jumps in the price process",
    "abstract": "In this paper we study the Fourier estimator of Malliavin and Mancino for the spot volatility. We establish the convergence of the trigonometric polynomial to the volatility's path in a setting that includes the following aspects. First, the volatility is required to satisfy a mild integrability condition, but otherwise allowed to be unbounded. Second, the price process is assumed to have cadlag paths, not necessarily continuous. We obtain convergence rates for the probability of a bad approximation in estimated coefficients, with a speed that allow to obtain an almost sure convergence and not just in probability in the estimated reconstruction of the volatility's path. This is a new result even in the setting of continuous paths. We prove that a rescaled trigonometric polynomial approximate the quadratic jump process.",
    "authors": [
      "L. J. Espinosa González",
      "Erick Treviño Aguilar"
    ],
    "published": "2026-01-14",
    "categories": [
      "q-fin.CP",
      "math.PR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09074v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09074v1",
    "fetched_at": "2026-01-15T08:38:27.128082",
    "chinese_title": "即期波动率的傅里叶估计：无界系数与价格过程中的跳跃",
    "chinese_summary": "本文研究Malliavin和Mancino的即期波动率傅里叶估计，在波动率仅满足温和可积条件（允许无界）、价格过程为 càdlàg路径（非连续）的设定下，建立三角多项式向波动率路径的收敛性，得到估计系数近似误差的概率收敛速率及几乎必然收敛（连续路径下为新结果），并证明 rescaled三角多项式可近似二次跳跃过程。",
    "tags": [
      "Volatility",
      "High Frequency",
      "Market Microstructure",
      "Options"
    ],
    "key_contributions": [
      "放宽傅里叶波动率估计的假设：允许波动率无界（仅温和可积）、价格过程含跳跃（càdlàg路径），建立三角多项式向波动率路径的收敛性，实现几乎必然收敛（连续路径下为新结果）",
      "证明 rescaled三角多项式可近似价格过程的二次跳跃过程"
    ],
    "processed_at": "2026-01-15T08:42:15.405659"
  },
  {
    "id": "2601.08896v1",
    "title": "XGBoost Forecasting of NEPSE Index Log Returns with Walk Forward Validation",
    "abstract": "This study develops a robust machine learning framework for one-step-ahead forecasting of daily log-returns in the Nepal Stock Exchange (NEPSE) Index using the XGBoost regressor. A comprehensive feature set is engineered, including lagged log-returns (up to 30 days) and established technical indicators such as short- and medium-term rolling volatility measures and the 14-period Relative Strength Index. Hyperparameter optimization is performed using Optuna with time-series cross-validation on the initial training segment. Out-of-sample performance is rigorously assessed via walk-forward validation under both expanding and fixed-length rolling window schemes across multiple lag configurations, simulating real-world deployment and avoiding lookahead bias. Predictive accuracy is evaluated using root mean squared error, mean absolute error, coefficient of determination (R-squared), and directional accuracy on both log-returns and reconstructed closing prices. Empirical results show that the optimal configuration, an expanding window with 20 lags, outperforms tuned ARIMA and Ridge regression benchmarks, achieving the lowest log-return RMSE (0.013450) and MAE (0.009814) alongside a directional accuracy of 65.15%. While the R-squared remains modest, consistent with the noisy nature of financial returns, primary emphasis is placed on relative error reduction and directional prediction. Feature importance analysis and visual inspection further enhance interpretability. These findings demonstrate the effectiveness of gradient boosting ensembles in modeling nonlinear dynamics in volatile emerging market time series and establish a reproducible benchmark for NEPSE Index forecasting.",
    "authors": [
      "Sahaj Raj Malla",
      "Shreeyash Kayastha",
      "Rumi Suwal",
      "Harish Chandra Bhandari",
      "Rajendra Adhikari"
    ],
    "published": "2026-01-13",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.ST"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.08896v1",
    "arxiv_url": "https://arxiv.org/abs/2601.08896v1",
    "fetched_at": "2026-01-15T08:38:27.128156",
    "chinese_title": "基于XGBoost与滚动验证的尼泊尔证券交易所（NEPSE）指数对数收益率预测",
    "chinese_summary": "该研究构建了针对NEPSE指数日对数收益率一步预测的XGBoost框架，通过工程化滞后收益率及滚动波动率、RSI等技术指标特征，结合Optuna超参数优化与时间序列交叉验证，采用滚动验证模拟真实部署；最优配置（20滞后扩展窗口）在误差指标与方向准确率上优于调优的ARIMA、Ridge基准，且通过特征重要性增强可解释性。",
    "tags": [
      "Time Series",
      "Benchmark",
      "Volatility"
    ],
    "key_contributions": [
      "构建了结合滚动验证避免前视偏差的NEPSE指数对数收益率预测框架，模拟真实市场部署场景",
      "最优XGBoost配置在误差指标与方向准确率上优于调优的传统基准模型，且提升了模型可解释性"
    ],
    "processed_at": "2026-01-15T08:42:38.461994"
  },
  {
    "id": "2601.09287v1",
    "title": "Explainable Autoencoder-Based Anomaly Detection in IEC 61850 GOOSE Networks",
    "abstract": "The IEC 61850 Generic Object-Oriented Substation Event (GOOSE) protocol plays a critical role in real-time protection and automation of digital substations, yet its lack of native security mechanisms can expose power systems to sophisticated cyberattacks. Traditional rule-based and supervised intrusion detection techniques struggle to detect protocol-compliant and zero-day attacks under significant class imbalance and limited availability of labeled data. This paper proposes an explainable, unsupervised multi-view anomaly detection framework for IEC 61850 GOOSE networks that explicitly separates semantic integrity and temporal availability. The approach employs asymmetric autoencoders trained only on real operational GOOSE traffic to learn distinct latent representations of sequence-based protocol semantics and timing-related transmission dynamics in normal traffic. Anomaly detection is implemented using reconstruction errors mixed with statistically grounded thresholds, enabling robust detection without specified attack types. Feature-level reconstruction analysis provides intrinsic explainability by directly linking detection outcomes to IEC 61850 protocol characteristics. The proposed framework is evaluated using real substation traffic for training and a public dataset containing normal traffic and message suppression, data manipulation, and denial-of-service attacks for testing. Experimental results show attack detection rates above 99% with false positives remaining below 5% of total traffic, demonstrating strong generalization across environments and effective operation under extreme class imbalance and interpretable anomaly attribution.",
    "authors": [
      "Dafne Lozano-Paredes",
      "Luis Bote-Curiel",
      "Juan Ramón Feijóo-Martínez",
      "Ismael Gómez-Talal",
      "José Luis Rojo-Álvarez"
    ],
    "published": "2026-01-14",
    "categories": [
      "cs.CR",
      "cs.LG",
      "eess.SP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09287v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09287v1",
    "fetched_at": "2026-01-15T08:38:39.879202",
    "chinese_title": "基于可解释自动编码器的IEC 61850 GOOSE网络异常检测",
    "chinese_summary": "针对IEC 61850 GOOSE协议缺乏原生安全机制且传统方法难检测合规/零日攻击的问题，本文提出无监督多视图异常检测框架，用非对称自动编码器学习正常流量的语义完整性与时序可用性特征，通过重构误差结合统计阈值实现鲁棒检测，还提供特征级可解释性，实验验证攻击检测率超99%且误报低。",
    "tags": [
      "Anomaly",
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "提出无监督多视图异常检测框架，显式分离语义完整性与时序可用性，采用非对称自动编码器学习正常IEC 61850 GOOSE流量的潜在表示",
      "通过特征级重构分析提供内在可解释性，且实验显示攻击检测率超99%、误报率低，可有效应对类不平衡与标签数据不足问题"
    ],
    "processed_at": "2026-01-15T08:43:01.131609"
  },
  {
    "id": "2601.09258v1",
    "title": "LatencyPrism: Online Non-intrusive Latency Sculpting for SLO-Guaranteed LLM Inference",
    "abstract": "LLM inference latency critically determines user experience and operational costs, directly impacting throughput under SLO constraints. Even brief latency spikes degrade service quality despite acceptable average performance. However, distributed inference environments featuring diverse software frameworks and XPU architectures combined with dynamic workloads make latency analysis challenging. Constrained by intrusive designs that necessitate service restarts or even suspension, and by hardware-bound implementations that fail to adapt to heterogeneous inference environments, existing AI profiling methods are often inadequate for real-time production analysis.   We present LatencyPrism, the first zero-intrusion multi-platform latency sculpting system. It aims to break down the inference latency across pipeline, proactively alert on inference latency anomalies, and guarantee adherence to SLOs, all without requiring code modifications or service restarts. LatencyPrism has been deployed across thousands of XPUs for over six months. It enables low-overhead real-time monitoring at batch level with alerts triggered in milliseconds. This approach distinguishes between workload-driven latency variations and anomalies indicating underlying issues with an F1-score of 0.98. We also conduct extensive experiments and investigations into root cause analysis to demonstrate LatencyPrism's capability.",
    "authors": [
      "Du Yin",
      "Jiayi Ren",
      "Xiayu Sun",
      "Tianyao Zhou",
      "Haizhu Zhou",
      "Ruiyan Ma",
      "Danyang Zhang"
    ],
    "published": "2026-01-14",
    "categories": [
      "cs.DC",
      "cs.LG",
      "cs.OS"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09258v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09258v1",
    "fetched_at": "2026-01-15T08:38:39.879241",
    "chinese_title": "LatencyPrism：面向SLO保障的LLM推理的在线非侵入式延迟塑造系统",
    "chinese_summary": "论文提出首个零侵入多平台延迟塑造系统LatencyPrism，无需代码修改或服务重启即可分解LLM推理延迟、主动告警异常并保障SLO；该系统已部署数千XPUs超六个月，毫秒级触发告警，异常检测F1得分为0.98，支持根因分析。",
    "tags": [
      "LLM",
      "Anomaly",
      "Transformer"
    ],
    "key_contributions": [
      "提出零侵入多平台延迟塑造系统LatencyPrism，无需代码修改或服务重启，实现LLM推理延迟分解、异常主动告警与SLO保障",
      "系统经大规模部署验证，具备低开销实时监控、毫秒级告警及高准确率异常检测（F1=0.98）能力，支持根因分析"
    ],
    "processed_at": "2026-01-15T08:43:21.453047"
  },
  {
    "id": "2601.09147v1",
    "title": "SSVP: Synergistic Semantic-Visual Prompting for Industrial Zero-Shot Anomaly Detection",
    "abstract": "Zero-Shot Anomaly Detection (ZSAD) leverages Vision-Language Models (VLMs) to enable supervision-free industrial inspection. However, existing ZSAD paradigms are constrained by single visual backbones, which struggle to balance global semantic generalization with fine-grained structural discriminability. To bridge this gap, we propose Synergistic Semantic-Visual Prompting (SSVP), that efficiently fuses diverse visual encodings to elevate model's fine-grained perception. Specifically, SSVP introduces the Hierarchical Semantic-Visual Synergy (HSVS) mechanism, which deeply integrates DINOv3's multi-scale structural priors into the CLIP semantic space. Subsequently, the Vision-Conditioned Prompt Generator (VCPG) employs cross-modal attention to guide dynamic prompt generation, enabling linguistic queries to precisely anchor to specific anomaly patterns. Furthermore, to address the discrepancy between global scoring and local evidence, the Visual-Text Anomaly Mapper (VTAM) establishes a dual-gated calibration paradigm. Extensive evaluations on seven industrial benchmarks validate the robustness of our method; SSVP achieves state-of-the-art performance with 93.0\\% Image-AUROC and 92.2\\% Pixel-AUROC on MVTec-AD, significantly outperforming existing zero-shot approaches.",
    "authors": [
      "Chenhao Fu",
      "Han Fang",
      "Xiuzheng Zheng",
      "Wenbo Wei",
      "Yonghua Li",
      "Hao Sun",
      "Xuelong Li"
    ],
    "published": "2026-01-14",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09147v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09147v1",
    "fetched_at": "2026-01-15T08:38:39.879270",
    "chinese_title": "SSVP：面向工业零样本异常检测的协同语义-视觉提示方法",
    "chinese_summary": "现有工业零样本异常检测（ZSAD）受单视觉骨干限制，难以平衡全局语义泛化与细粒度结构判别；本文提出SSVP，通过层次语义-视觉协同（HSVS）融合DINOv3多尺度结构先验与CLIP语义空间，结合视觉条件提示生成器（VCPG）引导动态提示生成，以及视觉-文本异常映射器（VTAM）双门校准解决全局评分与局部证据差异；在7个工业基准验证，MVTec-AD上图像AUROC达93.0%、像素AUROC92.2%，优于现有零样本方法。",
    "tags": [
      "Anomaly",
      "Deep Learning",
      "Transformer",
      "Benchmark"
    ],
    "key_contributions": [
      "提出SSVP方法，通过层次语义-视觉协同机制融合多视觉编码，提升工业异常检测的细粒度感知能力",
      "设计视觉条件提示生成器与视觉-文本异常映射器，解决零样本检测中语义锚定与评分校准问题，实现SOTA性能"
    ],
    "processed_at": "2026-01-15T08:43:36.703767"
  },
  {
    "id": "2601.08928v1",
    "title": "DriftGuard: A Hierarchical Framework for Concept Drift Detection and Remediation in Supply Chain Forecasting",
    "abstract": "Supply chain forecasting models degrade over time as real-world conditions change. Promotions shift, consumer preferences evolve, and supply disruptions alter demand patterns, causing what is known as concept drift. This silent degradation leads to stockouts or excess inventory without triggering any system warnings. Current industry practice relies on manual monitoring and scheduled retraining every 3-6 months, which wastes computational resources during stable periods while missing rapid drift events. Existing academic methods focus narrowly on drift detection without addressing diagnosis or remediation, and they ignore the hierarchical structure inherent in supply chain data. What retailers need is an end-to-end system that detects drift early, explains its root causes, and automatically corrects affected models. We propose DriftGuard, a five-module framework that addresses the complete drift lifecycle. The system combines an ensemble of four complementary detection methods, namely error-based monitoring, statistical tests, autoencoder anomaly detection, and Cumulative Sum (CUSUM) change-point analysis, with hierarchical propagation analysis to identify exactly where drift occurs across product lines. Once detected, Shapley Additive Explanations (SHAP) analysis diagnoses the root causes, and a cost-aware retraining strategy selectively updates only the most affected models. Evaluated on over 30,000 time series from the M5 retail dataset, DriftGuard achieves 97.8% detection recall within 4.2 days and delivers up to 417 return on investment through targeted remediation.",
    "authors": [
      "Shahnawaz Alam",
      "Mohammed Abdul Rahman",
      "Bareera Sadeqa"
    ],
    "published": "2026-01-13",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.08928v1",
    "arxiv_url": "https://arxiv.org/abs/2601.08928v1",
    "fetched_at": "2026-01-15T08:38:39.879291",
    "chinese_title": "DriftGuard：供应链预测中概念漂移检测与修复的分层框架",
    "chinese_summary": "针对供应链预测模型因概念漂移退化且现有方法缺诊断修复、忽略分层结构的问题，论文提出DriftGuard五层框架，结合四种互补检测方法（误差监测、统计检验、自动编码器异常检测、CUSUM变点分析）与分层传播分析定位漂移，用SHAP诊断根因并通过成本感知策略选择性更新模型；在M5零售数据集3万+时间序列上验证有效。",
    "tags": [
      "Time Series",
      "Anomaly",
      "Deep Learning",
      "Risk Management"
    ],
    "key_contributions": [
      "提出端到端的DriftGuard分层框架，完整覆盖概念漂移的检测、诊断与修复全生命周期",
      "创新结合多方法漂移检测、分层结构分析定位、SHAP根因解释及成本感知选择性重训练，解决现有方法忽略供应链数据分层性、缺乏诊断修复能力的痛点"
    ],
    "processed_at": "2026-01-15T08:43:54.332659"
  },
  {
    "id": "2601.08910v1",
    "title": "Towards a Self-Driving Trigger at the LHC: Adaptive Response in Real Time",
    "abstract": "Real-time data filtering and selection -- or trigger -- systems at high-throughput scientific facilities such as the experiments at the Large Hadron Collider (LHC) must process extremely high-rate data streams under stringent bandwidth, latency, and storage constraints. Yet these systems are typically designed as static, hand-tuned menus of selection criteria grounded in prior knowledge and simulation. In this work, we further explore the concept of a self-driving trigger, an autonomous data-filtering framework that reallocates resources and adjusts thresholds dynamically in real-time to optimize signal efficiency, rate stability, and computational cost as instrumentation and environmental conditions evolve. We introduce a benchmark ecosystem to emulate realistic collider scenarios and demonstrate real-time optimization of a menu including canonical energy sum triggers as well as modern anomaly-detection algorithms that target non-standard event topologies using machine learning. Using simulated data streams and publicly available collision data from the Compact Muon Solenoid (CMS) experiment, we demonstrate the capability to dynamically and automatically optimize trigger performance under specific cost objectives without manual retuning. Our adaptive strategy shifts trigger design from static menus with heuristic tuning to intelligent, automated, data-driven control, unlocking greater flexibility and discovery potential in future high-energy physics analyses.",
    "authors": [
      "Shaghayegh Emami",
      "Cecilia Tosciri",
      "Giovanna Salvi",
      "Zixin Ding",
      "Yuxin Chen",
      "Abhijith Gandrakota",
      "Christian Herwig",
      "David W. Miller",
      "Jennifer Ngadiuba",
      "Nhan Tran"
    ],
    "published": "2026-01-13",
    "categories": [
      "physics.ins-det",
      "cs.AI",
      "hep-ex"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.08910v1",
    "arxiv_url": "https://arxiv.org/abs/2601.08910v1",
    "fetched_at": "2026-01-15T08:38:39.879324",
    "chinese_title": "LHC上的自驱动触发系统：实时自适应响应",
    "chinese_summary": "论文针对大型强子对撞机（LHC）实验中实时数据过滤的触发系统，提出自驱动触发框架——可动态实时重分配资源、调整阈值以优化信号效率、速率稳定性和计算成本；通过模拟真实对撞场景的基准生态系统，结合模拟数据流与CMS实验公开数据，验证了无需手动重调即可自动优化触发性能的能力，推动触发设计向智能数据驱动控制转变。",
    "tags": [
      "Anomaly",
      "Benchmark",
      "Deep Learning"
    ],
    "key_contributions": [
      "构建模拟真实对撞场景的基准生态系统，验证无需手动重调即可自动优化触发性能的能力"
    ],
    "processed_at": "2026-01-15T08:44:05.254573"
  },
  {
    "id": "2601.09708v1",
    "title": "Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning",
    "abstract": "Vision-Language-Action (VLA) tasks require reasoning over complex visual scenes and executing adaptive actions in dynamic environments. While recent studies on reasoning VLAs show that explicit chain-of-thought (CoT) can improve generalization, they suffer from high inference latency due to lengthy reasoning traces. We propose Fast-ThinkAct, an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning. Fast-ThinkAct learns to reason efficiently with latent CoTs by distilling from a teacher, driven by a preference-guided objective to align manipulation trajectories that transfers both linguistic and visual planning capabilities for embodied control. This enables reasoning-enhanced policy learning that effectively connects compact reasoning to action execution. Extensive experiments across diverse embodied manipulation and reasoning benchmarks demonstrate that Fast-ThinkAct achieves strong performance with up to 89.3\\% reduced inference latency over state-of-the-art reasoning VLAs, while maintaining effective long-horizon planning, few-shot adaptation, and failure recovery.",
    "authors": [
      "Chi-Pin Huang",
      "Yunze Man",
      "Zhiding Yu",
      "Min-Hung Chen",
      "Jan Kautz",
      "Yu-Chiang Frank Wang",
      "Fu-En Yang"
    ],
    "published": "2026-01-14",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09708v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09708v1",
    "fetched_at": "2026-01-15T08:39:08.404237",
    "chinese_title": "Fast-ThinkAct：通过可语言化潜在规划实现高效视觉-语言-动作推理",
    "chinese_summary": "针对视觉-语言-动作（VLA）任务中显式思维链（CoT）推理模型泛化性好但推理延迟高的问题，提出Fast-ThinkAct框架，通过从教师模型蒸馏学习可语言化的潜在CoT，结合偏好引导目标对齐操作轨迹，高效转移语言与视觉规划能力；实验表明其推理延迟最多降低89.3%，且保持长horizon规划、少样本适应与故障恢复能力。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning",
      "LLM"
    ],
    "key_contributions": [
      "通过偏好引导目标对齐操作轨迹，有效转移语言与视觉规划能力，支持长horizon规划、少样本适应与故障恢复"
    ],
    "processed_at": "2026-01-15T08:44:23.937688"
  },
  {
    "id": "2601.09703v1",
    "title": "ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation",
    "abstract": "Code generation tasks aim to automate the conversion of user requirements into executable code, significantly reducing manual development efforts and enhancing software productivity. The emergence of large language models (LLMs) has significantly advanced code generation, though their efficiency is still impacted by certain inherent architectural constraints. Each token generation necessitates a complete inference pass, requiring persistent retention of contextual information in memory and escalating resource consumption. While existing research prioritizes inference-phase optimizations such as prompt compression and model quantization, the generation phase remains underexplored. To tackle these challenges, we propose a knowledge-infused framework named ShortCoder, which optimizes code generation efficiency while preserving semantic equivalence and readability. In particular, we introduce: (1) ten syntax-level simplification rules for Python, derived from AST-preserving transformations, achieving 18.1% token reduction without functional compromise; (2) a hybrid data synthesis pipeline integrating rule-based rewriting with LLM-guided refinement, producing ShorterCodeBench, a corpus of validated tuples of original code and simplified code with semantic consistency; (3) a fine-tuning strategy that injects conciseness awareness into the base LLMs. Extensive experimental results demonstrate that ShortCoder consistently outperforms state-of-the-art methods on HumanEval, achieving an improvement of 18.1%-37.8% in generation efficiency over previous methods while ensuring the performance of code generation.",
    "authors": [
      "Sicong Liu",
      "Yanxian Huang",
      "Mingwei Liu",
      "Jiachi Chen",
      "Ensheng Shi",
      "Yuchi Ma",
      "Hongyu Zhang",
      "Yin Zhang",
      "Yanlin Wang"
    ],
    "published": "2026-01-14",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09703v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09703v1",
    "fetched_at": "2026-01-15T08:39:08.404279",
    "chinese_title": "ShortCoder：面向令牌高效代码生成的知识增强语法优化",
    "chinese_summary": "针对大语言模型（LLM）代码生成效率受架构约束的问题，本文提出知识增强框架ShortCoder，通过设计10条基于AST保留变换的Python语法简化规则、构建混合数据合成 pipeline生成语义一致的代码语料库ShorterCodeBench，以及微调注入简洁性意识的策略，在HumanEval上优于现有方法，实现令牌高效且语义等价的代码生成。",
    "tags": [
      "LLM",
      "NLP",
      "Benchmark"
    ],
    "key_contributions": [
      "提出10条基于AST保留变换的Python语法简化规则，实现18.1%令牌减少且无功能损失",
      "构建混合数据合成 pipeline并生成语义一致的代码语料库ShorterCodeBench",
      "设计注入简洁性意识的微调策略提升LLM代码生成效率"
    ],
    "processed_at": "2026-01-15T08:44:43.560338"
  },
  {
    "id": "2601.09636v1",
    "title": "PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records",
    "abstract": "While GUI agents have shown strong performance under explicit and completion instructions, real-world deployment requires aligning with users' more complex implicit intents. In this work, we highlight Hierarchical Implicit Intent Alignment for Personalized GUI Agent (PersonalAlign), a new agent task that requires agents to leverage long-term user records as persistent context to resolve omitted preferences in vague instructions and anticipate latent routines by user state for proactive assistance. To facilitate this study, we introduce AndroidIntent, a benchmark designed to evaluate agents' ability in resolving vague instructions and providing proactive suggestions through reasoning over long-term user records. We annotated 775 user-specific preferences and 215 routines from 20k long-term records across different users for evaluation. Furthermore, we introduce Hierarchical Intent Memory Agent (HIM-Agent), which maintains a continuously updating personal memory and hierarchically organizes user preferences and routines for personalization. Finally, we evaluate a range of GUI agents on AndroidIntent, including GPT-5, Qwen3-VL, and UI-TARS, further results show that HIM-Agent significantly improves both execution and proactive performance by 15.7% and 7.3%.",
    "authors": [
      "Yibo Lyu",
      "Gongwei Chen",
      "Rui Shao",
      "Weili Guan",
      "Liqiang Nie"
    ],
    "published": "2026-01-14",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09636v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09636v1",
    "fetched_at": "2026-01-15T08:39:08.404306",
    "chinese_title": "PersonalAlign：基于长期用户中心记录的个性化GUI代理分层隐式意图对齐",
    "chinese_summary": "论文提出PersonalAlign任务，要求GUI代理利用长期用户记录解决模糊指令中的偏好遗漏并预判潜在行为routine以主动协助；引入AndroidIntent基准（含标注的用户偏好与routine数据），并提出HIM-Agent模型（分层维护用户记忆），实验显示其显著提升执行与主动性能。",
    "tags": [
      "LLM",
      "Benchmark",
      "Execution"
    ],
    "key_contributions": [
      "提出PersonalAlign任务及AndroidIntent基准，含775个用户偏好与215个routine的标注数据",
      "提出HIM-Agent模型，通过分层记忆组织提升GUI代理的模糊指令解决与主动协助能力"
    ],
    "processed_at": "2026-01-15T08:44:59.965987"
  },
  {
    "id": "2601.09625v1",
    "title": "The Promptware Kill Chain: How Prompt Injections Gradually Evolved Into a Multi-Step Malware",
    "abstract": "The rapid adoption of large language model (LLM)-based systems -- from chatbots to autonomous agents capable of executing code and financial transactions -- has created a new attack surface that existing security frameworks inadequately address. The dominant framing of these threats as \"prompt injection\" -- a catch-all phrase for security failures in LLM-based systems -- obscures a more complex reality: Attacks on LLM-based systems increasingly involve multi-step sequences that mirror traditional malware campaigns. In this paper, we propose that attacks targeting LLM-based applications constitute a distinct class of malware, which we term \\textit{promptware}, and introduce a five-step kill chain model for analyzing these threats. The framework comprises Initial Access (prompt injection), Privilege Escalation (jailbreaking), Persistence (memory and retrieval poisoning), Lateral Movement (cross-system and cross-user propagation), and Actions on Objective (ranging from data exfiltration to unauthorized transactions). By mapping recent attacks to this structure, we demonstrate that LLM-related attacks follow systematic sequences analogous to traditional malware campaigns. The promptware kill chain offers security practitioners a structured methodology for threat modeling and provides a common vocabulary for researchers across AI safety and cybersecurity to address a rapidly evolving threat landscape.",
    "authors": [
      "Ben Nassi",
      "Bruce Schneier",
      "Oleg Brodt"
    ],
    "published": "2026-01-14",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09625v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09625v1",
    "fetched_at": "2026-01-15T08:39:08.404328",
    "chinese_title": "Promptware杀伤链：提示注入如何逐步演变为多步骤恶意软件",
    "chinese_summary": "本文指出LLM系统攻击已从单一提示注入演变为类似传统恶意软件的多步骤序列，提出“提示恶意软件（promptware）”这一攻击类别；构建包含初始访问、权限提升等5步骤的杀伤链模型，为安全从业者提供威胁建模方法，也为AI安全与网络安全研究者提供通用词汇。",
    "tags": [
      "LLM",
      "Financial Agent",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出“提示恶意软件（promptware）”概念，揭示LLM攻击已演变为多步骤类似传统恶意软件的序列",
      "构建5步骤的promptware杀伤链模型，为威胁建模提供结构化框架并统一跨领域研究词汇"
    ],
    "processed_at": "2026-01-15T08:45:18.285152"
  },
  {
    "id": "2601.09503v1",
    "title": "What Do LLM Agents Know About Their World? Task2Quiz: A Paradigm for Studying Environment Understanding",
    "abstract": "Large language model (LLM) agents have demonstrated remarkable capabilities in complex decision-making and tool-use tasks, yet their ability to generalize across varying environments remains a under-examined concern. Current evaluation paradigms predominantly rely on trajectory-based metrics that measure task success, while failing to assess whether agents possess a grounded, transferable model of the environment. To address this gap, we propose Task-to-Quiz (T2Q), a deterministic and automated evaluation paradigm designed to decouple task execution from world-state understanding. We instantiate this paradigm in T2QBench, a suite comprising 30 environments and 1,967 grounded QA pairs across multiple difficulty levels. Our extensive experiments reveal that task success is often a poor proxy for environment understanding, and that current memory machanism can not effectively help agents acquire a grounded model of the environment. These findings identify proactive exploration and fine-grained state representation as primary bottlenecks, offering a robust foundation for developing more generalizable autonomous agents.",
    "authors": [
      "Siyuan Liu",
      "Hongbang Yuan",
      "Xinze Li",
      "Ziyue Zhu",
      "Yixin Cao",
      "Yu-Gang Jiang"
    ],
    "published": "2026-01-14",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09503v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09503v1",
    "fetched_at": "2026-01-15T08:39:08.404355",
    "chinese_title": "LLM智能体对其世界了解多少？Task2Quiz：一种研究环境理解的范式",
    "chinese_summary": "论文针对现有LLM智能体评估未充分考察环境理解的问题，提出Task-to-Quiz（T2Q）评估范式及包含30个环境、1967个落地QA对的T2QBench基准，解耦任务执行与环境状态理解；实验发现任务成功并非环境理解的有效代理，现有记忆机制无法帮助智能体建立落地环境模型，指出主动探索与细粒度状态表示是泛化瓶颈。",
    "tags": [
      "LLM",
      "NLP",
      "Benchmark"
    ],
    "key_contributions": [
      "提出T2Q评估范式及T2QBench基准，首次解耦任务执行与环境状态理解的评估",
      "揭示任务成功与环境理解的弱相关性，明确主动探索和细粒度状态表示为智能体泛化的核心瓶颈"
    ],
    "processed_at": "2026-01-15T08:45:33.545899"
  },
  {
    "id": "2601.09334v1",
    "title": "High-Performance Serverless Computing: A Systematic Literature Review on Serverless for HPC, AI, and Big Data",
    "abstract": "The widespread deployment of large-scale, compute-intensive applications such as high-performance computing, artificial intelligence, and big data is leading to convergence between cloud and high-performance computing infrastructures. Cloud providers are increasingly integrating high-performance computing capabilities in their infrastructures, such as hardware accelerators and high-speed interconnects, while researchers in the high-performance computing community are starting to explore cloud-native paradigms to improve scalability, elasticity, and resource utilization. In this context, serverless computing emerges as a promising execution model to efficiently handle highly dynamic, parallel, and distributed workloads. This paper presents a comprehensive systematic literature review of 122 research articles published between 2018 and early 2025, exploring the use of the serverless paradigm to develop, deploy, and orchestrate compute-intensive applications across cloud, high-performance computing, and hybrid environments. From these, a taxonomy comprising eight primary research directions and nine targeted use case domains is proposed, alongside an analysis of recent publication trends and collaboration networks among authors, highlighting the growing interest and interconnections within this emerging research field. Overall, this work aims to offer a valuable foundation for both new researchers and experienced practitioners, guiding the development of next-generation serverless solutions for parallel compute-intensive applications.",
    "authors": [
      "Valerio Besozzi",
      "Matteo Della Bartola",
      "Patrizio Dazzi",
      "Marco Danelutto"
    ],
    "published": "2026-01-14",
    "categories": [
      "cs.DC",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09334v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09334v1",
    "fetched_at": "2026-01-15T08:39:08.404384",
    "chinese_title": "高性能无服务器计算：HPC、AI与大数据领域无服务器技术的系统文献综述",
    "chinese_summary": "该论文针对2018至2025年初的122篇研究文献开展系统综述，探索无服务器范式在云、高性能计算（HPC）及混合环境中开发、部署与编排计算密集型应用的情况；提出包含8个核心研究方向和9个目标用例域的分类法，分析领域出版趋势与作者合作网络，为研究者和从业者提供基础支撑。",
    "tags": [
      "Deep Learning"
    ],
    "key_contributions": [
      "基于122篇文献系统梳理无服务器计算在云、HPC及混合环境计算密集型应用的研究现状",
      "构建含8个研究方向和9个用例域的分类体系，分析领域趋势与合作网络，提供研究实践基础"
    ],
    "processed_at": "2026-01-15T08:45:59.651445"
  },
  {
    "id": "2601.09306v1",
    "title": "On-Device Large Language Models for Sequential Recommendation",
    "abstract": "On-device recommendation is critical for a number of real-world applications, especially in scenarios that have agreements on execution latency, user privacy, and robust functionality when internet connectivity is unstable or even impossible. While large language models (LLMs) can now provide exceptional capabilities that model user behavior for sequential recommendation tasks, their substantial memory footprint and computational overhead make the deployment on resource-constrained devices a high risk proposition. In this paper, we propose OD-LLM, the first task-adaptive compression framework explicitly designed to provide efficient and accurate on-device deployment of LLMs for sequential recommendation tasks. OD-LLM uniquely integrates two complementary compression strategies: a low-rank structural compression algorithm which uses Singular Value Decomposition (SVD) to significantly reduce parameter redundancy in the model, and a novel tokenization normalization technique that better complements the low-rank decomposition process being used. Additionally, to minimize any potential performance degradation when using higher compression ratios, a novel progressive alignment algorithm is used to iteratively refine the parameters required layerwise in the target model. Empirical evaluations conducted on sequential recommendation benchmarks show that OD-LLM exhibits no loss in effectiveness when compared to the original recommendation model, when the deployed model size is halved. These promising results demonstrate the efficacy and scalability of OD-LLM, making this novel solution a practical alternative for real-time, on-device solutions wishing to replace expensive, remotely executed LLMs.",
    "authors": [
      "Xin Xia",
      "Hongzhi Yin",
      "Shane Culpepper"
    ],
    "published": "2026-01-14",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09306v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09306v1",
    "fetched_at": "2026-01-15T08:39:08.404407",
    "chinese_title": "面向序列推荐的端侧大语言模型",
    "chinese_summary": "针对端侧推荐对低延迟、隐私保护的需求及大语言模型（LLM）部署困难问题，提出OD-LLM任务自适应压缩框架，整合SVD低秩压缩、新型分词归一化及渐进对齐算法；实验表明该框架可将模型大小减半且推荐效果无损失。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出首个面向序列推荐端侧部署的任务自适应LLM压缩框架OD-LLM",
      "整合SVD低秩压缩、新型分词归一化及渐进对齐算法，实现模型大小减半且效果无损失"
    ],
    "processed_at": "2026-01-15T08:46:16.316800"
  },
  {
    "id": "2601.09259v1",
    "title": "MAXS: Meta-Adaptive Exploration with LLM Agents",
    "abstract": "Large Language Model (LLM) Agents exhibit inherent reasoning abilities through the collaboration of multiple tools. However, during agent inference, existing methods often suffer from (i) locally myopic generation, due to the absence of lookahead, and (ii) trajectory instability, where minor early errors can escalate into divergent reasoning paths. These issues make it difficult to balance global effectiveness and computational efficiency. To address these two issues, we propose meta-adaptive exploration with LLM agents https://github.com/exoskeletonzj/MAXS, a meta-adaptive reasoning framework based on LLM Agents that flexibly integrates tool execution and reasoning planning. MAXS employs a lookahead strategy to extend reasoning paths a few steps ahead, estimating the advantage value of tool usage, and combines step consistency variance and inter-step trend slopes to jointly select stable, consistent, and high-value reasoning steps. Additionally, we introduce a trajectory convergence mechanism that controls computational cost by halting further rollouts once path consistency is achieved, enabling a balance between resource efficiency and global effectiveness in multi-tool reasoning. We conduct extensive empirical studies across three base models (MiMo-VL-7B, Qwen2.5-VL-7B, Qwen2.5-VL-32B) and five datasets, demonstrating that MAXS consistently outperforms existing methods in both performance and inference efficiency. Further analysis confirms the effectiveness of our lookahead strategy and tool usage.",
    "authors": [
      "Jian Zhang",
      "Zhiyuan Wang",
      "Zhangqi Wang",
      "Yu He",
      "Haoran Luo",
      "li yuan",
      "Lingling Zhang",
      "Rui Mao",
      "Qika Lin",
      "Jun Liu"
    ],
    "published": "2026-01-14",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09259v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09259v1",
    "fetched_at": "2026-01-15T08:39:08.404440",
    "chinese_title": "MAXS：基于LLM智能体的元自适应探索框架",
    "chinese_summary": "针对LLM智能体推理中存在的局部短视（缺乏前瞻）和轨迹不稳定（早期小错误导致路径发散）问题，论文提出MAXS元自适应推理框架，通过前瞻策略扩展推理路径并估计工具使用优势，结合步骤一致性方差与趋势斜率选择稳定高价值步骤，同时引入轨迹收敛机制平衡资源效率与全局效果；实验在多基础模型和数据集上验证了其性能与推理效率的优势。",
    "tags": [
      "LLM",
      "NLP",
      "Financial Agent",
      "Transformer"
    ],
    "key_contributions": [
      "提出MAXS元自适应推理框架，通过前瞻策略与多指标联合选择稳定高价值推理步骤，解决LLM Agent的局部短视与轨迹不稳定问题",
      "引入轨迹收敛机制，在路径一致时停止扩展，平衡多工具推理中的资源效率与全局效果"
    ],
    "processed_at": "2026-01-15T08:46:37.182815"
  },
  {
    "id": "2601.09097v1",
    "title": "Programming over Thinking: Efficient and Robust Multi-Constraint Planning",
    "abstract": "Multi-constraint planning involves identifying, evaluating, and refining candidate plans while satisfying multiple, potentially conflicting constraints. Existing large language model (LLM) approaches face fundamental limitations in this domain. Pure reasoning paradigms, which rely on long natural language chains, are prone to inconsistency, error accumulation, and prohibitive cost as constraints compound. Conversely, LLMs combined with coding- or solver-based strategies lack flexibility: they often generate problem-specific code from scratch or depend on fixed solvers, failing to capture generalizable logic across diverse problems. To address these challenges, we introduce the Scalable COde Planning Engine (SCOPE), a framework that disentangles query-specific reasoning from generic code execution. By separating reasoning from execution, SCOPE produces solver functions that are consistent, deterministic, and reusable across queries while requiring only minimal changes to input parameters. SCOPE achieves state-of-the-art performance while lowering cost and latency. For example, with GPT-4o, it reaches 93.1% success on TravelPlanner, a 61.6% gain over the best baseline (CoT) while cutting inference cost by 1.4x and time by ~4.67x. Code is available at https://github.com/DerrickGXD/SCOPE.",
    "authors": [
      "Derrick Goh Xin Deik",
      "Quanyu Long",
      "Zhengyuan Liu",
      "Nancy F. Chen",
      "Wenya Wang"
    ],
    "published": "2026-01-14",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09097v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09097v1",
    "fetched_at": "2026-01-15T08:39:08.404466",
    "chinese_title": "编程优于思考：高效稳健的多约束规划",
    "chinese_summary": "该论文针对现有大语言模型（LLM）在多约束规划中存在的推理不一致、成本高或代码灵活性不足等问题，提出Scalable COde Planning Engine（SCOPE）框架，通过分离查询特定推理与通用代码执行，生成一致、可复用的求解函数；实验表明SCOPE在TravelPlanner任务上达到93.1%的成功率，较最优基线提升61.6%，同时降低推理成本和延迟。",
    "tags": [
      "LLM",
      "Financial Agent",
      "Transformer"
    ],
    "key_contributions": [
      "提出SCOPE框架，分离查询特定推理与通用代码执行，解决现有LLM多约束规划的灵活性与一致性矛盾",
      "在TravelPlanner任务上实现SOTA性能，显著降低推理成本和延迟"
    ],
    "processed_at": "2026-01-15T08:46:56.464235"
  },
  {
    "id": "2601.09084v1",
    "title": "How Many Human Judgments Are Enough? Feasibility Limits of Human Preference Evaluation",
    "abstract": "Human preference evaluations are widely used to compare generative models, yet it remains unclear how many judgments are required to reliably detect small improvements. We show that when preference signal is diffuse across prompts (i.e., all prompt types are similarly informative), proportional allocation is minimax-optimal: no allocation strategy substantially improves detectability. Empirical analysis of large-scale human preference datasets shows that most comparisons fall into this diffuse regime, exhibiting small preference margins that require far more judgments than typically collected, even in well-sampled comparisons. These limits persist across evaluation protocols and modalities, including chat, image generation, and code generation with execution feedback. In contrast, curated benchmarks that reduce prompt induced variability systematically induce larger margins and improve detectability through a $1.5\\times$ reduction in prompt-level variance. Our results show that inconclusive or negative human evaluation outcomes frequently reflect underpowered evaluation rather than model equivalence, underscoring the need to account explicitly for effect size, budget, and protocol design.",
    "authors": [
      "Wilson Y. Lee"
    ],
    "published": "2026-01-14",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09084v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09084v1",
    "fetched_at": "2026-01-15T08:39:08.404484",
    "chinese_title": "需要多少人类判断才足够？人类偏好评估的可行性限制",
    "chinese_summary": "该论文研究生成模型人类偏好评估所需的可靠判断数量，发现当偏好信号在提示中分散时比例分配策略最优；实证表明多数比较需远多于常规收集的判断，curated基准可减少1.5倍提示方差提升可检测性，强调评估无结论常因功率不足而非模型等价。",
    "tags": [
      "LLM",
      "Benchmark",
      "Deep Learning"
    ],
    "key_contributions": [
      "发现curated基准可降低提示方差1.5倍提升可检测性，指出评估无结论多因功率不足而非模型等价"
    ],
    "processed_at": "2026-01-15T08:47:18.231563"
  },
  {
    "id": "2601.09035v1",
    "title": "A Decompilation-Driven Framework for Malware Detection with Large Language Models",
    "abstract": "The parallel evolution of Large Language Models (LLMs) with advanced code-understanding capabilities and the increasing sophistication of malware presents a new frontier for cybersecurity research. This paper evaluates the efficacy of state-of-the-art LLMs in classifying executable code as either benign or malicious. We introduce an automated pipeline that first decompiles Windows executable into a C code using Ghidra disassembler and then leverages LLMs to perform the classification. Our evaluation reveals that while standard LLMs show promise, they are not yet robust enough to replace traditional anti-virus software. We demonstrate that a fine-tuned model, trained on curated malware and benign datasets, significantly outperforms its vanilla counterpart. However, the performance of even this specialized model degrades notably when encountering newer malware. This finding demonstrates the critical need for continuous fine-tuning with emerging threats to maintain model effectiveness against the changing coding patterns and behaviors of malicious software.",
    "authors": [
      "Aniesh Chawla",
      "Udbhav Prasad"
    ],
    "published": "2026-01-14",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09035v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09035v1",
    "fetched_at": "2026-01-15T08:39:08.404504",
    "chinese_title": "基于反编译和大语言模型的恶意软件检测框架",
    "chinese_summary": "本文提出一种自动流程：先通过Ghidra将Windows可执行文件反编译为C代码，再利用大语言模型（LLM）进行恶意软件分类；评估发现标准LLM有潜力但难替代传统杀毒软件，微调模型显著优于 vanilla 模型，但面对新型恶意软件性能下降，强调需持续用新兴威胁微调维持有效性。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出反编译驱动的LLM恶意软件检测自动pipeline",
      "揭示LLM（含微调模型）对新型恶意软件的性能缺陷及持续微调的必要性"
    ],
    "processed_at": "2026-01-15T08:47:32.949150"
  },
  {
    "id": "2601.09031v1",
    "title": "Generalizable Geometric Prior and Recurrent Spiking Feature Learning for Humanoid Robot Manipulation",
    "abstract": "Humanoid robot manipulation is a crucial research area for executing diverse human-level tasks, involving high-level semantic reasoning and low-level action generation. However, precise scene understanding and sample-efficient learning from human demonstrations remain critical challenges, severely hindering the applicability and generalizability of existing frameworks. This paper presents a novel RGMP-S, Recurrent Geometric-prior Multimodal Policy with Spiking features, facilitating both high-level skill reasoning and data-efficient motion synthesis. To ground high-level reasoning in physical reality, we leverage lightweight 2D geometric inductive biases to enable precise 3D scene understanding within the vision-language model. Specifically, we construct a Long-horizon Geometric Prior Skill Selector that effectively aligns the semantic instructions with spatial constraints, ultimately achieving robust generalization in unseen environments. For the data efficiency issue in robotic action generation, we introduce a Recursive Adaptive Spiking Network. We parameterize robot-object interactions via recursive spiking for spatiotemporal consistency, fully distilling long-horizon dynamic features while mitigating the overfitting issue in sparse demonstration scenarios. Extensive experiments are conducted across the Maniskill simulation benchmark and three heterogeneous real-world robotic systems, encompassing a custom-developed humanoid, a desktop manipulator, and a commercial robotic platform. Empirical results substantiate the superiority of our method over state-of-the-art baselines and validate the efficacy of the proposed modules in diverse generalization scenarios. To facilitate reproducibility, the source code and video demonstrations are publicly available at https://github.com/xtli12/RGMP-S.git.",
    "authors": [
      "Xuetao Li",
      "Wenke Huang",
      "Mang Ye",
      "Jifeng Xuan",
      "Bo Du",
      "Sheng Liu",
      "Miao Li"
    ],
    "published": "2026-01-13",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09031v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09031v1",
    "fetched_at": "2026-01-15T08:39:08.404532",
    "chinese_title": "用于类人机器人操作的可泛化几何先验与循环脉冲特征学习",
    "chinese_summary": "论文提出RGMP-S模型，针对类人机器人操作的场景理解与样本效率问题：一方面构建长程几何先验技能选择器，利用轻量2D几何归纳偏置对齐语义指令与空间约束，提升未知环境泛化性；另一方面引入递归自适应脉冲网络，通过递归脉冲参数化交互并提取长程动态特征，缓解稀疏演示下的过拟合，提升动作生成数据效率。",
    "tags": [
      "Deep Learning",
      "Reinforcement Learning",
      "Transformer",
      "LLM"
    ],
    "key_contributions": [
      "提出长程几何先验技能选择器，实现语义指令与空间约束对齐，增强未知环境泛化性",
      "引入递归自适应脉冲网络，提取长程动态特征并缓解稀疏演示过拟合，提升动作生成数据效率"
    ],
    "processed_at": "2026-01-15T08:47:49.495147"
  },
  {
    "id": "2601.08747v2",
    "title": "To Retrieve or To Think? An Agentic Approach for Context Evolution",
    "abstract": "Current context augmentation methods, such as retrieval-augmented generation, are essential for solving knowledge-intensive reasoning tasks. However, they typically adhere to a rigid, brute-force strategy that executes retrieval at every step. This indiscriminate approach not only incurs unnecessary computational costs but also degrades performance by saturating the context with irrelevant noise. To address these limitations, we introduce Agentic Context Evolution (ACE), a framework inspired by human metacognition that dynamically determines whether to seek new evidence or reason with existing knowledge. ACE employs a central orchestrator agent to make decisions strategically via majority voting. It aims to alternate between activating a retriever agent for external retrieval and a reasoner agent for internal analysis and refinement. By eliminating redundant retrieval steps, ACE maintains a concise and evolved context. Extensive experiments on challenging multi-hop QA benchmarks demonstrate that ACE significantly outperforms competitive baselines in accuracy while achieving efficient token consumption. Our work provides valuable insights into advancing context-evolved generation for complex, knowledge-intensive tasks.",
    "authors": [
      "Rubing Chen",
      "Jian Wang",
      "Wenjie Li",
      "Xiao-Yong Wei",
      "Qing Li"
    ],
    "published": "2026-01-13",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.08747v2",
    "arxiv_url": "https://arxiv.org/abs/2601.08747v2",
    "fetched_at": "2026-01-15T08:39:08.404584",
    "chinese_title": "检索还是思考？一种用于上下文演化的智能体方法",
    "chinese_summary": "针对当前检索增强生成等上下文增强方法刚性每步检索导致计算成本高、无关噪声多的问题，论文提出受人类元认知启发的ACE框架，通过中央协调智能体动态决策是否激活检索或推理智能体，消除冗余检索以保持简洁演化的上下文；实验在多跳QA基准上验证，ACE显著优于基线，兼具高准确率与高效token消耗。",
    "tags": [
      "LLM",
      "NLP"
    ],
    "key_contributions": [
      "提出Agentic Context Evolution（ACE）框架，动态决策是否检索外部证据或基于现有知识推理，解决传统上下文增强方法刚性检索的缺陷",
      "实验验证ACE在多跳QA任务中显著提升准确率，同时降低token消耗，实现高效的上下文演化生成"
    ],
    "processed_at": "2026-01-15T08:48:13.029844"
  },
  {
    "id": "2601.09151v1",
    "title": "Interpretable Probability Estimation with LLMs via Shapley Reconstruction",
    "abstract": "Large Language Models (LLMs) demonstrate potential to estimate the probability of uncertain events, by leveraging their extensive knowledge and reasoning capabilities. This ability can be applied to support intelligent decision-making across diverse fields, such as financial forecasting and preventive healthcare. However, directly prompting LLMs for probability estimation faces significant challenges: their outputs are often noisy, and the underlying predicting process is opaque. In this paper, we propose PRISM: Probability Reconstruction via Shapley Measures, a framework that brings transparency and precision to LLM-based probability estimation. PRISM decomposes an LLM's prediction by quantifying the marginal contribution of each input factor using Shapley values. These factor-level contributions are then aggregated to reconstruct a calibrated final estimate. In our experiments, we demonstrate PRISM improves predictive accuracy over direct prompting and other baselines, across multiple domains including finance, healthcare, and agriculture. Beyond performance, PRISM provides a transparent prediction pipeline: our case studies visualize how individual factors shape the final estimate, helping build trust in LLM-based decision support systems.",
    "authors": [
      "Yang Nan",
      "Qihao Wen",
      "Jiahao Wang",
      "Pengfei He",
      "Ravi Tandon",
      "Yong Ge",
      "Han Xu"
    ],
    "published": "2026-01-14",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09151v1",
    "arxiv_url": "https://arxiv.org/abs/2601.09151v1",
    "fetched_at": "2026-01-15T08:40:56.018762",
    "chinese_title": "基于Shapley值重构的LLM可解释概率估计",
    "chinese_summary": "论文提出PRISM框架，通过Shapley值量化输入因子的边际贡献并聚合重构校准后的概率估计，提升了LLM概率估计的精度与透明度；实验表明该框架在金融、医疗等多领域优于直接prompt及其他基线方法，且能可视化因子对预测的影响以增强决策信任。",
    "tags": [
      "LLM",
      "NLP",
      "Factor Model",
      "Risk Management"
    ],
    "key_contributions": [
      "提出PRISM框架，结合Shapley值实现LLM概率估计的可解释性与精度提升",
      "在多领域验证PRISM优于直接prompt等基线，且提供透明预测流程增强决策信任"
    ],
    "processed_at": "2026-01-15T08:48:26.909852"
  }
]