[
  {
    "id": "2601.14139v1",
    "title": "Log-optimality with small liability stream",
    "abstract": "In an incomplete financial market with general continuous semimartingale dynamics; we model an investor with log-utility preferences who, in addition to an initial capital, receives units of a non-traded endowment process. Using duality techniques, we derive the fourth-order expansion of the primal value function with respect to the units $ε$, held in the non-traded endowment. In turn, this lays the foundation for expanding the optimal wealth process, in this context, up to second order w.r.t. $ε$. The key processes underpinning the aforementioned results are given in terms of Kunita-Watanabe projections, mirroring the case of lower order expansions of similar nature. Both the case of finite and infinite horizons are treated in a unified manner.",
    "authors": [
      "Michail Anthropelos",
      "Constantinos Kardaras",
      "Constantinos Stefanakis"
    ],
    "published": "2026-01-20",
    "categories": [
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.14139v1",
    "arxiv_url": "https://arxiv.org/abs/2601.14139v1",
    "fetched_at": "2026-01-21T08:37:00.451763",
    "chinese_title": "小额负债流下的对数最优性",
    "chinese_summary": "在连续半鞅动态的不完全金融市场中，针对具有对数效用偏好且持有非交易禀赋（规模为ε）的投资者，论文利用对偶技术推导了原价值函数关于ε的四阶展开，进而得到最优财富过程的二阶展开；关键过程基于Kunita-Watanabe投影，且统一处理了有限与无限 horizon的情形。",
    "tags": [
      "Portfolio Optimization",
      "Risk Management",
      "Time Series"
    ],
    "key_contributions": [
      "推导了不完全连续半鞅市场中，带非交易禀赋的对数效用投资者价值函数关于禀赋规模ε的四阶展开，及最优财富过程的二阶展开",
      "基于Kunita-Watanabe投影的关键过程，统一处理了有限与无限 horizon的情况"
    ],
    "processed_at": "2026-01-21T08:40:20.565148"
  },
  {
    "id": "2601.14062v1",
    "title": "Demystifying the trend of the healthcare index: Is historical price a key driver?",
    "abstract": "Healthcare sector indices consolidate the economic health of pharmaceutical, biotechnology, and healthcare service firms. The short-term movements in these indices are closely intertwined with capital allocation decisions affecting research and development investment, drug availability, and long-term health outcomes. This research investigates whether historical open-high-low-close (OHLC) index data contain sufficient information for predicting the directional movement of the opening index on the subsequent trading day. The problem is formulated as a supervised classification task involving a one-step-ahead rolling window. A diverse feature set is constructed, comprising original prices, volatility-based technical indicators, and a novel class of nowcasting features derived from mutual OHLC ratios. The framework is evaluated on data from healthcare indices in the U.S. and Indian markets over a five-year period spanning multiple economic phases, including the COVID-19 pandemic. The results demonstrate robust predictive performance, with accuracy exceeding 0.8 and Matthews correlation coefficients above 0.6. Notably, the proposed nowcasting features have emerged as a key determinant of the market movement. We have employed the Shapley-based explainability paradigm to further elucidate the contribution of the features: outcomes reveal the dominant role of the nowcasting features, followed by a more moderate contribution of original prices. This research offers a societal utility: the proposed features and model for short-term forecasting of healthcare indices can reduce information asymmetry and support a more stable and equitable health economy.",
    "authors": [
      "Payel Sadhukhan",
      "Samrat Gupta",
      "Subhasis Ghosh",
      "Tanujit Chakraborty"
    ],
    "published": "2026-01-20",
    "categories": [
      "q-fin.ST",
      "stat.AP",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.14062v1",
    "arxiv_url": "https://arxiv.org/abs/2601.14062v1",
    "fetched_at": "2026-01-21T08:37:00.451805",
    "chinese_title": "揭秘医疗健康指数趋势：历史价格是关键驱动因素吗？",
    "chinese_summary": "本研究将医疗健康指数次日开盘方向预测建模为一步滚动窗口的监督分类任务，构建包含原始价格、波动率技术指标及新的互OHLC比率即时预测特征的特征集；在美印市场5年多经济阶段（含新冠期）数据上验证，预测准确率超0.8、MCC超0.6，且通过Shapley可解释性方法揭示即时预测特征为核心驱动因素。",
    "tags": [
      "Time Series",
      "Volatility",
      "Factor Mining"
    ],
    "key_contributions": [
      "提出融合原始价格、波动率指标与新的互OHLC比率即时预测特征的特征集，用于医疗健康指数次日开盘方向预测",
      "验证该方法在多市场多经济阶段的稳健预测性能，并通过可解释性方法明确即时预测特征的主导贡献"
    ],
    "processed_at": "2026-01-21T08:40:38.743166"
  },
  {
    "id": "2601.14005v1",
    "title": "Leveraged positions on decentralized lending platforms",
    "abstract": "We develop a mathematical framework to optimize leveraged staking (\"loopy\") strategies in Decentralized Finance (DeFi), in which a staked asset is supplied as collateral, the underlying is borrowed and re-staked, and the loop can be repeated across multiple lending markets. Exploiting the fact that DeFi borrow rates are deterministic functions of pool utilization, we reduce the multi-market problem to a convex allocation over market exposures and obtain closed-form solutions under three interest-rate models: linear, kinked, and adaptive (Morpho's AdaptiveCurveIRM). The framework incorporates market-specific leverage limits, utilization-dependent borrowing costs, and transaction fees. Backtests on the Ethereum and Base blockchains using the largest Morpho wstETH/WETH markets (from January 1 to April 1, 2025) show that rebalanced leveraged positions can reach up to 6.2% APY versus 3.1% for unleveraged staking, with strong dependence on position size and rebalancing frequency. Our results provide a mathematical basis for transparent, automated DeFi portfolio optimization.",
    "authors": [
      "Bastien Baude",
      "Vincent Danos",
      "Hamza El Khalloufi"
    ],
    "published": "2026-01-20",
    "categories": [
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.14005v1",
    "arxiv_url": "https://arxiv.org/abs/2601.14005v1",
    "fetched_at": "2026-01-21T08:37:00.451831",
    "chinese_title": "去中心化借贷平台上的杠杆头寸",
    "chinese_summary": "该论文开发数学框架优化DeFi中的杠杆质押（循环）策略，利用DeFi借贷利率是池利用率的确定性函数，将多市场问题简化为凸分配并得到三种利率模型下的闭式解；框架纳入市场杠杆限制、利用率依赖的借贷成本及交易费用，回测显示再平衡杠杆头寸APY可达6.2%（无杠杆为3.1%），为透明自动化DeFi投资组合优化提供数学基础。",
    "tags": [
      "Portfolio Optimization",
      "Risk Management",
      "Algorithmic Trading"
    ],
    "key_contributions": [
      "开发数学框架优化DeFi杠杆质押（循环）策略，将多市场问题简化为凸分配并得到三种利率模型下的闭式解",
      "框架纳入市场杠杆限制、利用率依赖的借贷成本及交易费用，回测验证再平衡杠杆头寸收益优势，为DeFi投资组合优化提供数学基础"
    ],
    "processed_at": "2026-01-21T08:41:02.661854"
  },
  {
    "id": "2601.13770v1",
    "title": "Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance",
    "abstract": "We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench",
    "authors": [
      "Mostapha Benhenda"
    ],
    "published": "2026-01-20",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "q-fin.CP",
      "q-fin.GN"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13770v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13770v1",
    "fetched_at": "2026-01-21T08:37:00.451853",
    "chinese_title": "Look-Ahead-Bench：金融时点大语言模型前瞻偏差的标准化基准",
    "chinese_summary": "论文引入Look-Ahead-Bench基准，用于衡量金融时点LLM的前瞻偏差，区别于现有QA测试内部知识的方法，该基准通过分析不同市场时期的性能衰减区分预测能力与记忆；对比发现标准开源LLM存在显著前瞻偏差，PiT模型随规模提升泛化推理能力更好，为金融LLM的时间偏差评估奠定基础。",
    "tags": [
      "LLM",
      "Benchmark",
      "Financial Agent",
      "Time Series"
    ],
    "key_contributions": [
      "提出标准化基准Look-Ahead-Bench，覆盖实际金融场景评估时点LLM的前瞻偏差，而非仅QA测试内部知识",
      "揭示标准开源LLM存在显著前瞻偏差，PiT模型随规模提升泛化推理能力更好，为金融LLM部署提供实用框架"
    ],
    "processed_at": "2026-01-21T08:41:13.628004"
  },
  {
    "id": "2601.13493v1",
    "title": "LQ Mean Field Games with Common Noise in Hilbert Spaces: Small and Arbitrary Finite Time Horizons",
    "abstract": "We extend the results of (Liu and Firoozi, 2025), which develops the theory of linear-quadratic (LQ) mean field games in Hilbert spaces, by incorporating a common noise. This common noise is an infinite-dimensional Wiener process affecting the dynamics of all agents. In the presence of common noise, the mean-field consistency condition is characterized by a system of coupled forward-backward stochastic evolution equations (FBSEEs) in Hilbert spaces, whereas in its absence, it is represented by forward-backward deterministic evolution equations. We establish the existence and uniqueness of solutions to the coupled linear FBSEEs associated with the LQ MFG setting for small time horizons and prove the $ε$-Nash property of the resulting equilibrium strategy. Furthermore, for the first time in the literature, we develop an analysis that establishes the well-posedness of these coupled linear FBSEEs in Hilbert spaces, for which only mild solutions exist, over arbitrary finite time horizons.",
    "authors": [
      "Hanchao Liu",
      "Dena Firoozi"
    ],
    "published": "2026-01-20",
    "categories": [
      "math.OC",
      "math.FA",
      "math.PR",
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13493v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13493v1",
    "fetched_at": "2026-01-21T08:37:00.451875",
    "chinese_title": "希尔伯特空间中带公共噪声的线性二次平均场博弈：小时间范围与任意有限时间范围",
    "chinese_summary": "本文扩展希尔伯特空间中线性二次（LQ）平均场博弈理论，引入影响所有主体的无限维公共噪声，其平均场一致性条件由耦合正倒向随机演化方程（FBSEE）刻画；建立小时间范围下该耦合线性FBSEE解的存在唯一性及均衡策略的ε-纳什性质，并首次证明任意有限时间范围下这类方程的适定性（仅存在mild解）。",
    "tags": [
      "Portfolio Optimization",
      "Risk Management"
    ],
    "key_contributions": [
      "扩展希尔伯特空间LQ平均场博弈理论，引入无限维公共噪声并以耦合FBSEE刻画平均场一致性条件",
      "建立小时间范围下解的存在唯一性及ε-纳什性质，首次证明任意有限时间范围下这类耦合线性FBSEE的适定性"
    ],
    "processed_at": "2026-01-21T08:41:30.933760"
  },
  {
    "id": "2601.13421v1",
    "title": "Market Making and Transient Impact in Spot FX",
    "abstract": "Dealers in foreign exchange markets provide bid and ask prices to their clients at which they are happy to buy and sell, respectively. To manage risk, dealers can skew their quotes and hedge in the interbank market. Hedging offers certainty but comes with transaction costs and market impact. Optimal market making with execution has previously been addressed within the Almgren-Chriss market impact model, which includes instantaneous and permanent components. However, there is overwhelming empirical evidence of the transient nature of market impact, with instantaneous and permanent impacts arising as the two limiting cases. In this note, we consider an intermediate scenario and study the interplay between risk management and impact resilience.",
    "authors": [
      "Alexander Barzykin"
    ],
    "published": "2026-01-19",
    "categories": [
      "q-fin.TR",
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13421v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13421v1",
    "fetched_at": "2026-01-21T08:37:00.451893",
    "chinese_title": "即期外汇市场中的做市与瞬态影响",
    "chinese_summary": "本文针对即期外汇市场做市商的风险管理问题，指出现有Almgren-Chriss市场影响模型仅涵盖瞬时和永久影响两种极端情况，而实证存在瞬态影响这一中间场景；研究了做市商报价倾斜、银行间对冲等风险管理策略与市场影响弹性之间的相互作用，弥补了中间场景下的研究空白。",
    "tags": [
      "Market Making",
      "Market Microstructure",
      "Risk Management",
      "Execution"
    ],
    "key_contributions": [
      "揭示现有Almgren-Chriss模型未覆盖瞬态影响中间场景的局限，呼应实证发现",
      "分析即期外汇市场中做市商风险管理与市场影响弹性的相互作用机制"
    ],
    "processed_at": "2026-01-21T08:41:40.965389"
  },
  {
    "id": "2601.13281v1",
    "title": "Spectral Dynamics and Regularization for High-Dimensional Copulas",
    "abstract": "We introduce a novel model for time-varying, asymmetric, tail-dependent copulas in high dimensions that incorporates both spectral dynamics and regularization. The dynamics of the dependence matrix' eigenvalues are modeled in a score-driven way, while biases in the unconditional eigenvalue spectrum are resolved by non-linear shrinkage. The dynamic parameterization of the copula dependence matrix ensures that it satisfies the appropriate restrictions at all times and for any dimension. The model is parsimonious, computationally efficient, easily scalable to high dimensions, and performs well for both simulated and empirical data. In an empirical application to financial market dynamics using 100 stocks from 10 different countries and 10 different industry sectors, we find that our copula model captures both geographic and industry related co-movements and outperforms recent computationally more intensive clustering-based factor copula alternatives. Both the spectral dynamics and the regularization contribute to the new model's performance. During periods of market stress, we find that the spectral dynamics reveal strong increases in international stock market dependence, which causes reductions in diversification potential and increases in systemic risk.",
    "authors": [
      "Koos B. Gubbels",
      "Andre Lucas"
    ],
    "published": "2026-01-19",
    "categories": [
      "econ.EM",
      "q-fin.RM",
      "stat.AP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13281v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13281v1",
    "fetched_at": "2026-01-21T08:37:00.451914",
    "chinese_title": "高维Copula的谱动力学与正则化方法",
    "chinese_summary": "本文提出高维时变非对称尾部依赖Copula新模型，融合谱动力学与正则化，通过得分驱动建模依赖矩阵特征值动态、非线性收缩修正特征谱偏差；模型简洁高效可扩展，实证分析100只跨国跨行业股票时，捕捉地理与行业联动且优于聚类因子Copula，市场压力下揭示国际依赖增强及分散化潜力下降。",
    "tags": [
      "Time Series",
      "Risk Management",
      "Factor Model"
    ],
    "key_contributions": [
      "提出结合谱动力学与正则化的高维时变Copula模型，满足维度与时间约束且高效可扩展",
      "实证验证模型优于聚类因子Copula，捕捉市场联动并揭示压力下系统风险变化"
    ],
    "processed_at": "2026-01-21T08:41:53.855816"
  },
  {
    "id": "2601.12990v1",
    "title": "Beyond Visual Realism: Toward Reliable Financial Time Series Generation",
    "abstract": "Generative models for financial time series often create data that look realistic and even reproduce stylized facts such as fat tails or volatility clustering. However, these apparent successes break down under trading backtests: models like GANs or WGAN-GP frequently collapse, yielding extreme and unrealistic results that make the synthetic data unusable in practice. We identify the root cause in the neglect of financial asymmetry and rare tail events, which strongly affect market risk but are often overlooked by objectives focusing on distribution matching. To address this, we introduce the Stylized Facts Alignment GAN (SFAG), which converts key stylized facts into differentiable structural constraints and jointly optimizes them with adversarial loss. This multi-constraint design ensures that generated series remain aligned with market dynamics not only in plots but also in backtesting. Experiments on the Shanghai Composite Index (2004--2024) show that while baseline GANs produce unstable and implausible trading outcomes, SFAG generates synthetic data that preserve stylized facts and support robust momentum strategy performance. Our results highlight that structure-preserving objectives are essential to bridge the gap between superficial realism and practical usability in financial generative modeling.",
    "authors": [
      "Fan Zhang",
      "Jiabin Luo",
      "Zheng Zhang",
      "Shuanghong Huang",
      "Zhipeng Liu",
      "Yu Chen"
    ],
    "published": "2026-01-19",
    "categories": [
      "q-fin.ST",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.12990v1",
    "arxiv_url": "https://arxiv.org/abs/2601.12990v1",
    "fetched_at": "2026-01-21T08:37:00.451941",
    "chinese_title": "超越视觉逼真性：迈向可靠的金融时间序列生成",
    "chinese_summary": "现有金融时间序列生成模型（如GAN）虽能生成视觉逼真且符合风格化事实的数据，但回测时易崩溃失效，根源是忽略金融不对称性与稀有尾部事件；论文提出Stylized Facts Alignment GAN（SFAG），将关键风格化事实转化为可微结构约束，联合对抗损失优化，实验表明其生成的数据保留风格化事实且支持稳健动量策略。",
    "tags": [
      "Time Series",
      "Deep Learning",
      "Risk Management",
      "Algorithmic Trading"
    ],
    "key_contributions": [
      "揭示现有金融时间序列生成模型回测失效的核心原因是忽视金融不对称性与稀有尾部事件",
      "提出SFAG模型，通过风格化事实的可微结构约束联合对抗损失优化，生成兼具视觉逼真性与实用可靠性的金融时间序列"
    ],
    "processed_at": "2026-01-21T08:42:04.571139"
  },
  {
    "id": "2601.12839v1",
    "title": "Knowledge-Integrated Representation Learning for Crypto Anomaly Detection under Extreme Label Scarcity; Relational Domain-Logic Integration with Retrieval-Grounded Context and Path-Level Explanations",
    "abstract": "Detecting anomalous trajectories in decentralized crypto networks is fundamentally challenged by extreme label scarcity and the adaptive evasion strategies of illicit actors. While Graph Neural Networks (GNNs) effectively capture local structural patterns, they struggle to internalize multi hop, logic driven motifs such as fund dispersal and layering that characterize sophisticated money laundering, limiting their forensic accountability under regulations like the FATF Travel Rule. To address this limitation, we propose Relational Domain Logic Integration (RDLI), a framework that embeds expert derived heuristics as differentiable, logic aware latent signals within representation learning. Unlike static rule based approaches, RDLI enables the detection of complex transactional flows that evade standard message passing. To further account for market volatility, we incorporate a Retrieval Grounded Context (RGC) module that conditions anomaly scoring on regulatory and macroeconomic context, mitigating false positives caused by benign regime shifts. Under extreme label scarcity (0.01%), RDLI outperforms state of the art GNN baselines by 28.9% in F1 score. A micro expert user study further confirms that RDLI path level explanations significantly improve trustworthiness, perceived usefulness, and clarity compared to existing methods, highlighting the importance of integrating domain logic with contextual grounding for both accuracy and explainability.",
    "authors": [
      "Gyuyeon Na",
      "Minjung Park",
      "Soyoun Kim",
      "Jungbin Shin",
      "Sangmi Chai"
    ],
    "published": "2026-01-19",
    "categories": [
      "cs.LG",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.12839v1",
    "arxiv_url": "https://arxiv.org/abs/2601.12839v1",
    "fetched_at": "2026-01-21T08:37:00.451966",
    "chinese_title": "极端标签稀缺下加密货币异常检测的知识集成表示学习——带检索接地上下文与路径级解释的关系领域逻辑集成",
    "chinese_summary": "针对加密网络异常检测面临的极端标签稀缺及复杂洗钱模式（资金分散、分层等）难以被现有图神经网络（GNN）捕捉的问题，论文提出关系领域逻辑集成（RDLI）框架，将专家启发式作为可微逻辑感知信号嵌入表示学习，并结合检索接地上下文（RGC）模块引入监管与宏观经济上下文减少误报；实验显示在0.01%标签稀缺下其F1得分较SOTA GNN提升28.9%，且路径级解释显著提升了方法的可信度、实用性与清晰度。",
    "tags": [
      "Anomaly",
      "Graph Neural Network",
      "Deep Learning",
      "Risk Management"
    ],
    "key_contributions": [
      "提出关系领域逻辑集成（RDLI）框架，将专家启发式转化为可微逻辑感知信号嵌入表示学习，有效捕捉复杂洗钱模式，解决极端标签稀缺下的检测难题",
      "结合检索接地上下文（RGC）模块引入监管与宏观经济上下文减少误报，且提供路径级解释显著提升方法的可信度、实用性与清晰度，性能优于现有SOTA GNN"
    ],
    "processed_at": "2026-01-21T08:42:25.124158"
  },
  {
    "id": "2601.12655v1",
    "title": "Optimal Underreporting and Competitive Equilibrium",
    "abstract": "This paper develops a dynamic insurance market model comprising two competing insurance companies and a continuum of insureds, and examines the interaction between strategic underreporting by the insureds and competitive pricing between the insurance companies under a Bonus-Malus System (BMS) framework. For the first time in an oligopolistic setting, we establish the existence and uniqueness of the insureds' optimal reporting barrier, as well as its continuous dependence on the BMS premiums. For the 2-class BMS case, we prove the existence of Nash equilibrium premium strategies and conduct an extensive sensitivity analysis on the impact of the model parameters on the equilibrium premiums.",
    "authors": [
      "Zongxia Liang",
      "Jiayu Zhang",
      "Zhou Zhou",
      "Bin Zou"
    ],
    "published": "2026-01-19",
    "categories": [
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.12655v1",
    "arxiv_url": "https://arxiv.org/abs/2601.12655v1",
    "fetched_at": "2026-01-21T08:37:00.451994",
    "chinese_title": "最优瞒报与竞争均衡",
    "chinese_summary": "本文构建包含两家竞争保险公司与连续被保险人的动态保险市场模型，在奖惩系统（BMS）框架下研究被保险人策略性瞒报与保险公司竞争定价的互动；首次在寡头垄断场景证明被保险人最优报告阈值的存在唯一性及对BMS保费的连续依赖性，针对2类BMS情形证明纳什均衡保费策略存在性并做参数敏感性分析。",
    "tags": [
      "Risk Management",
      "Behavioral Finance",
      "Asset Pricing"
    ],
    "key_contributions": [
      "首次在寡头垄断保险市场框架下，确立被保险人最优报告阈值的存在唯一性及其对奖惩系统（BMS）保费的连续依赖性",
      "针对2类BMS情形，证明保险公司纳什均衡保费策略的存在性，并分析模型参数对均衡保费的影响"
    ],
    "processed_at": "2026-01-21T08:42:43.378395"
  },
  {
    "id": "2601.12541v1",
    "title": "Admissible Information Structures and the Non-Existence of Global Martingale Pricing",
    "abstract": "No-arbitrage asset pricing characterizes valuation through the existence of equivalent martingale measures relative to a filtration and a class of admissible trading strategies. In practice, pricing is performed across multiple asset classes driven by economic variables that are only partially spanned by traded instruments, raising a structural question: does there exist a single admissible information structure under which all traded assets can be jointly priced as martingales?. We treat the filtration as an endogenous object constrained by admissibility and time-ordering, rather than as an exogenous primitive. For any finite collection of assets, whenever martingale pricing is feasible under some admissible filtration, it is already feasible under a canonical minimal filtration generated by the asset prices themselves; these pricing-sufficient filtrations are unique up to null sets and stable under restriction and aggregation when a common pricing measure exists. Our main result shows that this local compatibility does not extend globally: with three independent unspanned finite-variation drivers, there need not exist any admissible filtration and equivalent measure under which all assets are jointly martingales. The obstruction is sharp (absent with one driver and compatible pairwise with two) and equivalent to failure of admissible dynamic completeness. We complement the theory with numerical diagnostics based on discrete-time Doob--Meyer decompositions, illustrating how admissible information structures suppress predictable components, while inadmissible filtrations generate systematic predictability.",
    "authors": [
      "Alejandro Rodriguez Dominguez"
    ],
    "published": "2026-01-18",
    "categories": [
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.12541v1",
    "arxiv_url": "https://arxiv.org/abs/2601.12541v1",
    "fetched_at": "2026-01-21T08:37:00.452012",
    "chinese_title": "可允许信息结构与全局鞅定价的不存在性",
    "chinese_summary": "本文探讨是否存在单一可允许信息结构使所有交易资产联合鞅定价，将滤波视为受可允许性和时间顺序约束的内生对象而非外生原始变量；发现有限资产下若某可允许滤波可行则资产价格生成的规范最小滤波也可行，但当存在三个独立未被覆盖的有限变差驱动因子时，全局鞅定价不存在，阻碍等价于动态完备性失败。",
    "tags": [
      "Asset Pricing"
    ],
    "key_contributions": [
      "有限资产集合下，若某可允许滤波可行则资产价格生成的规范最小滤波也可行，且该滤波唯一（零测集等价）、稳定",
      "三个独立未被覆盖的有限变差驱动因子存在时，无全局可允许滤波和等价测度使资产联合为鞅，阻碍源于动态完备性失败"
    ],
    "processed_at": "2026-01-21T08:43:08.732895"
  },
  {
    "id": "2601.12414v1",
    "title": "On the Order Between the Standard Deviation and Gini Mean Difference",
    "abstract": "In this paper, we study the order between the standard deviation (SD) and the Gini mean difference (GMD) and derive sharp, interpretable sufficient conditions under which one exceeds the other. By expressing both the SD and the GMD in terms of pairwise differences and linking their comparison to the mean excess function of the absolute difference of two i.i.d.\\ copies, we reduce the problem to structural properties of the underlying distribution. Using tools from reliability and survival analysis, we show that SD dominance arises under heavy-tailed regimes, characterized by decreasing hazard rates or increasing reverse hazard rates. Conversely, when both tails are light -- equivalently, when the hazard rate is increasing and the reverse hazard rate is decreasing -- the GMD dominates the SD.   We further demonstrate that these dominance relations are preserved under affine transformations, mixtures, convolutions, and tail truncation, and we extend the analysis to discrete distributions. Numerous examples illustrate the sharpness of the results and highlight the distinct roles played by tail behavior and distributional regularity. Our findings provide a unified framework for understanding dispersion ordering and offer clear guidance for the choice of variability measures in risk-sensitive applications.",
    "authors": [
      "Nawaf Mohammed"
    ],
    "published": "2026-01-18",
    "categories": [
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.12414v1",
    "arxiv_url": "https://arxiv.org/abs/2601.12414v1",
    "fetched_at": "2026-01-21T08:37:00.452031",
    "chinese_title": "论标准差与基尼平均差的序关系",
    "chinese_summary": "本文研究标准差（SD）与基尼平均差（GMD）的序关系，通过将两者表达为 pairwise差异并关联均值超额函数，结合可靠性与生存分析工具推导了两者谁占优的严格充分条件（重尾下SD占优、轻尾下GMD占优）；进一步证明该关系在仿射变换等操作下保持，扩展至离散分布，为风险应用中选择变异性度量提供统一框架。",
    "tags": [
      "Risk Management",
      "Volatility"
    ],
    "key_contributions": [
      "推导了标准差与基尼平均差序关系的严格可解释充分条件（重尾下SD占优、轻尾下GMD占优）",
      "证明该序关系在仿射变换等操作下保持，扩展至离散分布，为风险应用中选择变异性度量提供统一框架"
    ],
    "processed_at": "2026-01-21T08:43:35.031644"
  },
  {
    "id": "2601.12175v1",
    "title": "Distributional Fitting and Tail Analysis of Lead-Time Compositions: Nights vs. Revenue on Airbnb",
    "abstract": "We analyze daily lead-time distributions for two Airbnb demand metrics, Nights Booked (volume) and Gross Booking Value (revenue), treating each day's allocation across 0-365 days as a compositional vector. The data span 2,557 days from January 2019 through December 2025 in a large North American region. Three findings emerge. First, GBV concentrates more heavily in mid-range horizons: beyond 90 days, GBV tail mass typically exceeds Nights by 20-50%, with ratios reaching 75% at the 180-day threshold during peak seasons. Second, Gamma and Weibull distributions fit comparably well under interval-censored cross-entropy. Gamma wins on 61% of days for Nights and 52% for GBV, with Weibull close behind at 38% and 45%. Lognormal rarely wins (<3%). Nonparametric GAMs achieve 18-80x lower CRPS but sacrifice interpretability. Third, generalized Pareto fits suggest bounded tails for both metrics at thresholds below 150 days, though this may partly reflect right-truncation at 365 days; above 150 days, estimates destabilize. Bai-Perron tests with HAC standard errors identify five structural breaks in the Wasserstein distance series, with early breaks coinciding with COVID-19 disruptions. The results show that volume and revenue lead-time shapes diverge systematically, that simple two-parameter distributions capture daily pmfs adequately, and that tail inference requires care near truncation boundaries.",
    "authors": [
      "Harrison E. Katz",
      "Jess Needleman",
      "Liz Medina"
    ],
    "published": "2026-01-17",
    "categories": [
      "q-fin.ST",
      "stat.AP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.12175v1",
    "arxiv_url": "https://arxiv.org/abs/2601.12175v1",
    "fetched_at": "2026-01-21T08:37:00.452052",
    "chinese_title": "前置时间组成的分布拟合与尾部分析：Airbnb上的入住夜数与收入",
    "chinese_summary": "论文以Airbnb 2019-2025年北美区域每日入住夜数（量）和总预订价值（收入）为对象，将每日0-365天前置时间分配视为组成向量，通过分布拟合、广义Pareto尾部分析及结构断点检验，发现两指标前置时间分布存在系统性差异、简单双参数分布可较好拟合每日概率质量函数且尾部推断需关注截断边界。",
    "tags": [
      "Time Series",
      "Risk Management"
    ],
    "key_contributions": [
      "揭示Airbnb入住夜数与收入的前置时间分布存在系统性差异，收入在中期前置时间（>90天）的尾部质量显著高于入住夜数",
      "验证Gamma、Weibull等简单双参数分布可较好拟合每日前置时间分布，非参数GAMs虽拟合优度更高但解释性不足，且尾部推断需注意365天右截断的影响"
    ],
    "processed_at": "2026-01-21T08:44:02.128699"
  },
  {
    "id": "2601.11958v1",
    "title": "Autonomous Market Intelligence: Agentic AI Nowcasting Predicts Stock Returns",
    "abstract": "Can fully agentic AI nowcast stock returns? We deploy a state-of-the-art Large Language Model to evaluate the attractiveness of each Russell 1000 stock daily, starting from April 2025 when AI web interfaces enabled real-time search. Our data contribution is unique along three dimensions. First, the nowcasting framework is completely out-of-sample and free of look-ahead bias by construction: predictions are collected at the current edge of time, ensuring the AI has no knowledge of future outcomes. Second, this temporal design is irreproducible -- once the information environment passes, it can never be recreated. Third, our framework is 100% agentic: we do not feed the model news, disclosures, or curated text; it autonomously searches the web, filters sources, and synthesises information into quantitative predictions. We find that AI possesses genuine stock selection ability, but only for identifying top winners. Longing the 20 highest-ranked stocks generates a daily Fama-French five-factor plus momentum alpha of 18.4 basis points and an annualised Sharpe ratio of 2.43. Critically, these returns derive from an implementable strategy trading highly liquid Russell 1000 constituents, with transaction costs representing less than 10\\% of gross alpha. However, this predictability is highly concentrated: expanding beyond the top tier rapidly dilutes alpha, and bottom-ranked stocks exhibit returns statistically indistinguishable from the market. We hypothesise that this asymmetry reflects online information structure: genuinely positive news generates coherent signals, while negative news is contaminated by strategic corporate obfuscation and social media noise.",
    "authors": [
      "Zefeng Chen",
      "Darcy Pu"
    ],
    "published": "2026-01-17",
    "categories": [
      "q-fin.GN",
      "q-fin.PM",
      "q-fin.TR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11958v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11958v1",
    "fetched_at": "2026-01-21T08:37:00.452073",
    "chinese_title": "自主市场智能：智能体AI即时预测股票收益",
    "chinese_summary": "该研究用最先进大语言模型构建完全自主的AI即时预测框架，针对罗素1000成分股每日自主搜索网络、过滤合成信息并预测收益；发现AI选股能力仅集中在top赢家，多空top20股票产生显著五因子加动量alpha（日度18.4基点）和高夏普比率（年化2.43），策略可交易且交易成本占比低，但收益集中头部，底部无显著异常。",
    "tags": [
      "LLM",
      "Financial Agent",
      "Asset Pricing",
      "Factor Model"
    ],
    "key_contributions": [
      "构建了完全自主（无人工输入信息）、样本外无前瞻偏差、不可复现的AI股票收益即时预测框架",
      "发现AI选股能力仅集中在top赢家，该可交易策略有显著alpha但扩展后稀释，底部收益无统计异常"
    ],
    "processed_at": "2026-01-21T08:44:20.784446"
  },
  {
    "id": "2601.11209v2",
    "title": "SANOS Smooth strictly Arbitrage-free Non-parametric Option Surfaces",
    "abstract": "We present a simple, numerically efficient but highly flexible non-parametric method to construct representations of option price surfaces which are both smooth and strictly arbitrage-free across time and strike. The method can be viewed as a smooth generalization of the widely-known linear interpolation scheme, and retains the simplicity and transparency of that baseline. Calibration of the model to observed market quotes is formulated as a linear program, allowing bid-ask spreads to be incorporated directly via linear penalties or inequalities, and delivering materially lower computational cost than most of the currently available implied-volatility surface fitting routines. As a further contribution, we derive an equivalent parameterization of the proposed surface in terms of strictly positive \"discrete local volatility\" variables. This yields, to our knowledge, the first construction of smooth, strictly arbitrage-free option price surfaces while requiring only trivial parameter constraints (positivity). We illustrate the approach using S&P 500 index options",
    "authors": [
      "Hans Buehler",
      "Blanka Horvath",
      "Anastasis Kratsios",
      "Yannick Limmer",
      "Raeid Saqur"
    ],
    "published": "2026-01-16",
    "categories": [
      "q-fin.CP",
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11209v2",
    "arxiv_url": "https://arxiv.org/abs/2601.11209v2",
    "fetched_at": "2026-01-21T08:37:00.452156",
    "chinese_title": "SANOS：光滑且严格无套利的非参数期权曲面",
    "chinese_summary": "论文提出一种简单高效的非参数方法，构建跨时间与行权价光滑且严格无套利的期权价格曲面，是线性插值的光滑推广；校准为线性规划可直接纳入买卖价差，计算成本低于现有隐含波动率曲面拟合方法，还推导了仅需严格正约束的等价参数化（离散局部波动率变量），实现首次光滑严格无套利期权曲面构造。",
    "tags": [
      "Options",
      "Volatility",
      "Asset Pricing",
      "Benchmark"
    ],
    "key_contributions": [
      "推导仅需严格正约束的等价参数化（离散局部波动率变量），首次实现光滑严格无套利期权曲面构造"
    ],
    "processed_at": "2026-01-21T08:44:36.829441"
  },
  {
    "id": "2601.09949v2",
    "title": "Kinematic Tokenization: Optimization-Based Continuous-Time Tokens for Learnable Decision Policies in Noisy Time Series",
    "abstract": "Transformers are designed for discrete tokens, yet many real-world signals are continuous processes observed through noisy sampling. Discrete tokenizations (raw values, patches, finite differences) can be brittle in low signal-to-noise regimes, especially when downstream objectives impose asymmetric penalties that rationally encourage abstention. We introduce Kinematic Tokenization, an optimization-based continuous-time representation that reconstructs an explicit spline from noisy measurements and tokenizes local spline coefficients (position, velocity, acceleration, jerk). This is applied to financial time series data in the form of asset prices in conjunction with trading volume profiles. Across a multi-asset daily-equity testbed, we use a risk-averse asymmetric classification objective as a stress test for learnability. Under this objective, several discrete baselines collapse to an absorbing cash policy (the Liquidation Equilibrium), whereas the continuous spline tokens sustain calibrated, non-trivial action distributions and stable policies. These results suggest that explicit continuous-time tokens can improve the learnability and calibration of selective decision policies in noisy time series under abstention-inducing losses.",
    "authors": [
      "Griffin Kearney"
    ],
    "published": "2026-01-15",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.09949v2",
    "arxiv_url": "https://arxiv.org/abs/2601.09949v2",
    "fetched_at": "2026-01-21T08:37:03.599239",
    "chinese_title": "运动学标记化：基于优化的连续时间标记用于噪声时间序列中的可学习决策策略",
    "chinese_summary": "论文针对Transformer适配离散标记与现实连续带噪信号的矛盾，提出运动学标记化方法：通过优化从噪声测量重建显式样条，标记局部样条系数（位置、速度等）；应用于金融时间序列，在风险规避决策任务中，该方法优于离散标记基线，维持稳定非平凡策略，提升可学习性与校准性。",
    "tags": [
      "Transformer",
      "Time Series",
      "Algorithmic Trading",
      "Risk Management"
    ],
    "key_contributions": [
      "提出运动学标记化，将带噪连续时间序列转化为显式样条系数的连续标记，适配Transformer的离散标记需求",
      "证明该方法在噪声金融时间序列的风险规避决策中，优于离散基线，维持稳定策略并提升可学习性与校准性"
    ],
    "processed_at": "2026-01-21T08:44:49.578215"
  },
  {
    "id": "2601.12213v1",
    "title": "One-Sided Matrix Completion from Ultra-Sparse Samples",
    "abstract": "Matrix completion is a classical problem that has received recurring interest across a wide range of fields. In this paper, we revisit this problem in an ultra-sparse sampling regime, where each entry of an unknown, $n\\times d$ matrix $M$ (with $n \\ge d$) is observed independently with probability $p = C / d$, for a fixed integer $C \\ge 2$. This setting is motivated by applications involving large, sparse panel datasets, where the number of rows far exceeds the number of columns. When each row contains only $C$ entries -- fewer than the rank of $M$ -- accurate imputation of $M$ is impossible. Instead, we estimate the row span of $M$ or the averaged second-moment matrix $T = M^{\\top} M / n$.   The empirical second-moment matrix computed from observed entries exhibits non-random and sparse missingness. We propose an unbiased estimator that normalizes each nonzero entry of the second moment by its observed frequency, followed by gradient descent to impute the missing entries of $T$. The normalization divides a weighted sum of $n$ binomial random variables by the total number of ones. We show that the estimator is unbiased for any $p$ and enjoys low variance. When the row vectors of $M$ are drawn uniformly from a rank-$r$ factor model satisfying an incoherence condition, we prove that if $n \\ge O({d r^5 ε^{-2} C^{-2} \\log d})$, any local minimum of the gradient-descent objective is approximately global and recovers $T$ with error at most $ε^2$.   Experiments on both synthetic and real-world data validate our approach. On three MovieLens datasets, our algorithm reduces bias by $88\\%$ relative to baseline estimators. We also empirically validate the linear sampling complexity of $n$ relative to $d$ on synthetic data. On an Amazon reviews dataset with sparsity $10^{-7}$, our method reduces the recovery error of $T$ by $59\\%$ and $M$ by $38\\%$ compared to baseline methods.",
    "authors": [
      "Hongyang R. Zhang",
      "Zhenshuo Zhang",
      "Huy L. Nguyen",
      "Guanghui Lan"
    ],
    "published": "2026-01-18",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.12213v1",
    "arxiv_url": "https://arxiv.org/abs/2601.12213v1",
    "fetched_at": "2026-01-21T08:37:06.745382",
    "chinese_title": "超稀疏采样下的单边矩阵补全",
    "chinese_summary": "本文针对超稀疏采样（矩阵元素以p=C/d概率观测，n≥d）下的矩阵补全问题，因单一行观测条目数少于矩阵秩无法直接补全矩阵，转而估计其平均二阶矩矩阵T=M^⊤M/n；提出无偏估计方法（对二阶矩非零条目按观测频率归一化）结合梯度下降补全缺失项，理论证明样本量足够大时可近似恢复T，实验验证了方法有效性。",
    "tags": [
      "Factor Model",
      "Deep Learning",
      "Asset Pricing"
    ],
    "key_contributions": [
      "针对超稀疏采样下的矩阵补全问题，提出无偏估计方法（对二阶矩非零条目按观测频率归一化）以估计平均二阶矩矩阵T",
      "理论证明样本量满足n≥O(d r⁵ ε⁻² C⁻² log d)时，梯度下降的局部极小近似全局，可恢复T的误差≤ε²，实验验证方法有效性"
    ],
    "processed_at": "2026-01-21T08:45:23.146787"
  },
  {
    "id": "2601.12039v1",
    "title": "Nonlinear Dynamic Factor Analysis With a Transformer Network",
    "abstract": "The paper develops a Transformer architecture for estimating dynamic factors from multivariate time series data under flexible identification assumptions. Performance on small datasets is improved substantially by using a conventional factor model as prior information via a regularization term in the training objective. The results are interpreted with Attention matrices that quantify the relative importance of variables and their lags for the factor estimate. Time variation in Attention patterns can help detect regime switches and evaluate narratives. Monte Carlo experiments suggest that the Transformer is more accurate than the linear factor model, when the data deviate from linear-Gaussian assumptions. An empirical application uses the Transformer to construct a coincident index of U.S. real economic activity.",
    "authors": [
      "Oliver Snellman"
    ],
    "published": "2026-01-17",
    "categories": [
      "econ.EM",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.12039v1",
    "arxiv_url": "https://arxiv.org/abs/2601.12039v1",
    "fetched_at": "2026-01-21T08:37:06.745412",
    "chinese_title": "基于Transformer网络的非线性动态因子分析",
    "chinese_summary": "论文提出一种Transformer架构用于灵活假设下的多元时间序列动态因子估计，通过正则项引入传统因子模型先验提升小数据集性能，并用注意力矩阵量化变量及滞后项对因子估计的相对重要性；蒙特卡洛实验显示其在数据偏离线性高斯假设时比线性因子模型更准确，实证应用于构建美国实际经济活动同步指数。",
    "tags": [
      "Transformer",
      "Factor Model",
      "Time Series",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出基于Transformer的非线性动态因子分析架构，结合传统因子模型正则项提升小数据集性能",
      "利用注意力矩阵解释因子估计的变量及滞后项重要性，且在非线性场景下优于线性因子模型"
    ],
    "processed_at": "2026-01-21T08:45:41.872199"
  },
  {
    "id": "2601.13748v1",
    "title": "EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory",
    "abstract": "Accurate epileptic seizure prediction from electroencephalography (EEG) remains challenging because pre-ictal dynamics may span long time horizons while clinically relevant signatures can be subtle and transient. Many deep learning models face a persistent trade-off between capturing local spatiotemporal patterns and maintaining informative long-range context when operating on ultralong sequences. We propose EEG-Titans, a dualbranch architecture that incorporates a modern neural memory mechanism for long-context modeling. The model combines sliding-window attention to capture short-term anomalies with a recurrent memory pathway that summarizes slower, progressive trends over time. On the CHB-MIT scalp EEG dataset, evaluated under a chronological holdout protocol, EEG-Titans achieves 99.46% average segment-level sensitivity across 18 subjects. We further analyze safety-first operating points on artifact-prone recordings and show that a hierarchical context strategy extending the receptive field for high-noise subjects can markedly reduce false alarms (down to 0.00 FPR/h in an extreme outlier) without sacrificing sensitivity. These results indicate that memory-augmented long-context modeling can provide robust seizure forecasting under clinically constrained evaluation",
    "authors": [
      "Tien-Dat Pham",
      "Xuan-The Tran"
    ],
    "published": "2026-01-20",
    "categories": [
      "cs.LG",
      "cs.HC"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13748v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13748v1",
    "fetched_at": "2026-01-21T08:37:13.029776",
    "chinese_title": "EEG-Titans：基于双分支注意力与神经记忆的长程癫痫发作预测",
    "chinese_summary": "论文提出双分支架构EEG-Titans，结合滑动窗口注意力捕捉短期异常与循环记忆路径总结长期渐进趋势，解决长程EEG序列中局部模式与长程上下文的权衡问题；在CHB-MIT数据集上实现99.46%的平均段级灵敏度，且通过分层上下文策略降低假警报，提升临床场景下的鲁棒性。",
    "tags": [
      "Deep Learning",
      "Time Series",
      "Anomaly"
    ],
    "key_contributions": [
      "提出双分支架构EEG-Titans，融合滑动窗口注意力（捕捉短期异常）与神经记忆（建模长程渐进趋势），缓解长程EEG序列中局部时空模式与长程上下文的权衡问题",
      "在CHB-MIT数据集上实现高灵敏度，且通过分层上下文策略显著降低假警报，增强临床约束下癫痫发作预测的鲁棒性"
    ],
    "processed_at": "2026-01-21T08:46:03.291401"
  },
  {
    "id": "2601.13644v1",
    "title": "Towards Token-Level Text Anomaly Detection",
    "abstract": "Despite significant progress in text anomaly detection for web applications such as spam filtering and fake news detection, existing methods are fundamentally limited to document-level analysis, unable to identify which specific parts of a text are anomalous. We introduce token-level anomaly detection, a novel paradigm that enables fine-grained localization of anomalies within text. We formally define text anomalies at both document and token-levels, and propose a unified detection framework that operates across multiple levels. To facilitate research in this direction, we collect and annotate three benchmark datasets spanning spam, reviews and grammar errors with token-level labels. Experimental results demonstrate that our framework get better performance than other 6 baselines, opening new possibilities for precise anomaly localization in text. All the codes and data are publicly available on https://github.com/charles-cao/TokenCore.",
    "authors": [
      "Yang Cao",
      "Bicheng Yu",
      "Sikun Yang",
      "Ming Liu",
      "Yujiu Yang"
    ],
    "published": "2026-01-20",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13644v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13644v1",
    "fetched_at": "2026-01-21T08:37:13.029813",
    "chinese_title": "面向词级别文本异常检测",
    "chinese_summary": "该论文针对现有文本异常检测仅能实现文档级分析、无法定位具体异常部分的局限，提出词级别异常检测新范式，形式化定义文档与词级别异常并构建统一多级别检测框架；同时收集标注三个含词级别标签的基准数据集（垃圾邮件、评论、语法错误），实验验证框架性能优于6个基线，代码与数据已公开。",
    "tags": [
      "NLP",
      "Anomaly",
      "Benchmark"
    ],
    "key_contributions": [
      "提出词级别文本异常检测新范式，形式化文档与词级别异常定义并构建统一多级别检测框架",
      "收集标注三个含词级别标签的基准数据集，实验验证框架性能优于现有6个基线，代码与数据公开"
    ],
    "processed_at": "2026-01-21T08:46:25.176814"
  },
  {
    "id": "2601.13546v1",
    "title": "ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution",
    "abstract": "LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasoning and multi-turn dialogue Dataset TSEData-20K and contribute the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Furthermore, 3) we propose the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, 4) we propose a LLM-driven Learning-based AD Benchmark LLADBench to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains, up to 34.50% in accuracy, 34.71% in F1, and a 37.42% reduction in false positives. Besides, via KTKO, our optimized ChatAD achieves competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.",
    "authors": [
      "Hui Sun",
      "Chang Xu",
      "Haonan Xie",
      "Hao Li",
      "Yuhao Huang",
      "Chuheng Zhang",
      "Ming Jin",
      "Xiaoguang Liu",
      "Gang Wang",
      "Jiang Bian"
    ],
    "published": "2026-01-20",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13546v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13546v1",
    "fetched_at": "2026-01-21T08:37:13.029849",
    "chinese_title": "ChatAD：基于推理增强的多轮指令演化时间序列异常检测",
    "chinese_summary": "论文针对现有LLM驱动异常检测方法推理不足、多轮对话缺失及泛化性窄的问题，提出多智能体时间序列演化算法TSEvol，构建AD推理多轮对话数据集TSEData-20K并开发ChatAD系列模型；同时提出TS Kahneman-Tversky优化TKTO提升跨任务泛化，建立LLADBench基准评估，实验表明ChatAD模型性能显著提升且TKTO优化后多任务表现优异。",
    "tags": [
      "LLM",
      "Anomaly",
      "Time Series",
      "Benchmark"
    ],
    "key_contributions": [
      "提出多智能体TS演化算法TSEvol，构建TSEData-20K数据集并开发ChatAD系列模型",
      "提出TKTO优化方法和LLADBench基准，提升跨任务泛化并实现有效评估"
    ],
    "processed_at": "2026-01-21T08:46:41.239733"
  },
  {
    "id": "2601.12866v1",
    "title": "PDFInspect: A Unified Feature Extraction Framework for Malicious Document Detection",
    "abstract": "The increasing prevalence of malicious Portable Document Format (PDF) files necessitates robust and comprehensive feature extraction techniques for effective detection and analysis. This work presents a unified framework that integrates graph-based, structural, and metadata-driven analysis to generate a rich feature representation for each PDF document. The system extracts text from PDF pages and constructs undirected graphs based on pairwise word relationships, enabling the computation of graph-theoretic features such as node count, edge density, and clustering coefficient. Simultaneously, the framework parses embedded metadata to quantify character distributions, entropy patterns, and inconsistencies across fields such as author, title, and producer. Temporal features are derived from creation and modification timestamps to capture behavioral signatures, while structural elements including, object streams, fonts, and embedded images, are quantified to reflect document complexity. Boolean flags for potentially malicious PDF constructs (e.g., JavaScript, launch actions) are also extracted. Together, these features form a high-dimensional vector representation (170 dimensions) that is well-suited for downstream tasks such as malware classification, anomaly detection, and forensic analysis. The proposed approach is scalable, extensible, and designed to support real-world PDF threat intelligence workflows.6",
    "authors": [
      "Sharmila S P"
    ],
    "published": "2026-01-19",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.12866v1",
    "arxiv_url": "https://arxiv.org/abs/2601.12866v1",
    "fetched_at": "2026-01-21T08:37:13.029868",
    "chinese_title": "PDFInspect：恶意文档检测的统一特征提取框架",
    "chinese_summary": "本文提出名为PDFInspect的恶意PDF文档检测统一特征提取框架，整合图结构、元数据、时间特征及潜在恶意构造等多维度分析，生成170维高维向量表示，支持恶意分类、异常检测等下游任务，具备可扩展及适配实战威胁情报流程的特点。",
    "tags": [
      "Anomaly",
      "Graph Neural Network"
    ],
    "key_contributions": [
      "提出整合图结构、元数据、时间特征等多维度的PDFInspect统一特征提取框架，生成170维高维向量表示",
      "框架可扩展、适配实战威胁情报流程，支持恶意分类、异常检测等下游任务"
    ],
    "processed_at": "2026-01-21T08:47:39.185405"
  },
  {
    "id": "2601.12745v1",
    "title": "A Graph Prompt Fine-Tuning Method for WSN Spatio-Temporal Correlation Anomaly Detection",
    "abstract": "Anomaly detection of multi-temporal modal data in Wireless Sensor Network (WSN) can provide an important guarantee for reliable network operation. Existing anomaly detection methods in multi-temporal modal data scenarios have the problems of insufficient extraction of spatio-temporal correlation features, high cost of anomaly sample category annotation, and imbalance of anomaly samples. In this paper, a graph neural network anomaly detection backbone network incorporating spatio-temporal correlation features and a multi-task self-supervised training strategy of \"pre-training - graph prompting - fine-tuning\" are designed for the characteristics of WSN graph structure data. First, the anomaly detection backbone network is designed by improving the Mamba model based on a multi-scale strategy and inter-modal fusion method, and combining it with a variational graph convolution module, which is capable of fully extracting spatio-temporal correlation features in the multi-node, multi-temporal modal scenarios of WSNs. Secondly, we design a three-subtask learning \"pre-training\" method with no-negative comparative learning, prediction, and reconstruction to learn generic features of WSN data samples from unlabeled data, and design a \"graph prompting-fine-tuning\" mechanism to guide the pre-trained self-supervised learning. The model is fine-tuned through the \"graph prompting-fine-tuning\" mechanism to guide the pre-trained self-supervised learning model to complete the parameter fine-tuning, thereby reducing the training cost and enhancing the detection generalization performance. The F1 metrics obtained from experiments on the public dataset and the actual collected dataset are up to 91.30% and 92.31%, respectively, which provides better detection performance and generalization ability than existing methods designed by the method.",
    "authors": [
      "Miao Ye",
      "Jing Cui",
      "Yuan huang",
      "Qian He",
      "Yong Wang",
      "Jiwen Zhang"
    ],
    "published": "2026-01-19",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.12745v1",
    "arxiv_url": "https://arxiv.org/abs/2601.12745v1",
    "fetched_at": "2026-01-21T08:37:13.029923",
    "chinese_title": "一种用于WSN时空关联异常检测的图提示微调方法",
    "chinese_summary": "针对WSN多节点多时间模态数据的时空关联特征提取不足、异常样本标注成本高及不平衡问题，设计融合改进Mamba与变分图卷积的异常检测骨干网，提出“预训练-图提示-微调”多任务自监督策略：预训练采用无负对比学习、预测和重建子任务学习通用特征，再通过图提示微调优化异常检测参数。",
    "tags": [
      "Anomaly",
      "Graph Neural Network",
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "设计融合改进Mamba与变分图卷积的骨干网，充分提取WSN多节点多时间模态的时空关联特征",
      "提出“预训练-图提示-微调”多任务自监督策略，解决异常样本标注成本高与不平衡问题"
    ],
    "processed_at": "2026-01-21T08:47:59.932659"
  },
  {
    "id": "2601.12667v1",
    "title": "Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration",
    "abstract": "It is foreseeable that the number of spacecraft will increase exponentially, ushering in an era dominated by satellite mega-constellations (SMC). This necessitates a focus on energy in space: spacecraft power systems (SPS), especially their health management (HM), given their role in power supply and high failure rates. Providing health management for dozens of SPS and for thousands of SPS represents two fundamentally different paradigms. Therefore, to adapt the health management in the SMC era, this work proposes a principle of aligning underlying capabilities (AUC principle) and develops SpaceHMchat, an open-source Human-AI collaboration (HAIC) framework for all-in-loop health management (AIL HM). SpaceHMchat serves across the entire loop of work condition recognition, anomaly detection, fault localization, and maintenance decision making, achieving goals such as conversational task completion, adaptive human-in-the-loop learning, personnel structure optimization, knowledge sharing, efficiency enhancement, as well as transparent reasoning and improved interpretability. Meanwhile, to validate this exploration, a hardware-realistic fault injection experimental platform is established, and its simulation model is built and open-sourced, both fully replicating the real SPS. The corresponding experimental results demonstrate that SpaceHMchat achieves excellent performance across 23 quantitative metrics, such as 100% conclusion accuracy in logical reasoning of work condition recognition, over 99% success rate in anomaly detection tool invocation, over 90% precision in fault localization, and knowledge base search time under 3 minutes in maintenance decision-making. Another contribution of this work is the release of the first-ever AIL HM dataset of SPS. This dataset contains four sub-datasets, involving 4 types of AIL HM sub-tasks, 17 types of faults, and over 700,000 timestamps.",
    "authors": [
      "Yi Di",
      "Zhibin Zhao",
      "Fujin Wang",
      "Xue Liu",
      "Jiafeng Tang",
      "Jiaxin Ren",
      "Zhi Zhai",
      "Xuefeng Chen"
    ],
    "published": "2026-01-19",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.12667v1",
    "arxiv_url": "https://arxiv.org/abs/2601.12667v1",
    "fetched_at": "2026-01-21T08:37:13.029954",
    "chinese_title": "卫星星座时代航天器电源系统全闭环健康管理的人机协作赋能研究",
    "chinese_summary": "本文针对卫星星座时代航天器电源系统（SPS）健康管理的新需求，提出能力对齐（AUC）原则，开发开源人机协作框架SpaceHMchat，覆盖工况识别、异常检测等全闭环健康管理流程；同时建立硬件真实故障注入实验平台及开源仿真模型，验证了框架在23项量化指标上的优异性能。",
    "tags": [
      "Anomaly",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出能力对齐（AUC）原则，开发开源人机协作框架SpaceHMchat，实现航天器电源系统全闭环健康管理",
      "建立硬件真实故障注入实验平台及开源仿真模型，验证框架的优异性能"
    ],
    "processed_at": "2026-01-21T08:49:31.046392"
  },
  {
    "id": "2601.12660v1",
    "title": "Toward Faithful Explanations in Acoustic Anomaly Detection",
    "abstract": "Interpretability is essential for user trust in real-world anomaly detection applications. However, deep learning models, despite their strong performance, often lack transparency. In this work, we study the interpretability of autoencoder-based models for audio anomaly detection, by comparing a standard autoencoder (AE) with a mask autoencoder (MAE) in terms of detection performance and interpretability. We applied several attribution methods, including error maps, saliency maps, SmoothGrad, Integrated Gradients, GradSHAP, and Grad-CAM. Although MAE shows a slightly lower detection, it consistently provides more faithful and temporally precise explanations, suggesting a better alignment with true anomalies. To assess the relevance of the regions highlighted by the explanation method, we propose a perturbation-based faithfulness metric that replaces them with their reconstructions to simulate normal input. Our findings, based on experiments in a real industrial scenario, highlight the importance of incorporating interpretability into anomaly detection pipelines and show that masked training improves explanation quality without compromising performance.",
    "authors": [
      "Maab Elrashid",
      "Anthony Deschênes",
      "Cem Subakan",
      "Mirco Ravanelli",
      "Rémi Georges",
      "Michael Morin"
    ],
    "published": "2026-01-19",
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.12660v1",
    "arxiv_url": "https://arxiv.org/abs/2601.12660v1",
    "fetched_at": "2026-01-21T08:37:13.029981",
    "chinese_title": "声学异常检测中的可信解释研究",
    "chinese_summary": "论文聚焦音频异常检测中自动编码器模型的可解释性，对比标准自动编码器（AE）与掩码自动编码器（MAE）的检测性能及解释效果，提出基于扰动的可信性度量评估解释区域相关性，实验表明MAE解释更可信精确且掩码训练未显著牺牲性能。",
    "tags": [
      "Anomaly",
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "对比AE与MAE在音频异常检测中的性能及解释性，发现MAE的解释更可信且时间精度更高",
      "提出基于扰动的可信性度量方法，通过替换解释区域为重建值模拟正常输入以评估其相关性"
    ],
    "processed_at": "2026-01-21T08:50:36.889582"
  },
  {
    "id": "2601.12426v1",
    "title": "Graph Attention Networks with Physical Constraints for Anomaly Detection",
    "abstract": "Water distribution systems (WDSs) face increasing cyber-physical risks, which make reliable anomaly detection essential. Many data-driven models ignore network topology and are hard to interpret, while model-based ones depend strongly on parameter accuracy. This work proposes a hydraulic-aware graph attention network using normalized conservation law violations as features. It combines mass and energy balance residuals with graph attention and bidirectional LSTM to learn spatio-temporal patterns. A multi-scale module aggregates detection scores from node to network level. On the BATADAL dataset, it reaches $F1=0.979$, showing $3.3$pp gain and high robustness under $15\\%$ parameter noise.",
    "authors": [
      "Mohammadhossein Homaei",
      "Iman Khazrak",
      "Ruben Molano",
      "Andres Caro",
      "Mar Avila"
    ],
    "published": "2026-01-18",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.12426v1",
    "arxiv_url": "https://arxiv.org/abs/2601.12426v1",
    "fetched_at": "2026-01-21T08:37:13.030057",
    "chinese_title": "带物理约束的图注意力网络用于异常检测",
    "chinese_summary": "针对供水系统异常检测中数据驱动模型忽略拓扑、模型依赖参数精度的问题，该文提出水力感知的图注意力网络，以归一化守恒律违反为特征，结合图注意力、双向LSTM及多尺度模块学习时空模式并聚合检测分数；在BATADAL数据集上取得F1=0.979的效果，提升3.3个百分点且15%参数噪声下鲁棒性良好。",
    "tags": [
      "Anomaly",
      "Graph Neural Network",
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "提出带物理约束（归一化守恒律违反）的图注意力网络，融合质量/能量平衡残差、图注意力与双向LSTM学习时空模式",
      "构建多尺度检测分数聚合模块，在BATADAL数据集上实现高F1值且15%参数噪声下鲁棒性良好"
    ],
    "processed_at": "2026-01-21T08:51:19.304608"
  },
  {
    "id": "2601.12286v1",
    "title": "Conversational Context Classification: A Representation Engineering Approach",
    "abstract": "The increasing prevalence of Large Language Models (LLMs) demands effective safeguards for their operation, particularly concerning their tendency to generate out-of-context responses. A key challenge is accurately detecting when LLMs stray from expected conversational norms, manifesting as topic shifts, factual inaccuracies, or outright hallucinations. Traditional anomaly detection struggles to directly apply within contextual semantics. This paper outlines our experiment in exploring the use of Representation Engineering (RepE) and One-Class Support Vector Machine (OCSVM) to identify subspaces within the internal states of LLMs that represent a specific context. By training OCSVM on in-context examples, we establish a robust boundary within the LLM's hidden state latent space. We evaluate out study with two open source LLMs - Llama and Qwen models in specific contextual domain. Our approach entailed identifying the optimal layers within the LLM's internal state subspaces that strongly associates with the context of interest. Our evaluation results showed promising results in identifying the subspace for a specific context. Aside from being useful in detecting in or out of context conversation threads, this research work contributes to the study of better interpreting LLMs.",
    "authors": [
      "Jonathan Pan"
    ],
    "published": "2026-01-18",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.12286v1",
    "arxiv_url": "https://arxiv.org/abs/2601.12286v1",
    "fetched_at": "2026-01-21T08:37:13.030075",
    "chinese_title": "对话上下文分类：一种表示工程方法",
    "chinese_summary": "针对大语言模型（LLM）易生成上下文外响应的问题，论文提出结合表示工程（RepE）与一类支持向量机（OCSVM）的方法，在LLM隐藏状态隐空间中识别特定上下文的子空间并建立边界，可有效检测对话是否符合上下文，同时助力LLM可解释性研究。",
    "tags": [
      "LLM",
      "NLP",
      "Anomaly",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出RepE+OCSVM方法，在LLM隐空间中识别特定上下文子空间并建立边界，解决上下文外响应检测问题",
      "验证该方法在Llama和Qwen模型上的有效性，为LLM可解释性研究提供支持"
    ],
    "processed_at": "2026-01-21T08:52:09.218157"
  },
  {
    "id": "2601.12231v1",
    "title": "Wavelet-Aware Anomaly Detection in Multi-Channel User Logs via Deviation Modulation and Resolution-Adaptive Attention",
    "abstract": "Insider threat detection is a key challenge in enterprise security, relying on user activity logs that capture rich and complex behavioral patterns. These logs are often multi-channel, non-stationary, and anomalies are rare, making anomaly detection challenging. To address these issues, we propose a novel framework that integrates wavelet-aware modulation, multi-resolution wavelet decomposition, and resolution-adaptive attention for robust anomaly detection. Our approach first applies a deviation-aware modulation scheme to suppress routine behaviors while amplifying anomalous deviations. Next, discrete wavelet transform (DWT) decomposes the log signals into multi-resolution representations, capturing both long-term trends and short-term anomalies. Finally, a learnable attention mechanism dynamically reweights the most discriminative frequency bands for detection. On the CERT r4.2 benchmark, our approach consistently outperforms existing baselines in precision, recall, and F1 score across various time granularities and scenarios.",
    "authors": [
      "Kaichuan Kong",
      "Dongjie Liu",
      "Xiaobo Jin",
      "Shijie Xu",
      "Guanggang Geng"
    ],
    "published": "2026-01-18",
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.CO"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.12231v1",
    "arxiv_url": "https://arxiv.org/abs/2601.12231v1",
    "fetched_at": "2026-01-21T08:37:13.030101",
    "chinese_title": "基于偏差调制与分辨率自适应注意力的多通道用户日志小波感知异常检测",
    "chinese_summary": "针对企业安全中多通道、非平稳用户日志的异常检测难题，该文提出整合小波感知调制、多分辨率小波分解与分辨率自适应注意力的框架；通过偏差感知调制抑制常规行为并放大异常偏差，利用离散小波变换（DWT）分解日志信号以捕捉多尺度模式，再经可学习注意力动态加权判别频带，在CERT r4.2基准上性能优于现有基线。",
    "tags": [
      "Anomaly",
      "Deep Learning",
      "Time Series",
      "Benchmark"
    ],
    "key_contributions": [
      "提出整合小波感知调制、多分辨率小波分解与分辨率自适应注意力的异常检测框架，适配多通道非平稳日志的异常检测需求",
      "在CERT r4.2基准上，该框架在不同时间粒度和场景下的精度、召回率、F1均优于现有基线"
    ],
    "processed_at": "2026-01-21T08:53:36.278790"
  },
  {
    "id": "2601.11998v1",
    "title": "Hybrid IDS Using Signature-Based and Anomaly-Based Detection",
    "abstract": "Intrusion detection systems (IDS) are essential for protecting computer systems and networks against a wide range of cyber threats that continue to evolve over time. IDS are commonly categorized into two main types, each with its own strengths and limitations, such as difficulty in detecting previously unseen attacks and the tendency to generate high false positive rates. This paper presents a comprehensive survey and a conceptual overview of Hybrid IDS, which integrate signature-based and anomaly-based detection techniques to enhance attack detection capabilities. The survey examines recent research on Hybrid IDS, classifies existing models into functional categories, and discusses their advantages, limitations, and application domains, including financial systems, air traffic control, and social networks. In addition, recent trends in Hybrid IDS research, such as machine learning-based approaches and cloud-based deployments, are reviewed. Finally, this work outlines potential future research directions aimed at developing more cost-effective Hybrid IDS solutions with improved ability to detect emerging and sophisticated cyberattacks.",
    "authors": [
      "Messaouda Boutassetta",
      "Amina Makhlouf",
      "Newfel Messaoudi",
      "Abdelmadjid Benmachiche",
      "Ines Boutabia"
    ],
    "published": "2026-01-17",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11998v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11998v1",
    "fetched_at": "2026-01-21T08:37:13.030125",
    "chinese_title": "基于签名和异常检测的混合入侵检测系统",
    "chinese_summary": "本文对融合签名与异常检测技术的混合入侵检测系统（IDS）开展全面调查及概念概述，分类现有模型并讨论其优缺点、应用领域；同时回顾机器学习、云部署等研究趋势，提出更具成本效益且能检测新兴复杂攻击的未来方向。",
    "tags": [
      "Anomaly",
      "Risk Management",
      "Deep Learning"
    ],
    "key_contributions": [
      "全面调查混合IDS并分类现有模型，分析其优缺点与应用场景",
      "回顾机器学习、云部署等研究趋势，提出针对新兴复杂攻击的未来研究方向"
    ],
    "processed_at": "2026-01-21T08:54:23.700292"
  },
  {
    "id": "2601.11937v1",
    "title": "Impact of Circuit Depth versus Qubit Count on Variational Quantum Classifiers for Higgs Boson Signal Detection",
    "abstract": "High-Energy Physics (HEP) experiments, such as those at the Large Hadron Collider (LHC), generate massive datasets that challenge classical computational limits. Quantum Machine Learning (QML) offers a potential advantage in processing high-dimensional data; however, finding the optimal architecture for current Noisy Intermediate-Scale Quantum (NISQ) devices remains an open challenge. This study investigates the performance of Variational Quantum Classifiers (VQC) in detecting Higgs Boson signals using the ATLAS Higgs Boson Machine Learning Challenge 2014 experiment dataset. We implemented a dimensionality reduction pipeline using Principal Component Analysis (PCA) to map 30 physical features into 4-qubit and 8-qubit latent spaces. We benchmarked three configurations: (A) a shallow 4-qubit circuit, (B) a deep 4-qubit circuit with increased entanglement layers, and (C) an expanded 8-qubit circuit. Experimental results demonstrate that increasing circuit depth significantly improves performance, yielding the highest accuracy of 56.2% (Configuration B), compared to a baseline of 51.9%. Conversely, simply scaling to 8 qubits resulted in a performance degradation to 50.6% due to optimization challenges associated with Barren Plateaus in the larger Hilbert space. These findings suggest that for near-term quantum hardware, prioritizing circuit depth and entanglement capability is more critical than increasing qubit count for effective anomaly detection in HEP data.",
    "authors": [
      "Fatih Maulana"
    ],
    "published": "2026-01-17",
    "categories": [
      "quant-ph",
      "cs.LG",
      "hep-ex"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11937v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11937v1",
    "fetched_at": "2026-01-21T08:37:13.030143",
    "chinese_title": "电路深度与量子比特数对希格斯玻色子信号检测的变分量子分类器的影响",
    "chinese_summary": "本文针对希格斯玻色子信号检测问题，采用PCA降维将30个物理特征映射到4和8量子比特空间，对比三种变分量子分类器（VQC）配置的性能；实验发现增加电路深度显著提升性能（最高56.2%），而单纯增加量子比特数因优化挑战导致性能下降，指出近中期量子硬件中优先电路深度和纠缠能力比增加量子比特数更关键。",
    "tags": [
      "Anomaly",
      "Benchmark",
      "Deep Learning"
    ],
    "key_contributions": [
      "量化对比电路深度、量子比特数对VQC在希格斯信号检测中的性能影响",
      "揭示近中期量子硬件中电路深度和纠缠能力比单纯增加量子比特数更关键的规律"
    ],
    "processed_at": "2026-01-21T08:55:01.581391"
  },
  {
    "id": "2601.11833v1",
    "title": "Karhunen-Loève Expansion-Based Residual Anomaly Map for Resource-Efficient Glioma MRI Segmentation",
    "abstract": "Accurate segmentation of brain tumors is essential for clinical diagnosis and treatment planning. Deep learning is currently the state-of-the-art for brain tumor segmentation, yet it requires either large datasets or extensive computational resources that are inaccessible in most areas. This makes the problem increasingly difficult: state-of-the-art models use thousands of training cases and vast computational power, where performance drops sharply when either is limited. The top performer in the Brats GLI 2023 competition relied on supercomputers trained on over 92,000 augmented MRI scans using an AMD EPYC 7402 CPU, six NVIDIA RTX 6000 GPUs (48GB VRAM each), and 1024GB of RAM over multiple weeks. To address this, the Karhunen--Loève Expansion (KLE) was implemented as a feature extraction step on downsampled, z-score normalized MRI volumes. Each 240$\\times$240$\\times$155 multi-modal scan is reduced to four $48^3$ channels and compressed into 32 KL coefficients. The resulting approximate reconstruction enables a residual-based anomaly map, which is upsampled and added as a fifth channel to a compact 3D U-Net. All experiments were run on a consumer workstation (AMD Ryzen 5 7600X CPU, RTX 4060Ti (8GB VRAM), and 64GB RAM while using far fewer training cases. This model achieves post-processed Dice scores of 0.929 (WT), 0.856 (TC), and 0.821 (ET), with HD95 distances of 2.93, 6.78, and 10.35 voxels. These results are significantly better than the winning BraTS 2023 methodology for HD95 distances and WT dice scores. This demonstrates that a KLE-based residual anomaly map can dramatically reduce computational cost and data requirements while retaining state-of-the-art performance.",
    "authors": [
      "Anthony Hur"
    ],
    "published": "2026-01-16",
    "categories": [
      "q-bio.QM",
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11833v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11833v1",
    "fetched_at": "2026-01-21T08:37:13.030161",
    "chinese_title": "基于Karhunen-Loève展开的残差异常图用于资源高效的胶质瘤MRI分割",
    "chinese_summary": "为解决现有脑肿瘤分割模型需大量数据和计算资源的问题，论文采用Karhunen-Loève展开（KLE）对MRI体积进行特征提取与压缩，生成残差异常图作为额外通道输入紧凑3D U-Net；在消费级工作站和少量训练样本下取得优于BraTS 2023冠军方法的分割性能。",
    "tags": [
      "Anomaly",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出基于KLE的残差异常图方法，实现MRI特征高效压缩与提取",
      "在消费级硬件和少量训练样本下，分割性能优于BraTS 2023冠军模型"
    ],
    "processed_at": "2026-01-21T08:55:29.648729"
  },
  {
    "id": "2601.11816v1",
    "title": "POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation",
    "abstract": "Enterprise back office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type checked directed acyclic graphs (DAGs), a rubric guided reasoning module selects a single compliant plan, and execution is guarded by validator gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document centric finance tasks, POLARIS produces decision grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95 to 1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI. Keywords Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation",
    "authors": [
      "Zahra Moslemi",
      "Keerthi Koneru",
      "Yen-Ting Lee",
      "Sheethal Kumar",
      "Ramesh Radhakrishnan"
    ],
    "published": "2026-01-16",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11816v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11816v1",
    "fetched_at": "2026-01-21T08:37:13.030195",
    "chinese_title": "POLARIS：面向后台自动化的Agentic AI的类型化规划与管控执行",
    "chinese_summary": "论文提出POLARIS治理编排框架，将企业后台自动化视为LLM Agent的类型化计划综合与验证执行，通过规划器生成类型检查的DAG计划、rubric引导推理选合规计划、执行时用验证器和政策护栏管控；应用于文档中心金融任务，提升决策级 artifact质量、减少人工干预，还构建了治理Agentic AI的初始基准。",
    "tags": [
      "LLM",
      "Financial Agent",
      "Benchmark",
      "Execution"
    ],
    "key_contributions": [
      "提出POLARIS治理编排框架，通过类型化规划、rubric引导推理和管控执行实现政策对齐的Agentic AI后台自动化",
      "构建治理Agentic AI的初始基准，在金融任务中验证框架有效性（如SROIE数据集微F1达0.81、异常路由精度0.95-1.00）"
    ],
    "processed_at": "2026-01-21T08:55:43.873480"
  },
  {
    "id": "2601.13082v1",
    "title": "Adversarial News and Lost Profits: Manipulating Headlines in LLM-Driven Algorithmic Trading",
    "abstract": "Large Language Models (LLMs) are increasingly adopted in the financial domain. Their exceptional capabilities to analyse textual data make them well-suited for inferring the sentiment of finance-related news. Such feedback can be leveraged by algorithmic trading systems (ATS) to guide buy/sell decisions. However, this practice bears the risk that a threat actor may craft \"adversarial news\" intended to mislead an LLM. In particular, the news headline may include \"malicious\" content that remains invisible to human readers but which is still ingested by the LLM. Although prior work has studied textual adversarial examples, their system-wide impact on LLM-supported ATS has not yet been quantified in terms of monetary risk. To address this threat, we consider an adversary with no direct access to an ATS but able to alter stock-related news headlines on a single day. We evaluate two human-imperceptible manipulations in a financial context: Unicode homoglyph substitutions that misroute models during stock-name recognition, and hidden-text clauses that alter the sentiment of the news headline. We implement a realistic ATS in Backtrader that fuses an LSTM-based price forecast with LLM-derived sentiment (FinBERT, FinGPT, FinLLaMA, and six general-purpose LLMs), and quantify monetary impact using portfolio metrics. Experiments on real-world data show that manipulating a one-day attack over 14 months can reliably mislead LLMs and reduce annual returns by up to 17.7 percentage points. To assess real-world feasibility, we analyze popular scraping libraries and trading platforms and survey 27 FinTech practitioners, confirming our hypotheses. We notified trading platform owners of this security issue.",
    "authors": [
      "Advije Rizvani",
      "Giovanni Apruzzese",
      "Pavel Laskov"
    ],
    "published": "2026-01-19",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13082v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13082v1",
    "fetched_at": "2026-01-21T08:37:31.860714",
    "chinese_title": "对抗性新闻与利润损失：LLM驱动的算法交易中操纵标题的研究",
    "chinese_summary": "该论文研究LLM驱动算法交易中对抗性新闻标题的风险，设计两种人类不可察觉的操纵方式（Unicode同形替换、隐藏文本条款），在融合LSTM价格预测与LLM情感的真实ATS中量化攻击影响，发现单日攻击可使年化收益最多降低17.7个百分点。",
    "tags": [
      "LLM",
      "Sentiment Analysis",
      "Algorithmic Trading",
      "Risk Management"
    ],
    "key_contributions": [
      "首次量化对抗性新闻标题对LLM驱动算法交易系统的货币风险（系统级影响）",
      "提出两种人类不可察觉的新闻标题操纵方式，并验证其对投资组合收益的显著负面影响"
    ],
    "processed_at": "2026-01-21T08:56:02.794434"
  },
  {
    "id": "2601.14242v1",
    "title": "APEX-Agents",
    "abstract": "We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX-Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open-source Archipelago, our infrastructure for agent execution and evaluation.",
    "authors": [
      "Bertie Vidgen",
      "Austin Mann",
      "Abby Fennelly",
      "John Wright Stanly",
      "Lucas Rothman",
      "Marco Burstein",
      "Julien Benchek",
      "David Ostrofsky",
      "Anirudh Ravichandran",
      "Debnil Sur",
      "Neel Venugopal",
      "Alannah Hsia",
      "Isaac Robinson",
      "Calix Huang",
      "Olivia Varones",
      "Daniyal Khan",
      "Michael Haines",
      "Zach Richards",
      "Chirag Mahapatra",
      "Brendan Foody",
      "Osvald Nitski"
    ],
    "published": "2026-01-20",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.14242v1",
    "arxiv_url": "https://arxiv.org/abs/2601.14242v1",
    "fetched_at": "2026-01-21T08:37:41.299036",
    "chinese_title": "APEX-Agents：智能体AI生产力指数基准",
    "chinese_summary": "论文引入APEX-Agents基准，用于评估AI智能体执行投行分析师、管理顾问及企业律师创建的长周期跨应用任务的能力；测试8个主流智能体并开源该基准（含480个任务的提示、评分标准等）及执行评估基础设施Archipelago。",
    "tags": [
      "LLM",
      "Financial Agent",
      "Benchmark"
    ],
    "key_contributions": [
      "提出面向金融等领域专业任务的APEX-Agents基准，评估AI智能体长周期跨应用执行能力",
      "开源APEX-Agents基准（含完整任务资源）及智能体执行评估基础设施Archipelago"
    ],
    "processed_at": "2026-01-21T08:56:15.432350"
  },
  {
    "id": "2601.14238v1",
    "title": "Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression",
    "abstract": "Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \\textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecasting with intelligent suppression strategies. Our framework first uses a deep spatiotemporal model to predict wildfire ignition. For high-risk predictions, we deploy a pre-trained reinforcement learning (RL) agent to execute real-time suppression tactics with helitack units inside a physics-informed 3D simulation. The framework generates a threat assessment report to help emergency responders optimize resource allocation and planning. In addition, we are publicly releasing a large-scale, spatiotemporal dataset containing $\\mathbf{9.5}$ million samples of environmental variables for wildfire prediction. Our work demonstrates how deep learning and RL can be combined to support both forecasting and tactical wildfire response. More details can be found at https://sites.google.com/view/firecastrl.",
    "authors": [
      "Shaurya Mathur",
      "Shreyas Bellary Manjunath",
      "Nitin Kulkarni",
      "Alina Vereshchaka"
    ],
    "published": "2026-01-20",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.14238v1",
    "arxiv_url": "https://arxiv.org/abs/2601.14238v1",
    "fetched_at": "2026-01-21T08:37:41.299071",
    "chinese_title": "时空野火预测与直升机灭火的强化学习方法",
    "chinese_summary": "本文提出FireCastRL框架，结合深度时空模型预测野火点燃，针对高风险区域用预训练强化学习代理在物理知情3D模拟中执行直升机灭火策略；同时发布含950万样本的野火预测环境变量时空数据集，生成威胁评估报告辅助应急响应者优化资源分配。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning",
      "Time Series",
      "Risk Management"
    ],
    "key_contributions": [
      "提出FireCastRL主动野火管理框架，融合深度时空预测与强化学习的直升机灭火策略",
      "发布950万样本的野火预测环境变量时空数据集，生成威胁评估报告辅助应急资源分配"
    ],
    "processed_at": "2026-01-21T08:56:41.454435"
  },
  {
    "id": "2601.13918v1",
    "title": "AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization",
    "abstract": "Large Language Models have demonstrated profound utility in the medical domain. However, their application to autonomous Electronic Health Records~(EHRs) navigation remains constrained by a reliance on curated inputs and simplified retrieval tasks. To bridge the gap between idealized experimental settings and realistic clinical environments, we present AgentEHR. This benchmark challenges agents to execute complex decision-making tasks, such as diagnosis and treatment planning, requiring long-range interactive reasoning directly within raw and high-noise databases. In tackling these tasks, we identify that existing summarization methods inevitably suffer from critical information loss and fractured reasoning continuity. To address this, we propose RetroSum, a novel framework that unifies a retrospective summarization mechanism with an evolving experience strategy. By dynamically re-evaluating interaction history, the retrospective mechanism prevents long-context information loss and ensures unbroken logical coherence. Additionally, the evolving strategy bridges the domain gap by retrieving accumulated experience from a memory bank. Extensive empirical evaluations demonstrate that RetroSum achieves performance gains of up to 29.16% over competitive baselines, while significantly decreasing total interaction errors by up to 92.3%.",
    "authors": [
      "Yusheng Liao",
      "Chuan Xuan",
      "Yutong Cai",
      "Lina Yang",
      "Zhe Chen",
      "Yanfeng Wang",
      "Yu Wang"
    ],
    "published": "2026-01-20",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13918v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13918v1",
    "fetched_at": "2026-01-21T08:37:41.299102",
    "chinese_title": "AgentEHR：通过回顾性摘要推进自主临床决策",
    "chinese_summary": "该论文针对大语言模型在电子健康记录（EHR）自主导航中依赖 curated输入、任务简化的问题，提出AgentEHR基准挑战及RetroSum框架；RetroSum通过回顾性摘要机制动态重评估交互历史避免长上下文信息丢失与逻辑断裂，结合进化经验策略从记忆库检索积累经验弥合领域差距；实验表明RetroSum性能比基线最多提升29.16%，交互错误最多减少92.3%。",
    "tags": [
      "LLM",
      "Benchmark",
      "NLP"
    ],
    "key_contributions": [
      "提出AgentEHR基准，挑战智能体在原始高噪声EHR数据库中完成诊断、治疗规划等复杂决策任务",
      "提出RetroSum框架，通过回顾性摘要机制与进化经验策略解决现有方法的信息丢失及推理断裂问题，显著提升自主临床决策性能"
    ],
    "processed_at": "2026-01-21T08:57:04.454711"
  },
  {
    "id": "2601.13864v1",
    "title": "HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware Code Generation",
    "abstract": "Large language models (LLMs) are being increasingly integrated into practical hardware and firmware development pipelines for code generation. Existing studies have primarily focused on evaluating the functional correctness of LLM-generated code, yet paid limited attention to its security issues. However, LLM-generated code that appears functionally sound may embed security flaws which could induce catastrophic damages after deployment. This critical research gap motivates us to design a benchmark for assessing security awareness under realistic specifications. In this work, we introduce HardSecBench, a benchmark with 924 tasks spanning Verilog Register Transfer Level (RTL) and firmware-level C, covering 76 hardware-relevant Common Weakness Enumeration (CWE) entries. Each task includes a structured specification, a secure reference implementation, and executable tests. To automate artifact synthesis, we propose a multi-agent pipeline that decouples synthesis from verification and grounds evaluation in execution evidence, enabling reliable evaluation. Using HardSecBench, we evaluate a range of LLMs on hardware and firmware code generation and find that models often satisfy functional requirements while still leaving security risks. We also find that security results vary with prompting. These findings highlight pressing challenges and offer actionable insights for future advancements in LLM-assisted hardware design. Our data and code will be released soon.",
    "authors": [
      "Qirui Chen",
      "Jingxian Shuai",
      "Shuangwu Chen",
      "Shenghao Ye",
      "Zijian Wen",
      "Xufei Su",
      "Jie Jin",
      "Jiangming Li",
      "Jun Chen",
      "Xiaobin Tan",
      "Jian Yang"
    ],
    "published": "2026-01-20",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13864v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13864v1",
    "fetched_at": "2026-01-21T08:37:41.299139",
    "chinese_title": "HardSecBench：基准测试大语言模型在硬件代码生成中的安全意识",
    "chinese_summary": "现有LLM硬件代码生成研究多聚焦功能正确性，忽略安全缺陷风险，为此论文设计包含924个任务（覆盖Verilog RTL、固件C及76个硬件相关CWE）的基准HardSecBench，还提出多智能体 pipeline 实现自动化合成与验证；通过该基准评估发现，LLM常满足功能要求但存在安全风险，且提示方式影响安全结果。",
    "tags": [
      "LLM",
      "Benchmark",
      "Deep Learning"
    ],
    "key_contributions": [
      "设计包含924个任务（覆盖Verilog RTL、固件C及76个硬件相关CWE）的基准HardSecBench，填补LLM硬件代码生成安全评估的研究空白",
      "提出多智能体 pipeline 实现代码合成与验证的自动化，支撑可靠的LLM安全意识评估"
    ],
    "processed_at": "2026-01-21T08:57:25.992753"
  },
  {
    "id": "2601.13695v1",
    "title": "OptiSQL: Executable SQL Generation from Optical TokensOptiSQL: Executable SQL Generation from Optical Tokens",
    "abstract": "Executable SQL generation is typically studied in text-to-SQL settings, where tables are provided as fully linearized textual schemas and contents. While effective, this formulation assumes access to structured text and incurs substantial token overhead, which is misaligned with many real-world scenarios where tables appear as visual artifacts in documents or webpages. We investigate whether compact optical representations can serve as an efficient interface for executable semantic parsing. We present OptiSQL, a vision-driven framework that generates executable SQL directly from table images and natural language questions using compact optical tokens. OptiSQL leverages an OCR-oriented visual encoder to compress table structure and content into a small set of optical tokens and fine-tunes a pretrained decoder for SQL generation while freezing the encoder to isolate representation sufficiency. Experiments on a visualized version of Spider 2.0-Snow show that OptiSQL retains strong execution accuracy while reducing table input tokens by an order of magnitude. Robustness analyses further demonstrate that optical tokens preserve essential structural information under visual perturbations.",
    "authors": [
      "Sifan Li",
      "Hongkai Chen",
      "Yujun Cai",
      "Liyang Chen",
      "Qingwen Ye",
      "Yiwei Wang"
    ],
    "published": "2026-01-20",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13695v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13695v1",
    "fetched_at": "2026-01-21T08:37:41.299166",
    "chinese_title": "OptiSQL：基于光学令牌的可执行SQL生成",
    "chinese_summary": "该论文针对传统文本到SQL任务依赖结构化文本且令牌开销大的问题，提出视觉驱动框架OptiSQL，可直接从表格图像和自然语言问题生成可执行SQL；OptiSQL通过OCR导向的视觉编码器将表格结构与内容压缩为少量光学令牌，冻结编码器后微调预训练解码器，实验表明其在保留强执行准确率的同时大幅减少输入令牌，且光学令牌在视觉扰动下仍保留关键结构信息。",
    "tags": [
      "NLP",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出视觉驱动的OptiSQL框架，无需依赖结构化文本即可从表格图像和自然语言问题生成可执行SQL",
      "利用OCR导向的视觉编码器压缩表格信息为少量光学令牌，大幅降低输入令牌开销且保留关键结构信息"
    ],
    "processed_at": "2026-01-21T08:57:42.527061"
  },
  {
    "id": "2601.13562v1",
    "title": "Reasoning is a Modality",
    "abstract": "The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.",
    "authors": [
      "Zhiguang Liu",
      "Yi Shang"
    ],
    "published": "2026-01-20",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13562v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13562v1",
    "fetched_at": "2026-01-21T08:37:41.299191",
    "chinese_title": "推理是一种模态",
    "chinese_summary": "论文针对现代AI（如LLM、ViT）缺乏可解释内部状态、与人类推理存在差距的问题，提出“推理是一种模态”的假设（推理应作为独立通道与规则应用的低层级工作区分隔）；设计角色分离Transformer块（拆分全局控制器token与网格工作区token以支持迭代规则执行），在VARC视觉协议下训练，在ARC-1任务上准确率达62.6%（超人类平均60.2%），且模型规则应用更连贯。",
    "tags": [
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出“推理是一种模态”的假设，明确推理需作为独立通道与规则应用工作区分隔",
      "设计角色分离Transformer块，在ARC-1任务上准确率超人类平均，且规则应用更连贯"
    ],
    "processed_at": "2026-01-21T08:58:04.768919"
  },
  {
    "id": "2601.13508v1",
    "title": "CatMaster: An Agentic Autonomous System for Computational Heterogeneous Catalysis Research",
    "abstract": "Density functional theory (DFT) is widely used to connect atomic structure with catalytic behavior, but computational heterogeneous catalysis studies often require long workflows that are costly, iterative, and sensitive to setup choices. Besides the intrinsic cost and accuracy limits of first-principles calculations, practical workflow issues such as keeping references consistent, preparing many related inputs, recovering from failed runs on computing clusters, and maintaining a complete record of what was done, can slow down projects and make results difficult to reproduce or extend.   Here we present CatMaster, a large-language-model (LLM)-driven agent system that turns natural language requests into complete calculation workspaces, including structures, inputs, outputs, logs, and a concise run record. CatMaster maintains a persistent project record of key facts, constraints, and file pointers to support inspection and restartability. It is paired with a multi-fidelity tool library that covers rapid surrogate relaxations and high-fidelity DFT calculations for validation when needed. We demonstrate CatMaster on four demonstrations of increasing complexity: an O2 spin-state check with remote execution, BCC Fe surface energies with a protocol-sensitivity study and CO adsorption site ranking, high-throughput Pt--Ni--Cu alloy screening for hydrogen evolution reaction (HER) descriptors with surrogate-to-DFT validation, and a demonstration beyond the predefined tool set, including equation-of-state fitting for BCC Fe and CO-FeN4-graphene single-atom catalyst geometry preparation. By reducing manual scripting and bookkeeping while keeping the full evidence trail, CatMaster aims to help catalysis researchers focus on modeling choices and chemical interpretation rather than workflow management.",
    "authors": [
      "Honghao Chen",
      "Jiangjie Qiu",
      "Yi Shen Tew",
      "Xiaonan Wang"
    ],
    "published": "2026-01-20",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13508v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13508v1",
    "fetched_at": "2026-01-21T08:37:41.299217",
    "chinese_title": "CatMaster：计算异质催化研究的智能自主系统",
    "chinese_summary": "针对计算异质催化中DFT工作流耗时迭代、设置敏感及可重复性差等问题，论文提出LLM驱动的CatMaster系统，可将自然语言请求转化为含结构、输入输出等的完整计算工作空间，结合多保真度工具库（快速代理松弛与高保真DFT验证）并通过多案例验证其性能。",
    "tags": [
      "LLM",
      "NLP"
    ],
    "key_contributions": [
      "开发LLM驱动的智能系统CatMaster，实现自然语言到完整催化计算工作空间的自动转化，支持项目记录与重启",
      "集成多保真度工具库（快速代理模型与高保真DFT），提升催化计算效率与可靠性，并通过多场景案例验证有效性"
    ],
    "processed_at": "2026-01-21T08:58:27.911682"
  },
  {
    "id": "2601.13443v1",
    "title": "Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models",
    "abstract": "The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured: problem framing, knowledge exploration, retrieval, methodological awareness, and explanation are typically collapsed into a single generative process. This cognitive collapse limits traceability, weakens epistemic control, and undermines reproducibility, particularly in high-responsibility settings.   We introduce Explicit Cognitive Allocation, a general principle for structuring AI-assisted inference through the explicit separation and orchestration of epistemic functions. We instantiate this principle in the Cognitive Universal Agent (CUA), an architecture that organizes inference into distinct stages of exploration and framing, epistemic anchoring, instrumental and methodological mapping, and interpretive synthesis. Central to this framework is the notion of Universal Cognitive Instruments (UCIs), which formalize heterogeneous means, including computational, experimental, organizational, regulatory, and educational instruments, through which abstract inquiries become investigable.   We evaluate the effects of explicit cognitive and instrumental allocation through controlled comparisons between CUA-orchestrated inference and baseline LLM inference under matched execution conditions. Across multiple prompts in the agricultural domain, CUA inference exhibits earlier and structurally governed epistemic convergence, higher epistemic alignment under semantic expansion, and systematic exposure of the instrumental landscape of inquiry. In contrast, baseline LLM inference shows greater variability in alignment and fails to explicitly surface instrumental structure.",
    "authors": [
      "Héctor Manuel Manzanilla-Granados",
      "Zaira Navarrete-Cazales",
      "Miriam Pescador-Rojas",
      "Tonahtiu Ramírez-Romero"
    ],
    "published": "2026-01-19",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13443v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13443v1",
    "fetched_at": "2026-01-21T08:37:41.299242",
    "chinese_title": "显式认知分配：大语言模型中可治理与可审计推理的原则",
    "chinese_summary": "论文指出当前大语言模型（LLM）推理存在认知坍缩问题，限制可追溯性与可治理性；提出显式认知分配原则，将推理分阶段编排并实例化为CUA架构（含UCIs形式化异构工具）；通过农业领域对比实验验证该方法提升了推理的可审计性等核心特性。",
    "tags": [
      "LLM",
      "NLP"
    ],
    "key_contributions": [
      "提出显式认知分配原则，通过显式分离与编排认知功能解决LLM推理的认知坍缩问题，提升可追溯性与可治理性",
      "构建认知通用智能体（CUA）架构，引入通用认知工具（UCIs）形式化整合异构工具，经农业领域实验验证其有效性"
    ],
    "processed_at": "2026-01-21T08:59:08.514169"
  },
  {
    "id": "2601.13401v1",
    "title": "Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics",
    "abstract": "Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning because their architectures destroy pixel-level information required for counting and measurements. Vision encoders compress images through patch embeddings, reducing spatial indexing and losing the precise pixel-level tracking required for accurate counting. We present two contributions to address this fundamental limitation. First, we introduce SQuID (Satellite Quantitative Intelligence Dataset), a benchmark of 2,000 satellite image Question-Answer pairs with both numerical range and categorical answers, designed to evaluate quantitative spatial reasoning. The dataset spans three difficulty tiers with annotations automatically generated from human labels and their learned variability. Second, we propose QVLM (Quantitative Vision-Language Model), a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis. Instead of encoding images into embeddings, QVLM generates executable code that first calls a segmentation model to obtain pixel-level masks, then operates directly on these masks, preserving spatial indexing throughout the reasoning process. Our experiments show that QVLM using GPT-5 as coder achieves 42.0% accuracy on SQuID compared to 28.1% for a VLM prompted with image-question pairs. Our work reveals that, for quantitative spatial reasoning, architectural decoupling enables better accuracy on quantitative tasks.",
    "authors": [
      "Peter A. Massih",
      "Eric Cosatto"
    ],
    "published": "2026-01-19",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13401v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13401v1",
    "fetched_at": "2026-01-21T08:37:41.299262",
    "chinese_title": "像素级精度推理：用于定量地理空间分析的QVLM架构与SQuID数据集",
    "chinese_summary": "该论文针对现有视觉语言模型（VLM）缺乏定量空间推理能力的问题，提出两个核心贡献：一是构建包含2000个卫星图像问答对的SQuID数据集，含数值范围和分类答案并分三级难度，用于定量地理空间分析评估；二是设计QVLM架构，通过解耦语言理解与视觉分析、生成代码调用分割模型获取像素级掩码并直接操作，保持像素精度，实验显示其在SQuID上准确率（42.0%）显著高于传统VLM（28.1%）。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "构建SQuID数据集：2000个卫星图像问答对，含数值范围和分类答案，分三级难度，用于定量地理空间分析评估",
      "提出QVLM架构：解耦语言理解与视觉分析，生成可执行代码调用分割模型获取像素级掩码并直接操作，保持像素精度"
    ],
    "processed_at": "2026-01-21T09:01:15.642951"
  },
  {
    "id": "2601.13398v1",
    "title": "Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility",
    "abstract": "LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. We systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks. We will release the code and the dataset upon acceptance.",
    "authors": [
      "Nickil Maveli",
      "Antonio Vergari",
      "Shay B. Cohen"
    ],
    "published": "2026-01-19",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13398v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13398v1",
    "fetched_at": "2026-01-21T08:37:41.299284",
    "chinese_title": "LLM能压缩（和解压缩）吗？通过可逆性评估代码理解与执行",
    "chinese_summary": "本文提出RoundTripCodeEval（RTCE）基准，通过可逆性测试LLM代码理解与执行的前后向一致性，采用免执行的精确匹配评估双射保真度；系统评估SOTA Code-LLM在零样本、微调执行轨迹及自反思机制下的表现，发现均未解决一致性差距，表明当前LLM缺乏可靠代码推理所需的内部连贯性，且RTCE捕捉了现有基准未覆盖的新见解。",
    "tags": [
      "LLM",
      "Execution",
      "Benchmark"
    ],
    "key_contributions": [
      "提出RTCE基准，通过可逆性测试代码前后向执行一致性，采用免执行精确匹配评估双射保真度"
    ],
    "processed_at": "2026-01-21T09:01:34.541848"
  },
  {
    "id": "2601.13383v1",
    "title": "A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge",
    "abstract": "The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs and local inference engines, and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.",
    "authors": [
      "Akbar Anbar Jafari",
      "Cagri Ozcinar",
      "Gholamreza Anbarjafari"
    ],
    "published": "2026-01-19",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13383v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13383v1",
    "fetched_at": "2026-01-21T08:37:41.299305",
    "chinese_title": "一种轻量级模块化框架：构建大语言模型驱动的自治代理——AgentForge的设计、实现与应用",
    "chinese_summary": "针对现有LLM驱动自治代理框架架构僵化、供应商锁定及复杂度高的问题，本文提出轻量开源Python框架AgentForge，通过可组合技能抽象、统一LLM后端接口、声明式YAML配置三大创新实现快速原型开发；实验表明其任务完成率具竞争力，开发时间较LangChain减少62%、较直接API集成减少78%，且延迟低于100ms适合实时应用。",
    "tags": [
      "LLM",
      "Financial Agent",
      "Benchmark"
    ],
    "key_contributions": [
      "提出轻量开源Python框架AgentForge，通过可组合技能抽象、统一LLM后端接口、声明式YAML配置解决现有框架的架构僵化等问题",
      "形式化技能组合为DAG并验证表达能力，实验证明AgentForge开发效率显著提升且低延迟适合实时应用"
    ],
    "processed_at": "2026-01-21T09:02:20.765088"
  },
  {
    "id": "2601.13111v1",
    "title": "CORE-T: COherent REtrieval of Tables for Text-to-SQL",
    "abstract": "Realistic text-to-SQL workflows often require joining multiple tables. As a result, accurately retrieving the relevant set of tables becomes a key bottleneck for end-to-end performance. We study an open-book setting where queries must be answered over large, heterogeneous table collections pooled from many sources, without clean scoping signals such as database identifiers. Here, dense retrieval (DR) achieves high recall but returns many distractors, while join-aware alternatives often rely on extra assumptions and/or incur high inference overhead. We propose CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference time, DR returns top-K candidates; a single LLM call selects a coherent, joinable subset, and a simple additive adjustment step restores strongly compatible tables. Across Bird, Spider, and MMQA, CORE-T improves table-selection F1 by up to 22.7 points while retrieving up to 42% fewer tables, improving multi-table execution accuracy by up to 5.0 points on Bird and 6.9 points on MMQA, and using 4-5x fewer tokens than LLM-intensive baselines.",
    "authors": [
      "Hassan Soliman",
      "Vivek Gupta",
      "Dan Roth",
      "Iryna Gurevych"
    ],
    "published": "2026-01-19",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13111v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13111v1",
    "fetched_at": "2026-01-21T08:37:41.299328",
    "chinese_title": "CORE-T：面向文本到SQL的表格连贯检索",
    "chinese_summary": "针对真实文本到SQL任务中多表连接的表格检索瓶颈，论文提出无训练可扩展框架CORE-T，通过LLM生成表格元数据并预计算兼容性缓存，推理时结合密集检索与单LLM调用筛选连贯可连接子集，显著提升表格选择F1和多表执行准确率，同时减少检索表数量与token使用。",
    "tags": [
      "LLM",
      "NLP"
    ],
    "key_contributions": [
      "提出无训练、可扩展的CORE-T框架，解决开放环境下文本到SQL的多表检索瓶颈问题",
      "在Bird、Spider等数据集上提升表格选择F1和多表执行准确率，同时减少检索表数量与token消耗"
    ],
    "processed_at": "2026-01-21T09:02:37.712994"
  },
  {
    "id": "2601.13097v1",
    "title": "RM -RF: Reward Model for Run-Free Unit Test Evaluation",
    "abstract": "We present RM-RF, a lightweight reward model for run-free evaluation of automatically generated unit tests. Instead of repeatedly compiling and executing candidate tests, RM-RF predicts - from source and test code alone - three execution-derived signals: (1) whether the augmented test suite compiles and runs successfully, (2) whether the generated test cases increase code coverage, and (3) whether the generated test cases improve the mutation kill rate. To train and evaluate RM-RF we assemble a multilingual dataset (Java, Python, Go) of focal files, test files, and candidate test additions labeled by an execution-based pipeline, and we release an associated dataset and methodology for comparative evaluation. We tested multiple model families and tuning regimes (zero-shot, full fine-tuning, and PEFT via LoRA), achieving an average F1 of 0.69 across the three targets. Compared to conventional compile-and-run instruments, RM-RF provides substantially lower latency and infrastructure cost while delivering competitive predictive fidelity, enabling fast, scalable feedback for large-scale test generation and RL-based code optimization.",
    "authors": [
      "Elena Bruches",
      "Daniil Grebenkin",
      "Mikhail Klementev",
      "Vadim Alperovich",
      "Roman Derunets",
      "Dari Baturova",
      "Georgy Mkrtchyan",
      "Oleg Sedukhin",
      "Ivan Bondarenko",
      "Nikolay Bushkov",
      "Stanislav Moiseev"
    ],
    "published": "2026-01-19",
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13097v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13097v1",
    "fetched_at": "2026-01-21T08:37:41.299364",
    "chinese_title": "RM-RF：无运行单元测试评估的奖励模型",
    "chinese_summary": "论文提出轻量级奖励模型RM-RF，无需编译执行候选测试，仅从源代码和测试代码预测编译运行成功、代码覆盖率提升、突变kill率提升三个执行衍生信号；构建多语言（Java、Python、Go）标注数据集，测试多种模型及调优方式，平均F1达0.69，相比传统工具 latency更低、成本更低且预测精度有竞争力，支持大规模测试生成和RL-based代码优化。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出轻量级奖励模型RM-RF，实现无运行的单元测试评估，无需编译执行即可预测编译运行成功、覆盖率提升、突变kill率三个核心信号",
      "构建多语言（Java、Python、Go）标注数据集，验证RM-RF latency更低、成本更低且预测精度有竞争力，支持大规模测试生成与RL-based代码优化"
    ],
    "processed_at": "2026-01-21T09:03:03.649457"
  },
  {
    "id": "2601.13079v1",
    "title": "Polychronous Wave Computing: Timing-Native Address Selection in Spiking Networks",
    "abstract": "Spike timing offers a combinatorial address space, suggesting that timing-based spiking inference can be executed as lookup and routing rather than as dense multiply--accumulate. Yet most neuromorphic and photonic systems still digitize events into timestamps, bins, or rates and then perform selection in clocked logic. We introduce Polychronous Wave Computing (PWC), a timing-native address-selection primitive that maps relative spike latencies directly to a discrete output route in the wave domain. Spike times are phase-encoded in a rotating frame and processed by a programmable multiport interferometer that evaluates K template correlations in parallel; a driven--dissipative winner-take-all stage then performs a physical argmax, emitting a one-hot output port. We derive the operating envelope imposed by phase wrapping and mutual coherence, and collapse timing jitter, static phase mismatch, and dephasing into a single effective phase-noise budget whose induced winner--runner-up margin predicts boundary-first failures and provides an intensity-only calibration target. Simulations show that nonlinear competition improves routing fidelity compared with noisy linear intensity readout, and that hardware-in-the-loop phase tuning rescues a temporal-order gate from 55.9% to 97.2% accuracy under strong static mismatch. PWC provides a fast routing coprocessor for LUT-style spiking networks and sparse top-1 gates (e.g., mixture-of-experts routing) across polaritonic, photonic, and oscillator platforms.",
    "authors": [
      "Natalila G. Berloff"
    ],
    "published": "2026-01-19",
    "categories": [
      "cond-mat.dis-nn",
      "cs.LG",
      "cs.NE",
      "physics.optics"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13079v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13079v1",
    "fetched_at": "2026-01-21T08:37:41.299382",
    "chinese_title": "多同步波计算：脉冲网络中基于时序的地址选择",
    "chinese_summary": "论文提出多同步波计算（PWC），一种时序原生的脉冲网络地址选择原语，通过相位编码与可编程多端口干涉仪等硬件，无需数字化处理即可直接将相对脉冲延迟映射到离散输出路径；推导工作包络与有效相位噪声预算，模拟及硬件实验验证其提升路由保真度并抗静态相位失配的效果。",
    "tags": [
      "Deep Learning",
      "High Frequency"
    ],
    "key_contributions": [
      "提出多同步波计算（PWC），实现时序原生的脉冲地址选择，无需数字化处理即可直接映射相对脉冲延迟到离散输出路径",
      "推导相位包裹、相干性的工作包络及有效相位噪声预算，验证非线性竞争提升路由保真度与硬件调优的抗噪声能力"
    ],
    "processed_at": "2026-01-21T09:03:41.752970"
  },
  {
    "id": "2601.13060v1",
    "title": "MagicGUI-RMS: A Multi-Agent Reward Model System for Self-Evolving GUI Agents via Automated Feedback Reflux",
    "abstract": "Graphical user interface (GUI) agents are rapidly progressing toward autonomous interaction and reliable task execution across diverse applications. However, two central challenges remain unresolved: automating the evaluation of agent trajectories and generating high-quality training data at scale to enable continual improvement. Existing approaches often depend on manual annotation or static rule-based verification, which restricts scalability and limits adaptability in dynamic environments. We present MagicGUI-RMS, a multi-agent reward model system that delivers adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities. MagicGUI-RMS integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM), enabling fine-grained action assessment and robust generalization across heterogeneous GUI tasks. To support reward learning at scale, we design a structured data construction pipeline that automatically produces balanced and diverse reward datasets, effectively reducing annotation costs while maintaining sample fidelity. During execution, the reward model system identifies erroneous actions, proposes refined alternatives, and continuously enhances agent behavior through an automated data-reflux mechanism. Extensive experiments demonstrate that MagicGUI-RMS yields substantial gains in task accuracy, behavioral robustness. These results establish MagicGUI-RMS as a principled and effective foundation for building self-improving GUI agents driven by reward-based adaptation.",
    "authors": [
      "Zecheng Li",
      "Zhihui Cao",
      "Wenke Huang",
      "Yudong Zhang",
      "Keying Qi",
      "Rui Wang",
      "Zeyu Zheng",
      "Jian Zhao",
      "Hao Zhu",
      "Hengxin Wu",
      "Yuran Wang",
      "Guitao Fan",
      "Guokun Wu",
      "Yicong Liu",
      "Zhilin Gao",
      "Haikun Xu",
      "He Yang",
      "Minqi Xiang",
      "Xingyu Liu",
      "Zuojian Wang"
    ],
    "published": "2026-01-19",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13060v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13060v1",
    "fetched_at": "2026-01-21T08:37:41.299435",
    "chinese_title": "MagicGUI-RMS：基于自动化反馈回流的自演化GUI智能体多智能体奖励模型系统",
    "chinese_summary": "该论文针对GUI智能体自动化评估与大规模训练数据生成的挑战，提出MagicGUI-RMS多智能体奖励模型系统，集成领域特定（DS-RM）与通用（GP-RM）奖励模型实现自适应轨迹评估及纠正反馈；设计自动数据构建 pipeline 生成高质量奖励数据集，通过反馈回流持续优化智能体，实验验证其任务准确率与鲁棒性显著提升。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning",
      "Financial Agent"
    ],
    "key_contributions": [
      "提出MagicGUI-RMS多智能体奖励模型系统，集成领域特定与通用奖励模型，实现GUI智能体自适应轨迹评估、纠正反馈与自演化能力，突破现有手动/静态方法的可扩展性限制；",
      "设计自动数据构建 pipeline 生成平衡多样的高质量奖励数据集，降低标注成本，并通过自动化反馈回流持续优化智能体行为，显著提升任务准确率与鲁棒性。"
    ],
    "processed_at": "2026-01-21T09:04:26.519849"
  },
  {
    "id": "2601.13435v1",
    "title": "A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization",
    "abstract": "Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose \\emph{WaveLSFormer}, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of $0.607 \\pm 0.045$ and a Sharpe ratio of $2.157 \\pm 0.166$, substantially improving both profitability and risk-adjusted returns over the strongest baselines.",
    "authors": [
      "Shuozhe Li",
      "Du Cheng",
      "Leqi Liu"
    ],
    "published": "2026-01-19",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.13435v1",
    "arxiv_url": "https://arxiv.org/abs/2601.13435v1",
    "fetched_at": "2026-01-21T08:38:12.731057",
    "chinese_title": "用于多空股票交易与风险调整收益优化的可学习小波Transformer",
    "chinese_summary": "论文针对金融时间序列的噪声、非平稳性等挑战，提出WaveLSFormer模型：含可学习小波前端（带谱正则化生成多尺度分量）、低导高频注入模块（融合多尺度信息），并优化满足固定风险预算的多空投资组合；实验证明其显著优于MLP、LSTM等基线，提升收益与夏普比率。",
    "tags": [
      "Transformer",
      "Portfolio Optimization",
      "Risk Management",
      "Algorithmic Trading"
    ],
    "key_contributions": [
      "提出WaveLSFormer模型，通过可学习小波前端（谱正则化）和低导高频注入模块融合多尺度金融时间序列信息"
    ],
    "processed_at": "2026-01-21T09:04:41.936254"
  }
]