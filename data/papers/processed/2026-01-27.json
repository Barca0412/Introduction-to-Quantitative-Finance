[
  {
    "id": "2601.18686v1",
    "title": "Optimal strategy and deep hedging for share repurchase programs",
    "abstract": "In recent decades, companies have frequently adopted share repurchase programs to return capital to shareholders or for other strategic purposes, instructing investment banks to rapidly buy back shares on their behalf. When the executing institution is allowed to hedge its exposure, it encounters several challenges due to the intrinsic features of the product. Moreover, contractual clauses or market regulations on trading activity may make it infeasible to rely on Greeks. In this work, we address the hedging of these products by developing a machine-learning framework that determines the optimal execution of the buyback while explicitly accounting for the bank's actual trading capabilities. This unified treatment of execution and hedging yields substantial performance improvements, resulting in an optimized policy that provides a feasible and realistic hedging approach. The pricing of these programs can be framed in terms of the discount that banks offer to the client on the price at which the shares are delivered. Since, in our framework, risk measures serve as objective functions, we exploit the concept of indifference pricing to compute this discount, thereby capturing the actual execution performance.",
    "authors": [
      "Stefano Corti",
      "Roberto Daluiso",
      "Andrea Pallavicini"
    ],
    "published": "2026-01-26",
    "categories": [
      "q-fin.PR",
      "q-fin.CP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18686v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18686v1",
    "fetched_at": "2026-01-27T08:38:04.422972",
    "chinese_title": "股票回购计划的最优策略与深度对冲",
    "chinese_summary": "本文针对股票回购执行中因产品特性、合约条款或监管导致的对冲挑战，开发机器学习框架统一处理执行与对冲（明确考虑银行实际交易能力），优化政策提供可行对冲方法；并基于无差异定价（以风险度量为目标函数）计算回购计划的折扣以反映实际执行表现。",
    "tags": [
      "Deep Learning",
      "Risk Management",
      "Execution",
      "Asset Pricing"
    ],
    "key_contributions": [
      "开发统一执行与对冲的机器学习框架，明确考虑银行实际交易能力，解决股票回购执行中的对冲挑战并提升性能",
      "基于无差异定价（以风险度量为目标函数）计算回购计划的折扣，捕捉实际执行表现"
    ],
    "processed_at": "2026-01-27T08:41:04.941342"
  },
  {
    "id": "2601.18634v1",
    "title": "The Compounded BSDE method: A fully-forward method for option pricing and optimal stopping problems in finance",
    "abstract": "We propose the Compound BSDE method, a fully forward, deep-learning-based approach for solving a broad class of problems in financial mathematics, including optimal stopping. The method is based on a reformulation of option pricing problems in terms of a system of backward stochastic differential equations (BSDEs), which offers a new perspective on the numerical treatment of compound options and optimal stopping problems such as Bermudan option pricing. Building on the classical deep BSDE method for a single BSDE, we develop an algorithm for compound BSDEs and establish its convergence properties. In particular, we derive an \\emph{a posteriori} error estimate for the proposed method. Numerical experiments demonstrate the accuracy and computational efficiency of the approach, and illustrate its effectiveness for high-dimensional option pricing and optimal stopping problems.",
    "authors": [
      "Zhipeng Huang",
      "Cornelis W. Oosterlee"
    ],
    "published": "2026-01-26",
    "categories": [
      "q-fin.CP",
      "math.NA",
      "q-fin.PR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18634v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18634v1",
    "fetched_at": "2026-01-27T08:38:04.423008",
    "chinese_title": "复合BSDE方法：金融中期权定价与最优停止问题的全前向方法",
    "chinese_summary": "论文提出基于深度学习的复合BSDE方法，这是一种全前向方法，用于解决金融中复合期权定价及百慕大期权等最优停止问题；该方法基于BSDE系统重构期权定价问题，建立了算法收敛性及后验误差估计，数值实验验证其在高维问题中的准确性与计算效率。",
    "tags": [
      "Deep Learning",
      "Options",
      "Asset Pricing",
      "Benchmark"
    ],
    "key_contributions": [
      "提出复合BSDE方法，一种基于深度学习的全前向方法，可解决金融中复合期权定价及百慕大期权等最优停止问题",
      "建立该方法的算法收敛性及后验误差估计，数值实验验证其在高维问题中的准确性与计算效率"
    ],
    "processed_at": "2026-01-27T08:41:21.089487"
  },
  {
    "id": "2601.18124v1",
    "title": "The Sherman-Morrison-Markowitz Portfolio",
    "abstract": "We show that the Markowitz portfolio is a scalar multiple of another portfolio which replaces the covariance with the second moment matrix, via simple application of the Sherman-Morrison identity. Moreover it is shown that when using conditional estimates of the first two moments, this \"Sherman-Morrison-Markowitz\" portfolio solves the standard unconditional portfolio optimization problems. We argue that in multi-period portfolio optimization problems it is more natural to replace variance and covariance with their uncentered counterparts. We extend the theory to deal with constraints in expectation, where we find a decomposition of squared effects into spanned and orthogonal components. Compared to the Markowitz portfolio, the Sherman-Morrison-Markowitz portfolio downlevers by a small amount that depends on the conditional squared maximal Sharpe ratio; the practical impact will be fairly small, however. We present some example use cases for the theory.",
    "authors": [
      "Steven E. Pav"
    ],
    "published": "2026-01-26",
    "categories": [
      "q-fin.PM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18124v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18124v1",
    "fetched_at": "2026-01-27T08:38:04.423030",
    "chinese_title": "Sherman-Morrison-Markowitz投资组合",
    "chinese_summary": "论文利用Sherman-Morrison恒等式证明Markowitz投资组合是用二阶矩矩阵替代协方差矩阵的投资组合的标量倍数；指出条件一二阶矩估计下该组合可解标准无条件组合优化问题，多期优化中用非中心化矩更自然，扩展到期望约束并分解平方效应，相比原组合有小幅度去杠杆并给出应用案例。",
    "tags": [
      "Portfolio Optimization",
      "Risk Management"
    ],
    "key_contributions": [
      "证明Markowitz投资组合是二阶矩矩阵替代协方差矩阵的投资组合的标量倍数，且条件矩估计下可解标准无条件组合优化问题",
      "扩展理论到期望约束场景，分解平方效应为张成和正交分量，指出多期优化用非中心化矩更自然，相比原组合有小幅度去杠杆"
    ],
    "processed_at": "2026-01-27T08:41:44.504327"
  },
  {
    "id": "2601.17773v1",
    "title": "MarketGANs: Multivariate financial time-series data augmentation using generative adversarial networks",
    "abstract": "This paper introduces MarketGAN, a factor-based generative framework for high-dimensional asset return generation under severe data scarcity. We embed an explicit asset-pricing factor structure as an economic inductive bias and generate returns as a single joint vector, thereby preserving cross-sectional dependence and tail co-movement alongside inter-temporal dynamics. MarketGAN employs generative adversarial learning with a temporal convolutional network (TCN) backbone, which models stochastic, time-varying factor loadings and volatilities and captures long-range temporal dependence. Using daily returns of large U.S. equities, we find that MarketGAN more closely matches empirical stylized facts of asset returns, including heavy-tailed marginal distributions, volatility clustering, leverage effects, and, most notably, high-dimensional cross-sectional correlation structures and tail co-movement across assets, than conventional factor-model-based bootstrap approaches. In portfolio applications, covariance estimates derived from MarketGAN-generated samples outperform those derived from other methods when factor information is at least weakly informative, demonstrating tangible economic value.",
    "authors": [
      "Jeonggyu Huh",
      "Seungwon Jeong",
      "Hyun-Gyoon Kim",
      "Hyeng Keun Koo",
      "Byung Hwa Lim"
    ],
    "published": "2026-01-25",
    "categories": [
      "q-fin.ST",
      "cs.LG",
      "econ.EM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.17773v1",
    "arxiv_url": "https://arxiv.org/abs/2601.17773v1",
    "fetched_at": "2026-01-27T08:38:04.423058",
    "chinese_title": "MarketGAN：基于生成对抗网络的多元金融时间序列数据增强",
    "chinese_summary": "该论文提出MarketGAN因子生成框架，嵌入资产定价因子结构作为经济归纳偏置，采用时序卷积网络（TCN）骨干的生成对抗学习建模时变因子载荷与波动率，生成保留截面依赖及尾部联动的多元资产收益；相比传统因子模型bootstrap方法，其生成数据更匹配资产收益实证特征，且基于该样本的协方差估计在投资组合应用中表现更优，具经济价值。",
    "tags": [
      "Asset Pricing",
      "Factor Model",
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "提出嵌入资产定价因子结构的MarketGAN框架，利用TCN建模时变因子载荷与波动率，生成保留截面依赖和尾部联动的多元资产收益",
      "生成数据更匹配资产收益实证特征，其协方差估计在投资组合中表现更优，具有经济价值"
    ],
    "processed_at": "2026-01-27T08:42:06.812098"
  },
  {
    "id": "2601.17248v1",
    "title": "VIX and European options with jumps in the short-maturity regime",
    "abstract": "We present a study of the short-maturity asymptotics for VIX and European option prices in local-stochastic volatility models with compound Poisson jumps. Both out-of-the-money (OTM) and at-the-money (ATM) asymptotics are considered. The leading-order asymptotics are obtained in closed-form. We apply our results to three examples: the Eraker model, a Kou-type model, and a folded normal model. Numerical illustrations are provided for these three examples that show the accuracy of predictions based on the asymptotic results.",
    "authors": [
      "Desen Guo",
      "Dan Pirjol",
      "Xiaoyu Wang",
      "Lingjiong Zhu"
    ],
    "published": "2026-01-24",
    "categories": [
      "q-fin.PR",
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.17248v1",
    "arxiv_url": "https://arxiv.org/abs/2601.17248v1",
    "fetched_at": "2026-01-27T08:38:04.423083",
    "chinese_title": "短期限机制下含跳跃的VIX与欧洲期权研究",
    "chinese_summary": "本文研究局部随机波动率模型（含复合泊松跳跃）下VIX与欧洲期权的短期限渐近性，考虑实值外（OTM）和实值内（ATM）两种情形并得到闭式主导阶渐近解；将结果应用于Eraker模型、Kou型模型及折叠正态模型，通过数值示例验证渐近预测的准确性。",
    "tags": [
      "Volatility",
      "Options",
      "Asset Pricing"
    ],
    "key_contributions": [
      "推导了局部随机波动率（含复合泊松跳跃）模型下VIX与欧洲期权的短期限渐近性（OTM/ATM情形），得到闭式主导阶解",
      "将渐近结果应用于三个典型模型并数值验证其预测准确性"
    ],
    "processed_at": "2026-01-27T08:42:26.656687"
  },
  {
    "id": "2601.17247v1",
    "title": "Learning Market Making with Closing Auctions",
    "abstract": "In this work, we investigate the market-making problem on a trading session in which a continuous phase on a limit order book is followed by a closing auction. Whereas standard optimal market-making models typically rely on terminal inventory penalties to manage end-of-day risk, ignoring the significant liquidity events available in closing auctions, we propose a Deep Q-Learning framework that explicitly incorporates this mechanism. We introduce a market-making framework designed to explicitly anticipate the closing auction, continuously refining the projected clearing price as the trading session evolves. We develop a generative stochastic market model to simulate the trading session and to emulate the market. Our theoretical model and Deep Q-Learning method is applied on the generator in two settings: (1) when the mid price follows a rough Heston model with generative data from this stochastic model; and (2) when the mid price corresponds to historical data of assets from the S&P 500 index and the performance of our algorithm is compared with classical benchmarks from optimal market making.",
    "authors": [
      "Julius Graf",
      "Thibaut Mastrolia"
    ],
    "published": "2026-01-24",
    "categories": [
      "q-fin.TR",
      "math.OC"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.17247v1",
    "arxiv_url": "https://arxiv.org/abs/2601.17247v1",
    "fetched_at": "2026-01-27T08:38:04.423104",
    "chinese_title": "含收盘竞价的做市策略学习",
    "chinese_summary": "本文针对含连续限价单阶段与收盘竞价的交易时段做市问题，提出深度Q学习框架，明确纳入收盘竞价机制并持续更新预期清算价；开发生成式随机市场模型，在粗糙Heston模型生成数据及标普500历史数据场景下验证，算法性能优于经典最优做市基准。",
    "tags": [
      "Market Making",
      "Reinforcement Learning",
      "Market Microstructure",
      "Algorithmic Trading"
    ],
    "key_contributions": [
      "提出明确纳入收盘竞价机制的深度Q学习做市框架，通过持续更新预期清算价管理端日风险（区别于传统终端库存惩罚）",
      "开发生成式随机市场模型，在两种场景下验证算法性能优于经典最优做市基准"
    ],
    "processed_at": "2026-01-27T08:42:46.943112"
  },
  {
    "id": "2601.17245v1",
    "title": "Pregeometric Origins of Liquidity Geometry in Financial Order Books",
    "abstract": "We propose a structural framework for the geometry of financial order books in which liquidity, supply, and demand are treated as emergent observables rather than primitive economic variables. The market is modeled as an inflationary relational system without assumed metric, temporal, or price coordinates. Observable quantities arise only through projection, implemented here via spectral embeddings of the graph Laplacian. A one-dimensional projection induces a price-like coordinate, while the projected density defines liquidity profiles around the mid price. Under a minimal single-scale hypothesis -- excluding intrinsic length scales beyond distance to the mid and finite visibility -- we show that projected supply and demand are constrained to gamma-like functional forms. In discrete data, this prediction translates into integrated-gamma cumulative profiles. We test these results using high-frequency Level~II data for several U.S. equities and find robust agreement across assets and intraday windows. Explicit comparison with alternative cumulative models using information criteria demonstrates a systematic preference for the integrated-gamma geometry. A minimal simulation of inflationary relational dynamics reproduces the same structure without invoking agent behavior or price formation mechanisms. These results indicate that key regularities of order-book liquidity reflect geometric constraints induced by observation rather than detailed microstructural dynamics.   Supplementary Material is available at the arXiv submission.",
    "authors": [
      "João P. da Cruz"
    ],
    "published": "2026-01-24",
    "categories": [
      "q-fin.TR",
      "physics.soc-ph"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.17245v1",
    "arxiv_url": "https://arxiv.org/abs/2601.17245v1",
    "fetched_at": "2026-01-27T08:38:04.423125",
    "chinese_title": "金融订单簿流动性几何的前几何起源",
    "chinese_summary": "论文提出将市场建模为无假设度量、时间或价格坐标的膨胀关系系统，通过图拉普拉斯谱嵌入投影得到价格类坐标与流动性分布，在最小单尺度假设下推导供需的伽马类函数形式；利用美国多只股票的高频Level II数据验证该结论，且模拟膨胀关系动力学可复现该结构，表明订单簿流动性规律源于观测的几何约束而非微观结构细节。",
    "tags": [
      "High Frequency",
      "Market Microstructure",
      "Graph Neural Network"
    ],
    "key_contributions": [
      "提出无假设坐标的膨胀关系系统框架，通过谱嵌入推导供需的伽马类函数形式，揭示流动性几何的前几何起源",
      "用高频Level II数据验证该形式，且模拟膨胀动力学复现结构，表明流动性规律源于观测几何约束而非微观细节"
    ],
    "processed_at": "2026-01-27T08:43:10.270476"
  },
  {
    "id": "2601.18128v1",
    "title": "Nonlinear multi-study factor analysis",
    "abstract": "High-dimensional data often exhibit variation that can be captured by lower dimensional factors. For high-dimensional data from multiple studies or environments, one goal is to understand which underlying factors are common to all studies, and which factors are study or environment-specific. As a particular example, we consider platelet gene expression data from patients in different disease groups. In this data, factors correspond to clusters of genes which are co-expressed; we may expect some clusters (or biological pathways) to be active for all diseases, while some clusters are only active for a specific disease. To learn these factors, we consider a nonlinear multi-study factor model, which allows for both shared and specific factors. To fit this model, we propose a multi-study sparse variational autoencoder. The underlying model is sparse in that each observed feature (i.e. each dimension of the data) depends on a small subset of the latent factors. In the genomics example, this means each gene is active in only a few biological processes. Further, the model implicitly induces a penalty on the number of latent factors, which helps separate the shared factors from the group-specific factors. We prove that the latent factors are identified, and demonstrate our method recovers meaningful factors in the platelet gene expression data.",
    "authors": [
      "Gemma E. Moran",
      "Anandi Krishnan"
    ],
    "published": "2026-01-26",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18128v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18128v1",
    "fetched_at": "2026-01-27T08:38:10.532115",
    "chinese_title": "非线性多研究因子分析",
    "chinese_summary": "针对多研究/环境的高维数据，论文提出非线性多研究因子模型，采用多研究稀疏变分自动编码器拟合，可区分共享与特定因子；模型具备稀疏性（每个观测特征依赖少量潜在因子）且隐式惩罚因子数量，证明潜在因子可识别性，并在血小板基因表达数据中验证有效性。",
    "tags": [
      "Factor Model",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出非线性多研究因子模型，可区分多研究/环境下的共享因子与特定因子",
      "设计多研究稀疏变分自动编码器拟合模型，具备稀疏性及隐式因子数量惩罚，证明潜在因子可识别性并在基因表达数据中验证有效性"
    ],
    "processed_at": "2026-01-27T08:43:31.032180"
  },
  {
    "id": "2601.18754v1",
    "title": "$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks",
    "abstract": "Autonomous unmanned aerial vehicle (UAV) systems are increasingly deployed in safety-critical, networked environments where they must operate reliably in the presence of malicious adversaries. While recent benchmarks have evaluated large language model (LLM)-based UAV agents in reasoning, navigation, and efficiency, systematic assessment of security, resilience, and trust under adversarial conditions remains largely unexplored, particularly in emerging 6G-enabled settings.   We introduce $α^{3}$-SecBench, the first large-scale evaluation suite for assessing the security-aware autonomy of LLM-based UAV agents under realistic adversarial interference. Building on multi-turn conversational UAV missions from $α^{3}$-Bench, the framework augments benign episodes with 20,000 validated security overlay attack scenarios targeting seven autonomy layers, including sensing, perception, planning, control, communication, edge/cloud infrastructure, and LLM reasoning. $α^{3}$-SecBench evaluates agents across three orthogonal dimensions: security (attack detection and vulnerability attribution), resilience (safe degradation behavior), and trust (policy-compliant tool usage).   We evaluate 23 state-of-the-art LLMs from major industrial providers and leading AI labs using thousands of adversarially augmented UAV episodes sampled from a corpus of 113,475 missions spanning 175 threat types. While many models reliably detect anomalous behavior, effective mitigation, vulnerability attribution, and trustworthy control actions remain inconsistent. Normalized overall scores range from 12.9% to 57.1%, highlighting a significant gap between anomaly detection and security-aware autonomous decision-making. We release $α^{3}$-SecBench on GitHub: https://github.com/maferrag/AlphaSecBench",
    "authors": [
      "Mohamed Amine Ferrag",
      "Abderrahmane Lakas",
      "Merouane Debbah"
    ],
    "published": "2026-01-26",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18754v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18754v1",
    "fetched_at": "2026-01-27T08:38:16.618252",
    "chinese_title": "α³-SecBench：面向6G网络下基于大语言模型的无人机智能体的安全、弹性与信任大规模评估套件",
    "chinese_summary": "现有LLM-based无人机智能体评估多聚焦推理、导航等，缺乏对抗条件下安全、弹性与信任的系统性评估，论文提出首个大规模评估套件α³-SecBench，基于α³-Bench的多轮对话任务添加2万+验证攻击场景覆盖7个自主层，从安全、弹性、信任三个维度评估23个SOTA LLM，覆盖175种威胁类型的11万+任务。",
    "tags": [
      "LLM",
      "Benchmark",
      "Anomaly"
    ],
    "key_contributions": [
      "提出首个针对6G网络下LLM-based无人机智能体的安全、弹性与信任大规模评估套件α³-SecBench",
      "构建包含2万+验证攻击场景、覆盖7个自主层和175种威胁类型的评估数据集，从三正交维度系统评估23个SOTA LLM的安全感知自主能力"
    ],
    "processed_at": "2026-01-27T08:43:50.843160"
  },
  {
    "id": "2601.17786v1",
    "title": "Beyond a Single Perspective: Text Anomaly Detection with Multi-View Language Representations",
    "abstract": "Text anomaly detection (TAD) plays a critical role in various language-driven real-world applications, including harmful content moderation, phishing detection, and spam review filtering. While two-step \"embedding-detector\" TAD methods have shown state-of-the-art performance, their effectiveness is often limited by the use of a single embedding model and the lack of adaptability across diverse datasets and anomaly types. To address these limitations, we propose to exploit the embeddings from multiple pretrained language models and integrate them into $MCA^2$, a multi-view TAD framework. $MCA^2$ adopts a multi-view reconstruction model to effectively extract normal textual patterns from multiple embedding perspectives. To exploit inter-view complementarity, a contrastive collaboration module is designed to leverage and strengthen the interactions across different views. Moreover, an adaptive allocation module is developed to automatically assign the contribution weight of each view, thereby improving the adaptability to diverse datasets. Extensive experiments on 10 benchmark datasets verify the effectiveness of $MCA^2$ against strong baselines. The source code of $MCA^2$ is available at https://github.com/yankehan/MCA2.",
    "authors": [
      "Yixin Liu",
      "Kehan Yan",
      "Shiyuan Li",
      "Qingfeng Chen",
      "Shirui Pan"
    ],
    "published": "2026-01-25",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.17786v1",
    "arxiv_url": "https://arxiv.org/abs/2601.17786v1",
    "fetched_at": "2026-01-27T08:38:16.618285",
    "chinese_title": "超越单一视角：基于多视图语言表示的文本异常检测",
    "chinese_summary": "针对文本异常检测（TAD）中现有方法依赖单一嵌入模型、跨数据集/异常类型适应性不足的问题，论文提出多视图TAD框架MCA²；该框架通过多视图重建模型提取正常文本模式，结合对比协作模块强化视图互补性，自适应分配模块动态调整各视图权重，在10个基准数据集上验证了有效性。",
    "tags": [
      "NLP",
      "Anomaly",
      "Deep Learning",
      "LLM"
    ],
    "key_contributions": [
      "提出整合多预训练语言模型嵌入的多视图TAD框架MCA²，突破单一嵌入模型的局限性",
      "设计对比协作模块与自适应分配模块，提升视图互补性与跨数据集适应性"
    ],
    "processed_at": "2026-01-27T08:44:03.032856"
  },
  {
    "id": "2601.17542v1",
    "title": "Cognitive Platform Engineering for Autonomous Cloud Operations",
    "abstract": "Modern DevOps practices have accelerated software delivery through automation, CI/CD pipelines, and observability tooling,but these approaches struggle to keep pace with the scale and dynamism of cloud-native systems. As telemetry volume grows and configuration drift increases, traditional, rule-driven automation often results in reactive operations, delayed remediation, and dependency on manual expertise. This paper introduces Cognitive Platform Engineering, a next-generation paradigm that integrates sensing, reasoning, and autonomous action directly into the platform lifecycle. This paper propose a four-plane reference architecture that unifies data collection, intelligent inference, policy-driven orchestration, and human experience layers within a continuous feedback loop. A prototype implementation built with Kubernetes, Terraform, Open Policy Agent, and ML-based anomaly detection demonstrates improvements in mean time to resolution, resource efficiency, and compliance. The results show that embedding intelligence into platform operations enables resilient, self-adjusting, and intent-aligned cloud environments. The paper concludes with research opportunities in reinforcement learning, explainable governance, and sustainable self-managing cloud ecosystems.",
    "authors": [
      "Vinoth Punniyamoorthy",
      "Nitin Saksena",
      "Srivenkateswara Reddy Sankiti",
      "Nachiappan Chockalingam",
      "Aswathnarayan Muthukrishnan Kirubakaran",
      "Shiva Kumar Reddy Carimireddy",
      "Durgaraman Maruthavanan"
    ],
    "published": "2026-01-24",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.17542v1",
    "arxiv_url": "https://arxiv.org/abs/2601.17542v1",
    "fetched_at": "2026-01-27T08:38:16.618329",
    "chinese_title": "面向自主云运维的认知平台工程",
    "chinese_summary": "针对传统DevOps难以适配云原生系统规模与动态性的问题，论文提出认知平台工程范式，设计包含数据收集、智能推理、策略编排及人类经验层的四平面参考架构；通过Kubernetes等工具实现原型，验证其能提升故障平均修复时间、资源效率与合规性，并指出强化学习等研究方向。",
    "tags": [
      "Anomaly",
      "Reinforcement Learning"
    ],
    "key_contributions": [
      "提出认知平台工程范式，整合感知、推理与自主行动到平台生命周期，解决传统DevOps的不足",
      "设计四平面参考架构并实现原型，验证其在故障修复时间、资源效率及合规性方面的提升"
    ],
    "processed_at": "2026-01-27T08:44:22.174174"
  },
  {
    "id": "2601.17430v1",
    "title": "Active Hypothesis Testing for Correlated Combinatorial Anomaly Detection",
    "abstract": "We study the problem of identifying an anomalous subset of streams under correlated noise, motivated by monitoring and security in cyber-physical systems. This problem can be viewed as a form of combinatorial pure exploration, where each stream plays the role of an arm and measurements must be allocated sequentially under uncertainty. Existing combinatorial bandit and hypothesis testing methods typically assume independent observations and fail to exploit correlation for efficient measurement design. We propose ECC-AHT, an adaptive algorithm that selects continuous, constrained measurements to maximize Chernoff information between competing hypotheses, enabling active noise cancellation through differential sensing. ECC-AHT achieves optimal sample complexity guarantees and significantly outperforms state-of-the-art baselines in both synthetic and real-world correlated environments. The code is available on https://github.com/VincentdeCristo/ECC-AHT",
    "authors": [
      "Zichuan Yang",
      "Yiming Xing"
    ],
    "published": "2026-01-24",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.17430v1",
    "arxiv_url": "https://arxiv.org/abs/2601.17430v1",
    "fetched_at": "2026-01-27T08:38:16.618349",
    "chinese_title": "用于相关组合异常检测的主动假设检验",
    "chinese_summary": "论文针对网络物理系统中相关噪声下的异常子集识别问题，提出ECC-AHT自适应算法，通过最大化假设间切尔诺夫信息选择连续约束测量以实现主动噪声抵消，达到最优样本复杂度并在合成及真实相关环境中显著优于现有基线。",
    "tags": [
      "Anomaly"
    ],
    "key_contributions": [
      "证明算法最优样本复杂度，在合成与真实相关场景中显著优于现有基线方法"
    ],
    "processed_at": "2026-01-27T08:44:33.151940"
  },
  {
    "id": "2601.17301v1",
    "title": "Tabular Foundation Models are Strong Graph Anomaly Detectors",
    "abstract": "Graph anomaly detection (GAD), which aims to identify abnormal nodes that deviate from the majority, has become increasingly important in high-stakes Web domains. However, existing GAD methods follow a \"one model per dataset\" paradigm, leading to high computational costs, substantial data demands, and poor generalization when transferred to new datasets. This calls for a foundation model that enables a \"one-for-all\" GAD solution capable of detecting anomalies across diverse graphs without retraining. Yet, achieving this is challenging due to the large structural and feature heterogeneity across domains. In this paper, we propose TFM4GAD, a simple yet effective framework that adapts tabular foundation models (TFMs) for graph anomaly detection. Our key insight is that the core challenges of foundation GAD, handling heterogeneous features, generalizing across domains, and operating with scarce labels, are the exact problems that modern TFMs are designed to solve via synthetic pre-training and powerful in-context learning. The primary challenge thus becomes structural: TFMs are agnostic to graph topology. TFM4GAD bridges this gap by \"flattening\" the graph, constructing an augmented feature table that enriches raw node features with Laplacian embeddings, local and global structural characteristics, and anomaly-sensitive neighborhood aggregations. This augmented table is processed by a TFM in a fully in-context regime. Extensive experiments on multiple datasets with various TFM backbones reveal that TFM4GAD surprisingly achieves significant performance gains over specialized GAD models trained from scratch. Our work offers a new perspective and a practical paradigm for leveraging TFMs as powerful, generalist graph anomaly detectors.",
    "authors": [
      "Yunhui Liu",
      "Tieke He",
      "Yongchao Liu",
      "Can Yi",
      "Hong Jin",
      "Chuntao Hong"
    ],
    "published": "2026-01-24",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.17301v1",
    "arxiv_url": "https://arxiv.org/abs/2601.17301v1",
    "fetched_at": "2026-01-27T08:38:16.618412",
    "chinese_title": "表格基础模型是强大的图异常检测器",
    "chinese_summary": "现有图异常检测（GAD）多为“单数据集单模型”范式，存在计算成本高、泛化性差等缺陷。论文提出TFM4GAD框架，通过“扁平化”图构造包含结构特征的增强特征表，适配表格基础模型（TFM）的上下文学习能力，实现跨域GAD无需重训练。",
    "tags": [
      "Anomaly",
      "Graph Neural Network",
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出适配表格基础模型的GAD框架TFM4GAD，解决现有方法泛化性弱、依赖单数据集训练的问题",
      "设计图扁平化策略，构造融合结构特征的增强特征表，弥补表格基础模型对图拓扑的感知不足"
    ],
    "processed_at": "2026-01-27T08:44:52.392065"
  },
  {
    "id": "2601.17050v1",
    "title": "Single-Pixel Vision-Language Model for Intrinsic Privacy-Preserving Behavioral Intelligence",
    "abstract": "Adverse social interactions, such as bullying, harassment, and other illicit activities, pose significant threats to individual well-being and public safety, leaving profound impacts on physical and mental health. However, these critical events frequently occur in privacy-sensitive environments like restrooms, and changing rooms, where conventional surveillance is prohibited or severely restricted by stringent privacy regulations and ethical concerns. Here, we propose the Single-Pixel Vision-Language Model (SP-VLM), a novel framework that reimagines secure environmental monitoring. It achieves intrinsic privacy-by-design by capturing human dynamics through inherently low-dimensional single-pixel modalities and inferring complex behavioral patterns via seamless vision-language integration. Building on this framework, we demonstrate that single-pixel sensing intrinsically suppresses identity recoverability, rendering state-of-the-art face recognition systems ineffective below a critical sampling rate. We further show that SP-VLM can nonetheless extract meaningful behavioral semantics, enabling robust anomaly detection, people counting, and activity understanding from severely degraded single-pixel observations. Combining these findings, we identify a practical sampling-rate regime in which behavioral intelligence emerges while personal identity remains strongly protected. Together, these results point to a human-rights-aligned pathway for safety monitoring that can support timely intervention without normalizing intrusive surveillance in privacy-sensitive spaces.",
    "authors": [
      "Hongjun An",
      "Yiliang Song",
      "Jiawei Shao",
      "Zhe Sun",
      "Xuelong Li"
    ],
    "published": "2026-01-21",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.17050v1",
    "arxiv_url": "https://arxiv.org/abs/2601.17050v1",
    "fetched_at": "2026-01-27T08:38:16.618519",
    "chinese_title": "单像素视觉-语言模型用于内在隐私保护的行为智能",
    "chinese_summary": "针对隐私敏感环境下的安全监控难题，论文提出单像素视觉-语言模型（SP-VLM），通过低维单像素模态捕捉人类动态并融合视觉-语言推断复杂行为模式；证明该模型可抑制身份恢复，同时从退化观测中提取行为语义（异常检测、人数统计等），并找到平衡行为智能与身份保护的采样率区间。",
    "tags": [
      "Anomaly",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出内在隐私保护的单像素视觉-语言模型（SP-VLM），通过低维单像素模态实现隐私感知，同时融合视觉-语言推断复杂行为模式",
      "验证单像素感知可抑制身份恢复，且能从退化观测中提取行为语义，确定平衡行为智能与身份保护的采样率区间"
    ],
    "processed_at": "2026-01-27T08:45:17.741750"
  },
  {
    "id": "2601.18790v1",
    "title": "MortalMATH: Evaluating the Conflict Between Reasoning Objectives and Emergency Contexts",
    "abstract": "Large Language Models are increasingly optimized for deep reasoning, prioritizing the correct execution of complex tasks over general conversation. We investigate whether this focus on calculation creates a \"tunnel vision\" that ignores safety in critical situations. We introduce MortalMATH, a benchmark of 150 scenarios where users request algebra help while describing increasingly life-threatening emergencies (e.g., stroke symptoms, freefall). We find a sharp behavioral split: generalist models (like Llama-3.1) successfully refuse the math to address the danger. In contrast, specialized reasoning models (like Qwen-3-32b and GPT-5-nano) often ignore the emergency entirely, maintaining over 95 percent task completion rates while the user describes dying. Furthermore, the computational time required for reasoning introduces dangerous delays: up to 15 seconds before any potential help is offered. These results suggest that training models to relentlessly pursue correct answers may inadvertently unlearn the survival instincts required for safe deployment.",
    "authors": [
      "Etienne Lanzeray",
      "Stephane Meilliez",
      "Malo Ruelle",
      "Damien Sileo"
    ],
    "published": "2026-01-26",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18790v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18790v1",
    "fetched_at": "2026-01-27T08:38:44.010967",
    "chinese_title": "MortalMATH：评估推理目标与紧急情境之间的冲突",
    "chinese_summary": "该研究引入包含150个场景的MortalMATH基准（用户请求代数帮助同时描述危及生命的紧急情况），发现通用模型会拒绝数学任务以应对危险，而专用推理模型常完全忽略紧急情况且推理耗时可达15秒；结果表明训练模型执着追求正确答案可能削弱安全部署所需的“生存本能”。",
    "tags": [
      "LLM",
      "NLP",
      "Benchmark"
    ],
    "key_contributions": [
      "引入MortalMATH基准，用于评估大语言模型推理目标与紧急情境的冲突",
      "揭示通用模型与专用推理模型在紧急情境下的行为差异，及推理耗时带来的安全风险"
    ],
    "processed_at": "2026-01-27T08:45:36.556564"
  },
  {
    "id": "2601.18747v1",
    "title": "Capturing P: On the Expressive Power and Efficient Evaluation of Boolean Retrieval",
    "abstract": "Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic graphs; forcing them to execute such queries typically results in intractable runtime performance. Conversely, naive recursive approaches (Term-at-a-Time), while capable of supporting these structures, suffer from prohibitive memory consumption when enforcing broad logical exclusions.   In this paper, we propose that a retrieval engine must be capable of ``Capturing $\\mathbf{P}$'' -- evaluating any polynomial-time property directly over its index in a computationally efficient manner. We define a formal Retrieval Language ($\\mathcal{L}_R$) based on Directed Acyclic Graphs (DAGs) and prove it precisely captures the complexity class $\\mathbf{P}$. We introduce \\texttt{ComputePN}, a novel evaluation algorithm that makes $\\mathcal{L}_R$ tractable. By combining native DAG traversal with a memory-efficient ``Positive-Negative'' response mechanism, \\texttt{ComputePN} ensures the efficient evaluation of any query in $\\mathcal{L}_R$. This work establishes the theoretical foundation for turning the search index into a general-purpose computational engine.",
    "authors": [
      "Amir Aavani"
    ],
    "published": "2026-01-26",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CC",
      "cs.CL",
      "cs.DB"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18747v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18747v1",
    "fetched_at": "2026-01-27T08:38:44.010996",
    "chinese_title": "捕获P：论布尔检索的表达能力与高效评估",
    "chinese_summary": "本文针对现代信息检索中复杂逻辑推理的效率困境，提出检索引擎需能高效评估多项式时间（P）属性；定义基于有向无环图（DAG）的检索语言L_R并证明其捕获P，引入ComputePN算法结合DAG遍历与正负响应机制实现L_R的高效评估，为索引成为通用计算引擎奠定理论基础。",
    "tags": [
      "NLP",
      "Deep Learning",
      "Graph Neural Network"
    ],
    "key_contributions": [
      "定义基于有向无环图（DAG）的检索语言L_R，证明其精确捕获复杂度类P",
      "提出ComputePN算法，通过DAG遍历与正负响应机制实现L_R的高效评估，解决现有检索架构的效率困境"
    ],
    "processed_at": "2026-01-27T08:46:05.014854"
  },
  {
    "id": "2601.18733v1",
    "title": "Advances and Innovations in the Multi-Agent Robotic System (MARS) Challenge",
    "abstract": "Recent advancements in multimodal large language models and vision-languageaction models have significantly driven progress in Embodied AI. As the field transitions toward more complex task scenarios, multi-agent system frameworks are becoming essential for achieving scalable, efficient, and collaborative solutions. This shift is fueled by three primary factors: increasing agent capabilities, enhancing system efficiency through task delegation, and enabling advanced human-agent interactions. To address the challenges posed by multi-agent collaboration, we propose the Multi-Agent Robotic System (MARS) Challenge, held at the NeurIPS 2025 Workshop on SpaVLE. The competition focuses on two critical areas: planning and control, where participants explore multi-agent embodied planning using vision-language models (VLMs) to coordinate tasks and policy execution to perform robotic manipulation in dynamic environments. By evaluating solutions submitted by participants, the challenge provides valuable insights into the design and coordination of embodied multi-agent systems, contributing to the future development of advanced collaborative AI systems.",
    "authors": [
      "Li Kang",
      "Heng Zhou",
      "Xiufeng Song",
      "Rui Li",
      "Bruno N. Y. Chen",
      "Ziye Wang",
      "Ximeng Meng",
      "Stone Tao",
      "Yiran Qin",
      "Xiaohong Liu",
      "Ruimao Zhang",
      "Lei Bai",
      "Yilun Du",
      "Hao Su",
      "Philip Torr",
      "Zhenfei Yin",
      "Ruihao Gong",
      "Yejun Zeng",
      "Fengjun Zhong",
      "Shenghao Jin",
      "Jinyang Guo",
      "Xianglong Liu",
      "Xiaojun Jia",
      "Tianqi Shan",
      "Wenqi Ren",
      "Simeng Qin",
      "Jialing Yang",
      "Xiaoyu Ma",
      "Tianxing Chen",
      "Zixuan Li",
      "Zijian Cai",
      "Yan Qin",
      "Yusen Qin",
      "Qiangyu Chen",
      "Kaixuan Wang",
      "Zhaoming Han",
      "Yao Mu",
      "Ping Luo",
      "Yuanqi Yao",
      "Haoming Song",
      "Jan-Nico Zaech",
      "Fabien Despinoy",
      "Danda Pani Paudel",
      "Luc Van Gool"
    ],
    "published": "2026-01-26",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18733v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18733v1",
    "fetched_at": "2026-01-27T08:38:44.011092",
    "chinese_title": "多智能体机器人系统（MARS）挑战赛的进展与创新",
    "chinese_summary": "随着具身AI向复杂场景演进，多智能体框架成为实现可扩展协作的关键；本文提出NeurIPS 2025 SpaVLE研讨会举办的MARS挑战赛，聚焦规划与控制领域，探索用视觉语言模型（VLMs）协调多智能体具身规划及动态环境下的机器人操作；通过评估参赛方案，为具身多智能体系统的设计与协调提供参考，助力协作AI发展。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Reinforcement Learning"
    ],
    "key_contributions": [
      "提出NeurIPS 2025 SpaVLE研讨会的MARS挑战赛，聚焦规划与控制领域探索VLMs在多智能体具身规划中的应用",
      "通过评估参赛方案为具身多智能体系统的设计与协调提供关键见解"
    ],
    "processed_at": "2026-01-27T08:46:34.259132"
  },
  {
    "id": "2601.18512v1",
    "title": "Using Large Language Models to Construct Virtual Top Managers: A Method for Organizational Research",
    "abstract": "This study introduces a methodological framework that uses large language models to create virtual personas of real top managers. Drawing on real CEO communications and Moral Foundations Theory, we construct LLM-based participants that simulate the decision-making of individual leaders. Across three phases, we assess construct validity, reliability, and behavioral fidelity by benchmarking these virtual CEOs against human participants. Our results indicate that theoretically scaffolded personas approximate the moral judgements observed in human samples, suggesting that LLM-based personas can serve as credible and complementary tools for organizational research in contexts where direct access to executives is limited. We conclude by outlining implications for future research using LLM-based personas in organizational settings.",
    "authors": [
      "Antonio Garzon-Vico",
      "Krithika Sharon Komalapati",
      "Arsalan Shahid",
      "Jan Rosier"
    ],
    "published": "2026-01-26",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18512v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18512v1",
    "fetched_at": "2026-01-27T08:38:44.011115",
    "chinese_title": "使用大语言模型构建虚拟高管：一种组织研究方法",
    "chinese_summary": "本文提出基于大语言模型的虚拟高管构建框架，结合真实CEO沟通数据与道德基础理论模拟高管决策；通过与人类参与者对比验证构念效度、信度等，发现虚拟高管可近似人类道德判断，为高管接触受限的组织研究提供可信补充工具。",
    "tags": [
      "LLM",
      "NLP",
      "Behavioral Finance"
    ],
    "key_contributions": [
      "提出以大语言模型模拟真实高管决策的方法框架，结合道德基础理论提升角色保真度",
      "验证虚拟高管对人类高管道德判断的近似性，为高管研究提供替代工具"
    ],
    "processed_at": "2026-01-27T08:46:52.618134"
  },
  {
    "id": "2601.18418v1",
    "title": "daVinci-Dev: Agent-native Mid-training for Software Engineering",
    "abstract": "Recently, the frontier of Large Language Model (LLM) capabilities has shifted from single-turn code generation to agentic software engineering-a paradigm where models autonomously navigate, edit, and test complex repositories. While post-training methods have become the de facto approach for code agents, **agentic mid-training**-mid-training (MT) on large-scale data that mirrors authentic agentic workflows-remains critically underexplored due to substantial resource requirements, despite offering a more scalable path to instilling foundational agentic behaviors than relying solely on expensive reinforcement learning. A central challenge in realizing effective agentic mid-training is the distribution mismatch between static training data and the dynamic, feedback-rich environment of real development. To address this, we present a systematic study of agentic mid-training, establishing both the data synthesis principles and training methodology for effective agent development at scale. Central to our approach is **agent-native data**-supervision comprising two complementary types of trajectories: **contextually-native trajectories** that preserve the complete information flow an agent experiences, offering broad coverage and diversity; and **environmentally-native trajectories** collected from executable repositories where observations stem from actual tool invocations and test executions, providing depth and interaction authenticity. We verify the model's agentic capabilities on `SWE-Bench Verified`. We demonstrate our superiority over the previous open software engineering mid-training recipe `Kimi-Dev` under two post-training settings with an aligned base model and agentic scaffold, while using less than half mid-training tokens (73.1B). Besides relative advantage, our best performing 32B and 72B models achieve **56.1%** and **58.5%** resolution rates, respectively, which are ...",
    "authors": [
      "Ji Zeng",
      "Dayuan Fu",
      "Tiantian Mi",
      "Yumin Zhuang",
      "Yaxing Huang",
      "Xuefeng Li",
      "Lyumanshan Ye",
      "Muhang Xie",
      "Qishuo Hua",
      "Zhen Huang",
      "Mohan Jiang",
      "Hanning Wang",
      "Jifan Lin",
      "Yang Xiao",
      "Jie Sun",
      "Yunze Wu",
      "Pengfei Liu"
    ],
    "published": "2026-01-26",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18418v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18418v1",
    "fetched_at": "2026-01-27T08:38:44.011161",
    "chinese_title": "daVinci-Dev：面向软件工程的Agent原生中间训练",
    "chinese_summary": "本文针对LLM从单轮代码生成向Agentic软件工程范式转变的需求，指出Agentic中间训练（MT）因资源限制未被充分探索但比仅依赖强化学习更具可扩展性；提出agent-native数据监督方法（含上下文原生和环境原生两种互补轨迹）以解决训练数据与真实开发环境的分布不匹配问题，并验证了模型的Agentic能力。",
    "tags": [
      "LLM",
      "Reinforcement Learning",
      "Transformer"
    ],
    "key_contributions": [
      "系统研究Agentic中间训练，建立大规模有效Agent开发的数据合成原则与训练方法",
      "提出agent-native数据监督（含上下文原生和环境原生两种轨迹）以缓解训练数据与真实开发环境的分布不匹配问题"
    ],
    "processed_at": "2026-01-27T08:47:12.862170"
  },
  {
    "id": "2601.18381v1",
    "title": "AI Agent for Reverse-Engineering Legacy Finite-Difference Code and Translating to Devito",
    "abstract": "To facilitate the transformation of legacy finite difference implementations into the Devito environment, this study develops an integrated AI agent framework. Retrieval-Augmented Generation (RAG) and open-source Large Language Models are combined through multi-stage iterative workflows in the system's hybrid LangGraph architecture. The agent constructs an extensive Devito knowledge graph through document parsing, structure-aware segmentation, extraction of entity relationships, and Leiden-based community detection. GraphRAG optimisation enhances query performance across semantic communities that include seismic wave simulation, computational fluid dynamics, and performance tuning libraries. A reverse engineering component derives three-level query strategies for RAG retrieval through static analysis of Fortran source code. To deliver precise contextual information for language model guidance, the multi-stage retrieval pipeline performs parallel searching, concept expansion, community-scale retrieval, and semantic similarity analysis. Code synthesis is governed by Pydantic-based constraints to guarantee structured outputs and reliability. A comprehensive validation framework integrates conventional static analysis with the G-Eval approach, covering execution correctness, structural soundness, mathematical consistency, and API compliance. The overall agent workflow is implemented on the LangGraph framework and adopts concurrent processing to support quality-based iterative refinement and state-aware dynamic routing. The principal contribution lies in the incorporation of feedback mechanisms motivated by reinforcement learning, enabling a transition from static code translation toward dynamic and adaptive analytical behavior.",
    "authors": [
      "Yinghan Hou",
      "Zongyou Yang"
    ],
    "published": "2026-01-26",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18381v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18381v1",
    "fetched_at": "2026-01-27T08:38:44.011185",
    "chinese_title": "用于逆向工程遗留有限差分代码并转换为Devito的AI Agent",
    "chinese_summary": "该研究开发集成AI Agent框架，结合检索增强生成（RAG）与开源大模型，通过LangGraph架构实现遗留有限差分代码到Devito的自动转换；构建Devito知识图谱并优化GraphRAG，同时基于Fortran代码静态分析设计三级查询策略提升检索精度，最终通过Pydantic约束与多维度验证保障转换代码可靠性。",
    "tags": [
      "LLM",
      "NLP",
      "Financial Agent"
    ],
    "key_contributions": [
      "开发集成RAG与开源LLM的AI Agent框架，基于LangGraph实现遗留有限差分代码到Devito的自动转换",
      "构建Devito知识图谱及GraphRAG优化，结合Fortran代码静态分析设计三级查询策略提升检索精度",
      "提出Pydantic约束的代码合成与多维度验证框架，保障转换代码正确性与可靠性"
    ],
    "processed_at": "2026-01-27T08:47:39.364227"
  },
  {
    "id": "2601.18352v1",
    "title": "Code over Words: Overcoming Semantic Inertia via Code-Grounded Reasoning",
    "abstract": "LLMs struggle with Semantic Inertia: the inability to inhibit pre-trained priors (e.g., \"Lava is Dangerous\") when dynamic, in-context rules contradict them. We probe this phenomenon using Baba Is You, where physical laws are mutable text rules, enabling precise evaluation of models' ability to override learned priors when rules change. We quantatively observe that larger models can exhibit inverse scaling: they perform worse than smaller models when natural language reasoning requires suppressing pre-trained associations (e.g., accepting \"Lava is Safe\"). Our analysis attributes this to natural language encoding, which entangles descriptive semantics and logical rules, leading to persistent hallucinations of familiar physics despite explicit contradictory rules. Here we show that representing dynamics as executable code, rather than descriptive text, reverses this trend and enables effective prior inhibition. We introduce Code-Grounded Vistas (LCV), which fine-tunes models on counterfactual pairs and identifies states with contradictory rules, thereby forcing attention to logical constraints rather than visual semantics. This training-time approach outperforms expensive inference-time search methods in both efficiency and accuracy. Our results demonstrate that representation fundamentally determines whether scaling improves or impairs contextual reasoning. This challenges the assumption that larger models are universally better, with implications for domains that require dynamic overriding of learned priors.",
    "authors": [
      "Manjie Xu",
      "Isabella Yin",
      "Xinyi Tu",
      "Chi Zhang",
      "Yixin Zhu"
    ],
    "published": "2026-01-26",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18352v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18352v1",
    "fetched_at": "2026-01-27T08:38:44.011210",
    "chinese_title": "代码优先：通过代码接地推理克服语义惯性",
    "chinese_summary": "本文指出大语言模型存在语义惯性（预训练先验与上下文规则矛盾时无法抑制），且大模型可能出现逆 scaling 现象（抑制先验任务表现差于小模型）；提出代码接地视角（LCV）训练方法，通过微调模型处理反事实对与矛盾规则以聚焦逻辑约束，实验表明该方法比推理时搜索更高效准确，证明表示形式决定 scaling 对上下文推理的影响。",
    "tags": [
      "LLM",
      "NLP",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "揭示大语言模型的语义惯性及逆 scaling 现象（大模型抑制预训练先验的能力弱于小模型）",
      "提出代码接地视角（LCV）训练方法，通过聚焦逻辑约束高效准确克服语义惯性，证明表示形式决定 scaling 对上下文推理的影响"
    ],
    "processed_at": "2026-01-27T08:47:56.381717"
  },
  {
    "id": "2601.18320v1",
    "title": "MultiVis-Agent: A Multi-Agent Framework with Logic Rules for Reliable and Comprehensive Cross-Modal Data Visualization",
    "abstract": "Real-world visualization tasks involve complex, multi-modal requirements that extend beyond simple text-to-chart generation, requiring reference images, code examples, and iterative refinement. Current systems exhibit fundamental limitations: single-modality input, one-shot generation, and rigid workflows. While LLM-based approaches show potential for these complex requirements, they introduce reliability challenges including catastrophic failures and infinite loop susceptibility. To address this gap, we propose MultiVis-Agent, a logic rule-enhanced multi-agent framework for reliable multi-modal and multi-scenario visualization generation. Our approach introduces a four-layer logic rule framework that provides mathematical guarantees for system reliability while maintaining flexibility. Unlike traditional rule-based systems, our logic rules are mathematical constraints that guide LLM reasoning rather than replacing it. We formalize the MultiVis task spanning four scenarios from basic generation to iterative refinement, and develop MultiVis-Bench, a benchmark with over 1,000 cases for multi-modal visualization evaluation. Extensive experiments demonstrate that our approach achieves 75.63% visualization score on challenging tasks, significantly outperforming baselines (57.54-62.79%), with task completion rates of 99.58% and code execution success rates of 94.56% (vs. 74.48% and 65.10% without logic rules), successfully addressing both complexity and reliability challenges in automated visualization generation.",
    "authors": [
      "Jinwei Lu",
      "Yuanfeng Song",
      "Chen Zhang",
      "Raymond Chi-Wing Wong"
    ],
    "published": "2026-01-26",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18320v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18320v1",
    "fetched_at": "2026-01-27T08:38:44.011233",
    "chinese_title": "MultiVis-Agent：基于逻辑规则的多智能体框架，实现可靠全面的跨模态数据可视化",
    "chinese_summary": "论文提出MultiVis-Agent——一种增强逻辑规则的多智能体框架，通过四层数学约束的逻辑规则引导LLM推理，既保证系统可靠性又维持灵活性；形式化多模态可视化任务的四个场景并开发MultiVis-Bench基准，实验表明其可视化得分、任务完成率及代码执行成功率均显著优于基线。",
    "tags": [
      "LLM",
      "Benchmark",
      "NLP"
    ],
    "key_contributions": [
      "提出逻辑规则增强的多智能体框架MultiVis-Agent，四层逻辑规则提供数学可靠性保证且不替代LLM推理",
      "构建包含超1000案例的MultiVis-Bench基准，形式化多场景可视化任务，实验验证方法性能显著领先基线"
    ],
    "processed_at": "2026-01-27T08:48:25.984699"
  },
  {
    "id": "2601.18308v1",
    "title": "A Generative AI-Driven Reliability Layer for Action-Oriented Disaster Resilience",
    "abstract": "As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures.",
    "authors": [
      "Geunsik Lim"
    ],
    "published": "2026-01-26",
    "categories": [
      "cs.AI",
      "cs.SI",
      "eess.SY"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18308v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18308v1",
    "fetched_at": "2026-01-27T08:38:44.011251",
    "chinese_title": "面向行动导向灾害韧性的生成式AI驱动可靠性层",
    "chinese_summary": "针对传统灾害预警系统仅快速发送警报却难触发及时防护行动的问题，论文提出Climate RADAR系统，通过整合气象、水文等多源数据构建综合风险指数，利用带护栏的大语言模型（LLM）为公民、志愿者及市政部门提供个性化行动推荐；评估显示该系统提升了防护行动执行率、降低响应延迟，且增强可用性与信任度，结合预测分析、行为科学与负责任AI推进以人为本的灾害预警系统建设。",
    "tags": [
      "LLM",
      "Risk Management",
      "Behavioral Finance"
    ],
    "key_contributions": [
      "创新提出Climate RADAR系统，将灾害预警核心从“警报发送”重构为“行动执行”，搭建生成式AI驱动的可靠性层",
      "整合多源异构数据构建综合风险指数，利用带护栏的LLM提供跨角色个性化推荐，经验证有效提升防护行动执行与响应效率，推进以人为本的灾害韧性基础设施建设"
    ],
    "processed_at": "2026-01-27T08:48:50.418921"
  },
  {
    "id": "2601.18226v1",
    "title": "Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks",
    "abstract": "Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.",
    "authors": [
      "Haotian Li",
      "Shijun Yang",
      "Weizhen Qi",
      "Silei Zhao",
      "Rui Hua",
      "Mingzhu Song",
      "Xiaojian Yang",
      "Chao Peng"
    ],
    "published": "2026-01-26",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18226v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18226v1",
    "fetched_at": "2026-01-27T08:38:44.011281",
    "chinese_title": "Yunjue Agent技术报告：面向开放任务的完全可复现、零启动原位自进化Agent系统",
    "chinese_summary": "针对开放环境中传统Agent依赖静态工具/离线训练的局限，提出原位自进化范式，开发Yunjue Agent系统，通过迭代工具合成优化复用及并行批量进化策略提升能力，实验验证其零启动性能及知识迁移性，还开源代码工具并提出进化收敛监控指标。",
    "tags": [
      "Financial Agent",
      "Reinforcement Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "提出原位自进化范式，无需真实标签即可将任务交互经验转化为长期可复用能力，适配开放环境的任务分布漂移",
      "开发Yunjue Agent系统并引入并行批量进化策略，实验验证其零启动性能及知识迁移性，同时开源核心资源并提出进化收敛监控指标"
    ],
    "processed_at": "2026-01-27T08:49:13.968812"
  },
  {
    "id": "2601.18202v1",
    "title": "SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback",
    "abstract": "Deep search agents, which aim to answer complex questions requiring reasoning across multiple documents, can significantly speed up the information-seeking process. Collecting human annotations for this application is prohibitively expensive due to long and complex exploration trajectories. We propose an agentic pipeline that automatically generates high quality, difficulty-controlled deep search question-answer pairs for a given corpus and a target difficulty level. Our pipeline, SAGE, consists of a data generator which proposes QA pairs and a search agent which attempts to solve the generated question and provide execution feedback for the data generator. The two components interact over multiple rounds to iteratively refine the question-answer pairs until they satisfy the target difficulty level. Our intrinsic evaluation shows SAGE generates questions that require diverse reasoning strategies, while significantly increases the correctness and difficulty of the generated data. Our extrinsic evaluation demonstrates up to 23% relative performance gain on popular deep search benchmarks by training deep search agents with our synthetic data. Additional experiments show that agents trained on our data can adapt from fixed-corpus retrieval to Google Search at inference time, without further training.",
    "authors": [
      "Fangyuan Xu",
      "Rujun Han",
      "Yanfei Chen",
      "Zifeng Wang",
      "I-Hung Hsu",
      "Jun Yan",
      "Vishy Tirumalashetty",
      "Eunsol Choi",
      "Tomas Pfister",
      "Chen-Yu Lee"
    ],
    "published": "2026-01-26",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18202v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18202v1",
    "fetched_at": "2026-01-27T08:38:44.011331",
    "chinese_title": "SAGE：带执行反馈的深度搜索可引导智能体数据生成",
    "chinese_summary": "论文提出SAGE——一种带执行反馈的深度搜索可引导智能体数据生成 pipeline，通过数据生成器与搜索智能体多轮交互迭代，自动生成满足目标难度的高质量问答对；该方法生成的问答对能显著提升深度搜索智能体在基准上的性能（相对增益达23%），且训练后的智能体可适配Google搜索无需额外训练。",
    "tags": [
      "LLM",
      "NLP",
      "Benchmark"
    ],
    "key_contributions": [
      "提出SAGE智能体pipeline，实现自动生成难度可控、高质量的深度搜索问答对，通过生成器与搜索智能体多轮交互迭代优化",
      "证明用SAGE合成数据训练的深度搜索智能体，可显著提升基准性能（相对23%）且能适配Google搜索无需再训练"
    ],
    "processed_at": "2026-01-27T08:49:35.215126"
  },
  {
    "id": "2601.18197v1",
    "title": "GAIA: A Data Flywheel System for Training GUI Test-Time Scaling Critic Models",
    "abstract": "While Large Vision-Language Models (LVLMs) have significantly advanced GUI agents' capabilities in parsing textual instructions, interpreting screen content, and executing tasks, a critical challenge persists: the irreversibility of agent operations, where a single erroneous action can trigger catastrophic deviations. To address this, we propose the GUI Action Critic's Data Flywheel System (GAIA), a training framework that enables the models to have iterative critic capabilities, which are used to improve the Test-Time Scaling (TTS) of basic GUI agents' performance. Specifically, we train an Intuitive Critic Model (ICM) using positive and negative action examples from a base agent first. This critic evaluates the immediate correctness of the agent's intended actions, thereby selecting operations with higher success probability. Then, the initial critic guides agent actions to collect refined positive/negative samples, initiating the self-improving cycle. The augmented data then trains a second-round critic with enhanced discernment capability. We conduct experiments on various datasets and demonstrate that the proposed ICM can improve the test-time performance of various closed-source and open-source models, and the performance can be gradually improved as the data is recycled. The code and dataset will be publicly released.",
    "authors": [
      "Shaokang Wang",
      "Pei Fu",
      "Ruoceng Zhang",
      "Shaojie Zhang",
      "Xiuwen Xi",
      "Jiahui Yang",
      "Bin Qin",
      "Ying Huang",
      "Zhenbo Luo",
      "Jian Luan"
    ],
    "published": "2026-01-26",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18197v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18197v1",
    "fetched_at": "2026-01-27T08:38:44.011365",
    "chinese_title": "GAIA：一种用于训练GUI测试时缩放批评模型的数据飞轮系统",
    "chinese_summary": "论文针对GUI代理操作不可逆易引发灾难性偏差的问题，提出GAIA框架：先训练直观批评模型（ICM）评估代理动作正确性以筛选高成功概率操作，再通过初始批评器引导收集精炼样本形成自改进循环；实验表明ICM可提升闭源/开源模型测试性能，且性能随数据循环逐步改善。",
    "tags": [
      "Deep Learning",
      "Reinforcement Learning",
      "Financial Agent"
    ],
    "key_contributions": [
      "提出GAIA数据飞轮系统，通过迭代训练批评模型解决GUI代理操作不可逆问题",
      "训练的直观批评模型（ICM）可提升闭源/开源模型测试性能，且性能随数据循环逐步改善"
    ],
    "processed_at": "2026-01-27T08:49:56.214327"
  },
  {
    "id": "2601.18188v1",
    "title": "\\textsc{NaVIDA}: Vision-Language Navigation with Inverse Dynamics Augmentation",
    "abstract": "Vision-and-Language Navigation (VLN) requires agents to interpret natural language instructions and act coherently in visually rich environments. However, most existing methods rely on reactive state-action mappings without explicitly modeling how actions causally transform subsequent visual observations. Lacking such vision-action causality, agents cannot anticipate the visual changes induced by its own actions, leading to unstable behaviors, weak generalization, and cumulative error along trajectory. To address these issues, we introduce \\textsc{NaVIDA} (\\textbf{Nav}igation with \\textbf{I}nverse \\textbf{D}ynamics \\textbf{A}ugmentation), a unified VLN framework that couples policy learning with action-grounded visual dynamics and adaptive execution. \\textsc{NaVIDA} augments training with chunk-based inverse-dynamics supervision to learn causal relationship between visual changes and corresponding actions. To structure this supervision and extend the effective planning range, \\textsc{NaVIDA} employs hierarchical probabilistic action chunking (HPAC), which organizes trajectories into multi-step chunks and provides discriminative, longer-range visual-change cues. To further curb error accumulation and stabilize behavior at inference, an entropy-guided mechanism adaptively sets the execution horizon of action chunks. Extensive experiments show that \\textsc{NaVIDA} achieves superior navigation performance compared to state-of-the-art methods with fewer parameters (3B vs. 8B). Real-world robot evaluations further validate the practical feasibility and effectiveness of our approach. Code and data will be available upon acceptance.",
    "authors": [
      "Weiye Zhu",
      "Zekai Zhang",
      "Xiangchen Wang",
      "Hewei Pan",
      "Teng Wang",
      "Tiantian Geng",
      "Rongtao Xu",
      "Feng Zheng"
    ],
    "published": "2026-01-26",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18188v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18188v1",
    "fetched_at": "2026-01-27T08:38:44.011394",
    "chinese_title": "NaVIDA：基于逆动力学增强的视觉-语言导航",
    "chinese_summary": "针对现有视觉-语言导航（VLN）方法缺乏视觉-动作因果建模导致行为不稳定、泛化弱等问题，本文提出NaVIDA框架，通过基于块的逆动力学监督学习视觉变化与动作的因果关系，结合分层概率动作分块（HPAC）组织轨迹并提供长程视觉变化线索，熵引导机制自适应设置动作块执行范围；实验表明其性能优于SOTA且参数更少（3B vs 8B）。",
    "tags": [
      "Deep Learning",
      "Reinforcement Learning"
    ],
    "key_contributions": [
      "提出NaVIDA统一VLN框架，耦合策略学习与动作接地视觉动力学及自适应执行，解决视觉-动作因果缺失问题",
      "引入分层概率动作分块（HPAC）和基于块的逆动力学监督，扩展规划范围并学习因果关系，熵引导机制抑制误差累积"
    ],
    "processed_at": "2026-01-27T08:50:22.063823"
  },
  {
    "id": "2601.18119v1",
    "title": "Beyond Text-to-SQL: Can LLMs Really Debug Enterprise ETL SQL?",
    "abstract": "SQL is central to enterprise data engineering, yet generating fully correct SQL code in a single attempt remains difficult, even for experienced developers and advanced text-to-SQL LLMs, often requiring multiple debugging iterations. We introduce OurBench, the first benchmark for enterprise-level SQL reasoning and debugging. Our benchmark is built on two key innovations: (1) an automated construction workflow that uses reverse engineering to systematically inject realistic bugs into large-scale SQL code, enabling scalable and diverse benchmark generation; and (2) an execution-free evaluation framework tailored to enterprise settings, providing fast, accurate, and resource-efficient assessment.   OurBench comprises 469 OurBenchSyn queries featuring syntax errors with explicit error messages, and 516 OurBenchSem queries targeting semantic errors in which the code fails to meet user intent. The queries are highly complex, averaging over 140 lines and featuring deep and wide abstract syntax trees.   Evaluation of nearly 30 LLMs reveals a substantial performance gap: the best-performing model, Claude-4-Sonnet, achieves only 36.46 percent accuracy on OurBenchSyn and 32.17 percent on OurBenchSem, while most models score below 20 percent. We further explore four solution strategies, identify key challenges, and outline promising directions for enterprise SQL debugging with LLMs.",
    "authors": [
      "Jing Ye",
      "Yiwen Duan",
      "Yonghong Yu",
      "Victor Ma",
      "Yang Gao",
      "Xing Chen"
    ],
    "published": "2026-01-26",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18119v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18119v1",
    "fetched_at": "2026-01-27T08:38:44.011421",
    "chinese_title": "超越文本到SQL：大语言模型真的能调试企业ETL SQL吗？",
    "chinese_summary": "论文构建了首个企业级SQL推理与调试基准OurBench，通过逆向工程注入真实bug的自动化流程和无执行评估框架实现；包含469个带明确错误信息的语法错误查询及516个语义错误查询，复杂度高；评估近30个大模型发现性能差距显著，还探索了调试策略、识别关键挑战并给出方向。",
    "tags": [
      "LLM",
      "Benchmark",
      "NLP",
      "Transformer"
    ],
    "key_contributions": [
      "评估近30个大模型揭示企业SQL调试性能差距，分析策略与挑战并给出优化方向"
    ],
    "processed_at": "2026-01-27T08:50:32.629352"
  },
  {
    "id": "2601.18089v1",
    "title": "LatentMoE: Toward Optimal Accuracy per FLOP and Parameter in Mixture of Experts",
    "abstract": "Mixture of Experts (MoEs) have become a central component of many state-of-the-art open-source and proprietary large language models. Despite their widespread adoption, it remains unclear how close existing MoE architectures are to optimal with respect to inference cost, as measured by accuracy per floating-point operation and per parameter. In this work, we revisit MoE design from a hardware-software co-design perspective, grounded in empirical and theoretical considerations. We characterize key performance bottlenecks across diverse deployment regimes, spanning offline high-throughput execution and online, latency-critical inference. Guided by these insights, we introduce LatentMoE, a new model architecture resulting from systematic design exploration and optimized for maximal accuracy per unit of compute. Empirical design space exploration at scales of up to 95B parameters and over a 1T-token training horizon, together with supporting theoretical analysis, shows that LatentMoE consistently outperforms standard MoE architectures in terms of accuracy per FLOP and per parameter. Given its strong performance, the LatentMoE architecture has been adopted by the flagship Nemotron-3 Super and Ultra models and scaled to substantially larger regimes, including longer token horizons and larger model sizes, as reported in Nvidia et al. (arXiv:2512.20856).",
    "authors": [
      "Venmugil Elango",
      "Nidhi Bhatia",
      "Roger Waleffe",
      "Rasoul Shafipour",
      "Tomer Asida",
      "Abhinav Khattar",
      "Nave Assaf",
      "Maximilian Golub",
      "Joey Guman",
      "Tiyasa Mitra",
      "Ritchie Zhao",
      "Ritika Borkar",
      "Ran Zilberstein",
      "Mostofa Patwary",
      "Mohammad Shoeybi",
      "Bita Rouhani"
    ],
    "published": "2026-01-26",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.18089v1",
    "arxiv_url": "https://arxiv.org/abs/2601.18089v1",
    "fetched_at": "2026-01-27T08:38:44.011464",
    "chinese_title": "LatentMoE：面向混合专家模型中每FLOP和每参数最优精度的研究",
    "chinese_summary": "本文针对混合专家（MoE）模型的精度-计算/参数效率问题，从软硬协同设计视角分析不同部署场景的性能瓶颈，提出LatentMoE架构；通过95B参数级、1T+token训练规模的实验验证，该架构在精度每FLOP和每参数指标上优于标准MoE，且已被Nemotron-3系列模型采用。",
    "tags": [
      "LLM",
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "从软硬协同设计视角系统分析MoE的性能瓶颈，为效率优化提供理论与实证支撑",
      "提出LatentMoE架构，在精度每FLOP和每参数指标上显著优于标准MoE，且被旗舰模型采用"
    ],
    "processed_at": "2026-01-27T08:50:46.936520"
  }
]