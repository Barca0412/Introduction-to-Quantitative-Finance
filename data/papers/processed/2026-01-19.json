[
  {
    "id": "2601.11375v1",
    "title": "Automated Liquidity: Market Impact, Cycles, and De-pegging Risk",
    "abstract": "Three traits of decentralized finance are studied. First, the market impact function is derived for optimal-growth liquidity providers. For a standard random walk, the classic square-root impact is recovered. An extension is then derived to fit general fractional Ornstein-Uhlenbeck processes. These findings break with the linearized liquidity models used in most decentralized exchanges. Second, a Constant Product Market Maker is viewed as a multi-phase Carnot engine, where one phase matches the exchange of tokens by a liquidity taker, and another the change of pool size by a liquidity provider. Third, stablecoin de-pegging is a form of catastrophe risk. By using growth optimization, default odds are linked to the cost of catastrophe bonds. De-pegging insurance can act as a counterweight and a key marketing tool when the law forbids the payment of interest on stablecoins.",
    "authors": [
      "B. K. Meister"
    ],
    "published": "2026-01-16",
    "categories": [
      "q-fin.PM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11375v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11375v1",
    "fetched_at": "2026-01-19T08:38:29.983698",
    "chinese_title": "自动化流动性：市场冲击、周期与脱钩风险",
    "chinese_summary": "论文聚焦去中心化金融三大问题：推导最优增长流动性提供者的市场冲击函数，从随机游走恢复经典平方根冲击并扩展至分数Ornstein-Uhlenbeck过程，突破多数DEX的线性模型；将恒定乘积做市商视为多相卡诺引擎，划分流动性交易与池规模调整阶段；指出稳定币脱钩属灾难风险，通过增长优化关联违约概率与灾难债券成本，提出脱钩保险的平衡作用。",
    "tags": [
      "Market Making",
      "Risk Management",
      "Market Microstructure"
    ],
    "key_contributions": [
      "推导最优增长流动性提供者的市场冲击函数并扩展至分数Ornstein-Uhlenbeck过程，突破DEX线性模型",
      "揭示稳定币脱钩的灾难风险本质，关联违约概率与灾难债券成本，提出脱钩保险的应用价值"
    ],
    "processed_at": "2026-01-19T08:41:43.253979"
  },
  {
    "id": "2601.11348v1",
    "title": "Optimal Abatement Schedules for Excess Carbon Emissions Towards a Net-Zero Target",
    "abstract": "Achieving net-zero carbon emissions requires a transformation of energy systems, industrial processes, and consumption patterns. In particular, a transition towards that goal involves a gradual reduction of excess carbon emissions that are not essential for the well-functioning of society. In this paper we study this problem from a stochastic control perspective to identify the optimal gradual reduction of the emission rate, when an allocated excess carbon budget is used up over time. Assuming that updates of the available carbon budget follow a diffusion process, we identify the emission strategy that maximizes expected discounted emissions under the constraint of a non-increasing emission rate, with an additional term rewarding the amount of time for which the budget is not yet depleted. We establish a link of this topic to optimal dividend problems in insurance risk theory under ratcheting constraints and show that the value function is the unique viscosity solution of the associated Hamilton-Jacobi-Bellman equation. We provide numerical illustrations of the resulting optimal abatement schedule of emissions and a quantitative evaluation of the effect of the non-increasing rate constraint on the value function.",
    "authors": [
      "Hansjoerg Albrecher",
      "Nora Muler"
    ],
    "published": "2026-01-16",
    "categories": [
      "math.OC",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11348v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11348v1",
    "fetched_at": "2026-01-19T08:38:29.983733",
    "chinese_title": "面向净零目标的超额碳排放最优减排进度安排",
    "chinese_summary": "本文从随机控制视角研究实现净零目标的超额碳排放最优减排问题，假设可用碳预算更新遵循扩散过程，在排放率非递增约束下最大化含预算未耗尽时间奖励的期望贴现排放；建立了与保险风险理论中棘轮约束最优分红问题的联系，证明值函数是对应Hamilton-Jacobi-Bellman方程的唯一粘性解，并通过数值方法展示最优减排进度及非递增约束的影响。",
    "tags": [
      "Risk Management"
    ],
    "key_contributions": [
      "从随机控制视角构建超额碳排放最优减排模型，假设碳预算更新为扩散过程，在排放率非递增约束下最大化含预算未耗尽时间奖励的期望贴现排放",
      "建立模型与保险风险理论中棘轮约束最优分红问题的联系，证明值函数是Hamilton-Jacobi-Bellman方程的唯一粘性解，并用数值展示最优减排计划及约束影响"
    ],
    "processed_at": "2026-01-19T08:42:23.950359"
  },
  {
    "id": "2601.11305v1",
    "title": "Multiscaling in the Rough Bergomi Model: A Tale of Tails",
    "abstract": "The rough Bergomi (rBergomi) model, characterised by its roughness parameter $H$, has been shown to exhibit multiscaling behaviour as $H$ approaches zero. Multiscaling has profound implications for financial modelling: it affects extreme risk estimation, influences optimal portfolio allocation across different time horizons, and challenges traditional option pricing approaches that assume uniscaling behaviours. Understanding whether multiscaling arises primarily from the roughness of volatility paths or from the resulting fat-tailed returns has important implications for financial modelling, option pricing, and risk management. This paper investigates the real source of this multiscaling behaviour by introducing a novel two-stage statistical testing procedure. In the first stage, we establish the presence of multiscaling in the rBergomi model against an uniscaling fractional Brownian motion process. We quantify multiscaling by using weighted least squares regression that accounts for heteroscedastic estimation errors across moments. In the second stage, we apply shuffled surrogates that preserve return distributions while destroying temporal correlations. This is done by using distance-based permutation tests robust to asymmetric null distributions. In order to validate our procedure, we check the robustness of the results by using synthetic processes with known multifractal properties, namely the Multifractal Random Walk (MRW) and the Fractional Lévy Stable Motion (FLSM). We provide compelling evidence that multiscaling in the rBergomi model arises primarily from fat-tailed return distributions rather than memory effects. Our findings suggest that the apparent multiscaling in rough volatility models is largely attributable to distributional properties rather than genuine temporal scaling behaviour.",
    "authors": [
      "Giuseppe Brandi",
      "Tiziana Di Matteo"
    ],
    "published": "2026-01-16",
    "categories": [
      "q-fin.ST"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11305v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11305v1",
    "fetched_at": "2026-01-19T08:38:29.983755",
    "chinese_title": "粗糙贝戈莫模型中的多重标度：尾部的故事",
    "chinese_summary": "本文聚焦粗糙贝戈莫模型（rBergomi）的多重标度来源，提出两阶段统计检验方法——第一阶段用加权最小二乘（考虑异方差）检验其多重标度性，第二阶段用打乱替代法结合排列检验分离收益分布与时序相关性的影响，并通过已知多分数性质的合成过程验证方法有效性，明确了多重标度的真实来源。",
    "tags": [
      "Volatility",
      "Options",
      "Risk Management",
      "Time Series"
    ],
    "key_contributions": [
      "提出两阶段统计检验方法，明确粗糙贝戈莫模型多重标度的真实来源",
      "采用加权最小二乘（考虑异方差）和打乱替代法+排列检验，结合合成过程验证方法可靠性"
    ],
    "processed_at": "2026-01-19T08:42:43.461107"
  },
  {
    "id": "2601.11209v1",
    "title": "SANOS -- Smooth strictly Arbitrage-free Non-parametric Option Surfaces",
    "abstract": "We present a simple, numerically efficient but highly flexible non-parametric method to construct representations of option price surfaces which are both smooth and strictly arbitrage-free across time and strike. The method can be viewed as a smooth generalization of the widely-known linear interpolation scheme, and retains the simplicity and transparency of that baseline. Calibration of the model to observed market quotes is formulated as a linear program, allowing bid-ask spreads to be incorporated directly via linear penalties or inequalities, and delivering materially lower computational cost than most of the currently available implied-volatility surface fitting routines. As a further contribution, we derive an equivalent parameterization of the proposed surface in terms of strictly positive \"discrete local volatility\" variables. This yields, to our knowledge, the first construction of smooth, strictly arbitrage-free option price surfaces while requiring only trivial parameter constraints (positivity). We illustrate the approach using S&P 500 index options",
    "authors": [
      "Hans Buehler",
      "Blanka Horvath",
      "Anastasis Kratsios",
      "Yannick Limmer",
      "Raeid Saqur"
    ],
    "published": "2026-01-16",
    "categories": [
      "q-fin.CP",
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11209v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11209v1",
    "fetched_at": "2026-01-19T08:38:29.983782",
    "chinese_title": "SANOS——光滑且严格无套利的非参数期权曲面",
    "chinese_summary": "该文提出简单高效的非参数方法SANOS，构建光滑且严格无套利的期权价格曲面，是线性插值的光滑推广；其校准为线性规划，可直接纳入买卖价差，计算成本低于现有隐含波动率曲面拟合方法；还推导等价的正离散局部波动率参数化，首次仅用正约束实现光滑严格无套利期权曲面。",
    "tags": [
      "Options",
      "Volatility",
      "Asset Pricing"
    ],
    "key_contributions": [
      "提出光滑严格无套利的非参数期权曲面方法SANOS，是线性插值的光滑推广，校准为线性规划且可纳入买卖价差，计算高效",
      "推导等价的正离散局部波动率参数化，首次仅用正约束实现光滑严格无套利期权曲面"
    ],
    "processed_at": "2026-01-19T08:43:10.638361"
  },
  {
    "id": "2601.11201v1",
    "title": "Fast Times, Slow Times: Timescale Separation in Financial Timeseries Data",
    "abstract": "Financial time series exhibit multiscale behavior, with interaction between multiple processes operating on different timescales. This paper introduces a method for separating these processes using variance and tail stationarity criteria, framed as generalized eigenvalue problems. The approach allows for the identification of slow and fast components in asset returns and prices, with applications to parameter drift, mean reversion, and tail risk management. Empirical examples using currencies, equity ETFs and treasury yields illustrate the practical utility of the method.",
    "authors": [
      "Jan Rosenzweig"
    ],
    "published": "2026-01-16",
    "categories": [
      "q-fin.PM",
      "q-fin.CP",
      "q-fin.RM",
      "q-fin.ST",
      "q-fin.TR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11201v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11201v1",
    "fetched_at": "2026-01-19T08:38:29.983800",
    "chinese_title": "快节奏与慢节奏：金融时间序列数据中的时间尺度分离",
    "chinese_summary": "金融时间序列存在多尺度过程交互特征，该论文提出以方差和尾部平稳性准则为基础（转化为广义特征值问题）的方法，分离资产收益与价格中的快慢成分；方法可应用于参数漂移、均值回归及尾部风险管理等场景，实证验证了对货币、股票ETF、国债收益率等资产的实用性。",
    "tags": [
      "Time Series",
      "Risk Management",
      "Volatility"
    ],
    "key_contributions": [
      "提出基于方差和尾部平稳性准则（转化为广义特征值问题）的金融时间序列多尺度过程分离方法，实现资产收益与价格快慢成分的识别",
      "验证该方法在参数漂移、均值回归及尾部风险管理等场景的实用性，实证覆盖货币、股票ETF、国债收益率等多元资产类别"
    ],
    "processed_at": "2026-01-19T08:43:41.090594"
  },
  {
    "id": "2601.11134v1",
    "title": "FSL-BDP: Federated Survival Learning with Bayesian Differential Privacy for Credit Risk Modeling",
    "abstract": "Credit risk models are a critical decision-support tool for financial institutions, yet tightening data-protection rules (e.g., GDPR, CCPA) increasingly prohibit cross-border sharing of borrower data, even as these models benefit from cross-institution learning. Traditional default prediction suffers from two limitations: binary classification ignores default timing, treating early defaulters (high loss) equivalently to late defaulters (low loss), and centralized training violates emerging regulatory constraints. We propose a Federated Survival Learning framework with Bayesian Differential Privacy (FSL-BDP) that models time-to-default trajectories without centralizing sensitive data. The framework provides Bayesian (data-dependent) differential privacy (DP) guarantees while enabling institutions to jointly learn risk dynamics. Experiments on three real-world credit datasets (LendingClub, SBA, Bondora) show that federation fundamentally alters the relative effectiveness of privacy mechanisms. While classical DP performs better than Bayesian DP in centralized settings, the latter benefits substantially more from federation (+7.0\\% vs +1.4\\%), achieving near parity of non-private performance and outperforming classical DP in the majority of participating clients. This ranking reversal yields a key decision-support insight: privacy mechanism selection should be evaluated in the target deployment architecture, rather than centralized benchmarks. These findings provide actionable guidance for practitioners designing privacy-preserving decision support systems in regulated, multi-institutional environments.",
    "authors": [
      "Sultan Amed",
      "Tanmay Sen",
      "Sayantan Banerjee"
    ],
    "published": "2026-01-16",
    "categories": [
      "cs.LG",
      "q-fin.RM",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11134v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11134v1",
    "fetched_at": "2026-01-19T08:38:29.983839",
    "chinese_title": "FSL-BDP：基于贝叶斯差分隐私的联邦生存学习信用风险建模",
    "chinese_summary": "针对传统信用风险模型忽略违约时间、集中训练违反监管的问题，论文提出FSL-BDP框架，结合联邦生存学习与贝叶斯差分隐私，无需集中敏感数据即可建模违约时间轨迹；实验表明联邦部署下贝叶斯DP比经典DP更优，强调隐私机制选择应基于目标架构而非集中基准。",
    "tags": [
      "Risk Management",
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "提出FSL-BDP框架，实现联邦生存学习与贝叶斯差分隐私的结合，在保护敏感数据的前提下建模违约时间轨迹",
      "通过实证发现联邦场景下贝叶斯DP性能优于经典DP，指出隐私机制选择需匹配目标部署架构，为金融机构提供决策支持"
    ],
    "processed_at": "2026-01-19T08:44:02.497329"
  },
  {
    "id": "2601.11097v1",
    "title": "KANHedge: Efficient Hedging of High-Dimensional Options Using Kolmogorov-Arnold Network-Based BSDE Solver",
    "abstract": "High-dimensional option pricing and hedging present significant challenges in quantitative finance, where traditional PDE-based methods struggle with the curse of dimensionality. The BSDE framework offers a computationally efficient alternative to PDE-based methods, and recently proposed deep BSDE solvers, generally utilizing conventional Multi-Layer Perceptrons (MLPs), build upon this framework to provide a scalable alternative to numerical BSDE solvers. In this research, we show that although such MLP-based deep BSDEs demonstrate promising results in option pricing, there remains room for improvement regarding hedging performance. To address this issue, we introduce KANHedge, a novel BSDE-based hedger that leverages Kolmogorov-Arnold Networks (KANs) within the BSDE framework. Unlike conventional MLP approaches that use fixed activation functions, KANs employ learnable B-spline activation functions that provide enhanced function approximation capabilities for continuous derivatives. We comprehensively evaluate KANHedge on both European and American basket options across multiple dimensions and market conditions. Our experimental results demonstrate that while KANHedge and MLP achieve comparable pricing accuracy, KANHedge provides improved hedging performance. Specifically, KANHedge achieves considerable reductions in hedging cost metrics, demonstrating enhanced risk control capabilities.",
    "authors": [
      "Rushikesh Handal",
      "Masanori Hirano"
    ],
    "published": "2026-01-16",
    "categories": [
      "q-fin.CP",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11097v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11097v1",
    "fetched_at": "2026-01-19T08:38:29.983858",
    "chinese_title": "KANHedge：基于Kolmogorov-Arnold网络的BSDE求解器在高维期权高效对冲中的应用",
    "chinese_summary": "论文针对传统PDE方法在高维期权定价对冲中面临的维度灾难问题，提出KANHedge——一种基于BSDE框架并采用Kolmogorov-Arnold网络（KAN）的新型对冲器，KAN以可学习的B样条激活函数替代固定激活函数，实验显示其定价精度与MLP相当但对冲性能更优，显著降低对冲成本。",
    "tags": [
      "Deep Learning",
      "Options",
      "Risk Management",
      "Asset Pricing"
    ],
    "key_contributions": [
      "提出KANHedge方法，结合Kolmogorov-Arnold网络（KAN）与BSDE框架，解决高维期权对冲的性能提升问题",
      "证明KAN的可学习B样条激活函数能在保持定价精度的同时，显著优化对冲表现，降低对冲成本"
    ],
    "processed_at": "2026-01-19T08:44:17.029575"
  },
  {
    "id": "2601.10851v1",
    "title": "Event-Driven Market Co-Movement Dynamics in Critical Mineral Equities: An Empirical Framework Using Change Point Detection and Cross-Sectional Analysis",
    "abstract": "This study examines market behavior in critical mineral investments using a novel analytical framework that combines change-point detection (PELT algorithm) with cross-sectional analysis. This research analyzes ESG-ranked critical mineral ETFs from March 31, 2014, to April 19, 2024, using the S&P 500 as a benchmark to evaluate market co-movements. The findings demonstrate that different critical mineral investments experienced change points at distinct times, but three major dates, July 23, 2015; March 17, 2020; and December 1, 2020, were common and aligned with global events such as the oil market shock, the COVID-19 pandemic, and later market adjustments. Herding behavior among investors increased after these shocks, following the 2015 and 2020 crises, but shifted to anti-herding after positive vaccine news in late 2020 and after the Russian invasion of Ukraine in 2022. The sensitivity analysis shows that investor coordination is strongest during market downturns but exhibits greater variation during stable periods or after major developments, with these dynamics sensitive to the length of the observation period. Additionally, anti-herding became more apparent during crises, suggesting investors reacted to specific risks rather than moving in lockstep, especially in response to geopolitical shocks.",
    "authors": [
      "Haibo Wang"
    ],
    "published": "2026-01-15",
    "categories": [
      "econ.EM",
      "q-fin.PM",
      "q-fin.PR",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.10851v1",
    "arxiv_url": "https://arxiv.org/abs/2601.10851v1",
    "fetched_at": "2026-01-19T08:38:29.983876",
    "chinese_title": "关键矿产股票的事件驱动市场联动动态：结合变点检测与横截面分析的实证框架",
    "chinese_summary": "本研究采用结合PELT变点检测算法与横截面分析的新框架，分析2014年3月至2024年4月ESG排名的关键矿产ETF及标普500基准的市场联动；发现共同变点对应油价冲击、新冠等全球事件，揭示投资者从众/反从众行为随事件的动态变化，及市场下行时投资者协调最强的特征。",
    "tags": [
      "Behavioral Finance",
      "Time Series",
      "Market Microstructure"
    ],
    "key_contributions": [
      "提出结合PELT变点检测与横截面分析的实证框架，识别关键矿产投资的市场联动变点及对应全球事件",
      "揭示投资者从众/反从众行为随重大事件的动态变化规律，及市场下行时投资者协调最强的特征"
    ],
    "processed_at": "2026-01-19T08:44:43.886172"
  },
  {
    "id": "2601.10812v1",
    "title": "Optimal Liquidation of Perpetual Contracts",
    "abstract": "An agent holds a position in a perpetual contract with payoff function $ψ$ and attempts to liquidate the position while managing transaction costs, inventory risk, and funding rate payments. By solving the agent's stochastic control problem we obtain a closed-form expression for the optimal trading strategy when the payoff function is given by $ψ(s) = s$. When the payoff function is non-linear we provide approximations to the optimal strategy which apply when the funding rate parameter is small or when the length of the trading interval is small. We further prove that when $ψ$ is non-linear, the short time approximation can be written in terms of the closed-form trading strategy corresponding to the case of the identity payoff function.",
    "authors": [
      "Ryan Donnelly",
      "Junhan Lin",
      "Matthew Lorig"
    ],
    "published": "2026-01-15",
    "categories": [
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.10812v1",
    "arxiv_url": "https://arxiv.org/abs/2601.10812v1",
    "fetched_at": "2026-01-19T08:38:29.983896",
    "chinese_title": "永续合约的最优平仓",
    "chinese_summary": "本文研究永续合约的最优平仓问题，考虑交易成本、库存风险及资金费率支付，通过求解随机控制问题得到收益函数为ψ(s)=s时最优策略的闭式表达式；针对非线性收益函数，给出资金费率参数小或交易区间短情况下的最优策略近似，且证明短时间近似可通过恒等收益函数的闭式策略表示。",
    "tags": [
      "Execution",
      "Risk Management",
      "Algorithmic Trading"
    ],
    "key_contributions": [
      "通过随机控制问题求解得到收益函数为ψ(s)=s时永续合约最优平仓策略的闭式表达式",
      "针对非线性收益函数的永续合约，给出资金费率小或交易区间短情况下的最优策略近似，并证明短时间近似可基于恒等收益函数的闭式策略推导"
    ],
    "processed_at": "2026-01-19T08:45:02.954114"
  },
  {
    "id": "2601.11091v1",
    "title": "Split-and-Conquer: Distributed Factor Modeling for High-Dimensional Matrix-Variate Time Series",
    "abstract": "In this paper, we propose a distributed framework for reducing the dimensionality of high-dimensional, large-scale, heterogeneous matrix-variate time series data using a factor model. The data are first partitioned column-wise (or row-wise) and allocated to node servers, where each node estimates the row (or column) loading matrix via two-dimensional tensor PCA. These local estimates are then transmitted to a central server and aggregated, followed by a final PCA step to obtain the global row (or column) loading matrix estimator. Given the estimated loading matrices, the corresponding factor matrices are subsequently computed. Unlike existing distributed approaches, our framework preserves the latent matrix structure, thereby improving computational efficiency and enhancing information utilization. We also discuss row- and column-wise clustering procedures for settings in which the group memberships are unknown. Furthermore, we extend the analysis to unit-root nonstationary matrix-variate time series. Asymptotic properties of the proposed method are derived for the diverging dimension of the data in each computing unit and the sample size $T$. Simulation results assess the computational efficiency and estimation accuracy of the proposed framework, and real data applications further validate its predictive performance.",
    "authors": [
      "Hangjin Jiang",
      "Yuzhou Li",
      "Zhaoxing Gao"
    ],
    "published": "2026-01-16",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11091v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11091v1",
    "fetched_at": "2026-01-19T08:38:36.290185",
    "chinese_title": "分而治之：高维矩阵变量时间序列的分布式因子建模",
    "chinese_summary": "本文提出一种分布式因子建模框架处理高维矩阵变量时间序列，先按列/行分割数据至各节点，各节点用二维张量PCA估计加载矩阵，中央聚合后经最终PCA得到全局加载矩阵及对应因子矩阵；该框架保留潜在矩阵结构，提升计算效率与信息利用率，还拓展至未知分组聚类、单位根非平稳情形，推导渐近性质并通过仿真与实证验证。",
    "tags": [
      "Factor Model",
      "Time Series",
      "Factor Mining"
    ],
    "key_contributions": [
      "提出保留潜在矩阵结构的分布式因子建模框架，提升计算效率与信息利用率",
      "拓展至未知分组聚类、单位根非平稳情形，推导渐近性质并验证方法有效性"
    ],
    "processed_at": "2026-01-19T08:45:36.154930"
  },
  {
    "id": "2601.11500v1",
    "title": "QUPID: A Partitioned Quantum Neural Network for Anomaly Detection in Smart Grid",
    "abstract": "Smart grid infrastructures have revolutionized energy distribution, but their day-to-day operations require robust anomaly detection methods to counter risks associated with cyber-physical threats and system faults potentially caused by natural disasters, equipment malfunctions, and cyber attacks. Conventional machine learning (ML) models are effective in several domains, yet they struggle to represent the complexities observed in smart grid systems. Furthermore, traditional ML models are highly susceptible to adversarial manipulations, making them increasingly unreliable for real-world deployment. Quantum ML (QML) provides a unique advantage, utilizing quantum-enhanced feature representations to model the intricacies of the high-dimensional nature of smart grid systems while demonstrating greater resilience to adversarial manipulation. In this work, we propose QUPID, a partitioned quantum neural network (PQNN) that outperforms traditional state-of-the-art ML models in anomaly detection. We extend our model to R-QUPID that even maintains its performance when including differential privacy (DP) for enhanced robustness. Moreover, our partitioning framework addresses a significant scalability problem in QML by efficiently distributing computational workloads, making quantum-enhanced anomaly detection practical in large-scale smart grid environments. Our experimental results across various scenarios exemplifies the efficacy of QUPID and R-QUPID to significantly improve anomaly detection capabilities and robustness compared to traditional ML approaches.",
    "authors": [
      "Hoang M. Ngo",
      "Tre' R. Jeter",
      "Jung Taek Seo",
      "My T. Thai"
    ],
    "published": "2026-01-16",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11500v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11500v1",
    "fetched_at": "2026-01-19T08:38:42.586732",
    "chinese_title": "QUPID：面向智能电网异常检测的分区量子神经网络",
    "chinese_summary": "针对智能电网异常检测中传统机器学习难以建模系统复杂度、易受对抗攻击的问题，本文提出分区量子神经网络QUPID，其性能优于传统最优模型；进一步扩展为带差分隐私的R-QUPID，同时通过分区框架解决量子机器学习的可扩展性问题，使量子增强异常检测适用于大规模智能电网场景。",
    "tags": [
      "Anomaly",
      "Risk Management",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出分区量子神经网络QUPID，在智能电网异常检测中性能优于传统最优机器学习模型，且通过分区框架解决量子机器学习的可扩展性难题",
      "扩展得到带差分隐私的R-QUPID，保持检测性能的同时增强模型鲁棒性与隐私保护能力，适配大规模智能电网场景"
    ],
    "processed_at": "2026-01-19T08:46:09.383861"
  },
  {
    "id": "2601.11415v1",
    "title": "Zero-Shot Detection of Elastic Transient Morphology Across Physical Systems",
    "abstract": "We test whether a representation learned from interferometric strain transients in gravitational-wave observatories can act as a frozen morphology-sensitive operator for unseen sensors, provided the target signals preserve coherent elastic transient structure. Using a neural encoder trained exclusively on non-Gaussian instrumental glitches, we perform strict zero-shot anomaly analysis on rolling-element bearings without retraining, fine-tuning, or target-domain labels.   On the IMS-NASA run-to-failure dataset, the operator yields a monotonic health index HI(t) = s0.99(t)/tau normalized to an early-life reference distribution, enabling fixed false-alarm monitoring at 1-q = 1e-3 with tau = Q0.999(P0). In discrete fault regimes (CWRU), it achieves strong window-level discrimination (AUC_win about 0.90) and file-level separability approaching unity (AUC_file about 0.99). Electrically dominated vibration signals (VSB) show weak, non-selective behavior, delineating a physical boundary for transfer.   Under a matched IMS controlled-split protocol, a generic EfficientNet-B0 encoder pretrained on ImageNet collapses in the intermittent regime (Lambda_tail about 2), while the interferometric operator retains strong extreme-event selectivity (Lambda_tail about 860), indicating that the effect is not a generic property of CNN features. Controlled morphology-destruction transformations selectively degrade performance despite per-window normalization, consistent with sensitivity to coherent time-frequency organization rather than marginal amplitude statistics.",
    "authors": [
      "Jose Sánchez Andreu"
    ],
    "published": "2026-01-16",
    "categories": [
      "astro-ph.IM",
      "cs.LG",
      "physics.data-an"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11415v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11415v1",
    "fetched_at": "2026-01-19T08:38:42.586760",
    "chinese_title": "跨物理系统弹性瞬态形态的零样本检测",
    "chinese_summary": "该研究利用引力波观测站干涉应变瞬态训练的神经编码器，实现跨物理系统（如滚动轴承）弹性瞬态形态的零样本异常检测，无需重训练、微调或目标域标签；在IMS-NASA、CWRU等数据集上表现优异，且对比通用CNN证明其形态敏感性的特异性。",
    "tags": [
      "Anomaly",
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "提出基于引力波干涉应变瞬态预训练的神经编码器，实现跨物理系统弹性瞬态形态的零样本异常检测，无需目标域重训练/微调/标签",
      "在滚动轴承故障数据集上验证有效性，对比通用CNN证明形态敏感性的特异性，明确电主导信号的物理边界"
    ],
    "processed_at": "2026-01-19T08:46:32.296007"
  },
  {
    "id": "2601.11154v1",
    "title": "Assesing the Viability of Unsupervised Learning with Autoencoders for Predictive Maintenance in Helicopter Engines",
    "abstract": "Unplanned engine failures in helicopters can lead to severe operational disruptions, safety hazards, and costly repairs. To mitigate these risks, this study compares two predictive maintenance strategies for helicopter engines: a supervised classification pipeline and an unsupervised anomaly detection approach based on autoencoders (AEs). The supervised method relies on labelled examples of both normal and faulty behaviour, while the unsupervised approach learns a model of normal operation using only healthy engine data, flagging deviations as potential faults. Both methods are evaluated on a real-world dataset comprising labelled snapshots of helicopter engine telemetry. While supervised models demonstrate strong performance when annotated failures are available, the AE achieves effective detection without requiring fault labels, making it particularly well suited for settings where failure data are scarce or incomplete. The comparison highlights the practical trade-offs between accuracy, data availability, and deployment feasibility, and underscores the potential of unsupervised learning as a viable solution for early fault detection in aerospace applications.",
    "authors": [
      "P. Sánchez",
      "K. Reyes",
      "B. Radu",
      "E. Fernández"
    ],
    "published": "2026-01-16",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11154v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11154v1",
    "fetched_at": "2026-01-19T08:38:42.586782",
    "chinese_title": "评估自编码器无监督学习在直升机发动机预测性维护中的可行性",
    "chinese_summary": "论文对比了直升机发动机预测性维护的两种策略——有监督分类 pipeline 和基于自编码器的无监督异常检测方法，前者依赖标注故障数据，后者仅用健康数据学习正常模型并标记偏差；结果显示有监督模型在有标注时性能强，但无监督方法无需故障标签，适合故障数据稀缺场景，凸显其在航空领域早期故障检测的可行性。",
    "tags": [
      "Anomaly",
      "Deep Learning",
      "Time Series",
      "Risk Management"
    ],
    "key_contributions": [
      "对比了有监督分类与无监督自编码器在直升机发动机预测维护中的性能差异及适用场景",
      "验证了无监督自编码器在故障数据稀缺时无需标注即可有效检测异常的可行性"
    ],
    "processed_at": "2026-01-19T08:46:47.153360"
  },
  {
    "id": "2601.10993v1",
    "title": "Memorize Early, Then Query: Inlier-Memorization-Guided Active Outlier Detection",
    "abstract": "Outlier detection (OD) aims to identify abnormal instances, known as outliers or anomalies, by learning typical patterns of normal data, or inliers. Performing OD under an unsupervised regime-without any information about anomalous instances in the training data-is challenging. A recently observed phenomenon, known as the inlier-memorization (IM) effect, where deep generative models (DGMs) tend to memorize inlier patterns during early training, provides a promising signal for distinguishing outliers. However, existing unsupervised approaches that rely solely on the IM effect still struggle when inliers and outliers are not well-separated or when outliers form dense clusters. To address these limitations, we incorporate active learning to selectively acquire informative labels, and propose IMBoost, a novel framework that explicitly reinforces the IM effect to improve outlier detection. Our method consists of two stages: 1) a warm-up phase that induces and promotes the IM effect, and 2) a polarization phase in which actively queried samples are used to maximize the discrepancy between inlier and outlier scores. In particular, we propose a novel query strategy and tailored loss function in the polarization phase to effectively identify informative samples and fully leverage the limited labeling budget. We provide a theoretical analysis showing that the IMBoost consistently decreases inlier risk while increasing outlier risk throughout training, thereby amplifying their separation. Extensive experiments on diverse benchmark datasets demonstrate that IMBoost not only significantly outperforms state-of-the-art active OD methods but also requires substantially less computational cost.",
    "authors": [
      "Minseo Kang",
      "Seunghwan Park",
      "Dongha Kim"
    ],
    "published": "2026-01-16",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.10993v1",
    "arxiv_url": "https://arxiv.org/abs/2601.10993v1",
    "fetched_at": "2026-01-19T08:38:42.586802",
    "chinese_title": "先记忆后查询：基于内点记忆引导的主动异常检测",
    "chinese_summary": "针对无监督异常检测中现有依赖内点记忆（IM）效应方法在内外点分离差或异常聚类密时的局限，论文提出IMBoost框架：分预热（强化IM效应）和极化（主动查询+定制损失最大化内外点分数差异）两阶段；理论证明该方法可降低内点风险、提升外点风险，增强内外点分离性。",
    "tags": [
      "Anomaly",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出IMBoost框架，结合主动学习解决现有依赖内点记忆的无监督异常检测方法的局限",
      "设计预热与极化阶段（含新颖查询策略和定制损失），理论证明可增强内外点分离性"
    ],
    "processed_at": "2026-01-19T08:47:10.124583"
  },
  {
    "id": "2601.11492v1",
    "title": "BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics",
    "abstract": "Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.",
    "authors": [
      "Kaiwen Wang",
      "Kaili Zheng",
      "Rongrong Deng",
      "Qingmin Fan",
      "Milin Zhang",
      "Zongrui Li",
      "Xuesi Zhou",
      "Bo Han",
      "Liren Chen",
      "Chenyi Guo",
      "Ji Wu"
    ],
    "published": "2026-01-16",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11492v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11492v1",
    "fetched_at": "2026-01-19T08:39:10.926184",
    "chinese_title": "BoxMind：2024奥运会验证的精英拳击闭环AI策略优化系统",
    "chinese_summary": "针对拳击战术分析AI应用不足，论文提出BoxMind闭环AI系统，通过定义原子拳击事件并解析为18个层级技战术指标，结合图预测模型融合显式技战术与时变潜在嵌入实现比赛结果高精度预测；利用预测梯度生成可执行战术调整，2024巴黎奥运会闭环部署验证并助力中国队取得历史成绩，建立非结构化视频转战略智能的可复制范式。",
    "tags": [
      "Graph Neural Network",
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "构建BoxMind闭环AI系统，通过原子拳击事件定义与18个层级技战术指标解析，结合图模型融合显式技战术与时变潜在嵌入，实现比赛结果预测的高精度表现",
      "2024巴黎奥运会闭环部署验证，直接助力中国拳击队取得历史成绩，建立非结构化视频数据转化为战略智能的可复制范式"
    ],
    "processed_at": "2026-01-19T08:47:33.167865"
  },
  {
    "id": "2601.11421v1",
    "title": "The Great March 100: 100 Detail-oriented Tasks for Evaluating Embodied AI Agents",
    "abstract": "Recently, with the rapid development of robot learning and imitation learning, numerous datasets and methods have emerged. However, these datasets and their task designs often lack systematic consideration and principles. This raises important questions: Do the current datasets and task designs truly advance the capabilities of robotic agents? Do evaluations on a few common tasks accurately reflect the differentiated performance of various methods proposed by different teams and evaluated on different tasks? To address these issues, we introduce the Great March 100 (\\textbf{GM-100}) as the first step towards a robot learning Olympics. GM-100 consists of 100 carefully designed tasks that cover a wide range of interactions and long-tail behaviors, aiming to provide a diverse and challenging set of tasks to comprehensively evaluate the capabilities of robotic agents and promote diversity and complexity in robot dataset task designs. These tasks are developed through systematic analysis and expansion of existing task designs, combined with insights from human-object interaction primitives and object affordances. We collect a large amount of trajectory data on different robotic platforms and evaluate several baseline models. Experimental results demonstrate that the GM-100 tasks are 1) feasible to execute and 2) sufficiently challenging to effectively differentiate the performance of current VLA models. Our data and code are available at https://rhos.ai/research/gm-100.",
    "authors": [
      "Ziyu Wang",
      "Chenyuan Liu",
      "Yushun Xiang",
      "Runhao Zhang",
      "Qingbo Hao",
      "Hongliang Lu",
      "Houyu Chen",
      "Zhizhong Feng",
      "Kaiyue Zheng",
      "Dehao Ye",
      "Xianchao Zeng",
      "Xinyu Zhou",
      "Boran Wen",
      "Jiaxin Li",
      "Mingyu Zhang",
      "Kecheng Zheng",
      "Qian Zhu",
      "Ran Cheng",
      "Yong-Lu Li"
    ],
    "published": "2026-01-16",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11421v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11421v1",
    "fetched_at": "2026-01-19T08:39:10.926242",
    "chinese_title": "Great March 100：用于评估具身AI智能体的100项细节导向任务",
    "chinese_summary": "针对现有机器人学习数据集任务设计缺乏系统性的问题，论文提出GM-100基准，包含100项覆盖广泛交互与长尾行为的精心设计任务，用于全面评估机器人智能体能力；同时收集多平台轨迹数据并评估基线模型，验证任务的可行性与区分模型性能的有效性。",
    "tags": [
      "Reinforcement Learning",
      "Benchmark",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出首个面向机器人智能体能力评估的系统性基准GM-100，包含100项覆盖多样交互与长尾行为的细节导向任务",
      "收集多机器人平台轨迹数据，验证GM-100任务可行且能有效区分当前VLA模型性能，推动机器人数据集任务设计的多样性与复杂性"
    ],
    "processed_at": "2026-01-19T08:48:01.677690"
  },
  {
    "id": "2601.11147v1",
    "title": "Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems",
    "abstract": "Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generates workflows either at task level or query level, but their relative costs and benefits remain unclear. After rethinking and empirical analyses, we show that query-level workflow generation is not always necessary, since a small set of top-K best task-level workflows together already covers equivalent or even more queries. We further find that exhaustive execution-based task-level evaluation is both extremely token-costly and frequently unreliable. Inspired by the idea of self-evolution and generative reward modeling, we propose a low-cost task-level generation framework \\textbf{SCALE}, which means \\underline{\\textbf{S}}elf prediction of the optimizer with few shot \\underline{\\textbf{CAL}}ibration for \\underline{\\textbf{E}}valuation instead of full validation execution. Extensive experiments demonstrate that \\textbf{SCALE} maintains competitive performance, with an average degradation of just 0.61\\% compared to existing approach across multiple datasets, while cutting overall token usage by up to 83\\%.",
    "authors": [
      "Zixu Wang",
      "Bingbing Xu",
      "Yige Yuan",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "published": "2026-01-16",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11147v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11147v1",
    "fetched_at": "2026-01-19T08:39:10.926265",
    "chinese_title": "我们总是需要查询级工作流吗？重新思考多智能体系统的智能工作流生成",
    "chinese_summary": "本文针对基于大语言模型的多智能体系统工作流生成问题，发现查询级工作流并非总是必要，少量top-K任务级工作流已覆盖等价甚至更多查询，且 exhaustive执行的任务级评估成本高不可靠；提出SCALE框架，通过少样本校准的自我预测优化器替代全验证执行，实验表明其性能仅平均下降0.61%，但token使用最多减少83%。",
    "tags": [
      "LLM",
      "Financial Agent",
      "Deep Learning"
    ],
    "key_contributions": [
      "揭示查询级工作流并非总是必要，少量top-K任务级工作流已覆盖等价甚至更多查询，且 exhaustive执行的任务级评估成本高不可靠",
      "提出SCALE框架，通过少样本校准的自我预测优化器替代全验证执行，大幅降低token使用（最多83%）且仅平均性能下降0.61%"
    ],
    "processed_at": "2026-01-19T08:48:36.975380"
  },
  {
    "id": "2601.11109v1",
    "title": "Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning",
    "abstract": "Vision-as-inverse-graphics, the concept of reconstructing an image as an editable graphics program is a long-standing goal of computer vision. Yet even strong VLMs aren't able to achieve this in one-shot as they lack fine-grained spatial and physical grounding capability. Our key insight is that closing this gap requires interleaved multimodal reasoning through iterative execution and verification. Stemming from this, we present VIGA (Vision-as-Inverse-Graphic Agent) that starts from an empty world and reconstructs or edits scenes through a closed-loop write-run-render-compare-revise procedure. To support long-horizon reasoning, VIGA combines (i) a skill library that alternates generator and verifier roles and (ii) an evolving context memory that contains plans, code diffs, and render history. VIGA is task-agnostic as it doesn't require auxiliary modules, covering a wide range of tasks such as 3D reconstruction, multi-step scene editing, 4D physical interaction, and 2D document editing, etc. Empirically, we found VIGA substantially improves one-shot baselines on BlenderGym (35.32%) and SlideBench (117.17%). Moreover, VIGA is also model-agnostic as it doesn't require finetuning, enabling a unified protocol to evaluate heterogeneous foundation VLMs. To better support this protocol, we introduce BlenderBench, a challenging benchmark that stress-tests interleaved multimodal reasoning with graphics engine, where VIGA improves by 124.70%.",
    "authors": [
      "Shaofeng Yin",
      "Jiaxin Ge",
      "Zora Zhiruo Wang",
      "Xiuyu Li",
      "Michael J. Black",
      "Trevor Darrell",
      "Angjoo Kanazawa",
      "Haiwen Feng"
    ],
    "published": "2026-01-16",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11109v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11109v1",
    "fetched_at": "2026-01-19T08:39:10.926293",
    "chinese_title": "基于交错多模态推理的视觉逆图形智能体",
    "chinese_summary": "论文提出视觉逆图形智能体VIGA，通过迭代的写-运行-渲染-比较-修正闭环流程，结合技能库与上下文记忆实现视觉逆图形任务；VIGA任务和模型无关（无需微调），在BlenderGym等基准上大幅提升性能，且引入新基准BlenderBench。",
    "tags": [
      "Deep Learning",
      "Benchmark",
      "LLM"
    ],
    "key_contributions": [
      "提出任务/模型无关的VIGA智能体，通过交错多模态推理闭环流程实现视觉逆图形任务；",
      "引入BlenderBench基准，在多基准上大幅提升现有方法性能。"
    ],
    "processed_at": "2026-01-19T08:49:00.285969"
  },
  {
    "id": "2601.11100v1",
    "title": "ReCreate: Reasoning and Creating Domain Agents Driven by Experience",
    "abstract": "Large Language Model agents are reshaping the industrial landscape. However, most practical agents remain human-designed because tasks differ widely, making them labor-intensive to build. This situation poses a central question: can we automatically create and adapt domain agents in the wild? While several recent approaches have sought to automate agent creation, they typically treat agent generation as a black-box procedure and rely solely on final performance metrics to guide the process. Such strategies overlook critical evidence explaining why an agent succeeds or fails, and often require high computational costs. To address these limitations, we propose ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate systematically leverages agent interaction histories, which provide rich concrete signals on both the causes of success or failure and the avenues for improvement. Specifically, we introduce an agent-as-optimizer paradigm that effectively learns from experience via three key components: (i) an experience storage and retrieval mechanism for on-demand inspection; (ii) a reasoning-creating synergy pipeline that maps execution experience into scaffold edits; and (iii) hierarchical updates that abstract instance-level details into reusable domain patterns. In experiments across diverse domains, ReCreate consistently outperforms human-designed agents and existing automated agent generation methods, even when starting from minimal seed scaffolds.",
    "authors": [
      "Zhezheng Hao",
      "Hong Wang",
      "Jian Luo",
      "Jianqing Zhang",
      "Yuyan Zhou",
      "Qiang Lin",
      "Can Wang",
      "Hande Dong",
      "Jiawei Chen"
    ],
    "published": "2026-01-16",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11100v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11100v1",
    "fetched_at": "2026-01-19T08:39:10.926322",
    "chinese_title": "ReCreate：基于经验驱动的推理与领域Agent创建框架",
    "chinese_summary": "针对现有自动创建领域Agent方法存在黑箱化、仅依赖最终性能且计算成本高的问题，论文提出经验驱动的ReCreate框架；该框架通过经验存储检索、推理-创建协同管道及分层更新三个组件，利用Agent交互历史中的因果信号与改进方向，实现领域Agent的自动创建与适配，实验表明其在多领域优于人类设计Agent及现有方法。",
    "tags": [
      "LLM",
      "Financial Agent",
      "Reinforcement Learning"
    ],
    "key_contributions": [
      "提出经验驱动的ReCreate框架，解决现有自动Agent创建方法黑箱化、依赖最终性能且计算成本高的问题；",
      "设计经验存储检索、推理-创建协同、分层更新三个关键组件，利用Agent交互历史的因果信号实现领域Agent自动创建与适配，实验优于人类设计及现有方法。"
    ],
    "processed_at": "2026-01-19T08:49:28.129098"
  },
  {
    "id": "2601.11077v1",
    "title": "ABC-Bench: Benchmarking Agentic Backend Coding in Real-World Development",
    "abstract": "The evolution of Large Language Models (LLMs) into autonomous agents has expanded the scope of AI coding from localized code generation to complex, repository-level, and execution-driven problem solving. However, current benchmarks predominantly evaluate code logic in static contexts, neglecting the dynamic, full-process requirements of real-world engineering, particularly in backend development which demands rigorous environment configuration and service deployment. To address this gap, we introduce ABC-Bench, a benchmark explicitly designed to evaluate agentic backend coding within a realistic, executable workflow. Using a scalable automated pipeline, we curated 224 practical tasks spanning 8 languages and 19 frameworks from open-source repositories. Distinct from previous evaluations, ABC-Bench require the agents to manage the entire development lifecycle from repository exploration to instantiating containerized services and pass the external end-to-end API tests. Our extensive evaluation reveals that even state-of-the-art models struggle to deliver reliable performance on these holistic tasks, highlighting a substantial disparity between current model capabilities and the demands of practical backend engineering. Our code is available at https://github.com/OpenMOSS/ABC-Bench.",
    "authors": [
      "Jie Yang",
      "Honglin Guo",
      "Li Ji",
      "Jiazheng Zhou",
      "Rui Zheng",
      "Zhikai Lei",
      "Shuo Zhang",
      "Zhiheng Xi",
      "Shichun Liu",
      "Yuxin Wang",
      "Bo Wang",
      "Yining Zheng",
      "Tao Gui",
      "Xipeng Qiu"
    ],
    "published": "2026-01-16",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11077v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11077v1",
    "fetched_at": "2026-01-19T08:39:10.926358",
    "chinese_title": "ABC-Bench：真实世界开发中智能体后端编码的基准测试",
    "chinese_summary": "现有AI编码基准多聚焦静态代码逻辑，忽略真实后端开发的动态全流程（含环境配置与部署）需求；本文提出ABC-Bench基准，通过自动化pipeline构建224个跨8语言19框架的实际任务，要求智能体完成从仓库探索到容器化服务实例化及端到端API测试的全生命周期；评估显示当前最先进模型在这类整体任务上表现欠佳，凸显能力与实际后端工程需求的差距。",
    "tags": [
      "LLM",
      "Benchmark",
      "NLP"
    ],
    "key_contributions": [
      "提出ABC-Bench基准，针对真实世界后端开发的动态全流程需求设计，填补现有静态代码逻辑编码基准的空白",
      "构建包含224个跨8语言19框架实际任务的自动化评估 pipeline，要求智能体完成从仓库探索到容器化服务部署及API测试的全生命周期开发"
    ],
    "processed_at": "2026-01-19T08:49:56.729353"
  },
  {
    "id": "2601.11063v1",
    "title": "H-AIM: Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning",
    "abstract": "In embodied artificial intelligence, enabling heterogeneous robot teams to execute long-horizon tasks from high-level instructions remains a critical challenge. While large language models (LLMs) show promise in instruction parsing and preliminary planning, they exhibit limitations in long-term reasoning and dynamic multi-robot coordination. We propose Hierarchical Autonomous Intelligent Multi-Robot Planning(H-AIM), a novel embodied multi-robot task planning framework that addresses these issues through a three-stage cascaded architecture: 1) It leverages an LLM to parse instructions and generate Planning Domain Definition Language (PDDL) problem descriptions, thereby transforming commands into formal planning problems; 2) It combines the semantic reasoning of LLMs with the search capabilities of a classical planner to produce optimized action sequences; 3) It compiles the resulting plan into behavior trees for reactive control. The framework supports dynamically sized heterogeneous robot teams via a shared blackboard mechanism for communication and state synchronization. To validate our approach, we introduce the MACE-THOR benchmark dataset, comprising 42 complex tasks across 8 distinct household layouts. Experimental results demonstrate that H-AIM achieves a remarkable performance improvement, elevating the task success rate from 12% to 55% and boosting the goal condition recall from 32% to 72% against the strongest baseline, LaMMA-P.",
    "authors": [
      "Haishan Zeng",
      "Peng Li"
    ],
    "published": "2026-01-16",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MA"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11063v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11063v1",
    "fetched_at": "2026-01-19T08:39:10.926377",
    "chinese_title": "H-AIM：结合大语言模型、PDDL和行为树的分层多机器人规划框架",
    "chinese_summary": "论文提出H-AIM分层多机器人规划框架，通过LLM解析指令生成PDDL问题描述，结合LLM语义推理与经典规划器搜索得到优化动作序列，再编译为行为树实现反应控制；引入MACE-THOR基准数据集，实验显示其任务成功率从基线12%提升至55%，目标条件召回从32%提升至72%。",
    "tags": [
      "LLM",
      "NLP",
      "Benchmark"
    ],
    "key_contributions": [
      "提出H-AIM分层多机器人规划框架，整合LLM、PDDL和行为树解决长程任务与动态协调问题",
      "引入MACE-THOR基准数据集，实验验证框架性能显著优于现有基线"
    ],
    "processed_at": "2026-01-19T08:50:14.400955"
  },
  {
    "id": "2601.11047v1",
    "title": "CoG: Controllable Graph Reasoning via Relational Blueprints and Failure-Aware Refinement over Knowledge Graphs",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable reasoning capabilities but often grapple with reliability challenges like hallucinations. While Knowledge Graphs (KGs) offer explicit grounding, existing paradigms of KG-augmented LLMs typically exhibit cognitive rigidity--applying homogeneous search strategies that render them vulnerable to instability under neighborhood noise and structural misalignment leading to reasoning stagnation. To address these challenges, we propose CoG, a training-free framework inspired by Dual-Process Theory that mimics the interplay between intuition and deliberation. First, functioning as the fast, intuitive process, the Relational Blueprint Guidance module leverages relational blueprints as interpretable soft structural constraints to rapidly stabilize the search direction against noise. Second, functioning as the prudent, analytical process, the Failure-Aware Refinement module intervenes upon encountering reasoning impasses. It triggers evidence-conditioned reflection and executes controlled backtracking to overcome reasoning stagnation. Experimental results on three benchmarks demonstrate that CoG significantly outperforms state-of-the-art approaches in both accuracy and efficiency.",
    "authors": [
      "Yuanxiang Liu",
      "Songze Li",
      "Xiaoke Guo",
      "Zhaoyan Gong",
      "Qifei Zhang",
      "Huajun Chen",
      "Wen Zhang"
    ],
    "published": "2026-01-16",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11047v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11047v1",
    "fetched_at": "2026-01-19T08:39:10.926402",
    "chinese_title": "CoG：基于知识图谱的关系蓝图与失败感知细化可控图推理",
    "chinese_summary": "针对大语言模型（LLM）推理可靠性不足（如幻觉）及现有知识图谱增强LLM方法认知僵化的问题，提出训练-free框架CoG；该框架受双过程理论启发，包含关系蓝图引导（用可解释软结构约束稳定搜索）和失败感知细化（遇推理停滞时触发反思与回溯）两个模块；实验在三个基准上证明CoG显著优于现有方法，提升准确率和效率。",
    "tags": [
      "LLM",
      "Graph Neural Network",
      "Benchmark"
    ],
    "key_contributions": [
      "提出训练-free框架CoG，结合直觉与分析过程解决LLM推理可靠性及KG增强LLM认知僵化问题",
      "设计关系蓝图引导与失败感知细化模块，实验验证其在准确率和效率上优于SOTA"
    ],
    "processed_at": "2026-01-19T08:50:34.574267"
  },
  {
    "id": "2601.11044v1",
    "title": "AgencyBench: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts",
    "abstract": "Large Language Models (LLMs) based autonomous agents demonstrate multifaceted capabilities to contribute substantially to economic production. However, existing benchmarks remain focused on single agentic capability, failing to capture long-horizon real-world scenarios. Moreover, the reliance on human-in-the-loop feedback for realistic tasks creates a scalability bottleneck, hindering automated rollout collection and evaluation. To bridge this gap, we introduce AgencyBench, a comprehensive benchmark derived from daily AI usage, evaluating 6 core agentic capabilities across 32 real-world scenarios, comprising 138 tasks with specific queries, deliverables, and rubrics. These scenarios require an average of 90 tool calls, 1 million tokens, and hours of execution time to resolve. To enable automated evaluation, we employ a user simulation agent to provide iterative feedback, and a Docker sandbox to conduct visual and functional rubric-based assessment. Experiments reveal that closed-source models significantly outperform open-source models (48.4% vs 32.1%). Further analysis reveals significant disparities across models in resource efficiency, feedback-driven self-correction, and specific tool-use preferences. Finally, we investigate the impact of agentic scaffolds, observing that proprietary models demonstrate superior performance within their native ecosystems (e.g., Claude-4.5-Opus via Claude-Agent-SDK), while open-source models exhibit distinct performance peaks, suggesting potential optimization for specific execution frameworks. AgencyBench serves as a critical testbed for next-generation agents, highlighting the necessity of co-optimizing model architecture with agentic frameworks. We believe this work sheds light on the future direction of autonomous agents, and we release the full benchmark and evaluation toolkit at https://github.com/GAIR-NLP/AgencyBench.",
    "authors": [
      "Keyu Li",
      "Junhao Shi",
      "Yang Xiao",
      "Mohan Jiang",
      "Jie Sun",
      "Yunze Wu",
      "Shijie Xia",
      "Xiaojie Cai",
      "Tianze Xu",
      "Weiye Si",
      "Wenjie Li",
      "Dequan Wang",
      "Pengfei Liu"
    ],
    "published": "2026-01-16",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11044v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11044v1",
    "fetched_at": "2026-01-19T08:39:10.926437",
    "chinese_title": "AgencyBench：在百万token真实世界场景中基准测试自主智能体前沿能力",
    "chinese_summary": "现有自主智能体基准多聚焦单能力、短场景且依赖人工反馈， scalability 不足；论文提出AgencyBench，含32真实场景138任务，评估6核心能力，采用用户模拟智能体+Docker沙盒实现自动评估；实验显示闭源模型（48.4%）显著优于开源（32.1%），并分析了模型在资源效率等维度的差异及智能体框架的影响。",
    "tags": [
      "LLM",
      "Benchmark",
      "Financial Agent"
    ],
    "key_contributions": [
      "构建AgencyBench全面基准，覆盖长时真实场景（百万token、平均90工具调用），评估6核心智能体能力",
      "提出自动评估方法（用户模拟反馈+Docker沙盒评估），突破人工反馈的 scalability 瓶颈"
    ],
    "processed_at": "2026-01-19T08:51:14.842102"
  },
  {
    "id": "2601.11035v1",
    "title": "Your One-Stop Solution for AI-Generated Video Detection",
    "abstract": "Recent advances in generative modeling can create remarkably realistic synthetic videos, making it increasingly difficult for humans to distinguish them from real ones and necessitating reliable detection methods.   However, two key limitations hinder the development of this field.   \\textbf{From the dataset perspective}, existing datasets are often limited in scale and constructed using outdated or narrowly scoped generative models, making it difficult to capture the diversity and rapid evolution of modern generative techniques. Moreover, the dataset construction process frequently prioritizes quantity over quality, neglecting essential aspects such as semantic diversity, scenario coverage, and technological representativeness.   \\textbf{From the benchmark perspective}, current benchmarks largely remain at the stage of dataset creation, leaving many fundamental issues and in-depth analysis yet to be systematically explored.   Addressing this gap, we propose AIGVDBench, a benchmark designed to be comprehensive and representative, covering \\textbf{31} state-of-the-art generation models and over \\textbf{440,000} videos. By executing more than \\textbf{1,500} evaluations on \\textbf{33} existing detectors belonging to four distinct categories. This work presents \\textbf{8 in-depth analyses} from multiple perspectives and identifies \\textbf{4 novel findings} that offer valuable insights for future research. We hope this work provides a solid foundation for advancing the field of AI-generated video detection.   Our benchmark is open-sourced at https://github.com/LongMa-2025/AIGVDBench.",
    "authors": [
      "Long Ma",
      "Zihao Xue",
      "Yan Wang",
      "Zhiyuan Yan",
      "Jin Xu",
      "Xiaorui Jiang",
      "Haiyang Yu",
      "Yong Liao",
      "Zhen Bi"
    ],
    "published": "2026-01-16",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.11035v1",
    "arxiv_url": "https://arxiv.org/abs/2601.11035v1",
    "fetched_at": "2026-01-19T08:39:10.926467",
    "chinese_title": "AI生成视频检测的一站式解决方案",
    "chinese_summary": "针对现有AI生成视频检测数据集规模有限、代表性不足及基准研究不深入的问题，本文提出综合代表性基准AIGVDBench，覆盖31个SOTA生成模型、超44万视频，对33个检测器完成超1500次评估；同时开展8项多视角深入分析并得出4个新发现，为该领域研究提供坚实基础。",
    "tags": [
      "Benchmark",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出综合覆盖多SOTA生成模型、大规模视频及多类检测器的AI生成视频检测基准AIGVDBench",
      "开展多视角深入分析并得出4个新发现，为领域研究提供基础"
    ],
    "processed_at": "2026-01-19T08:51:40.173767"
  },
  {
    "id": "2601.10971v1",
    "title": "AJAR: Adaptive Jailbreak Architecture for Red-teaming",
    "abstract": "As Large Language Models (LLMs) evolve from static chatbots into autonomous agents capable of tool execution, the landscape of AI safety is shifting from content moderation to action security. However, existing red-teaming frameworks remain bifurcated: they either focus on rigid, script-based text attacks or lack the architectural modularity to simulate complex, multi-turn agentic exploitations. In this paper, we introduce AJAR (Adaptive Jailbreak Architecture for Red-teaming), a proof-of-concept framework designed to bridge this gap through Protocol-driven Cognitive Orchestration. Built upon the robust runtime of Petri, AJAR leverages the Model Context Protocol (MCP) to decouple adversarial logic from the execution loop, encapsulating state-of-the-art algorithms like X-Teaming as standardized, plug-and-play services. We validate the architectural feasibility of AJAR through a controlled qualitative case study, demonstrating its ability to perform stateful backtracking within a tool-use environment. Furthermore, our preliminary exploration of the \"Agentic Gap\" reveals a complex safety dynamic: while tool usage introduces new injection vectors via code execution, the cognitive load of parameter formatting can inadvertently disrupt persona-based attacks. AJAR is open-sourced to facilitate the standardized, environment-aware evaluation of this emerging attack surface. The code and data are available at https://github.com/douyipu/ajar.",
    "authors": [
      "Yipu Dou",
      "Wang Yang"
    ],
    "published": "2026-01-16",
    "categories": [
      "cs.CR",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.10971v1",
    "arxiv_url": "https://arxiv.org/abs/2601.10971v1",
    "fetched_at": "2026-01-19T08:39:10.926484",
    "chinese_title": "AJAR：用于红队测试的自适应越狱架构",
    "chinese_summary": "论文提出AJAR（用于红队测试的自适应越狱架构），基于Petri运行时与模型上下文协议（MCP）解耦对抗逻辑与执行循环，将X-Teaming等算法封装为标准化即插即用服务；通过受控定性案例验证其在工具使用环境中的状态回溯能力，探索代理间隙的安全动态，开源代码助力环境感知的攻击面评估。",
    "tags": [
      "LLM",
      "NLP"
    ],
    "key_contributions": [
      "提出AJAR框架，实现对抗逻辑与执行循环的解耦，支持算法即插即用",
      "验证架构可行性，揭示代理间隙的安全动态，开源代码促进相关评估"
    ],
    "processed_at": "2026-01-19T08:52:03.474488"
  },
  {
    "id": "2601.08689v2",
    "title": "QuantEval: A Benchmark for Financial Quantitative Tasks in Large Language Models",
    "abstract": "Large Language Models (LLMs) have shown strong capabilities across many domains, yet their evaluation in financial quantitative tasks remains fragmented and mostly limited to knowledge-centric question answering. We introduce QuantEval, a benchmark that evaluates LLMs across three essential dimensions of quantitative finance: knowledge-based QA, quantitative mathematical reasoning, and quantitative strategy coding. Unlike prior financial benchmarks, QuantEval integrates a CTA-style backtesting framework that executes model-generated strategies and evaluates them using financial performance metrics, enabling a more realistic assessment of quantitative coding ability. We evaluate some state-of-the-art open-source and proprietary LLMs and observe substantial gaps to human experts, particularly in reasoning and strategy coding. Finally, we conduct large-scale supervised fine-tuning and reinforcement learning experiments on domain-aligned data, demonstrating consistent improvements. We hope QuantEval will facilitate research on LLMs' quantitative finance capabilities and accelerate their practical adoption in real-world trading workflows. We additionally release the full deterministic backtesting configuration (asset universe, cost model, and metric definitions) to ensure strict reproducibility.",
    "authors": [
      "Zhaolu Kang",
      "Junhao Gong",
      "Wenqing Hu",
      "Shuo Yin",
      "Kehan Jiang",
      "Zhicheng Fang",
      "Yingjie He",
      "Chunlei Meng",
      "Rong Fu",
      "Dongyang Chen",
      "Leqi Zheng",
      "Eric Hanchen Jiang",
      "Yunfei Feng",
      "Yitong Leng",
      "Junfan Zhu",
      "Xiaoyou Chen",
      "Xi Yang",
      "Richeng Xuan"
    ],
    "published": "2026-01-13",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.08689v2",
    "arxiv_url": "https://arxiv.org/abs/2601.08689v2",
    "fetched_at": "2026-01-19T08:40:01.465740",
    "chinese_title": "QuantEval：大语言模型金融量化任务基准测试",
    "chinese_summary": "论文提出QuantEval基准，覆盖金融量化的知识问答、数学推理、策略编码三大维度，集成CTA风格回测框架评估策略性能；评估发现主流LLM在推理和编码上与人类专家有差距，通过领域对齐数据的监督微调及强化学习可提升性能，且发布可复现的回测配置。",
    "tags": [
      "LLM",
      "Benchmark",
      "Reinforcement Learning",
      "Algorithmic Trading"
    ],
    "key_contributions": [
      "提出整合多维度评估与回测框架的QuantEval基准，全面衡量LLM金融量化能力",
      "验证领域微调及强化学习对LLM金融量化能力的提升，发布可复现的回测配置"
    ],
    "processed_at": "2026-01-19T08:52:20.007284"
  }
]