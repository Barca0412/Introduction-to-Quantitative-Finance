[
  {
    "id": "2601.22119v1",
    "title": "Alpha Discovery via Grammar-Guided Learning and Search",
    "abstract": "Automatically discovering formulaic alpha factors is a central problem in quantitative finance. Existing methods often ignore syntactic and semantic constraints, relying on exhaustive search over unstructured and unbounded spaces. We present AlphaCFG, a grammar-based framework for defining and discovering alpha factors that are syntactically valid, financially interpretable, and computationally efficient. AlphaCFG uses an alpha-oriented context-free grammar to define a tree-structured, size-controlled search space, and formulates alpha discovery as a tree-structured linguistic Markov decision process, which is then solved using a grammar-aware Monte Carlo Tree Search guided by syntax-sensitive value and policy networks. Experiments on Chinese and U.S. stock market datasets show that AlphaCFG outperforms state-of-the-art baselines in both search efficiency and trading profitability. Beyond trading strategies, AlphaCFG serves as a general framework for symbolic factor discovery and refinement across quantitative finance, including asset pricing and portfolio construction.",
    "authors": [
      "Han Yang",
      "Dong Hao",
      "Zhuohan Wang",
      "Qi Shi",
      "Xingtong Li"
    ],
    "published": "2026-01-29",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22119v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22119v1",
    "fetched_at": "2026-01-30T08:43:55.189949",
    "chinese_title": "基于语法引导学习与搜索的Alpha发现",
    "chinese_summary": "论文提出AlphaCFG语法框架，用面向Alpha的上下文无关文法定义树状可控搜索空间，将Alpha发现建模为树状语言马尔可夫决策过程，通过语法感知的蒙特卡洛树搜索求解；实验在中美市场验证其搜索效率与交易盈利能力优于SOTA基线，且可用于量化金融多场景的符号因子发现与细化。",
    "tags": [
      "Factor Mining",
      "Algorithmic Trading",
      "Reinforcement Learning",
      "Asset Pricing"
    ],
    "key_contributions": [
      "提出AlphaCFG语法框架，定义语法有效、金融可解释、计算高效的Alpha因子搜索空间，解决现有方法忽略语法语义约束的问题",
      "实验验证在中美市场上搜索效率与交易盈利能力优于SOTA基线，且可扩展至资产定价、组合构建等量化金融场景"
    ],
    "processed_at": "2026-01-30T08:46:51.390817"
  },
  {
    "id": "2601.22113v1",
    "title": "Diverse Approaches to Optimal Execution Schedule Generation",
    "abstract": "We present the first application of MAP-Elites, a quality-diversity algorithm, to trade execution. Rather than searching for a single optimal policy, MAP-Elites generates a diverse portfolio of regime-specialist strategies indexed by liquidity and volatility conditions. Individual specialists achieve 8-10% performance improvements within their behavioural niches, while other cells show degradation, suggesting opportunities for ensemble approaches that combine improved specialists with the baseline PPO policy. Results indicate that quality-diversity methods offer promise for regime-adaptive execution, though substantial computational resources per behavioural cell may be required for robust specialist development across all market conditions. To ensure experimental integrity, we develop a calibrated Gymnasium environment focused on order scheduling rather than tactical placement decisions. The simulator features a transient impact model with exponential decay and square-root volume scaling, fit to 400+ U.S. equities with R^2>0.02 out-of-sample. Within this environment, two Proximal Policy Optimization architectures - both MLP and CNN feature extractors - demonstrate substantial improvements over industry baselines, with the CNN variant achieving 2.13 bps arrival slippage versus 5.23 bps for VWAP on 4,900 out-of-sample orders ($21B notional). These results validate both the simulation realism and provide strong single-policy baselines for quality-diversity methods.",
    "authors": [
      "Robert de Witt",
      "Mikko S. Pakkanen"
    ],
    "published": "2026-01-29",
    "categories": [
      "q-fin.TR",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22113v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22113v1",
    "fetched_at": "2026-01-30T08:43:55.189981",
    "chinese_title": "最优执行调度生成的多样化方法",
    "chinese_summary": "该论文首次将MAP-Elites质量多样性算法应用于交易执行，生成适应不同流动性和波动率的多样化策略组合；同时开发了校准的Gymnasium交易执行环境，并用含CNN特征提取的PPO算法建立了优于VWAP的单策略基准，单个 niche 策略性能提升8-10%且具备集成潜力。",
    "tags": [
      "Reinforcement Learning",
      "Algorithmic Trading",
      "Execution",
      "Market Microstructure"
    ],
    "key_contributions": [
      "开发校准的Gymnasium交易执行环境，并用PPO（含CNN）建立优于行业基准的单策略基准"
    ],
    "processed_at": "2026-01-30T08:47:02.796594"
  },
  {
    "id": "2601.21447v1",
    "title": "Trade uncertainty impact on stock-bond correlations: Insights from conditional correlation models",
    "abstract": "This paper investigates the impact of Trade Policy Uncertainty (TPU) on stock-bond correlation dynamics in the United States. Using daily data on major U.S. stock indices and the 10-year Treasury bond from 2015 to 2025, we estimate correlation within a two-step GARCH-based framework, relying on multivariate specifications, including Constant Conditional Correlation (CCC), Smooth Transition Conditional Correlation (STCC), and Dynamic Conditional Correlation (DCC) models. We extend these frameworks by incorporating TPU index and a presidential dummy to capture effects of trade uncertainty and government cycles. The findings show that constant correlation models are strongly rejected in favor of time-varying specifications. Both STCC and DCC models confirm TPU's central role in driving correlation dynamics, with significant differences across political regimes. DCC models augmented with TPU and political effects deliver the best in-sample fit and strongest forecasting performance, as measured by statistical and economic loss functions.",
    "authors": [
      "Demetrio Lacava",
      "Edoardo Otranto"
    ],
    "published": "2026-01-29",
    "categories": [
      "q-fin.ST"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21447v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21447v1",
    "fetched_at": "2026-01-30T08:43:55.190004",
    "chinese_title": "贸易不确定性对股债相关性的影响：来自条件相关模型的洞察",
    "chinese_summary": "本文以2015-2025年美国主要股指及10年期国债日度数据为样本，采用两步GARCH框架结合CCC、STCC、DCC等多元条件相关模型，纳入贸易政策不确定性（TPU）指数和总统虚拟变量分析其对股债相关性的影响；研究发现常相关模型被显著拒绝，TPU是股债相关动态变化的核心驱动因素且跨政治 regimes 存在差异，加入TPU和政治效应的DCC模型拟合与预测表现最优。",
    "tags": [
      "Time Series",
      "Volatility",
      "Asset Pricing",
      "Risk Management"
    ],
    "key_contributions": [
      "揭示贸易政策不确定性（TPU）是美国股债相关性动态变化的核心驱动因素，且跨政治 regimes 存在显著差异",
      "证明加入TPU和政治效应的动态条件相关（DCC）模型在股债相关性的拟合与预测方面表现最优"
    ],
    "processed_at": "2026-01-30T08:47:21.300850"
  },
  {
    "id": "2601.21272v1",
    "title": "Finite-Sample Properties of Model Specification Tests for Multivariate Dynamic Regression Models",
    "abstract": "This paper proposes a new multivariate model specification test that generalizes Durbin regression to a seemingly unrelated regression framework and reframes the Durbin approach as a GLS-class estimator. The proposed estimator explicitly models cross-equation dependence and the joint second-order dynamics of regressors and disturbances. It remains consistent under a comparatively weak dependence condition in which conventional OLS- and GLS-based estimators can be inconsistent, and it is asymptotically efficient under stronger conditions. Monte Carlo experiments indicate that the associated Wald test achieves improved size control and competitive power in finite samples, especially when combined with a bootstrap-based bias correction. An empirical application further illustrates that the proposed procedure delivers stable inference and is practically useful for multi-equation specification testing.",
    "authors": [
      "Koichiro Moriya",
      "Akihiko Noda"
    ],
    "published": "2026-01-29",
    "categories": [
      "econ.EM",
      "q-fin.PR",
      "q-fin.ST"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21272v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21272v1",
    "fetched_at": "2026-01-30T08:43:55.190025",
    "chinese_title": "多元动态回归模型设定检验的有限样本性质",
    "chinese_summary": "论文提出一种新的多元模型设定检验，将Durbin回归推广至似不相关回归框架并重构为GLS类估计量，显式建模跨方程依赖及回归元与扰动项的联合二阶动态；该估计量在传统OLS/GLS可能不一致的弱依赖条件下仍一致且渐近有效；蒙特卡洛实验表明其Wald检验有限样本尺寸控制更优、功效具竞争力（结合bootstrap偏差修正更佳），实证应用验证其稳定推断与实用性。",
    "tags": [
      "Time Series",
      "Benchmark"
    ],
    "key_contributions": [
      "提出新的多元模型设定检验，将Durbin回归推广至似不相关回归框架并重构为GLS类估计量，显式建模跨方程依赖及回归元与扰动项的联合二阶动态",
      "该估计量在弱依赖条件下仍一致且渐近有效，有限样本下Wald检验尺寸控制更优、功效竞争力强（结合bootstrap偏差修正更佳）"
    ],
    "processed_at": "2026-01-30T08:58:02.270740"
  },
  {
    "id": "2601.20251v2",
    "title": "Efficient Evaluation of LLM Performance with Statistical Guarantees",
    "abstract": "Exhaustively evaluating many large language models (LLMs) on a large suite of benchmarks is expensive. We cast benchmarking as finite-population inference and, under a fixed query budget, seek tight confidence intervals (CIs) for model accuracy with valid frequentist coverage. We propose Factorized Active Querying (FAQ), which (a) leverages historical information through a Bayesian factor model; (b) adaptively selects questions using a hybrid variance-reduction/active-learning sampling policy; and (c) maintains validity through Proactive Active Inference -- a finite-population extension of active inference (Zrnic & Candès, 2024) that enables direct question selection while preserving coverage. With negligible overhead cost, FAQ delivers up to $5\\times$ effective sample size gains over strong baselines on two benchmark suites, across varying historical-data missingness levels: this means that it matches the CI width of uniform sampling while using up to $5\\times$ fewer queries. We release our source code and our curated datasets to support reproducible evaluation and future research.",
    "authors": [
      "Skyler Wu",
      "Yash Nair",
      "Emmanuel J. Candès"
    ],
    "published": "2026-01-28",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.20251v2",
    "arxiv_url": "https://arxiv.org/abs/2601.20251v2",
    "fetched_at": "2026-01-30T08:44:01.312973",
    "chinese_title": "带统计保证的大语言模型性能高效评估",
    "chinese_summary": "现有LLM基准评估成本较高，论文提出Factorized Active Querying（FAQ）方法，通过贝叶斯因子模型利用历史信息、混合方差减少/主动学习采样策略及主动推理扩展保证置信区间有效性；在两个基准套件上比强基线有效样本量提升最多5倍，可减少查询数，且开源代码与数据集支持复现。",
    "tags": [
      "LLM",
      "Factor Model",
      "Benchmark"
    ],
    "key_contributions": [
      "提出FAQ方法，结合贝叶斯因子模型、混合采样及主动推理扩展，实现带统计保证的LLM性能高效评估",
      "实验验证FAQ比强基线有效样本量提升最多5倍，减少查询数，同时开源代码与数据集支持复现"
    ],
    "processed_at": "2026-01-30T08:58:22.191463"
  },
  {
    "id": "2601.21802v1",
    "title": "A Unified XAI-LLM Approach for EndotrachealSuctioning Activity Recognition",
    "abstract": "Endotracheal suctioning (ES) is an invasive yet essential clinical procedure that requires a high degree of skill to minimize patient risk - particularly in home care and educational settings, where consistent supervision may be limited. Despite its critical importance, automated recognition and feedback systems for ES training remain underexplored. To address this gap, this study proposes a unified, LLM-centered framework for video-based activity recognition benchmarked against conventional machine learning and deep learning approaches, and a pilot study on feedback generation. Within this framework, the Large Language Model (LLM) serves as the central reasoning module, performing both spatiotemporal activity recognition and explainable decision analysis from video data. Furthermore, the LLM is capable of verbalizing feedback in natural language, thereby translating complex technical insights into accessible, human-understandable guidance for trainees. Experimental results demonstrate that the proposed LLM-based approach outperforms baseline models, achieving an improvement of approximately 15-20\\% in both accuracy and F1 score. Beyond recognition, the framework incorporates a pilot student-support module built upon anomaly detection and explainable AI (XAI) principles, which provides automated, interpretable feedback highlighting correct actions and suggesting targeted improvements. Collectively, these contributions establish a scalable, interpretable, and data-driven foundation for advancing nursing education, enhancing training efficiency, and ultimately improving patient safety.",
    "authors": [
      "Hoang Khang Phan",
      "Quang Vinh Dang",
      "Noriyo Colley",
      "Christina Garcia",
      "Nhat Tan Le"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21802v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21802v1",
    "fetched_at": "2026-01-30T08:44:07.437308",
    "chinese_title": "用于气管内吸痰活动识别的统一XAI-LLM方法",
    "chinese_summary": "论文针对气管内吸痰（ES）活动识别的自动化与反馈需求，提出以大语言模型（LLM）为核心的统一框架，LLM同时实现时空活动识别、可解释决策分析及自然语言反馈生成；实验表明该方法比基线模型准确率和F1分数提升15-20%，还包含基于异常检测和XAI的试点学生支持模块，提供可解释反馈。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Anomaly"
    ],
    "key_contributions": [
      "提出以LLM为核心的统一框架，实现气管内吸痰活动的时空识别、可解释分析及自然语言反馈生成",
      "实验证明该框架比基线模型准确率和F1分数提升15-20%，并包含基于异常检测与XAI的试点反馈模块"
    ],
    "processed_at": "2026-01-30T08:58:35.431558"
  },
  {
    "id": "2601.21463v1",
    "title": "Unifying Speech Editing Detection and Content Localization via Prior-Enhanced Audio LLMs",
    "abstract": "Speech editing achieves semantic inversion by performing fine-grained segment-level manipulation on original utterances, while preserving global perceptual naturalness. Existing detection studies mainly focus on manually edited speech with explicit splicing artifacts, and therefore struggle to cope with emerging end-to-end neural speech editing techniques that generate seamless acoustic transitions. To address this challenge, we first construct a large-scale bilingual dataset, AiEdit, which leverages large language models to drive precise semantic tampering logic and employs multiple advanced neural speech editing methods for data synthesis, thereby filling the gap of high-quality speech editing datasets. Building upon this foundation, we propose PELM (Prior-Enhanced Audio Large Language Model), the first large-model framework that unifies speech editing detection and content localization by formulating them as an audio question answering task. To mitigate the inherent forgery bias and semantic-priority bias observed in existing audio large models, PELM incorporates word-level probability priors to provide explicit acoustic cues, and further designs a centroid-aggregation-based acoustic consistency perception loss to explicitly enforce the modeling of subtle local distribution anomalies. Extensive experimental results demonstrate that PELM significantly outperforms state-of-the-art methods on both the HumanEdit and AiEdit datasets, achieving equal error rates (EER) of 0.57\\% and 9.28\\% (localization), respectively.",
    "authors": [
      "Jun Xue",
      "Yi Chai",
      "Yanzhen Ren",
      "Jinshen He",
      "Zhiqiang Tang",
      "Zhuolin Yi",
      "Yihuan Huang",
      "Yuankun Xie",
      "Yujie Chen"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21463v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21463v1",
    "fetched_at": "2026-01-30T08:44:07.437348",
    "chinese_title": "通过先验增强音频大语言模型统一语音编辑检测与内容定位",
    "chinese_summary": "该论文针对现有语音编辑检测难以应对端到端神经编辑技术的问题，首先构建了大规模双语数据集AiEdit（利用大语言模型驱动语义篡改逻辑并结合多先进神经编辑方法合成）；进而提出PELM框架，首次将语音编辑检测与内容定位统一为音频问答任务，通过词级概率先验和质心聚合的声学一致性感知损失解决模型偏差，实验显著优于现有方法。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Anomaly"
    ],
    "key_contributions": [
      "构建大规模双语语音编辑数据集AiEdit，填补高质量神经编辑语音数据缺口",
      "提出PELM框架，首次统一语音编辑检测与内容定位为音频问答任务，通过先验增强解决模型偏差并显著提升性能"
    ],
    "processed_at": "2026-01-30T08:58:51.154838"
  },
  {
    "id": "2601.21359v1",
    "title": "Graph-Free Root Cause Analysis",
    "abstract": "Failures in complex systems demand rapid Root Cause Analysis (RCA) to prevent cascading damage. Existing RCA methods that operate without dependency graph typically assume that the root cause having the highest anomaly score. This assumption fails when faults propagate, as a small delay at the root cause can accumulate into a much larger anomaly downstream. In this paper, we propose PRISM, a simple and efficient framework for RCA when the dependency graph is absent. We formulate a class of component-based systems under which PRISM performs RCA with theoretical guarantees. On 735 failures across 9 real-world datasets, PRISM achieves 68% Top-1 accuracy, a 258% improvement over the best baseline, while requiring only 8ms per diagnosis.",
    "authors": [
      "Luan Pham"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.LG",
      "cs.SE"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21359v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21359v1",
    "fetched_at": "2026-01-30T08:44:07.437367",
    "chinese_title": "无依赖图的根因分析",
    "chinese_summary": "现有无依赖图的根因分析（RCA）方法假设根因异常得分最高，但故障传播时延迟累积导致下游异常更大，该假设失效；本文提出PRISM框架，针对无依赖图场景实现带理论保证的根因分析，在9个真实数据集735次故障中Top1准确率达68%，较最优基线提升258%且诊断仅需8ms。",
    "tags": [
      "Anomaly",
      "Risk Management",
      "Time Series"
    ],
    "key_contributions": [
      "提出PRISM框架，解决无依赖图场景下根因分析问题，突破现有方法假设局限并提供理论保证",
      "在真实数据集上实现显著准确率提升（Top1达68%，较基线提升258%）且诊断效率极高（单诊断8ms）"
    ],
    "processed_at": "2026-01-30T08:59:14.693394"
  },
  {
    "id": "2601.21171v1",
    "title": "AC2L-GAD: Active Counterfactual Contrastive Learning for Graph Anomaly Detection",
    "abstract": "Graph anomaly detection aims to identify abnormal patterns in networks, but faces significant challenges from label scarcity and extreme class imbalance. While graph contrastive learning offers a promising unsupervised solution, existing methods suffer from two critical limitations: random augmentations break semantic consistency in positive pairs, while naive negative sampling produces trivial, uninformative contrasts. We propose AC2L-GAD, an Active Counterfactual Contrastive Learning framework that addresses both limitations through principled counterfactual reasoning. By combining information-theoretic active selection with counterfactual generation, our approach identifies structurally complex nodes and generates anomaly-preserving positive augmentations alongside normal negative counterparts that provide hard contrasts, while restricting expensive counterfactual generation to a strategically selected subset. This design reduces computational overhead by approximately 65% compared to full-graph counterfactual generation while maintaining detection quality. Experiments on nine benchmark datasets, including real-world financial transaction graphs from GADBench, show that AC2L-GAD achieves competitive or superior performance compared to state-of-the-art baselines, with notable gains in datasets where anomalies exhibit complex attribute-structure interactions.",
    "authors": [
      "Kamal Berahmand",
      "Saman Forouzandeh",
      "Mehrnoush Mohammadi",
      "Parham Moradi",
      "Mahdi Jalili"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21171v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21171v1",
    "fetched_at": "2026-01-30T08:44:07.437393",
    "chinese_title": "AC2L-GAD：用于图异常检测的主动反事实对比学习",
    "chinese_summary": "针对图异常检测中标签稀缺、类别不平衡及现有对比学习方法随机增强破坏语义一致性、负采样无信息量的问题，论文提出AC2L-GAD框架，结合信息论主动选择与反事实生成，生成异常保留的正增强和硬对比负样本，同时降低约65%计算开销；在含金融交易图的9个基准数据集上，该方法表现优于或媲美SOTA，复杂属性-结构交互异常的数据集上增益显著。",
    "tags": [
      "Anomaly",
      "Graph Neural Network",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "提出AC2L-GAD主动反事实对比学习框架，解决图异常检测标签稀缺、类别不平衡问题，克服现有对比学习的两大局限",
      "通过信息论主动选择减少反事实生成计算开销约65%，在含金融交易图的基准数据集上取得优异性能"
    ],
    "processed_at": "2026-01-30T08:59:34.041641"
  },
  {
    "id": "2601.21050v1",
    "title": "SMKC: Sketch Based Kernel Correlation Images for Variable Cardinality Time Series Anomaly Detection",
    "abstract": "Conventional anomaly detection in multivariate time series relies on the assumption that the set of observed variables remains static. In operational environments, however, monitoring systems frequently experience sensor churn. Signals may appear, disappear, or be renamed, creating data windows where the cardinality varies and may include values unseen during training. To address this challenge, we propose SMKC, a framework that decouples the dynamic input structure from the anomaly detector. We first employ permutation-invariant feature hashing to sketch raw inputs into a fixed size state sequence. We then construct a hybrid kernel image to capture global temporal structure through pairwise comparisons of the sequence and its derivatives. The model learns normal patterns using masked reconstruction and a teacher-student prediction objective. Our evaluation reveals that robust log-distance channels provide the primary discriminative signal, whereas cosine representations often fail to capture sufficient contrast. Notably, we find that a detector using random projections and nearest neighbors on the SMKC representation performs competitively with fully trained baselines without requiring gradient updates. This highlights the effectiveness of the representation itself and offers a practical cold-start solution for resource-constrained deployments.",
    "authors": [
      "Haokun Zhou"
    ],
    "published": "2026-01-28",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21050v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21050v1",
    "fetched_at": "2026-01-30T08:44:07.437410",
    "chinese_title": "SMKC：基于Sketch的核相关图像用于变量基数变化的时间序列异常检测",
    "chinese_summary": "针对多变量时间序列异常检测中变量基数动态变化（传感器波动、变量出现/消失等）的挑战，提出SMKC框架：先通过排列不变特征哈希将输入sketch为固定长度序列，再构建混合核图像捕捉全局时间结构，结合掩码重建与师生预测学习正常模式；实验发现基于随机投影和最近邻的SMKC表示检测器无需梯度更新即可与全训练基线媲美，为资源受限部署提供实用冷启动方案。",
    "tags": [
      "Anomaly",
      "Time Series",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出SMKC框架，通过sketch将动态输入结构与异常检测器解耦，解决多变量时间序列变量基数变化的异常检测问题",
      "发现基于随机投影和最近邻的SMKC表示检测器无需梯度更新即可与全训练基线竞争，为资源受限部署提供实用冷启动方案"
    ],
    "processed_at": "2026-01-30T08:59:52.819028"
  },
  {
    "id": "2601.22151v1",
    "title": "Late Breaking Results: Conversion of Neural Networks into Logic Flows for Edge Computing",
    "abstract": "Neural networks have been successfully applied in various resource-constrained edge devices, where usually central processing units (CPUs) instead of graphics processing units exist due to limited power availability. State-of-the-art research still focuses on efficiently executing enormous numbers of multiply-accumulate (MAC) operations. However, CPUs themselves are not good at executing such mathematical operations on a large scale, since they are more suited to execute control flow logic, i.e., computer algorithms. To enhance the computation efficiency of neural networks on CPUs, in this paper, we propose to convert them into logic flows for execution. Specifically, neural networks are first converted into equivalent decision trees, from which decision paths with constant leaves are then selected and compressed into logic flows. Such logic flows consist of if and else structures and a reduced number of MAC operations. Experimental results demonstrate that the latency can be reduced by up to 14.9 % on a simulated RISC-V CPU without any accuracy degradation.   The code is open source at https://github.com/TUDa-HWAI/NN2Logic",
    "authors": [
      "Daniel Stein",
      "Shaoyi Huang",
      "Rolf Drechsler",
      "Bing Li",
      "Grace Li Zhang"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.LG",
      "eess.SY"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22151v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22151v1",
    "fetched_at": "2026-01-30T08:44:35.038155",
    "chinese_title": "最新结果：将神经网络转换为逻辑流以用于边缘计算",
    "chinese_summary": "论文针对边缘设备CPU不擅长大规模乘加（MAC）运算的问题，提出先将神经网络转换为等价决策树，再选取常数叶节点的决策路径压缩为含if-else结构且MAC运算更少的逻辑流；实验在模拟RISC-V CPU上使延迟最多降低14.9%且无精度损失。",
    "tags": [
      "Deep Learning"
    ],
    "key_contributions": [
      "提出将神经网络转换为逻辑流的方法，通过决策树中间转换压缩得到含if-else结构且MAC运算减少的逻辑流，适配边缘CPU特性",
      "实验验证该方法可使模拟RISC-V CPU上神经网络延迟最多降低14.9%且无精度损失，提升边缘计算效率"
    ],
    "processed_at": "2026-01-30T09:00:03.862254"
  },
  {
    "id": "2601.22037v1",
    "title": "Optimizing Agentic Workflows using Meta-tools",
    "abstract": "Agentic AI enables LLM to dynamically reason, plan, and interact with tools to solve complex tasks. However, agentic workflows often require many iterative reasoning steps and tool invocations, leading to significant operational expense, end-to-end latency and failures due to hallucinations. This work introduces Agent Workflow Optimization (AWO), a framework that identifies and optimizes redundant tool execution patterns to improve the efficiency and robustness of agentic workflows. AWO analyzes existing workflow traces to discover recurring sequences of tool calls and transforms them into meta-tools, which are deterministic, composite tools that bundle multiple agent actions into a single invocation. Meta-tools bypass unnecessary intermediate LLM reasoning steps and reduce operational cost while also shortening execution paths, leading to fewer failures. Experiments on two agentic AI benchmarks show that AWO reduces the number of LLM calls up to 11.9% while also increasing the task success rate by up to 4.2 percent points.",
    "authors": [
      "Sami Abuzakuk",
      "Anne-Marie Kermarrec",
      "Rishi Sharma",
      "Rasmus Moorits Veski",
      "Martijn de Vos"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.22037v1",
    "arxiv_url": "https://arxiv.org/abs/2601.22037v1",
    "fetched_at": "2026-01-30T08:44:35.038210",
    "chinese_title": "使用元工具优化智能体工作流",
    "chinese_summary": "论文针对智能体AI工作流中迭代推理多、工具调用冗余导致的成本高、延迟长及幻觉失败问题，提出Agent Workflow Optimization（AWO）框架，通过分析工作流轨迹发现重复工具调用序列并转化为确定性复合元工具，减少中间LLM推理步骤；实验显示该框架可降低LLM调用次数最多11.9%，提升任务成功率最多4.2个百分点。",
    "tags": [
      "LLM",
      "Financial Agent",
      "Benchmark"
    ],
    "key_contributions": [
      "提出AWO框架，将重复工具调用序列转化为元工具以优化智能体工作流效率与鲁棒性",
      "实验验证AWO可显著降低LLM调用成本并提升任务成功率"
    ],
    "processed_at": "2026-01-30T09:00:16.169731"
  },
  {
    "id": "2601.21993v1",
    "title": "Liquid Interfaces: A Dynamic Ontology for the Interoperability of Autonomous Systems",
    "abstract": "Contemporary software architectures struggle to support autonomous agents whose reasoning is adaptive, probabilistic, and context-dependent, while system integration remains dominated by static interfaces and deterministic contracts. This paper introduces Liquid Interfaces, a coordination paradigm in which interfaces are not persistent technical artifacts, but ephemeral relational events that emerge through intention articulation and semantic negotiation at runtime.We formalize this model and present the Liquid Interface Protocol (LIP),which governs intention-driven interaction, negotiated execution, and enforce ephemerality under semantic uncertainty. We further discuss the governance implications of this approach and describe a reference architecture that demonstrates practical feasibility. Liquid Interfaces provide a principled foundation for adaptive coordination in agent-based systems",
    "authors": [
      "Dhiogo de Sá",
      "Carlos Schmiedel",
      "Carlos Pereira Lopes"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21993v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21993v1",
    "fetched_at": "2026-01-30T08:44:35.038231",
    "chinese_title": "液态接口：自治系统互操作性的动态本体",
    "chinese_summary": "当代软件架构难以支持自适应、概率性且上下文依赖的自治代理，系统集成多依赖静态接口与确定性契约；本文提出液态接口范式，将接口视为运行时通过意图表达和语义协商产生的短暂关系事件，形式化模型并设计液态接口协议（LIP），为基于代理系统的自适应协调提供原则性基础。",
    "tags": [
      "Financial Agent"
    ],
    "key_contributions": [
      "提出液态接口范式，突破静态接口局限，将接口定义为运行时通过意图表达与语义协商产生的短暂关系事件",
      "形式化该模型并设计液态接口协议（LIP），实现意图驱动交互、协商执行及语义不确定下的短暂性管理，同时给出参考架构证明可行性"
    ],
    "processed_at": "2026-01-30T09:00:45.661247"
  },
  {
    "id": "2601.21978v1",
    "title": "Bridging Graph Structure and Knowledge-Guided Editing for Interpretable Temporal Knowledge Graph Reasoning",
    "abstract": "Temporal knowledge graph reasoning (TKGR) aims to predict future events by inferring missing entities with dynamic knowledge structures. Existing LLM-based reasoning methods prioritize contextual over structural relations, struggling to extract relevant subgraphs from dynamic graphs. This limits structural information understanding, leading to unstructured, hallucination-prone inferences especially with temporal inconsistencies. To address this problem, we propose IGETR (Integration of Graph and Editing-enhanced Temporal Reasoning), a hybrid reasoning framework that combines the structured temporal modeling capabilities of Graph Neural Networks (GNNs) with the contextual understanding of LLMs. IGETR operates through a three-stage pipeline. The first stage aims to ground the reasoning process in the actual data by identifying structurally and temporally coherent candidate paths through a temporal GNN, ensuring that inference starts from reliable graph-based evidence. The second stage introduces LLM-guided path editing to address logical and semantic inconsistencies, leveraging external knowledge to refine and enhance the initial paths. The final stage focuses on integrating the refined reasoning paths to produce predictions that are both accurate and interpretable. Experiments on standard TKG benchmarks show that IGETR achieves state-of-the-art performance, outperforming strong baselines with relative improvements of up to 5.6% on Hits@1 and 8.1% on Hits@3 on the challenging ICEWS datasets. Additionally, we execute ablation studies and additional analyses confirm the effectiveness of each component.",
    "authors": [
      "Shiqi Fan",
      "Quanming Yao",
      "Hongyi Nie",
      "Wentao Ma",
      "Zhen Wang",
      "Wen Hua"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21978v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21978v1",
    "fetched_at": "2026-01-30T08:44:35.038256",
    "chinese_title": "桥接图结构与知识引导编辑的可解释时序知识图谱推理",
    "chinese_summary": "现有基于大语言模型（LLM）的时序知识图谱推理（TKGR）方法侧重上下文而非结构关系，难以从动态图中提取相关子图，易产生非结构化且易幻觉的推理。针对此，论文提出IGETR混合框架，结合图神经网络（GNN）的时序结构建模能力与LLM的上下文理解能力，通过三阶段流程（时序GNN提取候选路径、LLM引导路径编辑、整合路径生成预测）实现准确可解释的TKGR，实验在标准基准上取得SOTA性能。",
    "tags": [
      "LLM",
      "Graph Neural Network",
      "Time Series"
    ],
    "key_contributions": [
      "提出IGETR混合推理框架，融合GNN的时序结构建模与LLM的上下文理解，弥补现有LLM-based TKGR方法的结构信息缺失问题",
      "设计三阶段推理流程，通过路径编辑修正逻辑语义不一致，生成准确且可解释的预测，实验验证其SOTA性能"
    ],
    "processed_at": "2026-01-30T09:01:04.059034"
  },
  {
    "id": "2601.21972v1",
    "title": "Learning Decentralized LLM Collaboration with Multi-Agent Actor Critic",
    "abstract": "Recent work has explored optimizing LLM collaboration through Multi-Agent Reinforcement Learning (MARL). However, most MARL fine-tuning approaches rely on predefined execution protocols, which often require centralized execution. Decentralized LLM collaboration is more appealing in practice, as agents can run inference in parallel with flexible deployments. Also, current approaches use Monte Carlo methods for fine-tuning, which suffer from high variance and thus require more samples to train effectively. Actor-critic methods are prevalent in MARL for dealing with these issues, so we developed Multi-Agent Actor-Critic (MAAC) methods to optimize decentralized LLM collaboration. In this paper, we analyze when and why these MAAC methods are beneficial. We propose 2 MAAC approaches, \\textbf{CoLLM-CC} with a \\textbf{C}entralized \\textbf{C}ritic and \\textbf{CoLLM-DC} with \\textbf{D}ecentralized \\textbf{C}ritics. Our experiments across writing, coding, and game-playing domains show that Monte Carlo methods and CoLLM-DC can achieve performance comparable to CoLLM-CC in short-horizon and dense-reward settings. However, they both underperform CoLLM-CC on long-horizon or sparse-reward tasks, where Monte Carlo methods require substantially more samples and CoLLM-DC struggles to converge. Our code is available at https://github.com/OpenMLRL/CoMLRL/releases/tag/v1.3.2.",
    "authors": [
      "Shuo Liu",
      "Tianle Chen",
      "Ryan Amiri",
      "Christopher Amato"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.AI",
      "cs.DC",
      "cs.MA"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21972v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21972v1",
    "fetched_at": "2026-01-30T08:44:35.038280",
    "chinese_title": "基于多智能体演员-评论家的去中心化大语言模型协作学习",
    "chinese_summary": "现有LLM协作的MARL方法多依赖预定义协议（集中式执行）且蒙特卡洛方法方差高样本需求大，本文提出CoLLM-CC（集中式评论家）和CoLLM-DC（去中心化评论家）两种MAAC方法优化去中心化LLM协作；实验显示短horizon密奖励场景下蒙特卡洛与CoLLM-DC可媲美CoLLM-CC，但长horizon稀疏奖励任务中CoLLM-CC表现更优，后两者表现较差且CoLLM-DC收敛困难。",
    "tags": [
      "LLM",
      "Reinforcement Learning",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出两种基于多智能体演员-评论家（MAAC）的去中心化LLM协作方法CoLLM-CC（集中式评论家）和CoLLM-DC（去中心化评论家）",
      "通过实验分析不同方法在不同任务设置（短/长horizon、密/稀疏奖励）下的性能差异，揭示MAAC方法的适用场景"
    ],
    "processed_at": "2026-01-30T09:01:20.144201"
  },
  {
    "id": "2601.21971v1",
    "title": "MoE-ACT: Improving Surgical Imitation Learning Policies through Supervised Mixture-of-Experts",
    "abstract": "Imitation learning has achieved remarkable success in robotic manipulation, yet its application to surgical robotics remains challenging due to data scarcity, constrained workspaces, and the need for an exceptional level of safety and predictability. We present a supervised Mixture-of-Experts (MoE) architecture designed for phase-structured surgical manipulation tasks, which can be added on top of any autonomous policy. Unlike prior surgical robot learning approaches that rely on multi-camera setups or thousands of demonstrations, we show that a lightweight action decoder policy like Action Chunking Transformer (ACT) can learn complex, long-horizon manipulation from less than 150 demonstrations using solely stereo endoscopic images, when equipped with our architecture. We evaluate our approach on the collaborative surgical task of bowel grasping and retraction, where a robot assistant interprets visual cues from a human surgeon, executes targeted grasping on deformable tissue, and performs sustained retraction. We benchmark our method against state-of-the-art Vision-Language-Action (VLA) models and the standard ACT baseline. Our results show that generalist VLAs fail to acquire the task entirely, even under standard in-distribution conditions. Furthermore, while standard ACT achieves moderate success in-distribution, adopting a supervised MoE architecture significantly boosts its performance, yielding higher success rates in-distribution and demonstrating superior robustness in out-of-distribution scenarios, including novel grasp locations, reduced illumination, and partial occlusions. Notably, it generalizes to unseen testing viewpoints and also transfers zero-shot to ex vivo porcine tissue without additional training, offering a promising pathway toward in vivo deployment. To support this, we present qualitative preliminary results of policy roll-outs during in vivo porcine surgery.",
    "authors": [
      "Lorenzo Mazza",
      "Ariel Rodriguez",
      "Rayan Younis",
      "Martin Lelis",
      "Ortrun Hellig",
      "Chenpan Li",
      "Sebastian Bodenstedt",
      "Martin Wagner",
      "Stefanie Speidel"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21971v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21971v1",
    "fetched_at": "2026-01-30T08:44:35.038313",
    "chinese_title": "MoE-ACT：通过有监督混合专家提升手术模仿学习策略",
    "chinese_summary": "针对手术机器人模仿学习的数据稀缺、 workspace约束等挑战，提出可叠加于任意自主策略的有监督混合专家（MoE）架构，结合轻量动作解码器ACT，仅用不到150个演示样本（仅 stereo内窥镜图像）即可学习复杂长horizon操作；在肠道抓取与牵开协作手术任务中，MoE-ACT显著提升成功率和鲁棒性，优于SOTA VLA模型和标准ACT基线。",
    "tags": [
      "Transformer",
      "Deep Learning",
      "Reinforcement Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "提出可叠加的有监督MoE架构，解决手术机器人模仿学习的数据稀缺等核心挑战",
      "结合ACT实现仅150+样本（仅 stereo图像）学习复杂手术操作，性能超SOTA VLA模型和标准ACT基线"
    ],
    "processed_at": "2026-01-30T09:01:30.897849"
  },
  {
    "id": "2601.21947v1",
    "title": "ToolWeaver: Weaving Collaborative Semantics for Scalable Tool Use in Large Language Models",
    "abstract": "Prevalent retrieval-based tool-use pipelines struggle with a dual semantic challenge: their retrievers often employ encoders that fail to capture complex semantics, while the Large Language Model (LLM) itself lacks intrinsic tool knowledge from its natural language pretraining. Generative methods offer a powerful alternative by unifying selection and execution, tasking the LLM to directly learn and generate tool identifiers. However, the common practice of mapping each tool to a unique new token introduces substantial limitations: it creates a scalability and generalization crisis, as the vocabulary size explodes and each tool is assigned a semantically isolated token. This approach also creates a semantic bottleneck that hinders the learning of collaborative tool relationships, as the model must infer them from sparse co-occurrences of monolithic tool IDs within a vast library. To address these limitations, we propose ToolWeaver, a novel generative tool learning framework that encodes tools into hierarchical sequences. This approach makes vocabulary expansion logarithmic to the number of tools. Crucially, it enables the model to learn collaborative patterns from the dense co-occurrence of shared codes, rather than the sparse co-occurrence of monolithic tool IDs. We generate these structured codes through a novel tokenization process designed to weave together a tool's intrinsic semantics with its extrinsic co-usage patterns. These structured codes are then integrated into the LLM through a generative alignment stage, where the model is fine-tuned to produce the hierarchical code sequences. Evaluation results with nearly 47,000 tools show that ToolWeaver significantly outperforms state-of-the-art methods, establishing a more scalable, generalizable, and semantically-aware foundation for advanced tool-augmented agents.",
    "authors": [
      "Bowen Fang",
      "Wen Ye",
      "Yunyue Su",
      "Jinghao Zhang",
      "Qiang Liu",
      "Yesheng Liu",
      "Xin Sun",
      "Shu Wu",
      "Jiabing Yang",
      "Baole Wei",
      "Liang Wang"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21947v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21947v1",
    "fetched_at": "2026-01-30T08:44:35.038353",
    "chinese_title": "ToolWeaver：为大语言模型中可扩展工具使用编织协作语义",
    "chinese_summary": "现有基于检索的工具使用流程存在语义捕捉不足与工具知识缺失问题，生成式方法虽能统一选择与执行但工具映射为唯一token导致可扩展性危机与语义瓶颈；论文提出ToolWeaver框架，将工具编码为层次序列使词汇扩展对数依赖工具数量，并通过共享代码密集共现学习协作模式，解决上述挑战。",
    "tags": [
      "LLM",
      "NLP",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出ToolWeaver框架，将工具编码为层次序列，使词汇扩展规模与工具数量呈对数关系，缓解生成式工具使用的可扩展性危机",
      "设计结合工具内在语义与外部共现模式的结构化编码过程，让模型通过共享代码的密集共现学习协作关系，突破语义瓶颈"
    ],
    "processed_at": "2026-01-30T09:01:50.370062"
  },
  {
    "id": "2601.21937v1",
    "title": "Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities",
    "abstract": "Despite strong performance on existing benchmarks, it remains unclear whether large language models can reason over genuinely novel scientific information. Most evaluations score end-to-end RAG pipelines, where reasoning is confounded with retrieval and toolchain choices, and the signal is further contaminated by parametric memorization and open-web volatility. We introduce DeR2, a controlled deep-research sandbox that isolates document-grounded reasoning while preserving core difficulties of deep search: multi-step synthesis, denoising, and evidence-based conclusion making. DeR2 decouples evidence access from reasoning via four regimes--Instruction-only, Concepts (gold concepts without documents), Related-only (only relevant documents), and Full-set (relevant documents plus topically related distractors)--yielding interpretable regime gaps that operationalize retrieval loss vs. reasoning loss and enable fine-grained error attribution. To prevent parametric leakage, we apply a two-phase validation that requires parametric failure without evidence while ensuring oracle-concept solvability. To ensure reproducibility, each instance provides a frozen document library (drawn from 2023-2025 theoretical papers) with expert-annotated concepts and validated rationales. Experiments across a diverse set of state-of-the-art foundation models reveal substantial variation and significant headroom: some models exhibit mode-switch fragility, performing worse with the Full-set than with Instruction-only, while others show structural concept misuse, correctly naming concepts but failing to execute them as procedures.",
    "authors": [
      "Shuangshuang Ying",
      "Zheyu Wang",
      "Yunjian Peng",
      "Jin Chen",
      "Yuhao Wu",
      "Hongbin Lin",
      "Dingyu He",
      "Siyi Liu",
      "Gengchen Yu",
      "YinZhu Piao",
      "Yuchen Wu",
      "Xin Gui",
      "Zhongyuan Peng",
      "Xin Li",
      "Xeron Du",
      "Libo Qin",
      "YiXin Cao",
      "Ge Zhang"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21937v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21937v1",
    "fetched_at": "2026-01-30T08:44:35.038408",
    "chinese_title": "融合检索的推理沙盒：解耦检索与推理能力的基准测试",
    "chinese_summary": "针对现有基准无法清晰评估大模型对新科学信息的推理能力（推理与检索混淆、参数记忆污染等问题），论文提出名为DeR2的受控深度研究沙盒基准，通过四种机制解耦证据访问与推理，采用两阶段验证防参数泄漏并提供冻结文档库保证可复现；实验揭示了模型的模式切换脆弱性等问题及显著提升空间。",
    "tags": [
      "LLM",
      "NLP",
      "Benchmark"
    ],
    "key_contributions": [
      "提出DeR2受控深度研究沙盒基准，通过Instruction-only等四种机制解耦证据访问与推理，解决现有基准中推理与检索混淆、信号受参数记忆污染等问题，支持细粒度错误归因",
      "设计两阶段验证流程防参数泄漏（无证据时参数失败且有黄金概念可解），提供2023-2025理论论文组成的冻结文档库（含专家标注概念与验证 rationale）保证可复现"
    ],
    "processed_at": "2026-01-30T09:02:10.784765"
  },
  {
    "id": "2601.21916v1",
    "title": "JADE: Bridging the Strategic-Operational Gap in Dynamic Agentic RAG",
    "abstract": "The evolution of Retrieval-Augmented Generation (RAG) has shifted from static retrieval pipelines to dynamic, agentic workflows where a central planner orchestrates multi-turn reasoning. However, existing paradigms face a critical dichotomy: they either optimize modules jointly within rigid, fixed-graph architectures, or empower dynamic planning while treating executors as frozen, black-box tools. We identify that this \\textit{decoupled optimization} creates a ``strategic-operational mismatch,'' where sophisticated planning strategies fail to materialize due to unadapted local executors, often leading to negative performance gains despite increased system complexity. In this paper, we propose \\textbf{JADE} (\\textbf{J}oint \\textbf{A}gentic \\textbf{D}ynamic \\textbf{E}xecution), a unified framework for the joint optimization of planning and execution within dynamic, multi-turn workflows. By modeling the system as a cooperative multi-agent team unified under a single shared backbone, JADE enables end-to-end learning driven by outcome-based rewards. This approach facilitates \\textit{co-adaptation}: the planner learns to operate within the capability boundaries of the executors, while the executors evolve to align with high-level strategic intent. Empirical results demonstrate that JADE transforms disjoint modules into a synergistic system, yielding remarkable performance improvements via joint optimization and enabling a flexible balance between efficiency and effectiveness through dynamic workflow orchestration.",
    "authors": [
      "Yiqun Chen",
      "Erhan Zhang",
      "Tianyi Hu",
      "Shijie Wang",
      "Zixuan Yang",
      "Meizhi Zhong",
      "Xiaochi Wei",
      "Yan Gao",
      "Yi Wu",
      "Yao Hu",
      "Jiaxin Mao"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21916v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21916v1",
    "fetched_at": "2026-01-30T08:44:35.038443",
    "chinese_title": "JADE：弥合动态智能检索增强生成中的战略-运营鸿沟",
    "chinese_summary": "现有动态智能检索增强生成（RAG）范式因规划与执行解耦优化存在“战略-运营不匹配”问题，常导致复杂系统性能负增益；论文提出JADE框架，将系统建模为共享骨干的协作多智能体团队，实现规划与执行的联合优化及端到端学习，促进协同适应，显著提升性能并平衡效率与效果。",
    "tags": [
      "LLM",
      "NLP",
      "Reinforcement Learning",
      "Financial Agent"
    ],
    "key_contributions": [
      "识别动态智能RAG中规划与执行解耦优化导致的“战略-运营不匹配”问题及性能负增益后果",
      "提出JADE统一框架，通过共享骨干的协作多智能体建模实现规划与执行联合优化及端到端学习，实现协同适应并提升系统性能与效率平衡"
    ],
    "processed_at": "2026-01-30T09:02:32.525357"
  },
  {
    "id": "2601.21909v1",
    "title": "From Meta-Thought to Execution: Cognitively Aligned Post-Training for Generalizable and Reliable LLM Reasoning",
    "abstract": "Current LLM post-training methods optimize complete reasoning trajectories through Supervised Fine-Tuning (SFT) followed by outcome-based Reinforcement Learning (RL). While effective, a closer examination reveals a fundamental gap: this approach does not align with how humans actually solve problems. Human cognition naturally decomposes problem-solving into two distinct stages: first acquiring abstract strategies (i.e., meta-knowledge) that generalize across problems, then adapting them to specific instances. In contrast, by treating complete trajectories as basic units, current methods are inherently problem-centric, entangling abstract strategies with problem-specific execution. To address this misalignment, we propose a cognitively-inspired framework that explicitly mirrors the two-stage human cognitive process. Specifically, Chain-of-Meta-Thought (CoMT) focuses supervised learning on abstract reasoning patterns without specific executions, enabling acquisition of generalizable strategies. Confidence-Calibrated Reinforcement Learning (CCRL) then optimizes task adaptation via confidence-aware rewards on intermediate steps, preventing overconfident errors from cascading and improving execution reliability. Experiments across four models and eight benchmarks show 2.19\\% and 4.63\\% improvements in-distribution and out-of-distribution respectively over standard methods, while reducing training time by 65-70% and token consumption by 50%, demonstrating that aligning post-training with human cognitive principles yields not only superior generalization but also enhanced training efficiency.",
    "authors": [
      "Shaojie Wang",
      "Liang Zhang"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21909v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21909v1",
    "fetched_at": "2026-01-30T08:44:35.038463",
    "chinese_title": "从元思维到执行：面向可泛化与可靠LLM推理的认知对齐后训练",
    "chinese_summary": "该论文指出当前LLM后训练（SFT+基于结果的RL）未对齐人类分抽象策略与具体执行的认知过程，提出认知启发框架：用Chain-of-Meta-Thought（CoMT）学习抽象推理模式以获可泛化策略，用Confidence-Calibrated RL（CCRL）优化任务适配提升执行可靠性；实验显示其分布内/外性能分别提升2.19%/4.63%，还大幅减少训练时间（65-70%）与token消耗（50%）。",
    "tags": [
      "LLM",
      "Reinforcement Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出认知对齐的LLM后训练框架，显式模拟人类分抽象策略（元知识）与具体执行的问题解决过程，弥补现有方法问题-centric的缺陷",
      "设计CoMT（抽象推理模式监督学习）和CCRL（置信校准强化学习）核心方法，实验证明其在泛化性、可靠性及训练效率上的优势"
    ],
    "processed_at": "2026-01-30T09:02:47.967373"
  },
  {
    "id": "2601.21902v1",
    "title": "Hardware-Triggered Backdoors",
    "abstract": "Machine learning models are routinely deployed on a wide range of computing hardware. Although such hardware is typically expected to produce identical results, differences in its design can lead to small numerical variations during inference. In this work, we show that these variations can be exploited to create backdoors in machine learning models. The core idea is to shape the model's decision function such that it yields different predictions for the same input when executed on different hardware. This effect is achieved by locally moving the decision boundary close to a target input and then refining numerical deviations to flip the prediction on selected hardware. We empirically demonstrate that these hardware-triggered backdoors can be created reliably across common GPU accelerators. Our findings reveal a novel attack vector affecting the use of third-party models, and we investigate different defenses to counter this threat.",
    "authors": [
      "Jonas Möller",
      "Erik Imgrund",
      "Thorsten Eisenhofer",
      "Konrad Rieck"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21902v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21902v1",
    "fetched_at": "2026-01-30T08:44:35.038486",
    "chinese_title": "硬件触发的后门",
    "chinese_summary": "本文揭示了利用机器学习模型在不同硬件推理时的数值差异创建后门的新攻击向量，通过调整决策边界并细化数值偏差使同一输入在不同硬件上产生不同预测，在常见GPU上验证了该攻击的可靠性并探讨防御方法。",
    "tags": [
      "Deep Learning",
      "Anomaly",
      "Risk Management"
    ],
    "key_contributions": [
      "发现硬件推理数值差异可被利用创建ML模型后门的新攻击向量",
      "提出实现硬件触发后门的方法并验证其在常见GPU上的可靠性，同时探讨防御措施"
    ],
    "processed_at": "2026-01-30T09:03:07.119709"
  },
  {
    "id": "2601.21841v1",
    "title": "Embodied Task Planning via Graph-Informed Action Generation with Large Lanaguage Model",
    "abstract": "While Large Language Models (LLMs) have demonstrated strong zero-shot reasoning capabilities, their deployment as embodied agents still faces fundamental challenges in long-horizon planning. Unlike open-ended text generation, embodied agents must decompose high-level intent into actionable sub-goals while strictly adhering to the logic of a dynamic, observed environment. Standard LLM planners frequently fail to maintain strategy coherence over extended horizons due to context window limitation or hallucinate transitions that violate constraints. We propose GiG, a novel planning framework that structures embodied agents' memory using a Graph-in-Graph architecture. Our approach employs a Graph Neural Network (GNN) to encode environmental states into embeddings, organizing these embeddings into action-connected execution trace graphs within an experience memory bank. By clustering these graph embeddings, the framework enables retrieval of structure-aware priors, allowing agents to ground current decisions in relevant past structural patterns. Furthermore, we introduce a novel bounded lookahead module that leverages symbolic transition logic to enhance the agents' planning capabilities through the grounded action projection. We evaluate our framework on three embodied planning benchmarks-Robotouille Synchronous, Robotouille Asynchronous, and ALFWorld. Our method outperforms state-of-the-art baselines, achieving Pass@1 performance gains of up to 22% on Robotouille Synchronous, 37% on Asynchronous, and 15% on ALFWorld with comparable or lower computational cost.",
    "authors": [
      "Xiang Li",
      "Ning Yan",
      "Masood Mortazavi"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21841v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21841v1",
    "fetched_at": "2026-01-30T08:44:35.038506",
    "chinese_title": "基于图感知动作生成与大语言模型的具身任务规划",
    "chinese_summary": "针对大语言模型（LLM）作为具身智能体面临的长horizon规划挑战（上下文限制、环境约束幻觉等），提出GiG框架：采用Graph-in-Graph架构，通过图神经网络（GNN）编码环境状态并组织为动作连接的执行轨迹图，结合聚类检索结构感知先验；引入符号转移逻辑的有界前瞻模块增强规划能力。该方法在Robotouille同步/异步、ALFWorld三个基准上显著超越SOTA，Pass@1最高提升37%。",
    "tags": [
      "LLM",
      "Graph Neural Network",
      "Benchmark"
    ],
    "key_contributions": [
      "提出基于Graph-in-Graph架构的GiG框架，通过GNN编码环境状态并组织为执行轨迹图，结合聚类检索结构感知先验，缓解LLM具身规划的长horizon和约束幻觉问题",
      "引入符号转移逻辑驱动的有界前瞻模块，增强动作投影的规划能力，在三个具身规划基准上实现显著性能提升"
    ],
    "processed_at": "2026-01-30T09:03:32.292371"
  },
  {
    "id": "2601.21822v1",
    "title": "CORE:Toward Ubiquitous 6G Intelligence Through Collaborative Orchestration of Large Language Model Agents Over Hierarchical Edge",
    "abstract": "Rapid advancements in sixth-generation (6G) networks and large language models (LLMs) have paved the way for ubiquitous intelligence, wherein seamless connectivity and distributed artificial intelligence (AI) have revolutionized various aspects of our lives.However, realizing this vision faces significant challenges owing to the fragmented and heterogeneous computing resources across hierarchical networks, which are insufficient for individual LLM agents to perform complex reasoning tasks.To address this issue, we propose Collaborative Orchestration Role at Edge (CORE), an innovative framework that employs a collaborative learning system in which multiple LLMs, each assigned a distinct functional role, are distributed across mobile devices and tiered edge servers. The system integrates three optimization modules, encompassing real-time perception,dynamic role orchestration, and pipeline-parallel execution, to facilitate efficient and rapid collaboration among distributed agents. Furthermore, we introduce a novel role affinity scheduling algorithm for dynamically orchestrating LLM role assignments across the hierarchical edge infrastructure, intelligently matching computational demands with available dispersed resources.Finally, comprehensive case studies and performance evaluations across various 6G application scenarios demonstrated the efficacy of CORE, revealing significant enhancements in the system efficiency and task completion rates. Building on these promising outcomes, we further validated the practical applicability of CORE by deploying it on a real-world edge-computing platform,that exhibits robust performance in operational environments.",
    "authors": [
      "Zitong Yu",
      "Boquan Sun",
      "Yang Li",
      "Zheyan Qu",
      "Xing Zhang"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21822v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21822v1",
    "fetched_at": "2026-01-30T08:44:35.038530",
    "chinese_title": "CORE：通过分层边缘上大语言模型代理的协作编排实现无处不在的6G智能",
    "chinese_summary": "论文针对6G网络下分层异构计算资源难以支撑单LLM代理完成复杂推理的问题，提出CORE框架，通过多LLM代理（各有功能角色）分布在移动设备和分层边缘服务器，整合实时感知、动态角色编排、流水线并行执行三个优化模块，并引入角色亲和调度算法动态匹配计算需求与资源，经案例验证提升了系统效率和任务完成率。",
    "tags": [
      "LLM",
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出CORE框架，通过多角色LLM代理分布式部署在分层边缘并整合三优化模块实现高效协作",
      "引入角色亲和调度算法动态匹配计算需求与边缘资源，提升系统效率和任务完成率"
    ],
    "processed_at": "2026-01-30T09:03:43.419504"
  },
  {
    "id": "2601.21797v1",
    "title": "Enhancing Conversational Agents via Task-Oriented Adversarial Memory Adaptation",
    "abstract": "Conversational agents struggle to handle long conversations due to context window limitations. Therefore, memory systems are developed to leverage essential historical information. Existing memory systems typically follow a pipeline of offline memory construction and update, and online retrieval. Despite the flexible online phase, the offline phase remains fixed and task-independent. In this phase, memory construction operates under a predefined workflow and fails to emphasize task relevant information. Meanwhile, memory updates are guided by generic metrics rather than task specific supervision. This leads to a misalignment between offline memory preparation and task requirements, which undermines downstream task performance. To this end, we propose an Adversarial Memory Adaptation mechanism (AMA) that aligns memory construction and update with task objectives by simulating task execution. Specifically, first, a challenger agent generates question answer pairs based on the original dialogues. The constructed memory is then used to answer these questions, simulating downstream inference. Subsequently, an evaluator agent assesses the responses and performs error analysis. Finally, an adapter agent analyzes the error cases and performs dual level updates on both the construction strategy and the content. Through this process, the memory system receives task aware supervision signals in advance during the offline phase, enhancing its adaptability to downstream tasks. AMA can be integrated into various existing memory systems, and extensive experiments on long dialogue benchmark LoCoMo demonstrate its effectiveness.",
    "authors": [
      "Yimin Deng",
      "Yuqing Fu",
      "Derong Xu",
      "Yejing Wang",
      "Wei Ni",
      "Jingtong Gao",
      "Xiaopeng Li",
      "Chengxu Liu",
      "Xiao Han",
      "Guoshuai Zhao",
      "Xiangyu Zhao",
      "Li Zhu",
      "Xueming Qian"
    ],
    "published": "2026-01-29",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.21797v1",
    "arxiv_url": "https://arxiv.org/abs/2601.21797v1",
    "fetched_at": "2026-01-30T08:44:35.038568",
    "chinese_title": "通过面向任务的对抗性记忆适配增强对话代理",
    "chinese_summary": "现有对话代理记忆系统的离线阶段固定且任务无关，导致离线准备与任务需求错位；本文提出对抗性记忆适配（AMA）机制，通过模拟任务执行（挑战者生成问答对、评估者反馈、适配器双层面更新记忆），使记忆系统在离线阶段获得任务感知监督，提升下游任务适应性。",
    "tags": [
      "LLM",
      "NLP",
      "Financial Agent"
    ],
    "key_contributions": [
      "揭示现有对话代理记忆系统离线阶段与任务需求错位的关键问题",
      "提出面向任务的对抗性记忆适配（AMA）机制，通过模拟任务执行实现记忆构建与更新的任务感知优化，增强对话代理对下游任务的适应性"
    ],
    "processed_at": "2026-01-30T09:03:59.928401"
  }
]