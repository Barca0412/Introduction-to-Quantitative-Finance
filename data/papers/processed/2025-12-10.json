[
  {
    "id": "2512.08890v1",
    "title": "Modelling and valuation of catastrophe bonds across multiple regions",
    "abstract": "The insurance-linked securities (ILS) market, as a form of alternative risk transfer, has been at the forefront of innovative risk-transfer solutions. The catastrophe bond (CAT bond) market now represents almost half of the entire ILS market and is growing steadily. Since CAT bonds are often tied to risks in different regions, we follow this idea by constructing different pricing models that incorporate various scenarios of dependence between catastrophe losses in different areas. Namely, we consider independent, proportional, and arbitrary two-dimensional distribution cases. We also derive a normal approximation of the prices. Finally, to include the market price of risk, we apply Wang's transform. We illustrate the differences between the scenarios and the performance of the approximation on the Property Claim Services data.",
    "authors": [
      "Krzysztof Burnecki",
      "Marek Teuerle",
      "Martyna Zdeb"
    ],
    "published": "2025-12-09",
    "categories": [
      "q-fin.PR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08890v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08890v1",
    "fetched_at": "2025-12-10T08:33:48.918164",
    "chinese_title": "多区域巨灾债券的建模与估值",
    "chinese_summary": "本文针对多区域巨灾债券，构建了包含不同区域巨灾损失依赖情景（独立、比例、任意二维分布）的定价模型，推导了价格的正态近似并通过Wang变换纳入风险市场价格，结合Property Claim Services数据验证了模型差异与近似性能。",
    "tags": [
      "Asset Pricing",
      "Risk Management"
    ],
    "key_contributions": [
      "构建了考虑多区域巨灾损失不同依赖情景的巨灾债券定价模型",
      "推导价格正态近似并通过Wang变换纳入风险市场价格，结合实际数据验证模型"
    ],
    "processed_at": "2025-12-10T08:36:58.410917"
  },
  {
    "id": "2512.08851v1",
    "title": "A New Application of Hoeffding's Inequality Can Give Traders Early Warning of Financial Regime Change",
    "abstract": "Hoeffding's Inequality provides the maximum probability that a series of n draws from a bounded random variable differ from the variable's true expectation u by more than given tolerance t. The random variable is typically the error rate of a classifier in machine learning applications. Here, a trading strategy is premised on the assumption of an underlying distribution of causal factors, in other words, a market regime, and the random variable is the performance of that trading strategy. A larger deviation of observed performance from the trader's expectation u can be characterized as a lower probability that the financial regime supporting that strategy remains in force, and a higher probability of financial regime change. The changing Hoeffding probabilities can be used as an early warning indicator of this change.",
    "authors": [
      "Daniel Egger",
      "Jacob Vestal"
    ],
    "published": "2025-12-09",
    "categories": [
      "q-fin.RM",
      "math.PR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08851v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08851v1",
    "fetched_at": "2025-12-10T08:33:48.918204",
    "chinese_title": "霍夫丁不等式的新应用可向交易者提供金融机制转换的早期预警",
    "chinese_summary": "该论文将霍夫丁不等式应用于金融领域，以交易策略表现为随机变量，通过观察其与预期的偏离程度判断支撑策略的市场机制是否持续；偏离较大时，变化的霍夫丁概率可作为机制转换的早期预警指标。",
    "tags": [
      "Anomaly",
      "Risk Management",
      "Algorithmic Trading"
    ],
    "key_contributions": [
      "提出基于霍夫丁概率变化的金融机制转换早期预警方法，为交易者提供风险提示"
    ],
    "processed_at": "2025-12-10T08:37:17.864513"
  },
  {
    "id": "2512.08348v1",
    "title": "On the existence of personal equilibria",
    "abstract": "We consider an investor who, while maximizing his/her expected utility, also compares the outcome to a reference entity. We recall the notion of personal equilibrium and show that, in a multistep, generically incomplete financial market model such an equilibrium indeed exists, under appropriate technical assumptions.",
    "authors": [
      "Laurence Carassus",
      "Miklós Rásonyi"
    ],
    "published": "2025-12-09",
    "categories": [
      "q-fin.PM",
      "math.PR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08348v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08348v1",
    "fetched_at": "2025-12-10T08:33:48.918230",
    "chinese_title": "论个人均衡的存在性",
    "chinese_summary": "本文研究了同时最大化期望效用并与参考实体比较的投资者的个人均衡问题；在多步、一般不完全金融市场模型下，通过适当技术假设证明了该均衡的存在性。",
    "tags": [
      "Behavioral Finance",
      "Portfolio Optimization",
      "Benchmark"
    ],
    "key_contributions": [
      "明确考虑了投资者在最大化期望效用时与参考实体比较的行为特征",
      "证明了多步、一般不完全金融市场模型中个人均衡的存在性（满足适当技术假设）"
    ],
    "processed_at": "2025-12-10T08:37:34.109779"
  },
  {
    "id": "2512.08270v1",
    "title": "Reasoning Models Ace the CFA Exams",
    "abstract": "Previous research has reported that large language models (LLMs) demonstrate poor performance on the Chartered Financial Analyst (CFA) exams. However, recent reasoning models have achieved strong results on graduate-level academic and professional examinations across various disciplines. In this paper, we evaluate state-of-the-art reasoning models on a set of mock CFA exams consisting of 980 questions across three Level I exams, two Level II exams, and three Level III exams. Using the same pass/fail criteria from prior studies, we find that most models clear all three levels. The models that pass, ordered by overall performance, are Gemini 3.0 Pro, Gemini 2.5 Pro, GPT-5, Grok 4, Claude Opus 4.1, and DeepSeek-V3.1. Specifically, Gemini 3.0 Pro achieves a record score of 97.6% on Level I. Performance is also strong on Level II, led by GPT-5 at 94.3%. On Level III, Gemini 2.5 Pro attains the highest score with 86.4% on multiple-choice questions while Gemini 3.0 Pro achieves 92.0% on constructed-response questions.",
    "authors": [
      "Jaisal Patel",
      "Yunzhe Chen",
      "Kaiwen He",
      "Keyi Wang",
      "David Li",
      "Kairong Xiao",
      "Xiao-Yang Liu"
    ],
    "published": "2025-12-09",
    "categories": [
      "cs.AI",
      "cs.CL",
      "q-fin.GN"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08270v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08270v1",
    "fetched_at": "2025-12-10T08:33:48.918261",
    "chinese_title": "推理模型在CFA考试中表现优异",
    "chinese_summary": "本文针对此前大语言模型（LLMs）在CFA考试表现不佳的现状，评估了多款最先进推理模型在包含980道题的模拟CFA三级考试中的表现；结果显示多数模型通过所有三级考试，其中Gemini 3.0 Pro等模型在各等级取得高分（如Level I达97.6%）。",
    "tags": [
      "LLM",
      "Transformer",
      "Benchmark",
      "Financial Agent"
    ],
    "key_contributions": [
      "证实多款最先进推理模型可通过所有三级CFA考试，更新LLMs在金融专业考试中的表现认知",
      "系统评估多款模型在CFA各等级的表现，明确各等级最优模型及具体高分数据"
    ],
    "processed_at": "2025-12-10T08:38:00.852836"
  },
  {
    "id": "2512.08000v1",
    "title": "Analysis of Contagion in China's Stock Market: A Hawkes Process Perspective",
    "abstract": "This study explores contagion in the Chinese stock market using Hawkes processes to analyze autocorrelation and cross-correlation in multivariate time series data. We examine whether market indices exhibit trending behavior and whether sector indices influence one another. By fitting self-exciting and inhibitory Hawkes processes to daily returns of indices like the Shanghai Composite, Shenzhen Component, and ChiNext, as well as sector indices (CSI Consumer, Healthcare, and Financial), we identify long-term dependencies and trending patterns, including upward, downward, and oversold rebound trends. Results show that during high trading activity, sector indices tend to sustain their trends, while low activity periods exhibit strong sector rotation. This research models stock price movements using spatiotemporal Hawkes processes, leveraging conditional intensity functions to explain sector rotation, advancing the understanding of financial contagion.",
    "authors": [
      "Junwei Yang"
    ],
    "published": "2025-12-08",
    "categories": [
      "q-fin.ST",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08000v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08000v1",
    "fetched_at": "2025-12-10T08:33:48.918279",
    "chinese_title": "中国股市传染效应分析：基于Hawkes过程的视角",
    "chinese_summary": "本研究采用Hawkes过程分析中国股市多元时间序列的自相关与交叉相关，拟合自激发及抑制Hawkes过程于沪深综指、创业板指及消费、医疗、金融等行业指数日收益率，识别长期依赖与多类趋势模式；发现高交易活跃度时行业指数趋势持续，低活跃度时行业轮动显著，通过时空Hawkes过程结合条件强度函数解释行业轮动，推进对金融传染的理解。",
    "tags": [
      "Time Series",
      "Market Microstructure",
      "Behavioral Finance"
    ],
    "key_contributions": [
      "采用Hawkes过程（含自激发/抑制类型）分析中国股市多元指数收益率，识别长期依赖与上升、下降、超卖反弹等趋势模式",
      "揭示交易活跃度对行业趋势持续性及轮动的影响，结合时空Hawkes过程与条件强度函数解释行业轮动，深化金融传染认知"
    ],
    "processed_at": "2025-12-10T08:38:29.640386"
  },
  {
    "id": "2512.08885v1",
    "title": "Explainable Anomaly Detection for Industrial IoT Data Streams",
    "abstract": "Industrial maintenance is being transformed by the Internet of Things and edge computing, generating continuous data streams that demand real-time, adaptive decision-making under limited computational resources. While data stream mining (DSM) addresses this challenge, most methods assume fully supervised settings, yet in practice, ground-truth labels are often delayed or unavailable. This paper presents a collaborative DSM framework that integrates unsupervised anomaly detection with interactive, human-in-the-loop learning to support maintenance decisions. We employ an online Isolation Forest and enhance interpretability using incremental Partial Dependence Plots and a feature importance score, derived from deviations of Individual Conditional Expectation curves from a fading average, enabling users to dynamically reassess feature relevance and adjust anomaly thresholds. We describe the real-time implementation and provide initial results for fault detection in a Jacquard loom unit. Ongoing work targets continuous monitoring to predict and explain imminent bearing failures.",
    "authors": [
      "Ana Rita Paupério",
      "Diogo Risca",
      "Afonso Lourenço",
      "Goreti Marreiros",
      "Ricardo Martins"
    ],
    "published": "2025-12-09",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08885v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08885v1",
    "fetched_at": "2025-12-10T08:34:02.004331",
    "chinese_title": "工业物联网数据流的可解释异常检测",
    "chinese_summary": "针对工业物联网数据流实时异常检测中标签缺失/延迟的问题，本文提出集成无监督异常检测与人机交互学习的协作框架；采用在线隔离森林算法，通过增量部分依赖图和基于个体条件期望曲线偏离衰减平均的特征重要性得分增强可解释性，支持用户动态调整异常阈值；并验证了提花织机单元故障检测的初步效果。",
    "tags": [
      "Anomaly",
      "Time Series"
    ],
    "key_contributions": [
      "构建无监督异常检测与人机交互学习结合的协作框架，适配工业物联网数据流的实时、低资源决策需求",
      "提出增量可解释方法（增量部分依赖图+特征重要性得分），提升在线隔离森林的可解释性，支持用户动态调整异常阈值"
    ],
    "processed_at": "2025-12-10T08:38:54.090762"
  },
  {
    "id": "2512.08657v1",
    "title": "Reusability in MLOps: Leveraging Ports and Adapters to Build a Microservices Architecture for the Maritime Domain",
    "abstract": "ML-Enabled Systems (MLES) are inherently complex since they require multiple components to achieve their business goal. This experience report showcases the software architecture reusability techniques applied while building Ocean Guard, an MLES for anomaly detection in the maritime domain. In particular, it highlights the challenges and lessons learned to reuse the Ports and Adapters pattern to support building multiple microservices from a single codebase. This experience report hopes to inspire software engineers, machine learning engineers, and data scientists to apply the Hexagonal Architecture pattern to build their MLES.",
    "authors": [
      "Renato Cordeiro Ferreira",
      "Aditya Dhinavahi",
      "Rowanne Trapmann",
      "Willem-Jan van den Heuvel"
    ],
    "published": "2025-12-09",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08657v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08657v1",
    "fetched_at": "2025-12-10T08:34:02.004365",
    "chinese_title": "MLOps中的可复用性：利用端口与适配器构建海事领域微服务架构",
    "chinese_summary": "本文为经验报告，展示海事异常检测ML系统Ocean Guard中应用端口适配器模式（六边形架构），实现单代码库复用构建多微服务的技术与经验，旨在启发相关工程师将该模式用于ML系统开发。",
    "tags": [
      "Anomaly",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出在海事异常检测ML系统中应用端口适配器模式，实现单代码库复用构建多微服务的技术方案",
      "总结该模式应用中的挑战与经验，为ML系统架构设计提供实践启发"
    ],
    "processed_at": "2025-12-10T08:39:22.601599"
  },
  {
    "id": "2512.08277v1",
    "title": "FedLAD: A Modular and Adaptive Testbed for Federated Log Anomaly Detection",
    "abstract": "Log-based anomaly detection (LAD) is critical for ensuring the reliability of large-scale distributed systems. However, most existing LAD approaches assume centralized training, which is often impractical due to privacy constraints and the decentralized nature of system logs. While federated learning (FL) offers a promising alternative, there is a lack of dedicated testbeds tailored to the needs of LAD in federated settings. To address this, we present FedLAD, a unified platform for training and evaluating LAD models under FL constraints. FedLAD supports plug-and-play integration of diverse LAD models, benchmark datasets, and aggregation strategies, while offering runtime support for validation logging (self-monitoring), parameter tuning (self-configuration), and adaptive strategy control (self-adaptation). By enabling reproducible and scalable experimentation, FedLAD bridges the gap between FL frameworks and LAD requirements, providing a solid foundation for future research. Project code is publicly available at: https://github.com/AA-cityu/FedLAD.",
    "authors": [
      "Yihan Liao",
      "Jacky Keung",
      "Zhenyu Mao",
      "Jingyu Zhang",
      "Jialong Li"
    ],
    "published": "2025-12-09",
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08277v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08277v1",
    "fetched_at": "2025-12-10T08:34:02.004391",
    "chinese_title": "FedLAD：联邦日志异常检测的模块化自适应测试平台",
    "chinese_summary": "现有日志异常检测（LAD）多采用集中式训练，因隐私约束和分布式日志特性难以落地，且缺乏联邦学习（FL）场景下的专用测试床；本文提出FedLAD统一平台，支持即插即用集成多样LAD模型、基准数据集与聚合策略，还具备运行时自监控、自配置及自适应策略控制能力，桥接FL框架与LAD需求，为相关研究提供可复现可扩展的实验基础。",
    "tags": [
      "Anomaly",
      "Benchmark",
      "Time Series"
    ],
    "key_contributions": [
      "填补联邦日志异常检测（LAD）专用测试床的空白，提出统一平台FedLAD",
      "支持即插即用集成多样LAD模型、基准数据集与聚合策略，且具备运行时自监控、自配置及自适应控制能力，桥接联邦学习框架与LAD需求"
    ],
    "processed_at": "2025-12-10T08:39:50.917472"
  },
  {
    "id": "2512.08169v1",
    "title": "Information-Dense Reasoning for Efficient and Auditable Security Alert Triage",
    "abstract": "Security Operations Centers face massive, heterogeneous alert streams under minute-level service windows, creating the Alert Triage Latency Paradox: verbose reasoning chains ensure accuracy and compliance but incur prohibitive latency and token costs, while minimal chains sacrifice transparency and auditability. Existing solutions fail: signature systems are brittle, anomaly methods lack actionability, and fully cloud-hosted LLMs raise latency, cost, and privacy concerns. We propose AIDR, a hybrid cloud-edge framework that addresses this trade-off through constrained information-density optimization. The core innovation is gradient-based compression of reasoning chains to retain only decision-critical steps--minimal evidence sufficient to justify predictions while respecting token and latency budgets. We demonstrate that this approach preserves decision-relevant information while minimizing complexity. We construct compact datasets by distilling alerts into 3-5 high-information bullets (68% token reduction), train domain-specialized experts via LoRA, and deploy a cloud-edge architecture: a cloud LLM routes alerts to on-premises experts generating SOAR-ready JSON. Experiments demonstrate AIDR achieves higher accuracy and 40.6% latency reduction versus Chain-of-Thought, with robustness to data corruption and out-of-distribution generalization, enabling auditable and efficient SOC triage with full data residency compliance.",
    "authors": [
      "Guangze Zhao",
      "Yongzheng Zhang",
      "Changbo Tian",
      "Dan Xie",
      "Hongri Liu",
      "Bailing Wang"
    ],
    "published": "2025-12-09",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08169v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08169v1",
    "fetched_at": "2025-12-10T08:34:02.004417",
    "chinese_title": "信息密集推理用于高效可审计的安全警报分类",
    "chinese_summary": "针对安全运营中心（SOC）警报分类中延迟与合规的矛盾，论文提出混合云边框架AIDR，通过基于梯度的推理链压缩保留决策关键步骤，结合LoRA训练领域专家并采用云边架构，实现高效可审计且数据合规的警报分类，实验显示其准确率高于Chain-of-Thought且延迟降低40.6%。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Anomaly",
      "Risk Management"
    ],
    "key_contributions": [
      "提出混合云边框架AIDR，通过信息密度优化的推理链压缩，平衡安全警报分类的效率、准确率与审计合规性",
      "构建紧凑警报数据集并结合LoRA训练领域专家，实验验证AIDR在性能、鲁棒性与数据 residency合规上优于现有方法"
    ],
    "processed_at": "2025-12-10T08:40:21.188407"
  },
  {
    "id": "2512.08920v1",
    "title": "OSMO: Open-Source Tactile Glove for Human-to-Robot Skill Transfer",
    "abstract": "Human video demonstrations provide abundant training data for learning robot policies, but video alone cannot capture the rich contact signals critical for mastering manipulation. We introduce OSMO, an open-source wearable tactile glove designed for human-to-robot skill transfer. The glove features 12 three-axis tactile sensors across the fingertips and palm and is designed to be compatible with state-of-the-art hand-tracking methods for in-the-wild data collection. We demonstrate that a robot policy trained exclusively on human demonstrations collected with OSMO, without any real robot data, is capable of executing a challenging contact-rich manipulation task. By equipping both the human and the robot with the same glove, OSMO minimizes the visual and tactile embodiment gap, enabling the transfer of continuous shear and normal force feedback while avoiding the need for image inpainting or other vision-based force inference. On a real-world wiping task requiring sustained contact pressure, our tactile-aware policy achieves a 72% success rate, outperforming vision-only baselines by eliminating contact-related failure modes. We release complete hardware designs, firmware, and assembly instructions to support community adoption.",
    "authors": [
      "Jessica Yin",
      "Haozhi Qi",
      "Youngsun Wi",
      "Sayantan Kundu",
      "Mike Lambeta",
      "William Yang",
      "Changhao Wang",
      "Tingfan Wu",
      "Jitendra Malik",
      "Tess Hellebrekers"
    ],
    "published": "2025-12-09",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08920v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08920v1",
    "fetched_at": "2025-12-10T08:34:31.612639",
    "chinese_title": "OSMO：用于人机技能迁移的开源触觉手套",
    "chinese_summary": "论文提出开源触觉手套OSMO，配备12个三轴触觉传感器，兼容手部追踪方法以采集人类操作的接触信号；通过人类与机器人佩戴同款手套最小化感知差距，使机器人策略无需真实数据即可完成复杂接触任务，在擦拭任务中成功率72%优于视觉基线，且开源硬件设计等资源。",
    "tags": [
      "Deep Learning",
      "Reinforcement Learning"
    ],
    "key_contributions": [
      "提出开源触觉手套OSMO，配备12个三轴触觉传感器，兼容手部追踪，支持野外数据采集",
      "证明仅用OSMO采集的人类演示可训练出能完成复杂接触任务的机器人策略，无需真实机器人数据，且在擦拭任务中优于视觉基线"
    ],
    "processed_at": "2025-12-10T08:40:48.685642"
  },
  {
    "id": "2512.08769v1",
    "title": "A Practical Guide for Designing, Developing, and Deploying Production-Grade Agentic AI Workflows",
    "abstract": "Agentic AI marks a major shift in how autonomous systems reason, plan, and execute multi-step tasks. Unlike traditional single model prompting, agentic workflows integrate multiple specialized agents with different Large Language Models(LLMs), tool-augmented capabilities, orchestration logic, and external system interactions to form dynamic pipelines capable of autonomous decision-making and action. As adoption accelerates across industry and research, organizations face a central challenge: how to design, engineer, and operate production-grade agentic AI workflows that are reliable, observable, maintainable, and aligned with safety and governance requirements. This paper provides a practical, end-to-end guide for designing, developing, and deploying production-quality agentic AI systems. We introduce a structured engineering lifecycle encompassing workflow decomposition, multi-agent design patterns, Model Context Protocol(MCP), and tool integration, deterministic orchestration, Responsible-AI considerations, and environment-aware deployment strategies. We then present nine core best practices for engineering production-grade agentic AI workflows, including tool-first design over MCP, pure-function invocation, single-tool and single-responsibility agents, externalized prompt management, Responsible-AI-aligned model-consortium design, clean separation between workflow logic and MCP servers, containerized deployment for scalable operations, and adherence to the Keep it Simple, Stupid (KISS) principle to maintain simplicity and robustness. To demonstrate these principles in practice, we present a comprehensive case study: a multimodal news-analysis and media-generation workflow. By combining architectural guidance, operational patterns, and practical implementation insights, this paper offers a foundational reference to build robust, extensible, and production-ready agentic AI workflows.",
    "authors": [
      "Eranga Bandara",
      "Ross Gore",
      "Peter Foytik",
      "Sachin Shetty",
      "Ravi Mukkamala",
      "Abdul Rahman",
      "Xueping Liang",
      "Safdar H. Bouk",
      "Amin Hass",
      "Sachini Rajapakse",
      "Ng Wee Keong",
      "Kasun De Zoysa",
      "Aruna Withanage",
      "Nilaan Loganathan"
    ],
    "published": "2025-12-09",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08769v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08769v1",
    "fetched_at": "2025-12-10T08:34:31.612700",
    "chinese_title": "生产级Agentic AI工作流设计、开发与部署的实用指南",
    "chinese_summary": "该论文针对生产级Agentic AI工作流的可靠性、可观测性等挑战，提出端到端实用指南，涵盖包含工作流分解、多agent设计模式、模型上下文协议（MCP）等的结构化工程生命周期，并总结工具优先设计等9项核心最佳实践，助力构建符合安全治理要求的系统。",
    "tags": [
      "LLM",
      "Financial Agent",
      "NLP"
    ],
    "key_contributions": [
      "提出生产级Agentic AI工作流的端到端实用指南，涵盖结构化工程生命周期（含工作流分解、多agent设计模式、MCP等）",
      "总结9项核心最佳实践（如工具优先设计、单工具单职责agent等），指导构建可靠、可观测且符合安全治理要求的生产级系统"
    ],
    "processed_at": "2025-12-10T08:41:24.604867"
  },
  {
    "id": "2512.08629v1",
    "title": "See-Control: A Multimodal Agent Framework for Smartphone Interaction with a Robotic Arm",
    "abstract": "Recent advances in Multimodal Large Language Models (MLLMs) have enabled their use as intelligent agents for smartphone operation. However, existing methods depend on the Android Debug Bridge (ADB) for data transmission and action execution, limiting their applicability to Android devices. In this work, we introduce the novel Embodied Smartphone Operation (ESO) task and present See-Control, a framework that enables smartphone operation via direct physical interaction with a low-DoF robotic arm, offering a platform-agnostic solution. See-Control comprises three key components: (1) an ESO benchmark with 155 tasks and corresponding evaluation metrics; (2) an MLLM-based embodied agent that generates robotic control commands without requiring ADB or system back-end access; and (3) a richly annotated dataset of operation episodes, offering valuable resources for future research. By bridging the gap between digital agents and the physical world, See-Control provides a concrete step toward enabling home robots to perform smartphone-dependent tasks in realistic environments.",
    "authors": [
      "Haoyu Zhao",
      "Weizhong Ding",
      "Yuhao Yang",
      "Zheng Tian",
      "Linyi Yang",
      "Kun Shao",
      "Jun Wang"
    ],
    "published": "2025-12-09",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08629v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08629v1",
    "fetched_at": "2025-12-10T08:34:31.612738",
    "chinese_title": "See-Control：一种用于智能手机与机械臂交互的多模态Agent框架",
    "chinese_summary": "现有智能手机操作智能Agent依赖Android调试桥（ADB），仅适用于安卓设备；本文提出具身智能手机操作（ESO）任务，构建See-Control框架，通过低自由度机械臂物理交互实现跨平台操作，包含ESO基准、基于多模态大模型的具身Agent及标注数据集，推动家庭机器人完成依赖智能手机的任务。",
    "tags": [
      "LLM",
      "Benchmark",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出具身智能手机操作（ESO）任务，并构建包含155个任务的ESO基准及评估指标",
      "提出See-Control框架，通过低自由度机械臂物理交互实现跨平台智能手机操作，无需ADB或系统后端访问，同时提供丰富标注的操作episode数据集"
    ],
    "processed_at": "2025-12-10T08:42:02.306842"
  },
  {
    "id": "2512.08463v1",
    "title": "Using reinforcement learning to probe the role of feedback in skill acquisition",
    "abstract": "Many high-performance human activities are executed with little or no external feedback: think of a figure skater landing a triple jump, a pitcher throwing a curveball for a strike, or a barista pouring latte art. To study the process of skill acquisition under fully controlled conditions, we bypass human subjects. Instead, we directly interface a generalist reinforcement learning agent with a spinning cylinder in a tabletop circulating water channel to maximize or minimize drag. This setup has several desirable properties. First, it is a physical system, with the rich interactions and complex dynamics that only the physical world has: the flow is highly chaotic and extremely difficult, if not impossible, to model or simulate accurately. Second, the objective -- drag minimization or maximization -- is easy to state and can be captured directly in the reward, yet good strategies are not obvious beforehand. Third, decades-old experimental studies provide recipes for simple, high-performance open-loop policies. Finally, the setup is inexpensive and far easier to reproduce than human studies. In our experiments we find that high-dimensional flow feedback lets the agent discover high-performance drag-control strategies with only minutes of real-world interaction. When we later replay the same action sequences without any feedback, we obtain almost identical performance. This shows that feedback, and in particular flow feedback, is not needed to execute the learned policy. Surprisingly, without flow feedback during training the agent fails to discover any well-performing policy in drag maximization, but still succeeds in drag minimization, albeit more slowly and less reliably. Our studies show that learning a high-performance skill can require richer information than executing it, and learning conditions can be kind or wicked depending solely on the goal, not on dynamics or policy complexity.",
    "authors": [
      "Antonio Terpin",
      "Raffaello D'Andrea"
    ],
    "published": "2025-12-09",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO",
      "eess.SY"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08463v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08463v1",
    "fetched_at": "2025-12-10T08:34:31.612759",
    "chinese_title": "利用强化学习探究反馈在技能习得中的作用",
    "chinese_summary": "该研究构建了强化学习智能体与旋转圆柱-循环水槽物理系统的交互实验平台，以探究反馈在技能习得中的作用；发现高维流反馈可使智能体快速学到高性能阻力控制策略，且执行该策略时无需反馈，揭示反馈仅在策略习得阶段起关键作用。",
    "tags": [
      "Reinforcement Learning"
    ],
    "key_contributions": [
      "构建了物理系统与强化学习智能体的交互实验平台，为反馈在技能习得中的作用研究提供可控场景",
      "揭示高维流反馈仅在策略习得阶段关键，执行已习得策略无需反馈"
    ],
    "processed_at": "2025-12-10T08:42:35.255174"
  },
  {
    "id": "2512.08341v1",
    "title": "Multi-Agent Deep Reinforcement Learning for Collaborative UAV Relay Networks under Jamming Atatcks",
    "abstract": "The deployment of Unmanned Aerial Vehicle (UAV) swarms as dynamic communication relays is critical for next-generation tactical networks. However, operating in contested environments requires solving a complex trade-off, including maximizing system throughput while ensuring collision avoidance and resilience against adversarial jamming. Existing heuristic-based approaches often struggle to find effective solutions due to the dynamic and multi-objective nature of this problem. This paper formulates this challenge as a cooperative Multi-Agent Reinforcement Learning (MARL) problem, solved using the Centralized Training with Decentralized Execution (CTDE) framework. Our approach employs a centralized critic that uses global state information to guide decentralized actors which operate using only local observations. Simulation results show that our proposed framework significantly outperforms heuristic baselines, increasing the total system throughput by approximately 50% while simultaneously achieving a near-zero collision rate. A key finding is that the agents develop an emergent anti-jamming strategy without explicit programming. They learn to intelligently position themselves to balance the trade-off between mitigating interference from jammers and maintaining effective communication links with ground users.",
    "authors": [
      "Thai Duong Nguyen",
      "Ngoc-Tan Nguyen",
      "Thanh-Dao Nguyen",
      "Nguyen Van Huynh",
      "Dinh-Hieu Tran",
      "Symeon Chatzinotas"
    ],
    "published": "2025-12-09",
    "categories": [
      "cs.NI",
      "cs.LG",
      "cs.MA"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08341v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08341v1",
    "fetched_at": "2025-12-10T08:34:31.612787",
    "chinese_title": "干扰攻击下协作无人机中继网络的多智能体深度强化学习",
    "chinese_summary": "论文将干扰攻击下无人机中继网络的吞吐量最大化、避碰及抗干扰问题建模为合作多智能体强化学习（MARL）问题，采用集中训练分散执行（CTDE）框架，通过全局状态的集中评论器指导仅用局部观测的分散演员；仿真显示该方法比启发式基线提升约50%系统吞吐量且碰撞率近零，智能体自主学习到无需显式编程的抗干扰策略。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出基于CTDE框架的MARL方法，解决干扰下无人机中继网络的多目标优化问题",
      "智能体自主学习抗干扰策略，显著提升吞吐量并实现近零碰撞率"
    ],
    "processed_at": "2025-12-10T08:43:03.033931"
  },
  {
    "id": "2512.08290v1",
    "title": "Systematization of Knowledge: Security and Safety in the Model Context Protocol Ecosystem",
    "abstract": "The Model Context Protocol (MCP) has emerged as the de facto standard for connecting Large Language Models (LLMs) to external data and tools, effectively functioning as the \"USB-C for Agentic AI.\" While this decoupling of context and execution solves critical interoperability challenges, it introduces a profound new threat landscape where the boundary between epistemic errors (hallucinations) and security breaches (unauthorized actions) dissolves. This Systematization of Knowledge (SoK) aims to provide a comprehensive taxonomy of risks in the MCP ecosystem, distinguishing between adversarial security threats (e.g., indirect prompt injection, tool poisoning) and epistemic safety hazards (e.g., alignment failures in distributed tool delegation). We analyze the structural vulnerabilities of MCP primitives, specifically Resources, Prompts, and Tools, and demonstrate how \"context\" can be weaponized to trigger unauthorized operations in multi-agent environments. Furthermore, we survey state-of-the-art defenses, ranging from cryptographic provenance (ETDI) to runtime intent verification, and conclude with a roadmap for securing the transition from conversational chatbots to autonomous agentic operating systems.",
    "authors": [
      "Shiva Gaire",
      "Srijan Gyawali",
      "Saroj Mishra",
      "Suman Niroula",
      "Dilip Thakur",
      "Umesh Yadav"
    ],
    "published": "2025-12-09",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08290v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08290v1",
    "fetched_at": "2025-12-10T08:34:31.612813",
    "chinese_title": "知识系统化：模型上下文协议生态系统中的安全与防护",
    "chinese_summary": "本文针对作为Agentic AI连接LLM与外部工具事实标准的模型上下文协议（MCP），指出其带来认知错误与安全 breach边界模糊的新威胁；构建MCP生态风险综合分类（区分对抗性安全威胁与认知安全隐患），分析核心原语的结构漏洞，调查现有防御方法并提出从对话聊天机器人到自主Agent操作系统的安全过渡路线图。",
    "tags": [
      "LLM",
      "Risk Management"
    ],
    "key_contributions": [
      "构建MCP生态系统风险的综合分类体系，明确对抗性安全威胁与认知安全隐患的边界",
      "分析MCP核心原语的结构漏洞，提出从对话聊天机器人到自主Agent操作系统的安全过渡路线图"
    ],
    "processed_at": "2025-12-10T08:43:27.964369"
  },
  {
    "id": "2512.08188v1",
    "title": "Embodied Tree of Thoughts: Deliberate Manipulation Planning with Embodied World Model",
    "abstract": "World models have emerged as a pivotal component in robot manipulation planning, enabling agents to predict future environmental states and reason about the consequences of actions before execution. While video-generation models are increasingly adopted, they often lack rigorous physical grounding, leading to hallucinations and a failure to maintain consistency in long-horizon physical constraints. To address these limitations, we propose Embodied Tree of Thoughts (EToT), a novel Real2Sim2Real planning framework that leverages a physics-based interactive digital twin as an embodied world model. EToT formulates manipulation planning as a tree search expanded through two synergistic mechanisms: (1) Priori Branching, which generates diverse candidate execution paths based on semantic and spatial analysis; and (2) Reflective Branching, which utilizes VLMs to diagnose execution failures within the simulator and iteratively refine the planning tree with corrective actions. By grounding high-level reasoning in a physics simulator, our framework ensures that generated plans adhere to rigid-body dynamics and collision constraints. We validate EToT on a suite of short- and long-horizon manipulation tasks, where it consistently outperforms baselines by effectively predicting physical dynamics and adapting to potential failures. Website at https://embodied-tree-of-thoughts.github.io .",
    "authors": [
      "Wenjiang Xu",
      "Cindy Wang",
      "Rui Fang",
      "Mingkang Zhang",
      "Lusong Li",
      "Jing Xu",
      "Jiayuan Gu",
      "Zecui Zeng",
      "Rui Chen"
    ],
    "published": "2025-12-09",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08188v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08188v1",
    "fetched_at": "2025-12-10T08:34:31.612847",
    "chinese_title": "具身思维树：基于具身世界模型的精细操作规划",
    "chinese_summary": "针对现有视频生成模型缺乏物理 grounding导致幻觉及物理约束一致性差的问题，本文提出具身思维树（EToT）框架，以基于物理的交互式数字孪生为具身世界模型，将操作规划建模为树搜索，通过先验分支（语义空间分析生成候选路径）和反射分支（VLM诊断模拟失败并迭代优化）扩展规划树，确保计划符合物理约束且在长短 horizon任务中优于基线。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Reinforcement Learning"
    ],
    "key_contributions": [
      "提出具身思维树（EToT）框架，采用物理交互式数字孪生弥补视频生成模型物理 grounding缺失的缺陷",
      "设计先验分支与反射分支的树搜索机制，确保规划符合物理动力学与碰撞约束并适应执行失败"
    ],
    "processed_at": "2025-12-10T08:43:58.504219"
  },
  {
    "id": "2512.08145v1",
    "title": "Chat with UAV -- Human-UAV Interaction Based on Large Language Models",
    "abstract": "The future of UAV interaction systems is evolving from engineer-driven to user-driven, aiming to replace traditional predefined Human-UAV Interaction designs. This shift focuses on enabling more personalized task planning and design, thereby achieving a higher quality of interaction experience and greater flexibility, which can be used in many fileds, such as agriculture, aerial photography, logistics, and environmental monitoring. However, due to the lack of a common language between users and the UAVs, such interactions are often difficult to be achieved. The developments of Large Language Models possess the ability to understand nature languages and Robots' (UAVs') behaviors, marking the possibility of personalized Human-UAV Interaction. Recently, some HUI frameworks based on LLMs have been proposed, but they commonly suffer from difficulties in mixed task planning and execution, leading to low adaptability in complex scenarios. In this paper, we propose a novel dual-agent HUI framework. This framework constructs two independent LLM agents (a task planning agent, and an execution agent) and applies different Prompt Engineering to separately handle the understanding, planning, and execution of tasks. To verify the effectiveness and performance of the framework, we have built a task database covering four typical application scenarios of UAVs and quantified the performance of the HUI framework using three independent metrics. Meanwhile different LLM models are selected to control the UAVs with compared performance. Our user study experimental results demonstrate that the framework improves the smoothness of HUI and the flexibility of task execution in the tasks scenario we set up, effectively meeting users' personalized needs.",
    "authors": [
      "Haoran Wang",
      "Zhuohang Chen",
      "Guang Li",
      "Bo Ma",
      "Chuanghuang Li"
    ],
    "published": "2025-12-09",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08145v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08145v1",
    "fetched_at": "2025-12-10T08:34:31.612872",
    "chinese_title": "与无人机对话——基于大语言模型的人机无人机交互",
    "chinese_summary": "针对现有基于大语言模型（LLM）的人机无人机交互（HUI）框架存在混合任务规划与执行困难、复杂场景适应性低的问题，本文提出双智能体HUI框架，通过独立LLM智能体（任务规划与执行）及不同提示工程分别处理任务理解、规划与执行；同时构建覆盖4类典型无人机场景的任务数据库，用3个指标量化框架性能并对比不同LLM模型。",
    "tags": [
      "LLM",
      "NLP",
      "Transformer"
    ],
    "key_contributions": [
      "提出双智能体人机无人机交互框架，解决混合任务规划执行的适配性问题",
      "构建多场景任务数据库并设计量化指标，验证框架性能及对比不同LLM模型"
    ],
    "processed_at": "2025-12-10T08:44:24.212551"
  },
  {
    "id": "2512.08052v1",
    "title": "An Introduction to Deep Reinforcement and Imitation Learning",
    "abstract": "Embodied agents, such as robots and virtual characters, must continuously select actions to execute tasks effectively, solving complex sequential decision-making problems. Given the difficulty of designing such controllers manually, learning-based approaches have emerged as promising alternatives, most notably Deep Reinforcement Learning (DRL) and Deep Imitation Learning (DIL). DRL leverages reward signals to optimize behavior, while DIL uses expert demonstrations to guide learning. This document introduces DRL and DIL in the context of embodied agents, adopting a concise, depth-first approach to the literature. It is self-contained, presenting all necessary mathematical and machine learning concepts as they are needed. It is not intended as a survey of the field; rather, it focuses on a small set of foundational algorithms and techniques, prioritizing in-depth understanding over broad coverage. The material ranges from Markov Decision Processes to REINFORCE and Proximal Policy Optimization (PPO) for DRL, and from Behavioral Cloning to Dataset Aggregation (DAgger) and Generative Adversarial Imitation Learning (GAIL) for DIL.",
    "authors": [
      "Pedro Santana"
    ],
    "published": "2025-12-08",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08052v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08052v1",
    "fetched_at": "2025-12-10T08:34:31.612890",
    "chinese_title": "深度强化学习与模仿学习导论",
    "chinese_summary": "该文档针对具身智能体的序列决策问题，介绍深度强化学习（DRL）与深度模仿学习（DIL）的基础算法；涵盖DRL的MDP框架、REINFORCE及PPO，DIL的行为克隆、DAgger及GAIL，采用深度优先方式聚焦核心算法以促进深入理解，而非广泛综述。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning"
    ],
    "key_contributions": [
      "系统介绍具身智能体场景下DRL与DIL的基础算法，涵盖REINFORCE、PPO及行为克隆、DAgger、GAIL等核心方法",
      "采用深度优先、聚焦核心的方式，自包含必要数学与机器学习概念，助力对基础算法的深入理解"
    ],
    "processed_at": "2025-12-10T08:44:43.481407"
  },
  {
    "id": "2512.08006v1",
    "title": "Beyond Unified Models: A Service-Oriented Approach to Low Latency, Context Aware Phonemization for Real Time TTS",
    "abstract": "Lightweight, real-time text-to-speech systems are crucial for accessibility. However, the most efficient TTS models often rely on lightweight phonemizers that struggle with context-dependent challenges. In contrast, more advanced phonemizers with a deeper linguistic understanding typically incur high computational costs, which prevents real-time performance.   This paper examines the trade-off between phonemization quality and inference speed in G2P-aided TTS systems, introducing a practical framework to bridge this gap. We propose lightweight strategies for context-aware phonemization and a service-oriented TTS architecture that executes these modules as independent services. This design decouples heavy context-aware components from the core TTS engine, effectively breaking the latency barrier and enabling real-time use of high-quality phonemization models. Experimental results confirm that the proposed system improves pronunciation soundness and linguistic accuracy while maintaining real-time responsiveness, making it well-suited for offline and end-device TTS applications.",
    "authors": [
      "Mahta Fetrat",
      "Donya Navabi",
      "Zahra Dehghanian",
      "Morteza Abolghasemi",
      "Hamid R. Rabiee"
    ],
    "published": "2025-12-08",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08006v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08006v1",
    "fetched_at": "2025-12-10T08:34:31.612917",
    "chinese_title": "超越统一模型：面向实时TTS的低延迟、上下文感知音素化的服务化方法",
    "chinese_summary": "针对实时文本转语音（TTS）系统中轻量音素化模型上下文理解不足、高质量音素化模型推理延迟高的问题，本文提出上下文感知音素化的轻量策略，并设计服务化TTS架构将各模块作为独立服务运行以解耦重上下文组件与核心引擎；实验验证该系统可提升发音合理性与语言准确性，同时保持实时响应，适配离线及端设备场景。",
    "tags": [
      "NLP",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出上下文感知音素化的轻量策略，平衡音素化质量与推理速度",
      "设计服务化TTS架构，通过模块解耦突破实时性与高质量音素化的权衡瓶颈"
    ],
    "processed_at": "2025-12-10T08:44:57.954037"
  },
  {
    "id": "2512.07785v1",
    "title": "Automating High Energy Physics Data Analysis with LLM-Powered Agents",
    "abstract": "We present a proof-of-principle study demonstrating the use of large language model (LLM) agents to automate a representative high energy physics (HEP) analysis. Using the Higgs boson diphoton cross-section measurement as a case study with ATLAS Open Data, we design a hybrid system that combines an LLM-based supervisor-coder agent with the Snakemake workflow manager. In this architecture, the workflow manager enforces reproducibility and determinism, while the agent autonomously generates, executes, and iteratively corrects analysis code in response to user instructions. We define quantitative evaluation metrics including success rate, error distribution, costs per specific task, and average number of API calls, to assess agent performance across multi-stage workflows. To characterize variability across architectures, we benchmark a representative selection of state-of-the-art LLMs spanning the Gemini and GPT-5 series, the Claude family, and leading open-weight models. While the workflow manager ensures deterministic execution of all analysis steps, the final outputs still show stochastic variation. Although we set the temperature to zero, other sampling parameters (e.g., top-p, top-k) remained at their defaults, and some reasoning-oriented models internally adjust these settings. Consequently, the models do not produce fully deterministic results. This study establishes the first LLM-agent-driven automated data-analysis framework in HEP, enabling systematic benchmarking of model capabilities, stability, and limitations in real-world scientific computing environments. The baseline code used in this work is available at https://huggingface.co/HWresearch/LLM4HEP. This work was accepted as a poster at the Machine Learning and the Physical Sciences (ML4PS) workshop at NeurIPS 2025. The initial submission was made on August 30, 2025.",
    "authors": [
      "Eli Gendreau-Distler",
      "Joshua Ho",
      "Dongwon Kim",
      "Luc Tomas Le Pottier",
      "Haichen Wang",
      "Chengxi Yang"
    ],
    "published": "2025-12-08",
    "categories": [
      "physics.data-an",
      "cs.AI",
      "cs.LG",
      "hep-ex"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.07785v1",
    "arxiv_url": "https://arxiv.org/abs/2512.07785v1",
    "fetched_at": "2025-12-10T08:34:31.612945",
    "chinese_title": "用LLM驱动智能体自动化高能物理数据分析",
    "chinese_summary": "本文以希格斯玻色子双光子截面测量为案例，设计结合LLM监督编码智能体与Snakemake工作流管理器的混合系统，实现高能物理数据分析自动化；定义定量评估指标并基准测试多款主流LLM，建立该领域首个LLM驱动的自动化分析框架。",
    "tags": [
      "LLM",
      "Transformer",
      "Benchmark"
    ],
    "key_contributions": [
      "提出结合LLM智能体与工作流管理器的混合系统，自动化高能物理数据分析",
      "建立定量评估指标体系并基准测试多款主流LLM，填补HEP领域LLM驱动分析框架空白"
    ],
    "processed_at": "2025-12-10T08:45:14.468393"
  },
  {
    "id": "2512.07497v2",
    "title": "How Do LLMs Fail In Agentic Scenarios? A Qualitative Analysis of Success and Failure Scenarios of Various LLMs in Agentic Simulations",
    "abstract": "We investigate how large language models (LLMs) fail when operating as autonomous agents with tool-use capabilities. Using the Kamiwaza Agentic Merit Index (KAMI) v0.1 benchmark, we analyze 900 execution traces from three representative models - Granite 4 Small, Llama 4 Maverick, and DeepSeek V3.1 - across filesystem, text extraction, CSV analysis, and SQL scenarios. Rather than focusing on aggregate scores, we perform fine-grained, per-trial behavioral analysis to surface the strategies that enable successful multi-step tool execution and the recurrent failure modes that undermine reliability. Our findings show that model scale alone does not predict agentic robustness: Llama 4 Maverick (400B) performs only marginally better than Granite 4 Small (32B) in some uncertainty-driven tasks, while DeepSeek V3.1's superior reliability derives primarily from post-training reinforcement learning rather than architecture or size. Across models, we identify four recurring failure archetypes: premature action without grounding, over-helpfulness that substitutes missing entities, vulnerability to distractor-induced context pollution, and fragile execution under load. These patterns highlight the need for agentic evaluation methods that emphasize interactive grounding, recovery behavior, and environment-aware adaptation, suggesting that reliable enterprise deployment requires not just stronger models but deliberate training and design choices that reinforce verification, constraint discovery, and adherence to source-of-truth data.",
    "authors": [
      "JV Roig"
    ],
    "published": "2025-12-08",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.07497v2",
    "arxiv_url": "https://arxiv.org/abs/2512.07497v2",
    "fetched_at": "2025-12-10T08:34:31.613013",
    "chinese_title": "大语言模型在智能体场景中如何失败？不同大语言模型在智能体模拟中成功与失败场景的定性分析",
    "chinese_summary": "该研究使用KAMI v0.1基准，分析3个代表性大语言模型在4类任务中的900条执行轨迹，通过细粒度行为分析发现模型规模不直接预测智能体鲁棒性，DeepSeek V3.1的可靠表现主要来自强化学习而非架构/规模；同时识别出4种常见失败类型，指出需设计强调交互接地等的智能体评估方法。",
    "tags": [
      "LLM",
      "Reinforcement Learning",
      "Benchmark",
      "Financial Agent"
    ],
    "key_contributions": [
      "揭示模型规模不直接决定智能体鲁棒性，DeepSeek V3.1的优势源于强化学习而非架构/规模",
      "识别出智能体场景下4种常见失败类型，并提出需优化智能体评估方法以强调交互接地、恢复行为等"
    ],
    "processed_at": "2025-12-10T08:45:35.042542"
  },
  {
    "id": "2512.07917v1",
    "title": "CFD-copilot: leveraging domain-adapted large language model and model context protocol to enhance simulation automation",
    "abstract": "Configuring computational fluid dynamics (CFD) simulations requires significant expertise in physics modeling and numerical methods, posing a barrier to non-specialists. Although automating scientific tasks with large language models (LLMs) has attracted attention, applying them to the complete, end-to-end CFD workflow remains a challenge due to its stringent domain-specific requirements. We introduce CFD-copilot, a domain-specialized LLM framework designed to facilitate natural language-driven CFD simulation from setup to post-processing. The framework employs a fine-tuned LLM to directly translate user descriptions into executable CFD setups. A multi-agent system integrates the LLM with simulation execution, automatic error correction, and result analysis. For post-processing, the framework utilizes the model context protocol (MCP), an open standard that decouples LLM reasoning from external tool execution. This modular design allows the LLM to interact with numerous specialized post-processing functions through a unified and scalable interface, improving the automation of data extraction and analysis. The framework was evaluated on benchmarks including the NACA~0012 airfoil and the three-element 30P-30N airfoil. The results indicate that domain-specific adaptation and the incorporation of the MCP jointly enhance the reliability and efficiency of LLM-driven engineering workflows.",
    "authors": [
      "Zhehao Dong",
      "Shanghai Du",
      "Zhen Lu",
      "Yue Yang"
    ],
    "published": "2025-12-08",
    "categories": [
      "cs.SE",
      "cs.AI",
      "physics.flu-dyn"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.07917v1",
    "arxiv_url": "https://arxiv.org/abs/2512.07917v1",
    "fetched_at": "2025-12-10T08:34:31.613036",
    "chinese_title": "CFD-copilot：利用领域适配大语言模型与模型上下文协议提升仿真自动化",
    "chinese_summary": "针对计算流体力学（CFD）仿真配置需专业知识的问题，论文提出CFD-copilot领域专用LLM框架，通过领域微调LLM将自然语言转化为可执行CFD设置，结合多智能体系统整合仿真执行、自动纠错与结果分析；引入模型上下文协议（MCP）解耦LLM推理与外部工具执行，提升后处理自动化的模块化与可扩展性；在NACA 0012等基准上验证了该框架对LLM驱动工程工作流可靠性和效率的提升。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Transformer",
      "Benchmark"
    ],
    "key_contributions": [
      "提出CFD-copilot领域专用LLM框架，实现自然语言驱动的端到端CFD仿真（覆盖设置、执行、后处理全流程）",
      "引入模型上下文协议（MCP），解耦LLM推理与外部工具交互，提升后处理自动化的模块化与可扩展性"
    ],
    "processed_at": "2025-12-10T08:45:59.172271"
  },
  {
    "id": "2512.08088v1",
    "title": "Adaptation of Embedding Models to Financial Filings via LLM Distillation",
    "abstract": "Despite advances in generative large language models (LLMs), practical application of specialized conversational AI agents remains constrained by computation costs, latency requirements, and the need for precise domain-specific relevance measures. While existing embedding models address the first two constraints, they underperform on information retrieval in specialized domains like finance. This paper introduces a scalable pipeline that trains specialized models from an unlabeled corpus using a general purpose retrieval embedding model as foundation. Our method yields an average of 27.7% improvement in MRR$\\texttt{@}$5, 44.6% improvement in mean DCG$\\texttt{@}$5 across 14 financial filing types measured over 21,800 query-document pairs, and improved NDCG on 3 of 4 document classes in FinanceBench. We adapt retrieval embeddings (bi-encoder) for RAG, not LLM generators, using LLM-judged relevance to distill domain knowledge into a compact retriever. There are prior works which pair synthetically generated queries with real passages to directly fine-tune the retrieval model. Our pipeline differs from these by introducing interaction between student and teacher models that interleaves retrieval-based mining of hard positive/negative examples from the unlabeled corpus with iterative retraining of the student model's weights using these examples. Each retrieval iteration uses the refined student model to mine the corpus for progressively harder training examples for the subsequent training iteration. The methodology provides a cost-effective solution to bridging the gap between general-purpose models and specialized domains without requiring labor-intensive human annotation.",
    "authors": [
      "Eliot Brenner",
      "Dominic Seyler",
      "Manjunath Hegde",
      "Andrei Simion",
      "Koustuv Dasgupta",
      "Bing Xiang"
    ],
    "published": "2025-12-08",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08088v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08088v1",
    "fetched_at": "2025-12-10T08:35:59.949765",
    "chinese_title": "基于大语言模型蒸馏的金融文件嵌入模型适配方法",
    "chinese_summary": "本文提出可扩展pipeline，以通用检索嵌入模型为基础，通过学生-教师交互迭代挖掘无标签金融文件语料中的难样本，蒸馏LLM领域知识训练专用检索嵌入模型（适配RAG）；该方法在金融检索任务中显著提升MRR@5、DCG@5等指标，且在FinanceBench上表现更优。",
    "tags": [
      "LLM",
      "NLP",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "提出学生-教师交互迭代蒸馏的金融专用检索嵌入模型训练方法，通过难样本挖掘优化性能",
      "在金融检索任务中多指标显著提升，适配RAG场景且优于现有合成查询微调方法"
    ],
    "processed_at": "2025-12-10T08:46:20.629422"
  },
  {
    "id": "2512.08567v1",
    "title": "A Hybrid Model for Stock Market Forecasting: Integrating News Sentiment and Time Series Data with Graph Neural Networks",
    "abstract": "Stock market prediction is a long-standing challenge in finance, as accurate forecasts support informed investment decisions. Traditional models rely mainly on historical prices, but recent work shows that financial news can provide useful external signals. This paper investigates a multimodal approach that integrates companies' news articles with their historical stock data to improve prediction performance. We compare a Graph Neural Network (GNN) model with a baseline LSTM model. Historical data for each company is encoded using an LSTM, while news titles are embedded with a language model. These embeddings form nodes in a heterogeneous graph, and GraphSAGE is used to capture interactions between articles, companies, and industries. We evaluate two targets: a binary direction-of-change label and a significance-based label. Experiments on the US equities and Bloomberg datasets show that the GNN outperforms the LSTM baseline, achieving 53% accuracy on the first target and a 4% precision gain on the second. Results also indicate that companies with more associated news yield higher prediction accuracy. Moreover, headlines contain stronger predictive signals than full articles, suggesting that concise news summaries play an important role in short-term market reactions.",
    "authors": [
      "Nader Sadek",
      "Mirette Moawad",
      "Christina Naguib",
      "Mariam Elzahaby"
    ],
    "published": "2025-12-09",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2512.08567v1",
    "arxiv_url": "https://arxiv.org/abs/2512.08567v1",
    "fetched_at": "2025-12-10T08:36:35.893286",
    "chinese_title": "股票市场预测的混合模型：结合新闻情感与时间序列数据的图神经网络",
    "chinese_summary": "本文提出一种整合新闻情感与时间序列数据的股票预测混合模型，用LSTM编码公司历史股价、语言模型嵌入新闻标题，构建异质图并通过GraphSAGE捕捉文章、公司、行业间的交互；实验表明该模型优于LSTM基线，且新闻数量多的公司预测更准、新闻标题的预测信号强于全文。",
    "tags": [
      "Sentiment Analysis",
      "Deep Learning",
      "Time Series",
      "Graph Neural Network"
    ],
    "key_contributions": [
      "提出整合新闻情感与时间序列数据的多模态混合模型，通过GraphSAGE捕捉多实体交互提升预测性能",
      "实证验证新闻数量、标题与全文的预测信号差异，为新闻数据利用提供依据"
    ],
    "processed_at": "2025-12-10T08:46:33.974111"
  }
]