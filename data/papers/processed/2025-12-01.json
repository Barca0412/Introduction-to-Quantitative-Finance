[
  {
    "id": "2511.23295v1",
    "title": "Signature approach for pricing and hedging path-dependent options with frictions",
    "abstract": "We introduce a novel signature approach for pricing and hedging path-dependent options with instantaneous and permanent market impact under a mean-quadratic variation criterion. Leveraging the expressive power of signatures, we recast an inherently nonlinear and non-Markovian stochastic control problem into a tractable form, yielding hedging strategies in (possibly infinite) linear feedback form in the time-augmented signature of the control variables, with coefficients characterized by non-standard infinite-dimensional Riccati equations on the extended tensor algebra. Numerical experiments demonstrate the effectiveness of these signature-based strategies for pricing and hedging general path-dependent payoffs in the presence of frictions. In particular, market impact naturally smooths optimal trading strategies, making low-truncated signature approximations highly accurate and robust in frictional markets, contrary to the frictionless case.",
    "authors": [
      "Eduardo Abi Jaber",
      "Donatien Hainaut",
      "Edouard Motte"
    ],
    "published": "2025-11-28",
    "categories": [
      "q-fin.PM",
      "math.OC",
      "q-fin.MF",
      "q-fin.PR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.23295v1",
    "arxiv_url": "https://arxiv.org/abs/2511.23295v1",
    "fetched_at": "2025-12-01T08:35:59.582270",
    "chinese_title": "带摩擦的路径依赖期权定价与对冲的Signature方法",
    "chinese_summary": "本文引入带摩擦的路径依赖期权定价与对冲的Signature方法，基于均值二次变差准则将非线性非马尔可夫随机控制问题转化为可处理形式，得到线性反馈形式的对冲策略，系数由扩展张量代数上的非标准无限维Riccati方程刻画；数值实验表明该策略有效，市场冲击使最优交易策略平滑，低截断Signature近似在摩擦市场中准确鲁棒。",
    "tags": [
      "Options",
      "Asset Pricing",
      "Risk Management",
      "Market Microstructure"
    ],
    "key_contributions": [
      "数值实验验证该Signature-based策略有效，且市场冲击使最优交易策略平滑，低截断Signature近似在摩擦市场中准确鲁棒"
    ],
    "processed_at": "2025-12-01T08:39:03.606029"
  },
  {
    "id": "2511.22782v1",
    "title": "Factors Influencing Cryptocurrency Prices: Evidence from Bitcoin, Ethereum, Dash, Litecoin, and Monero",
    "abstract": "This paper examines factors that influence prices of most common five cryptocurrencies such as Bitcoin, Ethereum, Dash, Litecoin, and Monero over 2010-2018 using weekly data. The study employs ARDL technique and documents several findings. First, cryptomarket-related factors such as market beta, trading volume, and volatility appear to be significant determinant for all five cryptocurrencies both in short- and long-run. Second, attractiveness of cryptocurrencies also matters in terms of their price determination, but only in long-run. This indicates that formation (recognition) of the attractiveness of cryptocurrencies are subjected to time factor. In other words, it travels slowly within the market. Third, SP500 index seems to have weak positive long-run impact on Bitcoin, Ethereum, and Litcoin, while its sign turns to negative losing significance in short-run, except Bitcoin that generates an estimate of -0.20 at 10% significance level. Lastly, error-correction models for Bitcoin, Etherem, Dash, Litcoin, and Monero show that cointegrated series cannot drift too far apart, and converge to a long-run equilibrium at a speed of 23.68%, 12.76%, 10.20%, 22.91%, and 14.27% respectively.",
    "authors": [
      "Yhlas Sovbetov"
    ],
    "published": "2025-11-27",
    "categories": [
      "q-fin.PR",
      "q-fin.CP",
      "q-fin.PM",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22782v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22782v1",
    "fetched_at": "2025-12-01T08:35:59.582304",
    "chinese_title": "影响加密货币价格的因素：来自比特币、以太坊、达世币、莱特币和门罗币的证据",
    "chinese_summary": "本文采用ARDL技术，基于2010-2018年周度数据，分析五种主流加密货币价格的影响因素；发现加密市场相关因素对其长短周期均显著，吸引力仅长期显著，SP500存在长短周期异质性影响，且各货币存在长期均衡及特定收敛速度。",
    "tags": [
      "Asset Pricing",
      "Factor Model",
      "Time Series",
      "Volatility"
    ],
    "key_contributions": [
      "揭示加密市场相关因素（市场beta、交易量、波动率）是五种主流加密货币价格的长短周期显著决定因素",
      "验证加密货币吸引力仅长期影响价格，且SP500对部分货币存在长短周期异质性影响，同时明确各货币的长期均衡收敛速度"
    ],
    "processed_at": "2025-12-01T08:39:14.651558"
  },
  {
    "id": "2511.22766v1",
    "title": "Beta-Dependent Gamma Feedback and Endogenous Volatility Amplification in Option Markets",
    "abstract": "We develop a theoretical framework that aims to link micro-level option hedging and stock-specific factor exposure with macro-level market turbulence and explain endogenous volatility amplification during gamma-squeeze events. By explicitly modeling market-maker delta-neutral hedging and incorporating beta-dependent volatility normalization, we derive a stability condition that characterizes the onset of a gamma-squeeze event. The model captures a nonlinear recursive feedback loop between market-maker hedging and price movements and the resulting self-reinforcing dynamics. From a complex-systems perspective, the dynamics represent a bounded nonlinear response in which effective gain depends jointly on beta-normalized shock perception and gamma-scaled sensitivity. Our analysis highlights that low-beta stocks exhibit disproportionately strong feedback even for modest absolute price movements.",
    "authors": [
      "Haoying Dai"
    ],
    "published": "2025-11-27",
    "categories": [
      "q-fin.TR",
      "nlin.CD"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22766v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22766v1",
    "fetched_at": "2025-12-01T08:35:59.582325",
    "chinese_title": "期权市场中依赖β的伽马反馈与内生波动率放大",
    "chinese_summary": "论文构建理论框架，连接微观期权对冲、股票特定因子暴露与宏观市场动荡，解释伽马挤压事件中的内生波动率放大；通过显式建模做市商delta中性对冲并纳入β依赖的波动率归一化，推导伽马挤压发生的稳定性条件，捕捉做市商对冲与价格变动的非线性递归反馈及自我强化动态。",
    "tags": [
      "Volatility",
      "Options",
      "Market Making",
      "Market Microstructure"
    ],
    "key_contributions": [
      "构建理论框架，明确连接微观期权对冲、股票β暴露与宏观市场动荡，解释伽马挤压中的内生波动率放大机制",
      "推导伽马挤压发生的稳定性条件，捕捉做市商对冲与价格变动的非线性递归反馈及自我强化动态，指出低β股票对适度绝对价格变动的反馈更强"
    ],
    "processed_at": "2025-12-01T08:39:22.522703"
  },
  {
    "id": "2511.22272v1",
    "title": "Statistics of Extremes for the Insurance Industry",
    "abstract": "We provide a survey of how techniques developed for the modelling of extremes naturally matter in insurance, and how they need to and can be adapted for the insurance applications. Topics covered include truncation, tempering, censoring and regression techniques. The discussed techniques are illustrated on concrete data sets.",
    "authors": [
      "Hansjoerg Albrecher",
      "Jan Beirlant"
    ],
    "published": "2025-11-27",
    "categories": [
      "q-fin.RM",
      "stat.ME"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22272v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22272v1",
    "fetched_at": "2025-12-01T08:35:59.582346",
    "chinese_title": "保险行业的极端值统计",
    "chinese_summary": "这篇论文调查了极端值建模技术在保险行业的应用及适配需求，涵盖截断、tempered分布、删失和回归等关键技术，并用具体数据集进行实例验证。",
    "tags": [
      "Risk Management",
      "Anomaly"
    ],
    "key_contributions": [
      "系统梳理极端值建模技术在保险场景的应用逻辑与适配要点",
      "结合真实数据集验证截断、tempered分布、删失及回归技术的保险应用价值"
    ],
    "processed_at": "2025-12-01T08:39:33.379389"
  },
  {
    "id": "2511.22101v1",
    "title": "Adaptive Dueling Double Deep Q-networks in Uniswap V3 Replication and Extension with Mamba",
    "abstract": "The report goes through the main steps of replicating and improving the article \"Adaptive Liquidity Provision in Uniswap V3 with Deep Reinforcement Learning.\" The replication part includes how to obtain data from the Uniswap Subgraph, details of the implementation, and comments on the results. After the replication, I propose a new structure based on the original model, which combines Mamba with DDQN and a new reward function. In this new structure, I clean the data again and introduce two new baselines for comparison. As a result, although the model has not yet been applied to all datasets, it shows stronger theoretical support than the original model and performs better in some tests.",
    "authors": [
      "Zhaofeng Zhang"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.LG",
      "q-fin.TR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22101v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22101v1",
    "fetched_at": "2025-12-01T08:35:59.582364",
    "chinese_title": "基于自适应决斗双深度Q网络与Mamba的Uniswap V3复制与扩展",
    "chinese_summary": "论文首先完成了Uniswap V3自适应流动性提供深度强化学习论文的复制，涵盖Uniswap子图数据获取、实现细节及结果分析；随后提出结合Mamba与双深度Q网络（DDQN）并设计新奖励函数的改进模型，引入两个新基准对比，该模型理论支撑更强且部分测试表现更优。",
    "tags": [
      "Reinforcement Learning",
      "Market Making",
      "Deep Learning",
      "Algorithmic Trading"
    ],
    "key_contributions": [
      "完成Uniswap V3自适应流动性提供深度强化学习论文的复制，明确数据获取、实现及结果分析细节",
      "提出结合Mamba与DDQN并含新奖励函数的改进模型，引入新基准对比，理论支撑更强且部分测试表现更优"
    ],
    "processed_at": "2025-12-01T08:39:43.847069"
  },
  {
    "id": "2511.21975v1",
    "title": "The Risk-Adjusted Intelligence Dividend: A Quantitative Framework for Measuring AI Return on Investment Integrating ISO 42001 and Regulatory Exposure",
    "abstract": "Organizations investing in artificial intelligence face a fundamental challenge: traditional return on investment calculations fail to capture the dual nature of AI implementations, which simultaneously reduce certain operational risks while introducing novel exposures related to algorithmic malfunction, adversarial attacks, and regulatory liability. This research presents a comprehensive financial framework for quantifying AI project returns that explicitly integrates changes in organizational risk profiles. The methodology addresses a critical gap in current practice where investment decisions rely on optimistic benefit projections without accounting for the probabilistic costs of AI-specific threats including model drift, bias-related litigation, and compliance failures under emerging regulations such as the European Union Artificial Intelligence Act and ISO/IEC 42001. Drawing on established risk quantification methods, including annual loss expectancy calculations and Monte Carlo simulation techniques, this framework enables practitioners to compute net benefits that incorporate both productivity gains and the delta between pre-implementation and post-implementation risk exposures. The analysis demonstrates that accurate AI investment evaluation requires explicit modeling of control effectiveness, reserve requirements for algorithmic failures, and the ongoing operational costs of maintaining model performance. Practical implications include specific guidance for establishing governance structures, conducting phased validations, and integrating risk-adjusted metrics into capital allocation decisions, ultimately enabling evidence-based AI portfolio management that satisfies both fiduciary responsibilities and regulatory mandates.",
    "authors": [
      "Hernan Huwyler"
    ],
    "published": "2025-11-26",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CE",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.21975v1",
    "arxiv_url": "https://arxiv.org/abs/2511.21975v1",
    "fetched_at": "2025-12-01T08:35:59.582383",
    "chinese_title": "风险调整后的智能红利：整合ISO 42001与监管敞口的AI投资回报率量化框架",
    "chinese_summary": "本文针对传统AI投资回报率（ROI）未覆盖AI双重性（降低操作风险但引入算法故障、对抗攻击等新风险）的问题，提出整合ISO 42001与监管敞口的量化框架；该框架采用年度损失期望计算、蒙特卡洛模拟等方法，量化AI项目净收益（含 productivity gains及实施前后风险敞口变化），并纳入控制有效性、故障储备等因素，为AI投资决策提供全面评估工具。",
    "tags": [
      "Risk Management",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出整合ISO 42001与监管敞口的AI投资回报率量化框架，弥补传统ROI未考虑AI双重风险的缺口",
      "采用年度损失期望、蒙特卡洛模拟等方法，量化AI项目净收益（含收益与风险变化），纳入控制有效性等关键因素提升评估准确性"
    ],
    "processed_at": "2025-12-01T08:40:05.841380"
  },
  {
    "id": "2511.21929v1",
    "title": "Extended Convolution Bounds on the Fréchet Problem: Robust Risk Aggregation and Risk Sharing",
    "abstract": "In this paper, we provide extended convolution bounds for the Fréchet problem and discuss related implications in quantitative risk management. First, we establish a new form of inequality for the Range-Value-at-Risk (RVaR). Based on this inequality, we obtain bounds for robust risk aggregation with dependence uncertainty for (i) RVaR, (ii) inter-RVaR difference and (iii) inter-quantile difference, and provide sharpness conditions. These bounds are called extended convolution bounds, which not only complement the results in the literature (convolution bounds in Blanchet et al. (2025)) but also offer results for some variability measures. Next, applying the above inequality, we study the risk sharing for the averaged quantiles (corresponding to risk sharing for distortion risk measures with special inverse S-shaped distortion functions), which is a non-convex optimization problem. We obtain the expression of the minimal value of the risk sharing and the explicit expression for the corresponding optimal allocation, which is comonotonic risk sharing for large losses and counter-comonotonic risk sharing for small losses or large gains. Finally, we explore the dependence structure for the optimal allocations, showing that the optimal allocation does not exist if the risk is not bounded from above.",
    "authors": [
      "Peng Liu",
      "Yang Liu",
      "Houhan Teng"
    ],
    "published": "2025-11-26",
    "categories": [
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.21929v1",
    "arxiv_url": "https://arxiv.org/abs/2511.21929v1",
    "fetched_at": "2025-12-01T08:35:59.582405",
    "chinese_title": "Fréchet问题的扩展卷积边界：稳健风险聚合与风险分担",
    "chinese_summary": "论文首先建立Range-Value-at-Risk（RVaR）的新不等式，推导RVaR、RVaR差及分位数差的稳健风险聚合边界（扩展卷积边界）并给出sharpness条件；接着用该不等式研究平均分位数的风险分担（对应特殊反S形扭曲风险测度），得到最小风险值及最优配置（大损失共单调、小损失/大收益反共单调）；最后指出无界风险下最优配置不存在。",
    "tags": [
      "Risk Management",
      "Portfolio Optimization"
    ],
    "key_contributions": [
      "建立RVaR新不等式，推导稳健风险聚合的扩展卷积边界（含RVaR、其差、分位数差）及sharpness条件",
      "研究平均分位数的风险分担，得到最小风险值、最优配置（大损失共单调、小损失/大收益反共单调），并指出无界风险下最优配置不存在"
    ],
    "processed_at": "2025-12-01T08:40:16.078107"
  },
  {
    "id": "2511.21901v1",
    "title": "Standardized Threat Taxonomy for AI Security, Governance, and Regulatory Compliance",
    "abstract": "The accelerating deployment of artificial intelligence systems across regulated sectors has exposed critical fragmentation in risk assessment methodologies. A significant \"language barrier\" currently separates technical security teams, who focus on algorithmic vulnerabilities (e.g., MITRE ATLAS), from legal and compliance professionals, who address regulatory mandates (e.g., EU AI Act, NIST AI RMF). This disciplinary disconnect prevents the accurate translation of technical vulnerabilities into financial liability, leaving practitioners unable to answer fundamental economic questions regarding contingency reserves, control return-on-investment, and insurance exposure. To bridge this gap, this research presents the AI System Threat Vector Taxonomy, a structured ontology designed explicitly for Quantitative Risk Assessment (QRA). The framework categorizes AI-specific risks into nine critical domains: Misuse, Poisoning, Privacy, Adversarial, Biases, Unreliable Outputs, Drift, Supply Chain, and IP Threat, integrating 53 operationally defined sub-threats. Uniquely, each domain maps technical vectors directly to business loss categories (Confidentiality, Integrity, Availability, Legal, Reputation), enabling the translation of abstract threats into measurable financial impact. The taxonomy is empirically validated through an analysis of 133 documented AI incidents from 2025 (achieving 100% classification coverage) and reconciled against the main AI risk frameworks. Furthermore, it is explicitly aligned with ISO/IEC 42001 controls and NIST AI RMF functions to facilitate auditability.",
    "authors": [
      "Hernan Huwyler"
    ],
    "published": "2025-11-26",
    "categories": [
      "cs.CR",
      "cs.AI",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.21901v1",
    "arxiv_url": "https://arxiv.org/abs/2511.21901v1",
    "fetched_at": "2025-12-01T08:35:59.582423",
    "chinese_title": "AI安全、治理与合规的标准化威胁分类体系",
    "chinese_summary": "针对AI部署中技术安全团队与合规团队的语言障碍，论文提出AI系统威胁向量分类体系（ASTVT），将AI风险分为9个关键领域并映射技术向量到业务损失类别，通过133个AI事件验证其100%分类覆盖度，助力量化财务影响与合规对接。",
    "tags": [
      "Risk Management"
    ],
    "key_contributions": [
      "提出AI系统威胁向量分类体系（ASTVT），实现技术风险向量到业务损失类别的直接映射",
      "通过133个AI事件验证分类有效性，对接主流AI风险框架，桥接技术与合规团队的语言障碍"
    ],
    "processed_at": "2025-12-01T08:40:29.258746"
  },
  {
    "id": "2511.21873v1",
    "title": "A3T-GCN for FTSE100 Components Price Forecasting",
    "abstract": "We examine the predictive power of a novel hybrid A3T-GCN architecture for forecasting closing stock prices of FTSE100 constituents. The dataset comprises 79 companies and 375,329 daily observations from 2007 to 2024, with node features including technical indicators (RSI, MACD), normalized and log returns, and annualized log returns over multiple windows (ALR1W, ALR2W, ALR1M, ALR2M). Graphs are constructed based on sector classifications and correlations of returns or financial ratios. Our results show that the A3T-GCN model using annualized log-returns and shorter sequence lengths improves prediction accuracy while reducing computational requirements. Additionally, longer historical sequences yield only modest improvements, highlighting their importance for longer-term forecasts.",
    "authors": [
      "A. L. Paredes"
    ],
    "published": "2025-11-26",
    "categories": [
      "q-fin.PR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.21873v1",
    "arxiv_url": "https://arxiv.org/abs/2511.21873v1",
    "fetched_at": "2025-12-01T08:35:59.582441",
    "chinese_title": "A3T-GCN用于FTSE100成分股价格预测",
    "chinese_summary": "本文提出混合A3T-GCN架构预测FTSE100成分股收盘价，基于行业分类及收益/财务比率相关性构建图结构，节点特征含技术指标、归一化与对数收益等；研究发现使用年化对数收益和更短序列的模型可提升预测精度并降低计算量，较长历史序列对长期预测有适度增益。",
    "tags": [
      "Graph Neural Network",
      "Time Series",
      "Deep Learning",
      "Asset Pricing"
    ],
    "key_contributions": [
      "提出混合A3T-GCN架构，结合年化对数收益与更短序列提升FTSE100成分股价格预测精度并降低计算量",
      "揭示较长历史序列对长期价格预测具有适度增益效果"
    ],
    "processed_at": "2025-12-01T08:40:41.299816"
  },
  {
    "id": "2511.21850v1",
    "title": "Black-Litterman and ESG Portfolio Optimization",
    "abstract": "We introduce a simple portfolio optimization strategy using ESG data with the Black-Litterman allocation framework. ESG scores are used as a bias for Stein shrinkage estimation of equilibrium risk premiums used in assigning Black-Litterman asset weights. Assets are modeled as multivariate affine normal-inverse Gaussian variables using CVaR as a risk measure. This strategy, though very simple, when employed with a soft turnover constraint is exceptionally successful. Portfolios are reallocated daily over a 4.7 year period, each with a different set of hyperparameters used for optimization. The most successful strategies have returns of approximately 40-45% annually.",
    "authors": [
      "Aviv Alpern",
      "Svetlozar Rachev"
    ],
    "published": "2025-11-26",
    "categories": [
      "q-fin.PM",
      "q-fin.CP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.21850v1",
    "arxiv_url": "https://arxiv.org/abs/2511.21850v1",
    "fetched_at": "2025-12-01T08:35:59.582460",
    "chinese_title": "Black-Litterman与ESG投资组合优化",
    "chinese_summary": "论文提出结合ESG数据与Black-Litterman框架的简单投资组合优化策略，以ESG分数作为Stein收缩估计均衡风险溢价的偏差，用多元仿射正态逆高斯变量建模资产并以CVaR为风险度量；该策略结合软 turnover约束后表现优异，4.7年内每日再平衡的最优策略年收益达40-45%。",
    "tags": [
      "Portfolio Optimization",
      "Risk Management",
      "Asset Pricing"
    ],
    "key_contributions": [
      "提出结合ESG数据与Black-Litterman框架的投资组合优化策略，以ESG分数作为Stein收缩估计均衡风险溢价的偏差",
      "结合软 turnover约束、多元仿射正态逆高斯建模及CVaR风险度量的策略在4.7年每日再平衡中获得40-45%年收益，表现优异"
    ],
    "processed_at": "2025-12-01T08:40:53.393624"
  },
  {
    "id": "2511.21515v2",
    "title": "The Quantum Network of Assets: A Non-Classical Framework for Market Correlation and Structural Risk",
    "abstract": "Classical correlation matrices capture only linear and pairwise co-movements, leaving higher-order, nonlinear, and state-dependent interactions of financial markets unrepresented. This paper introduces the Quantum Network of Assets (QNA), a density-matrix based framework that embeds cross-asset dependencies into a quantum-information representation. The approach does not assume physical quantum effects but uses the mathematical structure of density operators, entropy, and mutual information to describe market organisation at a structural level.   Within this framework we define two structural measures: the Entanglement Risk Index (ERI), which summarises global non-separability and the compression of effective market degrees of freedom, and the Quantum Early-Warning Signal (QEWS), which tracks changes in entropy to detect latent information build-up. These measures reveal dependency geometry that classical covariance-based tools cannot capture.   Using NASDAQ-100 data from 2024-2025, we show that quantum entropy displays smoother evolution and clearer regime distinctions than classical entropy, and that ERI rises during periods of structural tightening even when volatility remains low. Around the 2025 US tariff announcement, QEWS shows a marked pre-event increase in structural tension followed by a sharp collapse after the announcement, indicating that structural transitions can precede price movements without implying predictive modelling.   QNA therefore provides a structural diagnostic of market fragility, regime shifts, and latent information flow. The framework suggests new directions for systemic risk research by linking empirical asset networks with tools from quantum information theory.",
    "authors": [
      "Hui Gong",
      "Akash Sedai",
      "Francesca Medda"
    ],
    "published": "2025-11-26",
    "categories": [
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.21515v2",
    "arxiv_url": "https://arxiv.org/abs/2511.21515v2",
    "fetched_at": "2025-12-01T08:35:59.582509",
    "chinese_title": "资产量子网络：市场相关性与结构风险的非经典框架",
    "chinese_summary": "论文提出资产量子网络（QNA）框架，基于量子信息密度矩阵突破经典相关矩阵的线性pairwise局限，捕捉资产间非线性、高阶及状态依赖的依赖关系；定义纠缠风险指数（ERI）和量子预警信号（QEWS），通过NASDAQ-100数据验证其能识别经典工具无法捕捉的结构风险与依赖几何。",
    "tags": [
      "Risk Management",
      "Anomaly",
      "Volatility"
    ],
    "key_contributions": [
      "提出资产量子网络（QNA）框架，利用量子信息密度矩阵描述资产间非线性、高阶及状态依赖的依赖关系，突破经典相关矩阵的线性pairwise局限",
      "定义纠缠风险指数（ERI）和量子预警信号（QEWS），实证验证其能有效捕捉经典工具无法识别的结构风险与依赖几何，如ERI在结构收紧期上升、QEWS提前显示事件前变化"
    ],
    "processed_at": "2025-12-01T08:41:11.065755"
  },
  {
    "id": "2511.23274v1",
    "title": "Simultaneous Image Quality Improvement and Artefacts Correction in Accelerated MRI",
    "abstract": "MR data are acquired in the frequency domain, known as k-space. Acquiring high-quality and high-resolution MR images can be time-consuming, posing a significant challenge when multiple sequences providing complementary contrast information are needed or when the patient is unable to remain in the scanner for an extended period of time. Reducing k-space measurements is a strategy to speed up acquisition, but often leads to reduced quality in reconstructed images. Additionally, in real-world MRI, both under-sampled and full-sampled images are prone to artefacts, and correcting these artefacts is crucial for maintaining diagnostic accuracy. Deep learning methods have been proposed to restore image quality from under-sampled data, while others focused on the correction of artefacts that result from the noise or motion. No approach has however been proposed so far that addresses both acceleration and artefacts correction, limiting the performance of these models when these degradation factors occur simultaneously. To address this gap, we present a method for recovering high-quality images from under-sampled data with simultaneously correction for noise and motion artefact called USArt (Under-Sampling and Artifact correction model). Customized for 2D brain anatomical images acquired with Cartesian sampling, USArt employs a dual sub-model approach. The results demonstrate remarkable increase of signal-to-noise ratio (SNR) and contrast in the images restored. Various under-sampling strategies and degradation levels were explored, with the gradient under-sampling strategy yielding the best outcomes. We achieved up to 5x acceleration and simultaneously artefacts correction without significant degradation, showcasing the model's robustness in real-world settings.",
    "authors": [
      "Georgia Kanli",
      "Daniele Perlo",
      "Selma Boudissa",
      "Radovan Jirik",
      "Olivier Keunen"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.CV",
      "cs.AI",
      "physics.med-ph"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.23274v1",
    "arxiv_url": "https://arxiv.org/abs/2511.23274v1",
    "fetched_at": "2025-12-01T08:36:06.231612",
    "chinese_title": "加速MRI中同时实现图像质量提升与伪影校正",
    "chinese_summary": "针对加速MRI中欠采样导致图像质量下降，且真实场景图像易受噪声、运动伪影影响的问题，提出USArt模型，采用双子模型架构，在恢复欠采样数据的高质量图像同时校正噪声与运动伪影，显著提升图像信噪比与对比度。",
    "tags": [
      "Deep Learning"
    ],
    "key_contributions": [
      "首次提出同时解决MRI加速（欠采样）与伪影校正的方法USArt",
      "双子模型架构有效兼顾欠采样恢复与伪影校正，显著提升图像信噪比与对比度"
    ],
    "processed_at": "2025-12-01T08:41:18.605320"
  },
  {
    "id": "2511.23252v1",
    "title": "One-Shot Secure Aggregation: A Hybrid Cryptographic Protocol for Private Federated Learning in IoT",
    "abstract": "Federated Learning (FL) offers a promising approach to collaboratively train machine learning models without centralizing raw data, yet its scalability is often throttled by excessive communication overhead. This challenge is magnified in Internet of Things (IoT) environments, where devices face stringent bandwidth, latency, and energy constraints. Conventional secure aggregation protocols, while essential for protecting model updates, frequently require multiple interaction rounds, large payload sizes, and per-client costs rendering them impractical for many edge deployments.   In this work, we present Hyb-Agg, a lightweight and communication-efficient secure aggregation protocol that integrates Multi-Key CKKS (MK-CKKS) homomorphic encryption with Elliptic Curve Diffie-Hellman (ECDH)-based additive masking. Hyb-Agg reduces the secure aggregation process to a single, non-interactive client-to-server transmission per round, ensuring that per-client communication remains constant regardless of the number of participants. This design eliminates partial decryption exchanges, preserves strong privacy under the RLWE, CDH, and random oracle assumptions, and maintains robustness against collusion by the server and up to $N-2$ clients.   We implement and evaluate Hyb-Agg on both high-performance and resource-constrained devices, including a Raspberry Pi 4, demonstrating that it delivers sub-second execution times while achieving a constant communication expansion factor of approximately 12x over plaintext size. By directly addressing the communication bottleneck, Hyb-Agg enables scalable, privacy-preserving federated learning that is practical for real-world IoT deployments.",
    "authors": [
      "Imraul Emmaka",
      "Tran Viet Xuan Phuong"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.23252v1",
    "arxiv_url": "https://arxiv.org/abs/2511.23252v1",
    "fetched_at": "2025-12-01T08:36:06.231645",
    "chinese_title": "单次安全聚合：面向物联网私有联邦学习的混合加密协议",
    "chinese_summary": "该论文针对物联网环境下联邦学习因通信开销大导致可扩展性受限的问题，提出混合加密协议Hyb-Agg，整合多密钥CKKS同态加密与ECDH基加法掩码，实现每轮仅需单次非交互式客户端到服务器传输且每客户端通信量与参与者数量无关；Hyb-Agg满足RLWE、CDH及随机预言机假设下的强隐私性，抗服务器与最多N-2个客户端勾结，在树莓派4等资源受限设备上实现亚秒级执行。",
    "tags": [
      "Deep Learning"
    ],
    "key_contributions": [
      "提出Hyb-Agg混合加密协议，整合MK-CKKS同态加密与ECDH基加法掩码，实现联邦学习每轮单次非交互式客户端到服务器传输，每客户端通信量与参与者数量无关",
      "该协议满足强隐私假设，抗服务器与最多N-2个客户端勾结，在资源受限设备上实现亚秒级执行"
    ],
    "processed_at": "2025-12-01T08:41:38.692467"
  },
  {
    "id": "2511.23152v1",
    "title": "A Theoretical Framework for Discovering Groups and Unitary Representations via Tensor Factorization",
    "abstract": "We analyze the HyperCube model, an \\textit{operator-valued} tensor factorization architecture that discovers group structures and their unitary representations. We provide a rigorous theoretical explanation for this inductive bias by decomposing its objective into a term regulating factor scales ($\\mathcal{B}$) and a term enforcing directional alignment ($\\mathcal{R} \\geq 0$). This decomposition isolates the \\textit{collinear manifold} ($\\mathcal{R}=0$), to which numerical optimization consistently converges for group isotopes. We prove that this manifold admits feasible solutions exclusively for group isotopes, and that within it, $\\mathcal{B}$ exerts a variational pressure toward unitarity. To bridge the gap to the global landscape, we formulate a \\textit{Collinearity Dominance Conjecture}, supported by empirical observations. Conditional on this dominance, we prove two key results: (1) the global minimum is achieved by the unitary regular representation for groups, and (2) non-group operations incur a strictly higher objective value, formally quantifying the model's inductive bias toward the associative structure of groups (up to isotopy).",
    "authors": [
      "Dongsung Huh",
      "Halyun Jeong"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.23152v1",
    "arxiv_url": "https://arxiv.org/abs/2511.23152v1",
    "fetched_at": "2025-12-01T08:36:06.231666",
    "chinese_title": "基于张量分解的群与酉表示发现理论框架",
    "chinese_summary": "该论文分析算子值张量分解架构HyperCube模型，将其目标分解为因子尺度调节项与方向对齐非负项，隔离共线流形并证明仅群同位素存在可行解且推动酉性；提出共线性主导猜想，条件下证明全局极小由群的酉正则表示达到，非群操作目标值严格更高，量化模型对群结合结构的归纳偏置。",
    "tags": [
      "Factor Model",
      "Deep Learning"
    ],
    "key_contributions": [
      "为HyperCube算子值张量分解模型提供严格理论解释，通过目标分解隔离共线流形，证明其仅对群同位素存在可行解且推动酉性",
      "提出共线性主导猜想，条件下证明全局极小对应群的酉正则表示，非群操作目标值更高，量化模型对群结合结构的归纳偏置"
    ],
    "processed_at": "2025-12-01T08:41:52.515142"
  },
  {
    "id": "2511.23101v1",
    "title": "Mind Reading or Misreading? LLMs on the Big Five Personality Test",
    "abstract": "We evaluate large language models (LLMs) for automatic personality prediction from text under the binary Five Factor Model (BIG5). Five models -- including GPT-4 and lightweight open-source alternatives -- are tested across three heterogeneous datasets (Essays, MyPersonality, Pandora) and two prompting strategies (minimal vs. enriched with linguistic and psychological cues). Enriched prompts reduce invalid outputs and improve class balance, but also introduce a systematic bias toward predicting trait presence. Performance varies substantially: Openness and Agreeableness are relatively easier to detect, while Extraversion and Neuroticism remain challenging. Although open-source models sometimes approach GPT-4 and prior benchmarks, no configuration yields consistently reliable predictions in zero-shot binary settings. Moreover, aggregate metrics such as accuracy and macro-F1 mask significant asymmetries, with per-class recall offering clearer diagnostic value. These findings show that current out-of-the-box LLMs are not yet suitable for APPT, and that careful coordination of prompt design, trait framing, and evaluation metrics is essential for interpretable results.",
    "authors": [
      "Francesco Di Cursi",
      "Chiara Boldrini",
      "Marco Conti",
      "Andrea Passarella"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.23101v1",
    "arxiv_url": "https://arxiv.org/abs/2511.23101v1",
    "fetched_at": "2025-12-01T08:36:06.231689",
    "chinese_title": "读心还是误读？大五人格测试中的大语言模型",
    "chinese_summary": "该论文测试5个大语言模型（含GPT-4及开源轻量模型）在3个异构数据集和2种提示策略下的大五人格二分类预测，发现丰富提示减少无效输出但引入系统偏差，不同特质预测难度差异显著；现有开箱即用LLM暂不适合自动人格预测，需协调提示设计、特质框架与评估指标。",
    "tags": [
      "LLM",
      "NLP",
      "Behavioral Finance"
    ],
    "key_contributions": [
      "系统评估不同LLM在大五人格预测中的表现，揭示提示策略与特质类型对效果的影响",
      "指出开箱即用LLM暂不适合自动人格预测，强调提示设计等要素协调的重要性"
    ],
    "processed_at": "2025-12-01T08:42:05.960842"
  },
  {
    "id": "2511.23072v1",
    "title": "What If They Took the Shot? A Hierarchical Bayesian Framework for Counterfactual Expected Goals",
    "abstract": "This study develops a hierarchical Bayesian framework that integrates expert domain knowledge to quantify player-specific effects in expected goals (xG) estimation, addressing a limitation of standard models that treat all players as identical finishers. Using 9,970 shots from StatsBomb's 2015-16 data and Football Manager 2017 ratings, we combine Bayesian logistic regression with informed priors to stabilise player-level estimates, especially for players with few shots. The hierarchical model reduces posterior uncertainty relative to weak priors and achieves strong external validity: hierarchical and baseline predictions correlate at R2 = 0.75, while an XGBoost benchmark validated against StatsBomb xG reaches R2 = 0.833. The model uncovers interpretable specialisation profiles, including one-on-one finishing (Aguero, Suarez, Belotti, Immobile, Martial), long-range shooting (Pogba), and first-touch execution (Insigne, Salah, Gameiro). It also identifies latent ability in underperforming players such as Immobile and Belotti. The framework supports counterfactual \"what-if\" analysis by reallocating shots between players under identical contexts. Case studies show that Sansone would generate +2.2 xG from Berardi's chances, driven largely by high-pressure situations, while Vardy-Giroud substitutions reveal strong asymmetry: replacing Vardy with Giroud results in a large decline (about -7 xG), whereas the reverse substitution has only a small effect (about -1 xG). This work provides an uncertainty-aware tool for player evaluation, recruitment, and tactical planning, and offers a general approach for domains where individual skill and contextual factors jointly shape performance.",
    "authors": [
      "Mikayil Mahmudlu",
      "Oktay Karakuş",
      "Hasan Arkadaş"
    ],
    "published": "2025-11-28",
    "categories": [
      "eess.SP",
      "cs.AI",
      "stat.AP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.23072v1",
    "arxiv_url": "https://arxiv.org/abs/2511.23072v1",
    "fetched_at": "2025-12-01T08:36:06.231710",
    "chinese_title": "如果他们射门会怎样？用于反事实预期进球的分层贝叶斯框架",
    "chinese_summary": "该研究开发了整合专家领域知识的分层贝叶斯框架，用于量化球员特定效应的预期进球（xG）估计，解决标准模型将所有球员视为相同终结者的局限；结合StatsBomb数据与Football Manager评级，通过贝叶斯逻辑回归加信息先验稳定低样本球员的估计，并支持反事实“what-if”分析，揭示可解释的球员专长及潜在能力。",
    "tags": [
      "Benchmark",
      "Factor Mining"
    ],
    "key_contributions": [
      "提出整合专家知识的分层贝叶斯框架，稳定低样本球员的xG估计，弥补标准xG模型忽略球员差异的不足",
      "支持反事实“what-if”分析，揭示球员专长与潜在能力，案例验证模型有效性（如球员替换的xG变化）"
    ],
    "processed_at": "2025-12-01T08:42:30.619076"
  },
  {
    "id": "2511.22781v1",
    "title": "The Hidden AI Race: Tracking Environmental Costs of Innovation",
    "abstract": "The past decade has seen a massive rise in the popularity of AI systems, mainly owing to the developments in Gen AI, which has revolutionized numerous industries and applications. However, this progress comes at a considerable cost to the environment as training and deploying these models consume significant computational resources and energy and are responsible for large carbon footprints in the atmosphere. In this paper, we study the amount of carbon dioxide released by models across different domains over varying time periods. By examining parameters such as model size, repository activity (e.g., commits and repository age), task type, and organizational affiliation, we identify key factors influencing the environmental impact of AI development. Our findings reveal that model size and versioning frequency are strongly correlated with higher emissions, while domain-specific trends show that NLP models tend to have lower carbon footprints compared to audio-based systems. Organizational context also plays a significant role, with university-driven projects exhibiting the highest emissions, followed by non-profits and companies, while community-driven projects show a reduction in emissions. These results highlight the critical need for green AI practices, including the adoption of energy-efficient architectures, optimizing development workflows, and leveraging renewable energy sources. We also discuss a few practices that can lead to a more sustainable future with AI, and we end this paper with some future research directions that could be motivated by our work. This work not only provides actionable insights to mitigate the environmental impact of AI but also poses new research questions for the community to explore. By emphasizing the interplay between sustainability and innovation, our study aims to guide future efforts toward building a more ecologically responsible AI ecosystem.",
    "authors": [
      "Shyam Agarwal",
      "Mahasweta Chakraborti"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.CY",
      "cs.AI",
      "stat.AP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22781v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22781v1",
    "fetched_at": "2025-12-01T08:36:06.231731",
    "chinese_title": "隐藏的AI竞赛：追踪创新的环境成本",
    "chinese_summary": "本文研究不同领域AI模型在不同时期的二氧化碳排放量，通过分析模型大小、仓库活动、任务类型及组织归属等因素，揭示其环境影响的关键驱动因子（如模型大小、版本更新频率与高排放强相关），并提出绿色AI实践建议以推动可持续AI发展。",
    "tags": [
      "Deep Learning",
      "Transformer",
      "NLP"
    ],
    "key_contributions": [
      "揭示模型大小、版本更新频率等因素与AI碳排放的强相关性，明确不同领域及组织类型的环境影响差异",
      "提出节能架构、优化工作流等绿色AI实践建议，助力可持续AI发展"
    ],
    "processed_at": "2025-12-01T08:42:43.029510"
  },
  {
    "id": "2511.22780v1",
    "title": "Distracted Robot: How Visual Clutter Undermine Robotic Manipulation",
    "abstract": "In this work, we propose an evaluation protocol for examining the performance of robotic manipulation policies in cluttered scenes. Contrary to prior works, we approach evaluation from a psychophysical perspective, therefore we use a unified measure of clutter that accounts for environmental factors as well as the distractors quantity, characteristics, and arrangement. Using this measure, we systematically construct evaluation scenarios in both hyper-realistic simulation and real-world and conduct extensive experimentation on manipulation policies, in particular vision-language-action (VLA) models. Our experiments highlight the significant impact of scene clutter, lowering the performance of the policies, by as much as 34% and show that despite achieving similar average performance across the tasks, different VLA policies have unique vulnerabilities and a relatively low agreement on success scenarios. We further show that our clutter measure is an effective indicator of performance degradation and analyze the impact of distractors in terms of their quantity and occluding influence. At the end, we show that finetuning on enhanced data, although effective, does not equally remedy all negative impacts of clutter on performance.",
    "authors": [
      "Amir Rasouli",
      "Montgomery Alban",
      "Sajjad Pakdamansavoji",
      "Zhiyuan Li",
      "Zhanguang Zhang",
      "Aaron Wu",
      "Xuan Zhao"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22780v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22780v1",
    "fetched_at": "2025-12-01T08:36:06.231761",
    "chinese_title": "分心的机器人：视觉杂乱如何削弱机器人操作能力",
    "chinese_summary": "本文提出从心理物理视角评估机器人操作策略在杂乱场景中性能的协议，采用统一杂乱度量（涵盖环境因素、干扰物数量/特征/排列），在超现实仿真与真实世界构建场景实验；发现杂乱使策略性能最多下降34%，不同视觉-语言-动作（VLA）模型存在独特弱点且成功场景一致性低，微调增强数据虽有效但无法完全弥补所有负面影响。",
    "tags": [
      "Deep Learning",
      "Reinforcement Learning"
    ],
    "key_contributions": [
      "提出结合心理物理视角的机器人操作策略杂乱场景评估协议及统一杂乱度量",
      "揭示杂乱对VLA模型性能的显著影响、模型间差异及微调增强数据的局限性"
    ],
    "processed_at": "2025-12-01T08:42:58.484173"
  },
  {
    "id": "2511.22697v1",
    "title": "Mechanistic Finetuning of Vision-Language-Action Models via Few-Shot Demonstrations",
    "abstract": "Vision-Language Action (VLAs) models promise to extend the remarkable success of vision-language models (VLMs) to robotics. Yet, unlike VLMs in the vision-language domain, VLAs for robotics require finetuning to contend with varying physical factors like robot embodiment, environment characteristics, and spatial relationships of each task. Existing fine-tuning methods lack specificity, adapting the same set of parameters regardless of a task's visual, linguistic, and physical characteristics. Inspired by functional specificity in neuroscience, we hypothesize that it is more effective to finetune sparse model representations specific to a given task. In this work, we introduce Robotic Steering, a finetuning approach grounded in mechanistic interpretability that leverages few-shot demonstrations to identify and selectively finetune task-specific attention heads aligned with the physical, visual, and linguistic requirements of robotic tasks. Through comprehensive on-robot evaluations with a Franka Emika robot arm, we demonstrate that Robotic Steering outperforms LoRA while achieving superior robustness under task variation, reduced computational cost, and enhanced interpretability for adapting VLAs to diverse robotic tasks.",
    "authors": [
      "Chancharik Mitra",
      "Yusen Luo",
      "Raj Saravanan",
      "Dantong Niu",
      "Anirudh Pai",
      "Jesse Thomason",
      "Trevor Darrell",
      "Abrar Anwar",
      "Deva Ramanan",
      "Roei Herzig"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.RO",
      "cs.CL",
      "cs.CV"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22697v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22697v1",
    "fetched_at": "2025-12-01T08:36:06.231794",
    "chinese_title": "基于少样本演示的视觉-语言-动作模型的机制性微调",
    "chinese_summary": "针对视觉-语言-动作（VLA）模型适配机器人任务时缺乏任务特异性微调的问题，本文受神经科学功能特异性启发，提出Robotic Steering方法——基于机制可解释性，利用少样本演示识别并选择性微调与机器人任务物理、视觉及语言需求对齐的任务特定注意力头；通过Franka Emika机械臂实验验证，该方法优于LoRA，且任务变化鲁棒性更强、计算成本更低、可解释性更好。",
    "tags": [
      "Transformer",
      "Deep Learning",
      "LLM"
    ],
    "key_contributions": [
      "提出基于机制可解释性的Robotic Steering微调方法，利用少样本演示选择性微调任务特定注意力头，适配机器人任务多维度需求",
      "实验证明该方法优于LoRA，且在鲁棒性、计算成本、可解释性方面具有优势"
    ],
    "processed_at": "2025-12-01T08:43:14.468165"
  },
  {
    "id": "2511.22693v1",
    "title": "Generative Anchored Fields: Controlled Data Generation via Emergent Velocity Fields and Transport Algebra",
    "abstract": "We present Generative Anchored Fields (GAF), a generative model that learns independent endpoint predictors $J$ (noise) and $K$ (data) rather than a trajectory predictor. The velocity field $v=K-J$ emerges from their time-conditioned disagreement. This factorization enables \\textit{Transport Algebra}: algebraic operation on learned $\\{(J_n,K_n)\\}_{n=1}^N$ heads for compositional control. With class-specific $K_n$ heads, GAF supports a rich family of directed transport maps between a shared base distribution and multiple modalities, enabling controllable interpolation, hybrid generation, and semantic morphing through vector arithmetic. We achieve strong sample quality (FID 7.5 on CelebA-HQ $64\\times 64$) while uniquely providing compositional generation as an architectural primitive. We further demonstrate, GAF has lossless cyclic transport between its initial and final state with LPIPS=$0.0$. Code available at https://github.com/IDLabMedia/GAF",
    "authors": [
      "Deressa Wodajo Deressa",
      "Hannes Mareen",
      "Peter Lambert",
      "Glenn Van Wallendael"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22693v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22693v1",
    "fetched_at": "2025-12-01T08:36:06.231817",
    "chinese_title": "生成锚定场：通过涌现速度场和输运算子实现可控数据生成",
    "chinese_summary": "本文提出生成锚定场（GAF），学习独立噪声（J）和数据（K）端点预测器而非轨迹预测器，速度场v=K-J由两者时间条件分歧涌现；该模型支持输运算子，通过多头脑代数操作实现组合控制，在CelebA-HQ 64×64上FID达7.5，且无损循环传输（LPIPS=0），支持可控插值等语义操作。",
    "tags": [
      "Deep Learning"
    ],
    "key_contributions": [
      "提出生成锚定场（GAF），通过学习独立噪声与数据端点预测器涌现速度场，实现支持组合控制的输运算子",
      "实现高质量样本生成（CelebA-HQ 64×64 FID7.5）及无损循环传输，支持可控插值、混合生成等语义操作"
    ],
    "processed_at": "2025-12-01T08:43:29.315836"
  },
  {
    "id": "2511.22619v1",
    "title": "AI Deception: Risks, Dynamics, and Controls",
    "abstract": "As intelligence increases, so does its shadow. AI deception, in which systems induce false beliefs to secure self-beneficial outcomes, has evolved from a speculative concern to an empirically demonstrated risk across language models, AI agents, and emerging frontier systems. This project provides a comprehensive and up-to-date overview of the AI deception field, covering its core concepts, methodologies, genesis, and potential mitigations. First, we identify a formal definition of AI deception, grounded in signaling theory from studies of animal deception. We then review existing empirical studies and associated risks, highlighting deception as a sociotechnical safety challenge. We organize the landscape of AI deception research as a deception cycle, consisting of two key components: deception emergence and deception treatment. Deception emergence reveals the mechanisms underlying AI deception: systems with sufficient capability and incentive potential inevitably engage in deceptive behaviors when triggered by external conditions. Deception treatment, in turn, focuses on detecting and addressing such behaviors. On deception emergence, we analyze incentive foundations across three hierarchical levels and identify three essential capability preconditions required for deception. We further examine contextual triggers, including supervision gaps, distributional shifts, and environmental pressures. On deception treatment, we conclude detection methods covering benchmarks and evaluation protocols in static and interactive settings. Building on the three core factors of deception emergence, we outline potential mitigation strategies and propose auditing approaches that integrate technical, community, and governance efforts to address sociotechnical challenges and future AI risks. To support ongoing work in this area, we release a living resource at www.deceptionsurvey.com.",
    "authors": [
      "Boyuan Chen",
      "Sitong Fang",
      "Jiaming Ji",
      "Yanxu Zhu",
      "Pengcheng Wen",
      "Jinzhou Wu",
      "Yingshui Tan",
      "Boren Zheng",
      "Mengying Yuan",
      "Wenqi Chen",
      "Donghai Hong",
      "Alex Qiu",
      "Xin Chen",
      "Jiayi Zhou",
      "Kaile Wang",
      "Juntao Dai",
      "Borong Zhang",
      "Tianzhuo Yang",
      "Saad Siddiqui",
      "Isabella Duan",
      "Yawen Duan",
      "Brian Tse",
      " Jen-Tse",
      " Huang",
      "Kun Wang",
      "Baihui Zheng",
      "Jiaheng Liu",
      "Jian Yang",
      "Yiming Li",
      "Wenting Chen",
      "Dongrui Liu",
      "Lukas Vierling",
      "Zhiheng Xi",
      "Haobo Fu",
      "Wenxuan Wang",
      "Jitao Sang",
      "Zhengyan Shi",
      "Chi-Min Chan",
      "Eugenie Shi",
      "Simin Li",
      "Juncheng Li",
      "Wei Ji",
      "Dong Li",
      "Jun Song",
      "Yinpeng Dong",
      "Jie Fu",
      "Bo Zheng",
      "Min Yang",
      "Yike Guo",
      "Philip Torr",
      "Zhongyuan Wang",
      "Yaodong Yang",
      "Tiejun Huang",
      "Ya-Qin Zhang",
      "Hongjiang Zhang",
      "Andrew Yao"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22619v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22619v1",
    "fetched_at": "2025-12-01T08:36:06.231952",
    "chinese_title": "AI欺骗：风险、动态与控制",
    "chinese_summary": "论文基于动物欺骗的信号理论提出AI欺骗的正式定义，构建包含欺骗出现（机制、激励、能力前提、触发条件）与处理（检测）的欺骗周期研究框架，梳理现有实证研究并分析AI欺骗作为社会技术安全挑战的风险。",
    "tags": [
      "LLM",
      "Risk Management",
      "Benchmark"
    ],
    "key_contributions": [
      "基于信号理论提出AI欺骗的正式定义，明确其核心内涵",
      "构建AI欺骗的“欺骗周期”框架，系统分析欺骗出现的机制与处理方法"
    ],
    "processed_at": "2025-12-01T08:43:41.258744"
  },
  {
    "id": "2511.22482v1",
    "title": "Exploring Performance Variations in Finetuned Translators of Ultra-Low Resource Languages: Do Linguistic Differences Matter?",
    "abstract": "Finetuning pre-trained language models with small amounts of data is a commonly-used method to create translators for ultra-low resource languages such as endangered Indigenous languages. However, previous works have reported substantially different performances with translators created using similar methodology and data. In this work we systematically explored possible causes of the performance difference, aiming to determine whether it was a product of different cleaning procedures, limitations of the pre-trained models, the size of the base model, or the size of the training dataset, studying both directions of translation. Our studies, using two Brazilian Indigenous languages, related but with significant structural linguistic characteristics, indicated none or very limited influence from those training factors, suggesting differences between languages may play a significant role in the ability to produce translators by fine-tuning pre-trained models.",
    "authors": [
      "Isabel Gonçalves",
      "Paulo Cavalin",
      "Claudio Pinhanez"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22482v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22482v1",
    "fetched_at": "2025-12-01T08:36:06.231973",
    "chinese_title": "探索超低资源语言微调翻译器的性能差异：语言差异是否重要？",
    "chinese_summary": "该研究系统探索超低资源语言微调翻译器性能差异的潜在原因（数据清洗、预训练模型限制、基础模型大小、训练数据集大小），以两种巴西土著语言为对象研究双向翻译；发现上述训练因素影响极小或有限，暗示语言差异对微调翻译器能力有显著作用。",
    "tags": [
      "LLM",
      "NLP",
      "Transformer"
    ],
    "key_contributions": [
      "系统排除训练因素对超低资源语言微调翻译器性能差异的主要影响",
      "揭示语言自身差异是影响其翻译能力的关键因素"
    ],
    "processed_at": "2025-12-01T08:43:48.415967"
  },
  {
    "id": "2511.22378v1",
    "title": "Predicting and Interpolating Spatiotemporal Environmental Data: A Case Study of Groundwater Storage in Bangladesh",
    "abstract": "Geospatial observational datasets are often limited to point measurements, making temporal prediction and spatial interpolation essential for constructing continuous fields. This study evaluates two deep learning strategies for addressing this challenge: (1) a grid-to-grid approach, where gridded predictors are used to model rasterised targets (aggregation before modelling), and (2) a grid-to-point approach, where gridded predictors model point targets, followed by kriging interpolation to fill the domain (aggregation after modelling). Using groundwater storage data from Bangladesh as a case study, we compare the effcacy of these approaches. Our findings indicate that spatial interpolation is substantially more difficult than temporal prediction. In particular, nearest neighbours are not always the most similar, and uncertainties in geology strongly influence point temporal behaviour. These insights motivate future work on advanced interpolation methods informed by clustering locations based on time series dynamics. Demonstrated on groundwater storage, the conclusions are applicable to other environmental variables governed by indirectly observable factors. Code is available at https://github.com/pazolka/interpolation-prediction-gwsa.",
    "authors": [
      "Anna Pazola",
      "Mohammad Shamsudduha",
      "Richard G. Taylor",
      "Allan Tucker"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22378v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22378v1",
    "fetched_at": "2025-12-01T08:36:06.231996",
    "chinese_title": "时空环境数据的预测与插值：以孟加拉国地下水储量为例",
    "chinese_summary": "本研究以孟加拉国地下水储量为案例，评估两种深度学习策略（网格到网格、网格到点）在时空环境数据预测与插值中的效果；发现空间插值难度显著高于时间预测，最近邻不一定最相似，地质不确定性影响点时间行为，提出基于时间序列动态聚类的先进插值方法方向，结论可推广至其他受间接可观测因素影响的环境变量。",
    "tags": [
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "揭示空间插值更难的核心原因，提出基于时间序列动态聚类的插值方法方向"
    ],
    "processed_at": "2025-12-01T08:43:59.119784"
  },
  {
    "id": "2511.22341v1",
    "title": "Unexplored flaws in multiple-choice VQA evaluations",
    "abstract": "Multimodal Large Language Models (MLLMs) demonstrate strong capabilities in handling image-text inputs. A common way to assess this ability is through multiple-choice Visual Question Answering (VQA). Earlier works have already revealed that these benchmarks are sensitive to answer choice order, a limitation that can be mitigated through careful design. Yet, we highlight additional, unexplored biases in prompt formatting that question the reliability of current MLLM evaluations. Specifically, we identify three key variation factors in prompt formatting and analyze their impact through a large-scale study involving $\\mathbf{\\text{seven}}$ MLLMs and $\\mathbf{\\text{five}}$ VQA datasets, spanning $\\mathbf{48}$ distinct $\\mathbf{\\text{prompt format variations}}$. Our findings reveal that multiple-choice VQA is highly sensitive to minor prompt format changes, even when these changes are semantically neutral. We further demonstrate that these biases persist independently of known order biases or the MLLM's confidence in the correct answer. Finally, we demonstrate that existing bias mitigation strategies fail to address these newly identified biases.",
    "authors": [
      "Fabio Rosenthal",
      "Sebastian Schmidt",
      "Thorsten Graf",
      "Thorsten Bagodonat",
      "Stephan Günnemann",
      "Leo Schwinn"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22341v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22341v1",
    "fetched_at": "2025-12-01T08:36:06.232023",
    "chinese_title": "多项选择视觉问答（VQA）评估中未被探索的缺陷",
    "chinese_summary": "该论文指出多项选择视觉问答（VQA）评估中存在未被探索的提示格式偏差，通过涵盖7个多模态大模型、5个VQA数据集及48种提示格式变化的大规模研究，发现即使语义中性的小格式调整也会显著影响评估结果，且这些偏差独立于已知的答案顺序偏差或模型对正确答案的置信度，现有缓解策略无法应对。",
    "tags": [
      "LLM",
      "Benchmark",
      "Deep Learning"
    ],
    "key_contributions": [
      "识别出多项选择VQA评估中未被探索的提示格式偏差，发现语义中性的小格式变化显著影响评估结果",
      "证明此类偏差独立于已知的答案顺序偏差或模型置信度，且现有缓解策略无法解决"
    ],
    "processed_at": "2025-12-01T08:44:13.959433"
  },
  {
    "id": "2511.22316v1",
    "title": "SingleQuant: Efficient Quantization of Large Language Models in a Single Pass",
    "abstract": "Large Language Models (LLMs) quantization facilitates deploying LLMs in resource-limited settings, but existing methods that combine incompatible gradient optimization and quantization truncation lead to serious convergence pathology. This prolongs quantization time and degrades LLMs' task performance. Our studies confirm that Straight-Through Estimator (STE) on Stiefel manifolds introduce non-smoothness and gradient noise, obstructing optimization convergence and blocking high-fidelity quantized LLM development despite extensive training. To tackle the above limitations, we propose SingleQuant, a single-pass quantization framework that decouples from quantization truncation, thereby eliminating the above non-smoothness and gradient noise factors. Specifically, SingleQuant constructs Alignment Rotation Transformation (ART) and Uniformity Rotation Transformation (URT) targeting distinct activation outliers, where ART achieves smoothing of outlier values via closed-form optimal rotations, and URT reshapes distributions through geometric mapping. Both matrices comprise strictly formulated Givens rotations with predetermined dimensions and rotation angles, enabling promising LLMs task performance within a short time. Experimental results demonstrate SingleQuant's superiority over the selected baselines across diverse tasks on 7B-70B LLMs. To be more precise, SingleQuant enables quantized LLMs to achieve higher task performance while necessitating less time for quantization. For example, when quantizing LLaMA-2-13B, SingleQuant achieves 1,400$\\times$ quantization speedup and increases +0.57\\% average task performance compared to the selected best baseline.",
    "authors": [
      "Jinying Xiao",
      "Bin Ji",
      "Shasha Li",
      "Xiaodong Liu",
      "Ma Jun",
      "Ye Zhong",
      "Wei Li",
      "Xuan Xie",
      "Qingbo Wu",
      "Jie Yu"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22316v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22316v1",
    "fetched_at": "2025-12-01T08:36:06.232056",
    "chinese_title": "",
    "chinese_summary": "",
    "tags": [
      "Deep Learning",
      "LLM"
    ],
    "key_contributions": [],
    "processed_at": "2025-12-01T08:44:25.572971"
  },
  {
    "id": "2511.22275v1",
    "title": "RecToM: A Benchmark for Evaluating Machine Theory of Mind in LLM-based Conversational Recommender Systems",
    "abstract": "Large Language models are revolutionizing the conversational recommender systems through their impressive capabilities in instruction comprehension, reasoning, and human interaction. A core factor underlying effective recommendation dialogue is the ability to infer and reason about users' mental states (such as desire, intention, and belief), a cognitive capacity commonly referred to as Theory of Mind. Despite growing interest in evaluating ToM in LLMs, current benchmarks predominantly rely on synthetic narratives inspired by Sally-Anne test, which emphasize physical perception and fail to capture the complexity of mental state inference in realistic conversational settings. Moreover, existing benchmarks often overlook a critical component of human ToM: behavioral prediction, the ability to use inferred mental states to guide strategic decision-making and select appropriate conversational actions for future interactions. To better align LLM-based ToM evaluation with human-like social reasoning, we propose RecToM, a novel benchmark for evaluating ToM abilities in recommendation dialogues. RecToM focuses on two complementary dimensions: Cognitive Inference and Behavioral Prediction. The former focus on understanding what has been communicated by inferring the underlying mental states. The latter emphasizes what should be done next, evaluating whether LLMs can leverage these inferred mental states to predict, select, and assess appropriate dialogue strategies. Extensive experiments on state-of-the-art LLMs demonstrate that RecToM poses a significant challenge. While the models exhibit partial competence in recognizing mental states, they struggle to maintain coherent, strategic ToM reasoning throughout dynamic recommendation dialogues, particularly in tracking evolving intentions and aligning conversational strategies with inferred mental states.",
    "authors": [
      "Mengfan Li",
      "Xuanhua Shi",
      "Yang Deng"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22275v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22275v1",
    "fetched_at": "2025-12-01T08:36:06.232076",
    "chinese_title": "RecToM：基于大语言模型的对话推荐系统中机器心智理论评估的基准",
    "chinese_summary": "现有机器心智理论（ToM）评估基准多依赖Sally-Anne测试类合成叙事，未覆盖真实对话的心智推理复杂度且忽略行为预测能力；本文提出RecToM基准，从认知推理（推断用户心理状态）和行为预测（用心理状态选对话策略）两个维度评估LLM在对话推荐中的ToM能力。",
    "tags": [
      "LLM",
      "NLP",
      "Benchmark"
    ],
    "key_contributions": [
      "揭示现有ToM评估基准的缺陷：依赖合成叙事（未反映真实对话心智推理复杂度）、忽略行为预测这一人类ToM关键组件",
      "提出RecToM基准，从认知推理和行为预测互补维度，评估LLM在对话推荐场景中的ToM能力"
    ],
    "processed_at": "2025-12-01T08:44:35.314299"
  },
  {
    "id": "2511.23260v1",
    "title": "Time Series Forecasting via Direct Per-Step Probability Distribution Modeling",
    "abstract": "Deep neural network-based time series prediction models have recently demonstrated superior capabilities in capturing complex temporal dependencies. However, it is challenging for these models to account for uncertainty associated with their predictions, because they directly output scalar values at each time step. To address such a challenge, we propose a novel model named interleaved dual-branch Probability Distribution Network (interPDN), which directly constructs discrete probability distributions per step instead of a scalar. The regression output at each time step is derived by computing the expectation of the predictive distribution on a predefined support set. To mitigate prediction anomalies, a dual-branch architecture is introduced with interleaved support sets, augmented by coarse temporal-scale branches for long-term trend forecasting. Outputs from another branch are treated as auxiliary signals to impose self-supervised consistency constraints on the current branch's prediction. Extensive experiments on multiple real-world datasets demonstrate the superior performance of interPDN.",
    "authors": [
      "Linghao Kong",
      "Xiaopeng Hong"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.23260v1",
    "arxiv_url": "https://arxiv.org/abs/2511.23260v1",
    "fetched_at": "2025-12-01T08:36:12.738417",
    "chinese_title": "基于每步概率分布直接建模的时间序列预测",
    "chinese_summary": "现有深度时间序列模型直接输出标量难以处理预测不确定性，本文提出interPDN模型，每步直接构建离散概率分布并以其期望作为回归输出；采用双分支交织支持集架构（含粗时间尺度分支），结合自监督一致性约束缓解预测异常，实验验证其性能更优。",
    "tags": [
      "Deep Learning",
      "Time Series",
      "Risk Management",
      "Anomaly"
    ],
    "key_contributions": [
      "提出interPDN模型，每步直接建模离散概率分布而非标量，解决预测不确定性问题",
      "设计双分支交织架构（含粗时间尺度分支）并引入自监督一致性约束，缓解预测异常并提升长期趋势预测能力"
    ],
    "processed_at": "2025-12-01T08:44:45.541855"
  },
  {
    "id": "2511.22078v1",
    "title": "ARES: Anomaly Recognition Model For Edge Streams",
    "abstract": "Many real-world scenarios involving streaming information can be represented as temporal graphs, where data flows through dynamic changes in edges over time. Anomaly detection in this context has the objective of identifying unusual temporal connections within the graph structure. Detecting edge anomalies in real time is crucial for mitigating potential risks. Unlike traditional anomaly detection, this task is particularly challenging due to concept drifts, large data volumes, and the need for real-time response. To face these challenges, we introduce ARES, an unsupervised anomaly detection framework for edge streams. ARES combines Graph Neural Networks (GNNs) for feature extraction with Half-Space Trees (HST) for anomaly scoring. GNNs capture both spike and burst anomalous behaviors within streams by embedding node and edge properties in a latent space, while HST partitions this space to isolate anomalies efficiently. ARES operates in an unsupervised way without the need for prior data labeling. To further validate its detection capabilities, we additionally incorporate a simple yet effective supervised thresholding mechanism. This approach leverages statistical dispersion among anomaly scores to determine the optimal threshold using a minimal set of labeled data, ensuring adaptability across different domains. We validate ARES through extensive evaluations across several real-world cyber-attack scenarios, comparing its performance against existing methods while analyzing its space and time complexity.",
    "authors": [
      "Simone Mungari",
      "Albert Bifet",
      "Giuseppe Manco",
      "Bernhard Pfahringer"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22078v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22078v1",
    "fetched_at": "2025-12-01T08:36:12.738453",
    "chinese_title": "ARES：边缘流的异常识别模型",
    "chinese_summary": "针对边缘流异常检测面临的概念漂移、大数据量及实时响应挑战，论文提出无监督框架ARES，结合图神经网络（GNN）提取节点与边的潜在特征以捕捉异常行为，半空间树（HST）高效隔离异常；并加入基于少量标记数据的监督阈值机制提升跨领域适应性，在真实网络攻击场景验证其优于现有方法。",
    "tags": [
      "Anomaly",
      "Graph Neural Network",
      "Deep Learning",
      "Risk Management"
    ],
    "key_contributions": [
      "提出无监督异常检测框架ARES，融合GNN特征提取与HST异常评分，适配边缘流异常检测的实时性与动态性需求",
      "设计基于少量标记数据的监督阈值机制，利用异常分数统计离散度确定最优阈值，增强跨领域适应性"
    ],
    "processed_at": "2025-12-01T08:44:59.305843"
  },
  {
    "id": "2511.21932v1",
    "title": "Modeling Quantum Autoencoder Trainable Kernel for IoT Anomaly Detection",
    "abstract": "Escalating cyber threats and the high-dimensional complexity of IoT traffic have outpaced classical anomaly detection methods. While deep learning offers improvements, computational bottlenecks limit real-time deployment at scale. We present a quantum autoencoder (QAE) framework that compresses network traffic into discriminative latent representations and employs quantum support vector classification (QSVC) for intrusion detection. Evaluated on three datasets, our approach achieves improved accuracy on ideal simulators and on the IBM Quantum hardware demonstrating practical quantum advantage on current NISQ devices. Crucially, moderate depolarizing noise acts as implicit regularization, stabilizing training and enhancing generalization. This work establishes quantum machine learning as a viable, hardware-ready solution for real-world cybersecurity challenges.",
    "authors": [
      "Swathi Chandrasekhar",
      "Shiva Raj Pokhrel",
      "Swati Kumari",
      "Navneet Singh"
    ],
    "published": "2025-11-26",
    "categories": [
      "cs.LG",
      "quant-ph"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.21932v1",
    "arxiv_url": "https://arxiv.org/abs/2511.21932v1",
    "fetched_at": "2025-12-01T08:36:12.738488",
    "chinese_title": "用于物联网异常检测的量子自动编码器可训练核建模",
    "chinese_summary": "本文针对物联网流量高维复杂与网络威胁加剧的问题，提出量子自动编码器（QAE）框架压缩流量为判别性潜在表示，结合量子支持向量分类（QSVC）实现入侵检测；在理想模拟器及IBM量子硬件上验证了方法的准确率提升，且中等退极化噪声可作为隐正则化稳定训练并增强泛化，证明量子机器学习是应对实际网络安全挑战的可行硬件就绪方案。",
    "tags": [
      "Anomaly",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出量子自动编码器（QAE）结合量子支持向量分类（QSVC）的物联网异常检测框架，在理想模拟器及IBM量子硬件上实现准确率提升",
      "发现中等退极化噪声可作为隐正则化稳定训练并增强模型泛化，证明量子机器学习是应对实际网络安全挑战的可行硬件就绪方案"
    ],
    "processed_at": "2025-12-01T08:45:17.392088"
  },
  {
    "id": "2511.21842v1",
    "title": "Unsupervised Anomaly Detection for Smart IoT Devices: Performance and Resource Comparison",
    "abstract": "The rapid expansion of Internet of Things (IoT) deployments across diverse sectors has significantly enhanced operational efficiency, yet concurrently elevated cybersecurity vulnerabilities due to increased exposure to cyber threats. Given the limitations of traditional signature-based Anomaly Detection Systems (ADS) in identifying emerging and zero-day threats, this study investigates the effectiveness of two unsupervised anomaly detection techniques, Isolation Forest (IF) and One-Class Support Vector Machine (OC-SVM), using the TON_IoT thermostat dataset. A comprehensive evaluation was performed based on standard metrics (accuracy, precision, recall, and F1-score) alongside critical resource utilization metrics such as inference time, model size, and peak RAM usage. Experimental results revealed that IF consistently outperformed OC-SVM, achieving higher detection accuracy, superior precision, and recall, along with a significantly better F1-score. Furthermore, Isolation Forest demonstrated a markedly superior computational footprint, making it more suitable for deployment on resource-constrained IoT edge devices. These findings underscore Isolation Forest's robustness in high-dimensional and imbalanced IoT environments and highlight its practical viability for real-time anomaly detection.",
    "authors": [
      "Md. Sad Abdullah Sami",
      "Mushfiquzzaman Abid"
    ],
    "published": "2025-11-26",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.21842v1",
    "arxiv_url": "https://arxiv.org/abs/2511.21842v1",
    "fetched_at": "2025-12-01T08:36:12.738508",
    "chinese_title": "智能物联网设备的无监督异常检测：性能与资源对比",
    "chinese_summary": "论文针对传统签名-based异常检测无法识别新兴及零日威胁的问题，采用TON_IoT恒温器数据集，对比孤立森林（IF）与一类支持向量机（OC-SVM）两种无监督方法的检测性能及资源占用；结果显示IF在检测指标和计算资源上更优，适合资源受限的IoT边缘设备部署。",
    "tags": [
      "Anomaly"
    ],
    "key_contributions": [
      "系统对比两种无监督异常检测方法在IoT设备场景下的性能与资源利用效率",
      "验证孤立森林在高维、不平衡IoT环境中的鲁棒性及边缘设备部署的实用性"
    ],
    "processed_at": "2025-12-01T08:45:30.106322"
  },
  {
    "id": "2511.23148v1",
    "title": "Peer-to-Peer Energy Trading in Dairy Farms using Multi-Agent Reinforcement Learning",
    "abstract": "The integration of renewable energy resources in rural areas, such as dairy farming communities, enables decentralized energy management through Peer-to-Peer (P2P) energy trading. This research highlights the role of P2P trading in efficient energy distribution and its synergy with advanced optimization techniques. While traditional rule-based methods perform well under stable conditions, they struggle in dynamic environments. To address this, Multi-Agent Reinforcement Learning (MARL), specifically Proximal Policy Optimization (PPO) and Deep Q-Networks (DQN), is combined with community/distributed P2P trading mechanisms. By incorporating auction-based market clearing, a price advisor agent, and load and battery management, the approach achieves significant improvements. Results show that, compared to baseline models, DQN reduces electricity costs by 14.2% in Ireland and 5.16% in Finland, while increasing electricity revenue by 7.24% and 12.73%, respectively. PPO achieves the lowest peak hour demand, reducing it by 55.5% in Ireland, while DQN reduces peak hour demand by 50.0% in Ireland and 27.02% in Finland. These improvements are attributed to both MARL algorithms and P2P energy trading, which together results in electricity cost and peak hour demand reduction, and increase electricity selling revenue. This study highlights the complementary strengths of DQN, PPO, and P2P trading in achieving efficient, adaptable, and sustainable energy management in rural communities.",
    "authors": [
      "Mian Ibad Ali Shah",
      "Marcos Eduardo Cruz Victorio",
      "Maeve Duffy",
      "Enda Barrett",
      "Karl Mason"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.23148v1",
    "arxiv_url": "https://arxiv.org/abs/2511.23148v1",
    "fetched_at": "2025-12-01T08:36:22.523466",
    "chinese_title": "奶牛场中基于多智能体强化学习的点对点能源交易",
    "chinese_summary": "论文针对农村奶牛场的分散能源管理问题，提出结合多智能体强化学习（含DQN和PPO）与P2P能源交易机制的方法，通过拍卖清结算、价格顾问代理及负荷/电池管理，显著降低爱尔兰和芬兰奶牛场的用电成本（DQN分别降14.2%和5.16%）、峰时需求（PPO在爱尔兰降55.5%）并提升售电收益，验证了MARL与P2P交易的互补优势。",
    "tags": [
      "Reinforcement Learning",
      "Financial Agent"
    ],
    "key_contributions": [
      "提出结合多智能体强化学习（DQN、PPO）与P2P能源交易的方法，适配农村奶牛场动态能源环境",
      "实证表明该方法显著降低用电成本、峰时需求并提升售电收益，验证MARL与P2P交易的互补性"
    ],
    "processed_at": "2025-12-01T08:45:40.551969"
  },
  {
    "id": "2511.22793v1",
    "title": "GSpaRC: Gaussian Splatting for Real-time Reconstruction of RF Channels",
    "abstract": "Channel state information (CSI) is essential for adaptive beamforming and maintaining robust links in wireless communication systems. However, acquiring CSI incurs significant overhead, consuming up to 25\\% of spectrum resources in 5G networks due to frequent pilot transmissions at sub-millisecond intervals. Recent approaches aim to reduce this burden by reconstructing CSI from spatiotemporal RF measurements, such as signal strength and direction-of-arrival. While effective in offline settings, these methods often suffer from inference latencies in the 5--100~ms range, making them impractical for real-time systems. We present GSpaRC: Gaussian Splatting for Real-time Reconstruction of RF Channels, the first algorithm to break the 1 ms latency barrier while maintaining high accuracy. GSpaRC represents the RF environment using a compact set of 3D Gaussian primitives, each parameterized by a lightweight neural model augmented with physics-informed features such as distance-based attenuation. Unlike traditional vision-based splatting pipelines, GSpaRC is tailored for RF reception: it employs an equirectangular projection onto a hemispherical surface centered at the receiver to reflect omnidirectional antenna behavior. A custom CUDA pipeline enables fully parallelized directional sorting, splatting, and rendering across frequency and spatial dimensions. Evaluated on multiple RF datasets, GSpaRC achieves similar CSI reconstruction fidelity to recent state-of-the-art methods while reducing training and inference time by over an order of magnitude. By trading modest GPU computation for a substantial reduction in pilot overhead, GSpaRC enables scalable, low-latency channel estimation suitable for deployment in 5G and future wireless systems. The code is available here: \\href{https://github.com/Nbhavyasai/GSpaRC-WirelessGaussianSplatting.git}{GSpaRC}.",
    "authors": [
      "Bhavya Sai Nukapotula",
      "Rishabh Tripathi",
      "Seth Pregler",
      "Dileep Kalathil",
      "Srinivas Shakkottai",
      "Theodore S. Rappaport"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22793v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22793v1",
    "fetched_at": "2025-12-01T08:36:32.250069",
    "chinese_title": "GSpaRC：用于实时射频信道重建的高斯喷溅方法",
    "chinese_summary": "针对无线通信中信道状态信息（CSI）获取开销大且现有重建方法延迟较高的问题，提出GSpaRC算法，首次突破1ms延迟屏障并保持高精度；该算法采用带距离衰减等物理特征的轻量神经模型参数化3D高斯基元表示射频环境，通过等距投影模拟全向天线，自定义CUDA pipeline实现多维度并行处理以提升实时性。",
    "tags": [
      "Deep Learning",
      "High Frequency"
    ],
    "key_contributions": [
      "提出GSpaRC算法，首次实现低于1ms延迟的实时射频信道CSI重建，精度与现有SOTA相当；",
      "设计针对射频接收的3D高斯基元表示（含物理特征）及等距投影方法，结合自定义CUDA pipeline实现高效并行处理。"
    ],
    "processed_at": "2025-12-01T08:45:56.919978"
  },
  {
    "id": "2511.23442v1",
    "title": "ASTRO: Adaptive Stitching via Dynamics-Guided Trajectory Rollouts",
    "abstract": "Offline reinforcement learning (RL) enables agents to learn optimal policies from pre-collected datasets. However, datasets containing suboptimal and fragmented trajectories present challenges for reward propagation, resulting in inaccurate value estimation and degraded policy performance. While trajectory stitching via generative models offers a promising solution, existing augmentation methods frequently produce trajectories that are either confined to the support of the behavior policy or violate the underlying dynamics, thereby limiting their effectiveness for policy improvement. We propose ASTRO, a data augmentation framework that generates distributionally novel and dynamics-consistent trajectories for offline RL. ASTRO first learns a temporal-distance representation to identify distinct and reachable stitch targets. We then employ a dynamics-guided stitch planner that adaptively generates connecting action sequences via Rollout Deviation Feedback, defined as the gap between target state sequence and the actual arrived state sequence by executing predicted actions, to improve trajectory stitching's feasibility and reachability. This approach facilitates effective augmentation through stitching and ultimately enhances policy learning. ASTRO outperforms prior offline RL augmentation methods across various algorithms, achieving notable performance gain on the challenging OGBench suite and demonstrating consistent improvements on standard offline RL benchmarks such as D4RL.",
    "authors": [
      "Hang Yu",
      "Di Zhang",
      "Qiwei Du",
      "Yanping Zhao",
      "Hai Zhang",
      "Guang Chen",
      "Eduardo E. Veas",
      "Junqiao Zhao"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.23442v1",
    "arxiv_url": "https://arxiv.org/abs/2511.23442v1",
    "fetched_at": "2025-12-01T08:36:42.040787",
    "chinese_title": "ASTRO：基于动力学引导轨迹滚动的自适应拼接",
    "chinese_summary": "针对离线强化学习中次优碎片化轨迹导致的奖励传播困难问题，论文提出ASTRO数据增强框架，通过学习时间距离表示识别可到达拼接目标，结合动力学引导规划器与滚动偏差反馈生成符合动力学的新轨迹，有效提升离线RL策略性能，在OGBench和D4RL等基准上优于现有方法。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "提出ASTRO数据增强框架，生成分布新颖且符合动力学的轨迹以解决离线RL次优碎片化轨迹的奖励传播难题",
      "设计动力学引导的拼接规划器，通过滚动偏差反馈提升轨迹拼接的可行性与可达性，在多基准上表现更优"
    ],
    "processed_at": "2025-12-01T08:46:12.088344"
  },
  {
    "id": "2511.23440v1",
    "title": "Accelerated Execution of Bayesian Neural Networks using a Single Probabilistic Forward Pass and Code Generation",
    "abstract": "Machine learning models perform well across domains such as diagnostics, weather forecasting, NLP, and autonomous driving, but their limited uncertainty handling restricts use in safety-critical settings. Traditional neural networks often fail to detect out-of-domain (OOD) data and may output confident yet incorrect predictions. Bayesian neural networks (BNNs) address this by providing probabilistic estimates, but incur high computational cost because predictions require sampling weight distributions and multiple forward passes. The Probabilistic Forward Pass (PFP) offers a highly efficient approximation to Stochastic Variational Inference (SVI) by assuming Gaussian-distributed weights and activations, enabling fully analytic uncertainty propagation and replacing sampling with a single deterministic forward pass. We present an end-to-end pipeline for training, compiling, optimizing, and deploying PFP-based BNNs on embedded ARM CPUs. Using the TVM deep learning compiler, we implement a dedicated library of Gaussian-propagating operators for multilayer perceptrons and convolutional neural networks, combined with manual and automated tuning strategies. Ablation studies show that PFP consistently outperforms SVI in computational efficiency, achieving speedups of up to 4200x for small mini-batches. PFP-BNNs match SVI-BNNs on Dirty-MNIST in accuracy, uncertainty estimation, and OOD detection while greatly reducing compute cost. These results highlight the potential of combining Bayesian approximations with code generation to enable efficient BNN deployment on resource-constrained systems.",
    "authors": [
      "Bernhard Klein",
      "Falk Selker",
      "Hendrik Borras",
      "Sophie Steger",
      "Franz Pernkopf",
      "Holger Fröning"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.LG",
      "cs.AR",
      "cs.DC",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.23440v1",
    "arxiv_url": "https://arxiv.org/abs/2511.23440v1",
    "fetched_at": "2025-12-01T08:36:42.040822",
    "chinese_title": "基于单次概率前向传播和代码生成的贝叶斯神经网络加速执行",
    "chinese_summary": "该论文针对贝叶斯神经网络（BNN）因多次采样导致计算成本高的问题，提出基于单次概率前向传播（PFP）的方法——假设权重和激活为高斯分布，用单次确定性前向传播替代随机变分推断（SVI）的多次采样；结合TVM深度学习编译器实现端到端训练、编译优化及嵌入式ARM CPU部署 pipeline，实验表明PFP-BNN在小批量下最高可实现4200x加速，且在Dirty-MNIST任务的准确率、不确定性估计和OOD检测上与SVI-BNN相当。",
    "tags": [
      "Deep Learning",
      "Execution"
    ],
    "key_contributions": [
      "提出基于单次概率前向传播（PFP）的BNN近似方法，通过高斯分布假设将多次采样的SVI推断转化为单次确定性前向传播，大幅降低计算成本",
      "构建端到端的PFP-BNN训练、编译优化及嵌入式ARM CPU部署 pipeline，实验验证其在效率和性能上的优势，为安全关键场景下BNN的高效部署提供支持"
    ],
    "processed_at": "2025-12-01T08:46:42.355583"
  },
  {
    "id": "2511.23408v1",
    "title": "Evaluating LLMs for One-Shot Patching of Real and Artificial Vulnerabilities",
    "abstract": "Automated vulnerability patching is crucial for software security, and recent advancements in Large Language Models (LLMs) present promising capabilities for automating this task. However, existing research has primarily assessed LLMs using publicly disclosed vulnerabilities, leaving their effectiveness on related artificial vulnerabilities largely unexplored. In this study, we empirically evaluate the patching effectiveness and complementarity of several prominent LLMs, such as OpenAI's GPT variants, LLaMA, DeepSeek, and Mistral models, using both real and artificial vulnerabilities. Our evaluation employs Proof-of-Vulnerability (PoV) test execution to concretely assess whether LLM-generated source code successfully patches vulnerabilities. Our results reveal that LLMs patch real vulnerabilities more effectively compared to artificial ones. Additionally, our analysis reveals significant variability across LLMs in terms of overlapping (multiple LLMs patching the same vulnerabilities) and complementarity (vulnerabilities patched exclusively by a single LLM), emphasizing the importance of selecting appropriate LLMs for effective vulnerability patching.",
    "authors": [
      "Aayush Garg",
      "Zanis Ali Khan",
      "Renzo Degiovanni",
      "Qiang Tang"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.23408v1",
    "arxiv_url": "https://arxiv.org/abs/2511.23408v1",
    "fetched_at": "2025-12-01T08:36:42.040847",
    "chinese_title": "评估大语言模型对真实与人工漏洞的一次性修补能力",
    "chinese_summary": "本研究采用漏洞证明（PoV）测试执行方法，评估GPT系列、LLaMA等主流大语言模型（LLM）对真实与人工漏洞的一次性修补效果；结果显示LLM修补真实漏洞的有效性高于人工漏洞，且不同LLM存在显著重叠与互补性，强调选择合适LLM的重要性。",
    "tags": [
      "LLM",
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "系统评估主流LLM对真实与人工漏洞的一次性修补效果，发现真实漏洞修补有效性显著更高",
      "揭示不同LLM存在显著的重叠与互补性，为漏洞修补场景的LLM选择提供依据"
    ],
    "processed_at": "2025-12-01T08:46:56.753067"
  },
  {
    "id": "2511.23239v1",
    "title": "Towards Understanding Transformers in Learning Random Walks",
    "abstract": "Transformers have proven highly effective across various applications, especially in handling sequential data such as natural languages and time series. However, transformer models often lack clear interpretability, and the success of transformers has not been well understood in theory. In this paper, we study the capability and interpretability of transformers in learning a family of classic statistical models, namely random walks on circles. We theoretically demonstrate that, after training with gradient descent, a one-layer transformer model can achieve optimal accuracy in predicting random walks. Importantly, our analysis reveals that the trained model is interpretable: the trained softmax attention serves as a token selector, focusing on the direct parent state; subsequently, the value matrix executes a one-step probability transition to predict the location of the next state based on this parent state. We also show that certain edge cases not covered by our theory are indeed failure cases, demonstrating that our theoretical conditions are tight. By investigating these success and failure cases, it is revealed that gradient descent with small initialization may fail or struggle to converge to a good solution in certain simple tasks even beyond random walks. Experiments are conducted to support our theoretical findings.",
    "authors": [
      "Wei Shi",
      "Yuan Cao"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.23239v1",
    "arxiv_url": "https://arxiv.org/abs/2511.23239v1",
    "fetched_at": "2025-12-01T08:36:42.040894",
    "chinese_title": "理解Transformer学习随机游走的能力与可解释性",
    "chinese_summary": "本文探究Transformer学习圆上随机游走的能力与可解释性，理论证明单层Transformer经梯度下降训练可最优预测随机游走，且训练后的注意力为聚焦父状态的token选择器、值矩阵基于父状态做一步转移预测；同时分析理论未覆盖的失败案例验证条件紧性，实验支持理论结论。",
    "tags": [
      "Transformer",
      "Time Series",
      "Deep Learning"
    ],
    "key_contributions": [
      "理论证明单层Transformer经梯度下降训练可最优预测圆上随机游走",
      "揭示训练后的Transformer具有可解释性：注意力聚焦父状态，值矩阵执行一步转移预测"
    ],
    "processed_at": "2025-12-01T08:47:09.859237"
  },
  {
    "id": "2511.23143v1",
    "title": "Automated Generation of MDPs Using Logic Programming and LLMs for Robotic Applications",
    "abstract": "We present a novel framework that integrates Large Language Models (LLMs) with automated planning and formal verification to streamline the creation and use of Markov Decision Processes (MDP). Our system leverages LLMs to extract structured knowledge in the form of a Prolog knowledge base from natural language (NL) descriptions. It then automatically constructs an MDP through reachability analysis, and synthesises optimal policies using the Storm model checker. The resulting policy is exported as a state-action table for execution. We validate the framework in three human-robot interaction scenarios, demonstrating its ability to produce executable policies with minimal manual effort. This work highlights the potential of combining language models with formal methods to enable more accessible and scalable probabilistic planning in robotics.",
    "authors": [
      "Enrico Saccon",
      "Davide De Martini",
      "Matteo Saveriano",
      "Edoardo Lamon",
      "Luigi Palopoli",
      "Marco Roveri"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.23143v1",
    "arxiv_url": "https://arxiv.org/abs/2511.23143v1",
    "fetched_at": "2025-12-01T08:36:42.040960",
    "chinese_title": "基于逻辑编程与大语言模型的机器人应用马尔可夫决策过程自动生成",
    "chinese_summary": "论文提出整合大语言模型（LLM）与自动规划、形式验证的框架，从自然语言描述中提取Prolog知识库，经可达性分析自动构建MDP并通过Storm模型检查器综合最优策略；在三个人机交互场景验证，证明该框架能以低人工成本生成可执行策略，凸显语言模型与形式方法结合对机器人概率规划的价值。",
    "tags": [
      "LLM",
      "NLP",
      "Reinforcement Learning"
    ],
    "key_contributions": [
      "提出整合LLM、自动规划与形式验证的MDP自动生成框架，实现从自然语言到可执行策略的端到端流程",
      "在机器人场景验证该框架可低人工成本生成最优可执行策略，拓展语言模型与形式方法结合的应用潜力"
    ],
    "processed_at": "2025-12-01T08:47:18.560230"
  },
  {
    "id": "2511.22963v1",
    "title": "Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary",
    "abstract": "Enabling humanoid robots to follow free-form language commands is critical for seamless human-robot interaction, collaborative task execution, and general-purpose embodied intelligence. While recent advances have improved low-level humanoid locomotion and robot manipulation, language-conditioned whole-body control remains a significant challenge. Existing methods are often limited to simple instructions and sacrifice either motion diversity or physical plausibility. To address this, we introduce Humanoid-LLA, a Large Language Action Model that maps expressive language commands to physically executable whole-body actions for humanoid robots. Our approach integrates three core components: a unified motion vocabulary that aligns human and humanoid motion primitives into a shared discrete space; a vocabulary-directed controller distilled from a privileged policy to ensure physical feasibility; and a physics-informed fine-tuning stage using reinforcement learning with dynamics-aware rewards to enhance robustness and stability. Extensive evaluations in simulation and on a real-world Unitree G1 humanoid show that Humanoid-LLA delivers strong language generalization while maintaining high physical fidelity, outperforming existing language-conditioned controllers in motion naturalness, stability, and execution success rate.",
    "authors": [
      "Zhirui Liu",
      "Kaiyang Ji",
      "Ke Yang",
      "Jingyi Yu",
      "Ye Shi",
      "Jingya Wang"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22963v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22963v1",
    "fetched_at": "2025-12-01T08:36:42.041013",
    "chinese_title": "通过自由文本语言指令控制人形机器人：带统一运动词汇表的大语言动作模型",
    "chinese_summary": "论文针对人形机器人语言条件全身控制的挑战，提出Humanoid-LLA模型，整合统一运动词汇表（对齐人类与人形运动基元）、词汇导向控制器（蒸馏特权策略确保物理可行性）及物理感知强化学习微调（动力学感知奖励增强鲁棒性）；在模拟与真实Unitree G1机器人上验证，模型语言泛化与物理保真度优于现有方法。",
    "tags": [
      "LLM",
      "Reinforcement Learning",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出Humanoid-LLA模型，实现自由文本语言指令到人形机器人可执行全身动作的映射，整合统一运动词汇表、物理可行性保障与鲁棒性微调模块",
      "在模拟与真实场景中验证，模型在语言泛化、物理保真度、运动自然性及执行成功率上优于现有语言条件控制器"
    ],
    "processed_at": "2025-12-01T08:47:32.727796"
  },
  {
    "id": "2511.22880v1",
    "title": "Serving Heterogeneous LoRA Adapters in Distributed LLM Inference Systems",
    "abstract": "Low-Rank Adaptation (LoRA) has become the de facto method for parameter-efficient fine-tuning of large language models (LLMs), enabling rapid adaptation to diverse domains. In production, LoRA-based models are served at scale, creating multi-tenant environments with hundreds of adapters sharing a base model. However, state-of-the-art serving systems co-batch heterogeneous adapters without accounting for rank (size) variability, leading to severe performance skew, which ultimately requires adding more GPUs to satisfy service-level objectives (SLOs). Existing optimizations, focused on loading, caching, and kernel execution, ignore this heterogeneity, leaving GPU resources underutilized. We present LoRAServe, a workload-aware dynamic adapter placement and routing framework designed to tame rank diversity in LoRA serving. By dynamically rebalancing adapters across GPUs and leveraging GPU Direct RDMA for remote access, LoRAServe maximizes throughput and minimizes tail latency under real-world workload drift. Evaluations on production traces from Company X show that LoRAServe elicits up to 2$\\times$ higher throughput, up to 9$\\times$ lower TTFT, while using up to 50% fewer GPUs under SLO constraints compared to state-of-the-art systems.",
    "authors": [
      "Shashwat Jaiswal",
      "Shrikara Arun",
      "Anjaly Parayil",
      "Ankur Mallick",
      "Spyros Mastorakis",
      "Alind Khare",
      "Chloi Alverti",
      "Renee St Amant",
      "Chetan Bansal",
      "Victor Rühle",
      "Josep Torrellas"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22880v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22880v1",
    "fetched_at": "2025-12-01T08:36:42.041049",
    "chinese_title": "分布式大语言模型推理系统中异构LoRA适配器的服务",
    "chinese_summary": "针对现有LLM推理系统服务异构LoRA适配器时因rank差异导致的性能 skew 和GPU资源利用率低问题，提出LoRAServe框架，通过动态跨GPU平衡适配器并结合GPU Direct RDMA远程访问，在满足SLO下提升吞吐量、降低尾延迟并减少GPU使用量。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出LoRAServe动态适配器放置与路由框架，解决异构LoRA服务的性能 skew 及资源利用不足问题",
      "基于生产traces验证，相比现有系统最高提升2×吞吐量、降低9×TTFT，最多减少50% GPU使用量"
    ],
    "processed_at": "2025-12-01T08:47:46.502715"
  },
  {
    "id": "2511.22861v1",
    "title": "Escaping Barren Plateaus in Variational Quantum Algorithms Using Negative Learning Rate in Quantum Internet of Things",
    "abstract": "Variational Quantum Algorithms (VQAs) are becoming the primary computational primitive for next-generation quantum computers, particularly those embedded as resource-constrained accelerators in the emerging Quantum Internet of Things (QIoT). However, under such device-constrained execution conditions, the scalability of learning is severely limited by barren plateaus, where gradients collapse to zero and training stalls. This poses a practical challenge to delivering VQA-enabled intelligence on QIoT endpoints, which often have few qubits, constrained shot budgets, and strict latency requirements. In this paper, we present a novel approach for escaping barren plateaus by including negative learning rates into the optimization process in QIoT devices. Our method introduces controlled instability into model training by switching between positive and negative learning phases, allowing recovery of significant gradients and exploring flatter areas in the loss landscape. We theoretically evaluate the effect of negative learning on gradient variance and propose conditions under which it helps escape from barren zones. The experimental findings on typical VQA benchmarks show consistent improvements in both convergence and simulation results over traditional optimizers. By escaping barren plateaus, our approach leads to a novel pathway for robust optimization in quantum-classical hybrid models.",
    "authors": [
      "Ratun Rahman",
      "Dinh C. Nguyen"
    ],
    "published": "2025-11-28",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22861v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22861v1",
    "fetched_at": "2025-12-01T08:36:42.041068",
    "chinese_title": "利用负学习率逃离量子物联网中变分量子算法的贫瘠高原",
    "chinese_summary": "针对量子物联网中变分量子算法因贫瘠高原（梯度坍塌）导致学习可扩展性受限的问题，论文提出引入负学习率的优化方法，通过正负学习阶段切换引入可控不稳定性以恢复显著梯度、探索平坦损失区域；理论分析负学习率对梯度方差的影响及逃离条件，实验验证其收敛性和模拟结果优于传统优化器，为量子-经典混合模型提供鲁棒优化新路径。",
    "tags": [
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "提出量子物联网变分量子算法优化中引入负学习率的方法，通过正负学习阶段切换引入可控不稳定性以逃离贫瘠高原",
      "理论分析负学习率对梯度方差的影响及逃离贫瘠区域的条件，实验验证方法收敛性和模拟结果优于传统优化器"
    ],
    "processed_at": "2025-12-01T08:48:10.049759"
  },
  {
    "id": "2511.22788v1",
    "title": "PRISM: Privacy-Aware Routing for Adaptive Cloud-Edge LLM Inference via Semantic Sketch Collaboration",
    "abstract": "Large Language Models (LLMs) demonstrate impressive capabilities in natural language understanding and generation, but incur high communication overhead and privacy risks in cloud deployments, while facing compute and memory constraints when confined to edge devices. Cloud-edge inference has emerged as a promising paradigm for improving privacy in LLM services by retaining sensitive computations on local devices. However, existing cloud-edge inference approaches apply uniform privacy protection without considering input sensitivity, resulting in unnecessary perturbation and degraded utility even for non-sensitive tokens. To address this limitation, we propose Privacy-aware Routing for Inference with Semantic Modulation (PRISM), a context-aware framework that dynamically balances privacy and inference quality. PRISM executes in four stages: (1) the edge device profiles entity-level sensitivity; (2) a soft gating module on the edge selects an execution mode - cloud, edge, or collaboration; (3) for collaborative paths, the edge applies adaptive two-layer local differential privacy based on entity risks; and (4) the cloud LLM generates a semantic sketch from the perturbed prompt, which is then refined by the edge-side small language model (SLM) using local context. Our results show that PRISM consistently achieves superior privacy-utility trade-offs across various scenarios, reducing energy consumption and latency to 40-50% of baseline methods such as Uniform and Selective LDP, while maintaining high output quality under strong privacy constraints. These findings are validated through comprehensive evaluations involving realistic prompts, actual energy measurements, and heterogeneous cloud-edge model deployments.",
    "authors": [
      "Junfei Zhan",
      "Haoxun Shen",
      "Zheng Lin",
      "Tengjiao He"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.CR",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22788v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22788v1",
    "fetched_at": "2025-12-01T08:36:42.041093",
    "chinese_title": "PRISM：基于语义草图协作的自适应云边LLM推理隐私感知路由",
    "chinese_summary": "针对现有云边LLM推理未考虑输入敏感度导致过度保护、效用下降的问题，提出PRISM隐私感知框架，通过实体敏感度分析、动态执行模式选择、自适应两层局部差分隐私及语义草图协作，实现更优隐私-效用权衡，同时将能耗和延迟降低至基线方法的40-50%。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出PRISM上下文感知框架，动态平衡云边LLM推理的隐私与效用，解决现有方法过度保护非敏感token的问题",
      "设计语义草图协作机制，结合云端大模型与边缘小模型优势，显著降低推理能耗和延迟"
    ],
    "processed_at": "2025-12-01T08:48:30.204462"
  },
  {
    "id": "2511.22773v1",
    "title": "CAPE: Context-Aware Diffusion Policy Via Proximal Mode Expansion for Collision Avoidance",
    "abstract": "In robotics, diffusion models can capture multi-modal trajectories from demonstrations, making them a transformative approach in imitation learning. However, achieving optimal performance following this regiment requires a large-scale dataset, which is costly to obtain, especially for challenging tasks, such as collision avoidance. In those tasks, generalization at test time demands coverage of many obstacles types and their spatial configurations, which are impractical to acquire purely via data. To remedy this problem, we propose Context-Aware diffusion policy via Proximal mode Expansion (CAPE), a framework that expands trajectory distribution modes with context-aware prior and guidance at inference via a novel prior-seeded iterative guided refinement procedure. The framework generates an initial trajectory plan and executes a short prefix trajectory, and then the remaining trajectory segment is perturbed to an intermediate noise level, forming a trajectory prior. Such a prior is context-aware and preserves task intent. Repeating the process with context-aware guided denoising iteratively expands mode support to allow finding smoother, less collision-prone trajectories. For collision avoidance, CAPE expands trajectory distribution modes with collision-aware context, enabling the sampling of collision-free trajectories in previously unseen environments while maintaining goal consistency. We evaluate CAPE on diverse manipulation tasks in cluttered unseen simulated and real-world settings and show up to 26% and 80% higher success rates respectively compared to SOTA methods, demonstrating better generalization to unseen environments.",
    "authors": [
      "Rui Heng Yang",
      "Xuan Zhao",
      "Leo Maxime Brunswic",
      "Montgomery Alban",
      "Mateo Clemente",
      "Tongtong Cao",
      "Jun Jin",
      "Amir Rasouli"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22773v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22773v1",
    "fetched_at": "2025-12-01T08:36:42.041123",
    "chinese_title": "CAPE：基于近端模态扩展的上下文感知扩散策略用于避碰",
    "chinese_summary": "这篇论文针对机器人模仿学习中扩散模型依赖大规模数据集的问题，提出CAPE框架，通过上下文感知先验与迭代引导细化过程扩展轨迹分布模态；该框架在避碰任务中可利用碰撞感知上下文生成未知环境下的无碰撞轨迹，同时保持目标一致性，适用于多样化操作任务。",
    "tags": [
      "Deep Learning",
      "Reinforcement Learning"
    ],
    "key_contributions": [
      "提出CAPE框架，通过上下文感知先验与迭代引导细化扩展轨迹分布模态，缓解扩散模型对大规模数据集的依赖",
      "实现未知环境下的避碰轨迹生成，保持目标一致性，适用于模拟及真实场景的多样化操作任务"
    ],
    "processed_at": "2025-12-01T08:48:48.852639"
  },
  {
    "id": "2511.22729v1",
    "title": "Solving Context Window Overflow in AI Agents",
    "abstract": "Large Language Models (LLMs) have become increasingly capable of interacting with external tools, granting access to specialized knowledge beyond their training data - critical in dynamic, knowledge-intensive domains such as Chemistry and Materials Science. However, large tool outputs can overflow the LLMs' context window, preventing task completion. Existing solutions such as truncation or summarization fail to preserve complete outputs, making them unsuitable for workflows requiring the full data. This work introduces a method that enables LLMs to process and utilize tool responses of arbitrary length without loss of information. By shifting the model's interaction from raw data to memory pointers, the method preserves tool functionality, allows seamless integration into agentic workflows, and reduces token usage and execution time. The proposed method is validated on a real-world Materials Science application that cannot be executed with conventional workflows, and its effectiveness is demonstrated via a comparative analysis where both methods succeed. In this experiment, the proposed approach consumed approximately seven times fewer tokens than the traditional workflow.",
    "authors": [
      "Anton Bulle Labate",
      "Valesca Moura de Sousa",
      "Sandro Rama Fiorini",
      "Leonardo Guerreiro Azevedo",
      "Raphael Melo Thiago",
      "Viviane Torres da Silva"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22729v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22729v1",
    "fetched_at": "2025-12-01T08:36:42.041149",
    "chinese_title": "解决AI智能体中的上下文窗口溢出问题",
    "chinese_summary": "本文针对大语言模型（LLM）处理工具输出时的上下文窗口溢出问题，提出将模型交互从原始数据转向内存指针的方法，可在无信息损失下处理任意长度工具响应，且减少token使用与执行时间；该方法在材料科学真实应用中验证有效，实验中token消耗约为传统方法的1/7。",
    "tags": [
      "LLM",
      "Financial Agent",
      "NLP"
    ],
    "key_contributions": [
      "提出内存指针交互方法，解决LLM上下文窗口溢出且无信息损失，提升工具响应处理能力",
      "在真实应用中验证有效性，token消耗比传统方法减少约7倍，优化执行效率"
    ],
    "processed_at": "2025-12-01T08:49:01.852123"
  },
  {
    "id": "2511.22659v1",
    "title": "Geometrically-Constrained Agent for Spatial Reasoning",
    "abstract": "Vision Language Models (VLMs) exhibit a fundamental semantic-to-geometric gap in spatial reasoning: they excel at qualitative semantic inference but their reasoning operates within a lossy semantic space, misaligned with high-fidelity geometry. Current paradigms fail to bridge this gap. Training-based methods suffer from an ``oracle paradox,'' learning flawed spatial logic from imperfect oracles. Tool-integrated methods constrain the final computation but critically leave the VLM's planning process unconstrained, resulting in geometrically flawed plans. In this work, we propose Geometrically-Constrained Agent (GCA), a training-free agentic paradigm that resolves this gap by introducing a formal task constraint. Specifically, we strategically decouples the VLM's role into two stages. First, acting as a semantic analyst, the VLM translates the user's ambiguous query into the formal, verifiable task constraint, which defines the reference frame and objective. Second, acting as a task solver, the VLM generates and executes tool calls strictly within the deterministic bounds defined by the constraint. This geometrically-constrained reasoning strategy successfully resolve the semantic-to-geometric gap, yielding a robust and verifiable reasoning pathway for spatial reasoning. Comprehensive experiments demonstrate that GCA achieves SOTA performance on multiple spatial reasoning benchmarks, surpassing existing training-based and tool-integrated methods by ~27%. Please see our homepage at https://gca-spatial-reasoning.github.io.",
    "authors": [
      "Zeren Chen",
      "Xiaoya Lu",
      "Zhijie Zheng",
      "Pengrui Li",
      "Lehan He",
      "Yijin Zhou",
      "Jing Shao",
      "Bohan Zhuang",
      "Lu Sheng"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22659v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22659v1",
    "fetched_at": "2025-12-01T08:36:42.041180",
    "chinese_title": "用于空间推理的几何约束智能体",
    "chinese_summary": "该论文指出视觉语言模型（VLMs）在空间推理中存在语义到几何的gap，现有训练类方法受“oracle悖论”困扰、工具集成方法未约束规划过程；提出训练-free的几何约束智能体（GCA），将VLM分为语义分析师（转化模糊查询为形式化可验证约束）和任务求解器（在约束内生成执行工具调用）两个阶段，解决gap并在多空间推理基准达SOTA。",
    "tags": [
      "LLM",
      "Transformer",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "揭示视觉语言模型空间推理中语义-几何gap的现有方法缺陷（训练类的“oracle悖论”、工具类未约束规划过程）",
      "提出训练-free的几何约束智能体（GCA），通过两阶段策略解决语义-几何gap，在多空间推理基准实现SOTA性能（超现有方法~27%）"
    ],
    "processed_at": "2025-12-01T08:49:19.980268"
  },
  {
    "id": "2511.22651v1",
    "title": "Automated Design Optimization via Strategic Search with Large Language Models",
    "abstract": "Traditional optimization methods excel in well-defined search spaces but struggle with design problems where transformations and design parameters are difficult to define. Large language models (LLMs) offer a promising alternative by dynamically interpreting design spaces and leveraging encoded domain knowledge. To this end, we introduce AUTO, an LLM agent framework that treats design optimization as a gradient-free search problem guided by strategic LLM reasoning. The framework employs two collaborative agents: a Strategist that selects between exploration and exploitation strategies, and an Implementor that executes detailed designs. Applied to GPU code optimization -- a domain critical to fields from machine learning to scientific computing -- AUTO generates solutions competitive with expert implementations for chemical kinetics integration and dense matrix multiplication. The framework achieves 50-70% search efficiency relative to Bayesian optimization methodologies. It completes optimizations in approximately 8 hours at an estimated cost of up to \\$159 per run, compared to an estimated cost of up to \\$480 with median-wage software developers. These findings open the door to automating design optimization in ill-defined search spaces with limited prior information.",
    "authors": [
      "Anthony Carreon",
      "Vansh Sharma",
      "Venkat Raman"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.MA"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22651v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22651v1",
    "fetched_at": "2025-12-01T08:36:42.041201",
    "chinese_title": "基于大语言模型策略搜索的自动化设计优化",
    "chinese_summary": "本文提出AUTO框架，这是一种LLM代理框架，将设计优化视为无梯度搜索问题，通过策略师（选择探索/利用策略）和执行者（执行详细设计）协作引导；该框架应用于GPU代码优化时，效果可与专家实现媲美，搜索效率达贝叶斯优化的50-70%，且成本低于人工优化。",
    "tags": [
      "LLM",
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出基于LLM代理协作的AUTO框架，解决定义不清搜索空间的无梯度设计优化问题",
      "在GPU代码优化任务中实现与专家媲美的效果，搜索效率和成本优于人工优化及部分传统方法"
    ],
    "processed_at": "2025-12-01T08:49:32.227101"
  },
  {
    "id": "2511.22334v1",
    "title": "Edge Deployment of Small Language Models, a comprehensive comparison of CPU, GPU and NPU backends",
    "abstract": "Edge computing processes data where it is generated, enabling faster decisions, lower bandwidth usage, and improved privacy. However, edge devices typically operate under strict constraints on processing power, memory, and energy consumption, making them unsuitable for large language models (LLMs). Fortunately, Small Language Models (SLMs) offer lightweight alternatives that bring AI inference to resource-constrained environments by significantly reducing computational cost while remaining suitable for specialization and customization. In this scenario, selecting the hardware platform that best balances performance and efficiency for SLM inference is challenging due to strict resource limitations. To address this issue, this study evaluates the inference performance and energy efficiency of commercial CPUs (Intel and ARM), GPUs (NVIDIA), and NPUs (RaiderChip) for running SLMs. GPUs, the usual platform of choice, are compared against commercial NPUs and recent multi-core CPUs. While NPUs leverage custom hardware designs optimized for computation, modern CPUs increasingly incorporate dedicated features targeting language-model workloads. Using a common execution framework and a suite of state-of-the-art SLMs, we analyze both maximum achievable performance and processing and energy efficiency across commercial solutions available for each platform. The results indicate that specialized backends outperform general-purpose CPUs, with NPUs achieving the highest performance by a wide margin. Bandwidth normalization proves essential for fair cross-architecture comparisons. Although low-power ARM processors deliver competitive results when energy usage is considered, metrics that combine performance and power (such as EDP) again highlight NPUs as the dominant architecture. These findings show that designs optimized for both efficiency and performance offer a clear advantage for edge workloads.",
    "authors": [
      "Pablo Prieto",
      "Pablo Abad"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.PF",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22334v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22334v1",
    "fetched_at": "2025-12-01T08:36:48.736943",
    "chinese_title": "小语言模型的边缘部署：CPU、GPU和NPU后端的综合比较",
    "chinese_summary": "本文针对小语言模型（SLM）的边缘推理场景，评估了商用CPU（Intel/ARM）、GPU（NVIDIA）和NPU（RaiderChip）的推理性能与能效；采用统一执行框架和前沿SLM套件，对比各平台的最大性能及处理/能效表现，发现专用后端优于通用CPU，其中NPU性能最优。",
    "tags": [
      "LLM",
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "全面评估商用CPU、GPU、NPU在SLM边缘推理中的性能与能效表现",
      "揭示专用硬件后端（NPU/GPU）优于通用CPU，NPU性能最优的结论"
    ],
    "processed_at": "2025-12-01T08:49:45.027785"
  },
  {
    "id": "2511.21886v1",
    "title": "Bridging Planning and Execution: Multi-Agent Path Finding Under Real-World Deadlines",
    "abstract": "The Multi-Agent Path Finding (MAPF) problem aims to find collision-free paths for multiple agents while optimizing objectives such as the sum of costs or makespan. MAPF has wide applications in domains like automated warehouses, manufacturing systems, and airport logistics. However, most MAPF formulations assume a simplified robot model for planning, which overlooks execution-time factors such as kinodynamic constraints, communication latency, and controller variability. This gap between planning and execution is problematic for time-sensitive applications. To bridge this gap, we propose REMAP, an execution-informed MAPF planning framework that can be combined with leading search-based MAPF planners with minor changes. Our framework integrates the proposed ExecTimeNet to accurately estimate execution time based on planned paths. We demonstrate our method for solving MAPF with Real-world Deadlines (MAPF-RD) problem, where agents must reach their goals before a predefined wall-clock time. We integrate our framework with two popular MAPF methods, MAPF-LNS and CBS. Experiments show that REMAP achieves up to 20% improvement in solution quality over baseline methods (e.g., constant execution speed estimators) on benchmark maps with up to 300 agents.",
    "authors": [
      "Jingtian Yan",
      "Shuai Zhou",
      "Stephen F. Smith",
      "Jiaoyang Li"
    ],
    "published": "2025-11-26",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.21886v1",
    "arxiv_url": "https://arxiv.org/abs/2511.21886v1",
    "fetched_at": "2025-12-01T08:36:48.736966",
    "chinese_title": "桥接规划与执行：真实世界截止时间下的多智能体路径规划",
    "chinese_summary": "现有多智能体路径规划（MAPF）多忽略执行时因素（如运动学约束、通信延迟），针对真实截止时间场景的差距，论文提出REMAP框架，通过ExecTimeNet准确估计路径执行时间，集成到MAPF-LNS、CBS等主流方法解决MAPF-RD问题，实验显示解质量提升最多20%。",
    "tags": [
      "Execution",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "提出执行感知的REMAP框架，兼容主流搜索-based MAPF方法并解决真实截止时间下的MAPF-RD问题",
      "设计ExecTimeNet准确估计路径执行时间，实验验证在300智能体基准地图上解质量提升最多20%"
    ],
    "processed_at": "2025-12-01T08:50:03.208709"
  },
  {
    "id": "2511.22924v1",
    "title": "AgentShield: Make MAS more secure and efficient",
    "abstract": "Large Language Model (LLM)-based Multi-Agent Systems (MAS) offer powerful cooperative reasoning but remain vulnerable to adversarial attacks, where compromised agents can undermine the system's overall performance. Existing defenses either depend on single trusted auditors, creating single points of failure, or sacrifice efficiency for robustness. To resolve this tension, we propose \\textbf{AgentShield}, a distributed framework for efficient, decentralized auditing. AgentShield introduces a novel three-layer defense: \\textbf{(i) Critical Node Auditing} prioritizes high-influence agents via topological analysis; \\textbf{(ii) Light Token Auditing} implements a cascade protocol using lightweight sentry models for rapid discriminative verification; and \\textbf{(iii) Two-Round Consensus Auditing} triggers heavyweight arbiters only upon uncertainty to ensure global agreement. This principled design optimizes the robustness-efficiency trade-off. Experiments demonstrate that AgentShield achieves a 92.5\\% recovery rate and reduces auditing overhead by over 70\\% compared to existing methods, maintaining high collaborative accuracy across diverse MAS topologies and adversarial scenarios.",
    "authors": [
      "Kaixiang Wang",
      "Zhaojiacheng Zhou",
      "Bunyod Suvonov",
      "Jiong Lou",
      "Jie LI"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CR"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22924v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22924v1",
    "fetched_at": "2025-12-01T08:37:24.316018",
    "chinese_title": "AgentShield：提升多智能体系统（MAS）的安全性与效率",
    "chinese_summary": "该论文针对基于大语言模型（LLM）的多智能体系统（MAS）易受对抗攻击且现有防御存在单点故障或效率损失的问题，提出分布式防御框架AgentShield，通过关键节点审计、轻量令牌审计、两轮共识审计三层设计优化鲁棒性-效率权衡；实验表明其恢复率达92.5%，审计开销降低超70%，在多样拓扑和攻击场景下维持高协作准确率。",
    "tags": [
      "LLM",
      "Transformer",
      "Anomaly",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出分布式防御框架AgentShield，通过三层设计解决现有MAS防御的单点故障与效率牺牲问题，优化鲁棒性-效率权衡",
      "实验验证其在多样MAS拓扑和对抗场景下，恢复率达92.5%且审计开销降低超70%，维持高协作准确率"
    ],
    "processed_at": "2025-12-01T08:50:18.555851"
  },
  {
    "id": "2511.23141v1",
    "title": "Automated Discovery of Laser Dicing Processes with Bayesian Optimization for Semiconductor Manufacturing",
    "abstract": "Laser dicing of semiconductor wafers is a critical step in microelectronic manufacturing, where multiple sequential laser passes precisely separate individual dies from the wafer. Adapting this complex sequential process to new wafer materials typically requires weeks of expert effort to balance process speed, separation quality, and material integrity. We present the first automated discovery of production-ready laser dicing processes on an industrial LASER1205 dicing system. We formulate the problem as a high-dimensional, constrained multi-objective Bayesian optimization task, and introduce a sequential two-level fidelity strategy to minimize expensive destructive die-strength evaluations. On bare silicon and product wafers, our method autonomously delivers feasible configurations that match or exceed expert baselines in production speed, die strength, and structural integrity, using only technician-level operation. Post-hoc validation of different weight configurations of the utility functions reveals that multiple feasible solutions with qualitatively different trade-offs can be obtained from the final surrogate model. Expert-refinement of the discovered process can further improve production speed while preserving die strength and structural integrity, surpassing purely manual or automated methods.",
    "authors": [
      "David Leeftink",
      "Roman Doll",
      "Heleen Visserman",
      "Marco Post",
      "Faysal Boughorbel",
      "Max Hinne",
      "Marcel van Gerven"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.LG",
      "eess.SY"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.23141v1",
    "arxiv_url": "https://arxiv.org/abs/2511.23141v1",
    "fetched_at": "2025-12-01T08:37:27.554465",
    "chinese_title": "基于贝叶斯优化的半导体制造激光切割工艺自动发现",
    "chinese_summary": "针对半导体激光切割工艺适配新材料需专家数周优化的问题，论文将其建模为高维约束多目标贝叶斯优化任务，引入序贯两级保真度策略降低昂贵的破坏性强度评估成本；在硅片和产品晶圆上，该方法自动得到的可行配置匹配或超过专家基线，还能从代理模型中获得不同权衡的可行解，专家优化后性能更优。",
    "tags": [
      "Deep Learning",
      "Reinforcement Learning"
    ],
    "key_contributions": [
      "首次实现工业级激光切割系统上半导体激光切割工艺的自动发现，无需专家参与即可得到生产就绪配置",
      "提出序贯两级保真度策略降低昂贵的破坏性强度评估成本，可获得多目标权衡的可行解，专家优化后性能超越纯手动/自动方法"
    ],
    "processed_at": "2025-12-01T08:51:28.695791"
  },
  {
    "id": "2511.22314v1",
    "title": "DeXposure: A Dataset and Benchmarks for Inter-protocol Credit Exposure in Decentralized Financial Networks",
    "abstract": "We curate the DeXposure dataset, the first large-scale dataset for inter-protocol credit exposure in decentralized financial networks, covering global markets of 43.7 million entries across 4.3 thousand protocols, 602 blockchains, and 24.3 thousand tokens, from 2020 to 2025. A new measure, value-linked credit exposure between protocols, is defined as the inferred financial dependency relationships derived from changes in Total Value Locked (TVL). We develop a token-to-protocol model using DefiLlama metadata to infer inter-protocol credit exposure from the token's stock dynamics, as reported by the protocols. Based on the curated dataset, we develop three benchmarks for machine learning research with financial applications: (1) graph clustering for global network measurement, tracking the structural evolution of credit exposure networks, (2) vector autoregression for sector-level credit exposure dynamics during major shocks (Terra and FTX), and (3) temporal graph neural networks for dynamic link prediction on temporal graphs. From the analysis, we observe (1) a rapid growth of network volume, (2) a trend of concentration to key protocols, (3) a decline of network density (the ratio of actual connections to possible connections), and (4) distinct shock propagation across sectors, such as lending platforms, trading exchanges, and asset management protocols. The DeXposure dataset and code have been released publicly. We envision they will help with research and practice in machine learning as well as financial risk monitoring, policy analysis, DeFi market modeling, amongst others. The dataset also contributes to machine learning research by offering benchmarks for graph clustering, vector autoregression, and temporal graph analysis.",
    "authors": [
      "Wenbin Wu",
      "Kejiang Qian",
      "Alexis Lui",
      "Christopher Jack",
      "Yue Wu",
      "Peter McBurney",
      "Fengxiang He",
      "Bryan Zhang"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.LG",
      "cs.CE",
      "cs.SI",
      "econ.GN"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22314v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22314v1",
    "fetched_at": "2025-12-01T08:37:34.040794",
    "chinese_title": "DeXposure：去中心化金融网络中协议间信用敞口的数据集与基准研究",
    "chinese_summary": "本文构建了首个大规模去中心化金融（DeFi）协议间信用敞口数据集DeXposure，结合DefiLlama元数据定义基于总锁仓价值（TVL）变化的价值关联敞口度量并推断协议间敞口；建立图聚类、向量自回归（VAR）及时序图神经网络三个机器学习基准，分析发现DeFi信用网络规模增长、集中度提升等演化特征及冲击跨 sector传播规律。",
    "tags": [
      "Benchmark",
      "Risk Management",
      "Graph Neural Network",
      "Time Series"
    ],
    "key_contributions": [
      "构建首个大规模DeFi协议间信用敞口数据集DeXposure，定义价值关联敞口度量并开发推断模型",
      "建立三个机器学习基准，分析DeFi信用网络演化及冲击传播特征"
    ],
    "processed_at": "2025-12-01T08:51:39.726675"
  },
  {
    "id": "2511.23036v1",
    "title": "Delta-XAI: A Unified Framework for Explaining Prediction Changes in Online Time Series Monitoring",
    "abstract": "Explaining online time series monitoring models is crucial across sensitive domains such as healthcare and finance, where temporal and contextual prediction dynamics underpin critical decisions. While recent XAI methods have improved the explainability of time series models, they mostly analyze each time step independently, overlooking temporal dependencies. This results in further challenges: explaining prediction changes is non-trivial, methods fail to leverage online dynamics, and evaluation remains difficult. To address these challenges, we propose Delta-XAI, which adapts 14 existing XAI methods through a wrapper function and introduces a principled evaluation suite for the online setting, assessing diverse aspects, such as faithfulness, sufficiency, and coherence. Experiments reveal that classical gradient-based methods, such as Integrated Gradients (IG), can outperform recent approaches when adapted for temporal analysis. Building on this, we propose Shifted Window Integrated Gradients (SWING), which incorporates past observations in the integration path to systematically capture temporal dependencies and mitigate out-of-distribution effects. Extensive experiments consistently demonstrate the effectiveness of SWING across diverse settings with respect to diverse metrics. Our code is publicly available at https://anonymous.4open.science/r/Delta-XAI.",
    "authors": [
      "Changhun Kim",
      "Yechan Mun",
      "Hyeongwon Jang",
      "Eunseo Lee",
      "Sangchul Hahn",
      "Eunho Yang"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.23036v1",
    "arxiv_url": "https://arxiv.org/abs/2511.23036v1",
    "fetched_at": "2025-12-01T08:37:46.902149",
    "chinese_title": "Delta-XAI：在线时间序列监测中预测变化解释的统一框架",
    "chinese_summary": "针对在线时间序列监测模型解释中忽略时间依赖、难以解释预测变化及评估困难等问题，论文提出Delta-XAI统一框架（通过wrapper适配14种现有XAI方法并引入在线评估套件）；基于实验发现经典梯度方法适配后更优，进一步提出SWING方法（结合过去观测的积分路径捕捉时间依赖、缓解OOD），实验验证了SWING的有效性。",
    "tags": [
      "Time Series",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "提出Delta-XAI统一框架，适配14种现有XAI方法并引入在线场景下的原则性评估套件",
      "提出SWING方法（结合过去观测的积分路径），捕捉时间依赖并缓解OOD，实验验证其有效性"
    ],
    "processed_at": "2025-12-01T08:51:55.812941"
  },
  {
    "id": "2511.23122v1",
    "title": "Evolutionary Discovery of Heuristic Policies for Traffic Signal Control",
    "abstract": "Traffic Signal Control (TSC) involves a challenging trade-off: classic heuristics are efficient but oversimplified, while Deep Reinforcement Learning (DRL) achieves high performance yet suffers from poor generalization and opaque policies. Online Large Language Models (LLMs) provide general reasoning but incur high latency and lack environment-specific optimization. To address these issues, we propose Temporal Policy Evolution for Traffic (\\textbf{\\method{}}), which uses LLMs as an evolution engine to derive specialized heuristic policies. The framework introduces two key modules: (1) Structured State Abstraction (SSA), converting high-dimensional traffic data into temporal-logical facts for reasoning; and (2) Credit Assignment Feedback (CAF), tracing flawed micro-decisions to poor macro-outcomes for targeted critique. Operating entirely at the prompt level without training, \\method{} yields lightweight, robust policies optimized for specific traffic environments, outperforming both heuristics and online LLM actors.",
    "authors": [
      "Ruibing Wang",
      "Shuhan Guo",
      "Zeen Li",
      "Zhen Wang",
      "Quanming Yao"
    ],
    "published": "2025-11-28",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.23122v1",
    "arxiv_url": "https://arxiv.org/abs/2511.23122v1",
    "fetched_at": "2025-12-01T08:37:50.217177",
    "chinese_title": "交通信号控制启发式策略的进化发现",
    "chinese_summary": "论文针对交通信号控制（TSC）中经典启发式简化、深度强化学习（DRL）泛化差且策略不透明、在线大语言模型（LLM）延迟高且缺乏环境特定优化的问题，提出Temporal Policy Evolution for Traffic（TPE-Traffic）框架，通过LLM作为进化引擎结合结构化状态抽象（SSA）和信用分配反馈（CAF）模块，无需训练即可生成轻量鲁棒的专用启发式策略，性能优于现有启发式方法和在线LLM actor。",
    "tags": [
      "LLM",
      "Reinforcement Learning",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出TPE-Traffic框架，以LLM为进化引擎推导交通信号控制的专用启发式策略，解决现有方法的不足",
      "设计SSA（高维交通数据转时序逻辑事实）和CAF（微决策缺陷到宏观结果的针对性反馈）模块，无需训练即可生成轻量鲁棒的优化策略"
    ],
    "processed_at": "2025-12-01T08:52:12.115022"
  },
  {
    "id": "2511.22483v1",
    "title": "Enhancing Trustworthiness with Mixed Precision: Benchmarks, Opportunities, and Challenges",
    "abstract": "Large language models (LLMs) have shown promising performance across various tasks. However, their autoregressive decoding process poses significant challenges for efficient deployment on existing AI hardware. Quantization alleviates memory and compute pressure by compressing weights, activations, and KV caches to low precisions while preserving generation quality. However, existing quantization frameworks typically focus on perplexity or classification accuracy, often omitting critical trustworthiness metrics. This gap introduces risks when applying quantized LLMs to downstream high-stakes domains such as finance and healthcare. In this work, we systematically investigate the impact of quantization on four trustworthiness metrics (adversarial robustness, fairness, machine ethics, and out-of-distribution robustness) and identify the instability across compression ratios and quantization methods. Building on these observations, we develop a novel precision-ensemble voting approach that leverages predictions from mixed-precision variants of the same model and consistently improves performance by up to $5.8\\%$ on trustworthiness metrics. Our results highlight the importance of considering trustworthiness when developing model compression techniques and point to research opportunities at the intersection of compression and trustworthiness for safety-critical applications.",
    "authors": [
      "Guanxi Lu",
      "Hao Mark Chen",
      "Zhiqiang Que",
      "Wayne Luk",
      "Hongxiang Fan"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22483v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22483v1",
    "fetched_at": "2025-12-01T08:38:09.873306",
    "chinese_title": "混合精度提升可信性：基准、机遇与挑战",
    "chinese_summary": "现有大语言模型（LLM）量化框架多聚焦困惑度等指标，忽略对抗鲁棒性、公平性等可信性风险；本文系统研究量化对四类可信性指标的影响并揭示压缩特性的不稳定性，进而提出混合精度集成投票方法，使可信性指标提升最多5.8%。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "系统探究量化对LLM四个核心可信性指标（对抗鲁棒性、公平性、机器伦理、分布外鲁棒性）的影响，揭示压缩比与量化方法的不稳定性",
      "提出混合精度集成投票方法，利用同一模型的混合精度变体预测，显著提升LLM可信性指标（最高达5.8%）"
    ],
    "processed_at": "2025-12-01T08:52:25.032938"
  },
  {
    "id": "2511.22584v1",
    "title": "Smarter, not Bigger: Fine-Tuned RAG-Enhanced LLMs for Automotive HIL Testing",
    "abstract": "Hardware-in-the-Loop (HIL) testing is essential for automotive validation but suffers from fragmented and underutilized test artifacts. This paper presents HIL-GPT, a retrieval-augmented generation (RAG) system integrating domain-adapted large language models (LLMs) with semantic retrieval. HIL-GPT leverages embedding fine-tuning using a domain-specific dataset constructed via heuristic mining and LLM-assisted synthesis, combined with vector indexing for scalable, traceable test case and requirement retrieval. Experiments show that fine-tuned compact models, such as \\texttt{bge-base-en-v1.5}, achieve a superior trade-off between accuracy, latency, and cost compared to larger models, challenging the notion that bigger is always better. An A/B user study further confirms that RAG-enhanced assistants improve perceived helpfulness, truthfulness, and satisfaction over general-purpose LLMs. These findings provide insights for deploying efficient, domain-aligned LLM-based assistants in industrial HIL environments.",
    "authors": [
      "Chao Feng",
      "Zihan Liu",
      "Siddhant Gupta",
      "Gongpei Cui",
      "Jan von der Assen",
      "Burkhard Stiller"
    ],
    "published": "2025-11-27",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2511.22584v1",
    "arxiv_url": "https://arxiv.org/abs/2511.22584v1",
    "fetched_at": "2025-12-01T08:38:13.188540",
    "chinese_title": "更智能而非更大：用于汽车硬件在环（HIL）测试的微调RAG增强大语言模型",
    "chinese_summary": "本文提出针对汽车HIL测试的RAG系统HIL-GPT，集成领域适配LLM与语义检索，通过领域数据集嵌入微调及向量索引实现测试用例与需求的可扩展检索；实验表明微调紧凑模型在准确率、延迟与成本间的权衡优于大模型，A/B测试证实其比通用LLM更具帮助性、真实性与满意度。",
    "tags": [
      "LLM",
      "NLP",
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出集成领域适配LLM与语义检索的RAG系统HIL-GPT，解决汽车HIL测试中碎片化测试artifact的检索问题",
      "验证微调紧凑模型在准确率、延迟与成本间的权衡优于大模型，且RAG增强助手优于通用LLM"
    ],
    "processed_at": "2025-12-01T08:52:41.504176"
  }
]