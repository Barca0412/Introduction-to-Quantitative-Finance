[
  {
    "id": "2601.14139v2",
    "title": "Log-optimality with small liability stream",
    "abstract": "In an incomplete financial market with general continuous semimartingale dynamics; we model an investor with log-utility preferences who, in addition to an initial capital, receives units of a non-traded endowment process. Using duality techniques, we derive the fourth-order expansion of the primal value function with respect to the units $ε$, held in the non-traded endowment. In turn, this lays the foundation for expanding the optimal wealth process, in this context, up to second order w.r.t. $ε$. The key processes underpinning the aforementioned results are given in terms of Kunita-Watanabe projections, mirroring the case of lower order expansions of similar nature. Both the case of finite and infinite horizons are treated in a unified manner.",
    "authors": [
      "Michail Anthropelos",
      "Constantinos Kardaras",
      "Constantinos Stefanakis"
    ],
    "published": "2026-01-20",
    "categories": [
      "q-fin.MF"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.14139v2",
    "arxiv_url": "https://arxiv.org/abs/2601.14139v2",
    "fetched_at": "2026-01-23T08:35:41.186987",
    "chinese_title": "带小额非交易禀赋流的对数最优性",
    "chinese_summary": "本文在具有一般连续半鞅动态的不完全金融市场中，针对具有对数效用偏好且初始资本外还持有小额非交易禀赋流（单位为ε）的投资者，采用对偶技术推导了原价值函数关于ε的四阶展开，进而得到最优财富过程关于ε的二阶展开；关键过程以Kunita-Watanabe投影表示，且统一处理了有限与无限 horizon的情形。",
    "tags": [
      "Portfolio Optimization",
      "Asset Pricing"
    ],
    "key_contributions": [
      "推导了不完全连续半鞅市场中带小额非交易禀赋流的对数效用投资者原价值函数关于ε的四阶展开及最优财富过程的二阶展开",
      "关键过程以Kunita-Watanabe投影表示，统一处理有限与无限 horizon情形"
    ],
    "processed_at": "2026-01-23T08:38:52.321976"
  },
  {
    "id": "2601.15798v1",
    "title": "VitalDiagnosis: AI-Driven Ecosystem for 24/7 Vital Monitoring and Chronic Disease Management",
    "abstract": "Chronic diseases have become the leading cause of death worldwide, a challenge intensified by strained medical resources and an aging population. Individually, patients often struggle to interpret early signs of deterioration or maintain adherence to care plans. In this paper, we introduce VitalDiagnosis, an LLM-driven ecosystem designed to shift chronic disease management from passive monitoring to proactive, interactive engagement. By integrating continuous data from wearable devices with the reasoning capabilities of LLMs, the system addresses both acute health anomalies and routine adherence. It analyzes triggers through context-aware inquiries, produces provisional insights within a collaborative patient-clinician workflow, and offers personalized guidance. This approach aims to promote a more proactive and cooperative care paradigm, with the potential to enhance patient self-management and reduce avoidable clinical workload.",
    "authors": [
      "Zhikai Xue",
      "Tianqianjin Lin",
      "Pengwei Yan",
      "Ruichun Wang",
      "Yuxin Liu",
      "Zhuoren Jiang",
      "Xiaozhong Liu"
    ],
    "published": "2026-01-22",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.15798v1",
    "arxiv_url": "https://arxiv.org/abs/2601.15798v1",
    "fetched_at": "2026-01-23T08:35:53.517470",
    "chinese_title": "VitalDiagnosis：AI驱动的24/7生命体征监测与慢性病管理生态系统",
    "chinese_summary": "本文提出LLM驱动的VitalDiagnosis生态系统，整合可穿戴设备连续数据与LLM推理能力，将慢性病管理从被动监测转向主动互动模式；该系统通过上下文感知查询分析健康异常触发因素，在医患协作流程中生成临时见解并提供个性化指导，旨在提升患者自我管理能力、减轻不必要的临床工作量。",
    "tags": [
      "LLM",
      "Anomaly",
      "Transformer"
    ],
    "key_contributions": [
      "提出LLM驱动的VitalDiagnosis生态系统，实现慢性病管理从被动监测到主动互动的范式转变",
      "设计上下文感知异常分析、医患协作见解生成及个性化指导机制，提升患者自我管理并减轻临床负担"
    ],
    "processed_at": "2026-01-23T08:39:04.131174"
  },
  {
    "id": "2601.15641v1",
    "title": "Machine Failure Detection Based on Projected Quantum Models",
    "abstract": "Detecting machine failures promptly is of utmost importance in industry for maintaining efficiency and minimizing downtime. This paper introduces a failure detection algorithm based on quantum computing and a statistical change-point detection approach. Our method leverages the potential of projected quantum feature maps to enhance the precision of anomaly detection in machine monitoring systems. We empirically validate our approach on benchmark multi-dimensional time series datasets as well as on a real-world dataset comprising IoT sensor readings from operational machines, ensuring the practical relevance of our study. The algorithm was executed on IBM's 133-qubit Heron quantum processor, demonstrating the feasibility of integrating quantum computing into industrial maintenance procedures. The presented results underscore the effectiveness of our quantum-based failure detection system, showcasing its capability to accurately identify anomalies in noisy time series data. This work not only highlights the potential of quantum computing in industrial diagnostics but also paves the way for more sophisticated quantum algorithms in the realm of predictive maintenance.",
    "authors": [
      "Larry Bowden",
      "Qi Chu",
      "Bernard Cena",
      "Kentaro Ohno",
      "Bob Parney",
      "Deepak Sharma",
      "Mitsuharu Takeori"
    ],
    "published": "2026-01-22",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.15641v1",
    "arxiv_url": "https://arxiv.org/abs/2601.15641v1",
    "fetched_at": "2026-01-23T08:35:53.517507",
    "chinese_title": "基于投影量子模型的机器故障检测",
    "chinese_summary": "本文提出结合量子计算与统计变点检测的故障检测算法，利用投影量子特征映射提升机器监测系统的异常检测精度；在基准多维时间序列及真实工业IoT传感器数据集验证，且在IBM133量子处理器上成功执行，证明量子计算可集成于工业维护流程。",
    "tags": [
      "Anomaly",
      "Time Series",
      "Benchmark"
    ],
    "key_contributions": [
      "提出结合量子计算与统计变点检测的故障检测算法，利用投影量子特征映射增强异常检测精度",
      "实证验证算法在真实工业场景的有效性，且在量子处理器上可行，为工业预测维护的量子应用铺路"
    ],
    "processed_at": "2026-01-23T08:39:14.768357"
  },
  {
    "id": "2601.16206v1",
    "title": "LLM-in-Sandbox Elicits General Agentic Intelligence",
    "abstract": "We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverage the file system to handle long contexts, and execute scripts to satisfy formatting requirements. We further show that these agentic capabilities can be enhanced through LLM-in-Sandbox Reinforcement Learning (LLM-in-Sandbox-RL), which uses only non-agentic data to train models for sandbox exploration. Experiments demonstrate that LLM-in-Sandbox, in both training-free and post-trained settings, achieves robust generalization spanning mathematics, physics, chemistry, biomedicine, long-context understanding, and instruction following. Finally, we analyze LLM-in-Sandbox's efficiency from computational and system perspectives, and open-source it as a Python package to facilitate real-world deployment.",
    "authors": [
      "Daixuan Cheng",
      "Shaohan Huang",
      "Yuxian Gu",
      "Huatong Song",
      "Guoxin Chen",
      "Li Dong",
      "Wayne Xin Zhao",
      "Ji-Rong Wen",
      "Furu Wei"
    ],
    "published": "2026-01-22",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.16206v1",
    "arxiv_url": "https://arxiv.org/abs/2601.16206v1",
    "fetched_at": "2026-01-23T08:36:21.225545",
    "chinese_title": "LLM-in-Sandbox：激发通用智能体智能",
    "chinese_summary": "论文提出LLM-in-Sandbox框架，让大语言模型（LLM）在代码沙箱中探索，无需额外训练即可利用沙箱处理非代码任务（如访问外部资源、处理长上下文等）；进一步通过仅用非智能体数据训练的LLM-in-Sandbox-RL增强其智能体能力，在多领域实现泛化，并开源Python包。",
    "tags": [
      "LLM",
      "Reinforcement Learning",
      "NLP"
    ],
    "key_contributions": [
      "提出LLM-in-Sandbox框架，使无额外训练的LLM能自发利用代码沙箱处理非代码任务（如外部资源访问、长上下文管理等）",
      "提出LLM-in-Sandbox-RL方法，仅用非智能体数据增强模型沙箱探索能力，多领域泛化且开源Python包"
    ],
    "processed_at": "2026-01-23T08:39:24.421546"
  },
  {
    "id": "2601.16038v1",
    "title": "Grounding Large Language Models in Reaction Knowledge Graphs for Synthesis Retrieval",
    "abstract": "Large Language Models (LLMs) can aid synthesis planning in chemistry, but standard prompting methods often yield hallucinated or outdated suggestions. We study LLM interactions with a reaction knowledge graph by casting reaction path retrieval as a Text2Cypher (natural language to graph query) generation problem, and define single- and multi-step retrieval tasks. We compare zero-shot prompting to one-shot variants using static, random, and embedding-based exemplar selection, and assess a checklist-driven validator/corrector loop. To evaluate our framework, we consider query validity and retrieval accuracy. We find that one-shot prompting with aligned exemplars consistently performs best. Our checklist-style self-correction loop mainly improves executability in zero-shot settings and offers limited additional retrieval gains once a good exemplar is present. We provide a reproducible Text2Cypher evaluation setup to facilitate further work on KG-grounded LLMs for synthesis planning. Code is available at https://github.com/Intelligent-molecular-systems/KG-LLM-Synthesis-Retrieval.",
    "authors": [
      "Olga Bunkova",
      "Lorenzo Di Fruscia",
      "Sophia Rupprecht",
      "Artur M. Schweidtmann",
      "Marcel J. T. Reinders",
      "Jana M. Weber"
    ],
    "published": "2026-01-22",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.16038v1",
    "arxiv_url": "https://arxiv.org/abs/2601.16038v1",
    "fetched_at": "2026-01-23T08:36:21.225580",
    "chinese_title": "将大语言模型接地于反应知识图谱以实现合成检索",
    "chinese_summary": "本文针对大语言模型（LLM）在化学合成规划中易产生幻觉或过时建议的问题，将反应路径检索转化为Text2Cypher（自然语言到图查询）生成问题，定义单步和多步检索任务；比较零样本提示与不同示例选择的单样本提示，并评估checklist驱动的验证/修正循环，发现对齐示例的单样本提示性能最优，且提供可复现的评估框架。",
    "tags": [
      "LLM",
      "NLP",
      "Graph Neural Network"
    ],
    "key_contributions": [
      "提出将化学合成中的反应路径检索转化为Text2Cypher生成问题，定义单步和多步检索任务",
      "实验验证对齐示例的单样本提示性能最优，且提供可复现的Text2Cypher评估框架"
    ],
    "processed_at": "2026-01-23T08:39:44.202758"
  },
  {
    "id": "2601.15912v1",
    "title": "TeNet: Text-to-Network for Compact Policy Synthesis",
    "abstract": "Robots that follow natural-language instructions often either plan at a high level using hand-designed interfaces or rely on large end-to-end models that are difficult to deploy for real-time control. We propose TeNet (Text-to-Network), a framework for instantiating compact, task-specific robot policies directly from natural language descriptions. TeNet conditions a hypernetwork on text embeddings produced by a pretrained large language model (LLM) to generate a fully executable policy, which then operates solely on low-dimensional state inputs at high control frequencies. By using the language only once at the policy instantiation time, TeNet inherits the general knowledge and paraphrasing robustness of pretrained LLMs while remaining lightweight and efficient at execution time. To improve generalization, we optionally ground language in behavior during training by aligning text embeddings with demonstrated actions, while requiring no demonstrations at inference time. Experiments on MuJoCo and Meta-World benchmarks show that TeNet produces policies that are orders of magnitude smaller than sequence-based baselines, while achieving strong performance in both multi-task and meta-learning settings and supporting high-frequency control. These results show that text-conditioned hypernetworks offer a practical way to build compact, language-driven controllers for ressource-constrained robot control tasks with real-time requirements.",
    "authors": [
      "Ariyan Bighashdel",
      "Kevin Sebastian Luck"
    ],
    "published": "2026-01-22",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.15912v1",
    "arxiv_url": "https://arxiv.org/abs/2601.15912v1",
    "fetched_at": "2026-01-23T08:36:21.225601",
    "chinese_title": "TeNet：面向紧凑策略合成的文本到网络框架",
    "chinese_summary": "论文提出TeNet（文本到网络）框架，利用预训练大语言模型（LLM）的文本嵌入条件化超网络，直接从自然语言描述生成紧凑、任务特定的机器人可执行策略，执行时仅依赖低维状态输入且高效轻量；还可选在训练阶段对齐文本嵌入与演示动作以提升泛化能力，推理时无需演示数据，实验验证其策略规模远小于序列基线且性能优异，支持高频控制。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Reinforcement Learning",
      "High Frequency"
    ],
    "key_contributions": [
      "提出TeNet框架，通过LLM文本嵌入条件化超网络，实现从自然语言到紧凑可执行机器人策略的直接生成，执行阶段轻量高效且仅依赖低维状态输入",
      "引入可选的训练时文本-行为对齐机制提升泛化能力，推理无需演示数据，实验表明其策略规模远小于序列基线，在多任务和元学习场景下性能优异并支持高频控制"
    ],
    "processed_at": "2026-01-23T08:40:03.687683"
  },
  {
    "id": "2601.15876v1",
    "title": "EvoCUA: Evolving Computer Use Agents via Learning from Scalable Synthetic Experience",
    "abstract": "The development of native computer-use agents (CUA) represents a significant leap in multimodal AI. However, their potential is currently bottlenecked by the constraints of static data scaling. Existing paradigms relying primarily on passive imitation of static datasets struggle to capture the intricate causal dynamics inherent in long-horizon computer tasks. In this work, we introduce EvoCUA, a native computer use agentic model. Unlike static imitation, EvoCUA integrates data generation and policy optimization into a self-sustaining evolutionary cycle. To mitigate data scarcity, we develop a verifiable synthesis engine that autonomously generates diverse tasks coupled with executable validators. To enable large-scale experience acquisition, we design a scalable infrastructure orchestrating tens of thousands of asynchronous sandbox rollouts. Building on these massive trajectories, we propose an iterative evolving learning strategy to efficiently internalize this experience. This mechanism dynamically regulates policy updates by identifying capability boundaries -- reinforcing successful routines while transforming failure trajectories into rich supervision through error analysis and self-correction. Empirical evaluations on the OSWorld benchmark demonstrate that EvoCUA achieves a success rate of 56.7%, establishing a new open-source state-of-the-art. Notably, EvoCUA significantly outperforms the previous best open-source model, OpenCUA-72B (45.0%), and surpasses leading closed-weights models such as UI-TARS-2 (53.1%). Crucially, our results underscore the generalizability of this approach: the evolving paradigm driven by learning from experience yields consistent performance gains across foundation models of varying scales, establishing a robust and scalable path for advancing native agent capabilities.",
    "authors": [
      "Taofeng Xue",
      "Chong Peng",
      "Mianqiu Huang",
      "Linsen Guo",
      "Tiancheng Han",
      "Haozhe Wang",
      "Jianing Wang",
      "Xiaocheng Zhang",
      "Xin Yang",
      "Dengchang Zhao",
      "Jinrui Ding",
      "Xiandi Ma",
      "Yuchen Xie",
      "Peng Pei",
      "Xunliang Cai",
      "Xipeng Qiu"
    ],
    "published": "2026-01-22",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.15876v1",
    "arxiv_url": "https://arxiv.org/abs/2601.15876v1",
    "fetched_at": "2026-01-23T08:36:21.225644",
    "chinese_title": "EvoCUA：通过可扩展合成经验学习的进化型计算机使用智能体",
    "chinese_summary": "本文提出EvoCUA——一种进化型计算机使用智能体，针对现有静态数据模仿的瓶颈，整合数据生成与策略优化为自维持进化循环，通过可验证合成引擎、可扩展异步沙盒rollout及迭代进化学习策略提升性能，在OSWorld基准上创下开源新SOTA。",
    "tags": [
      "Reinforcement Learning",
      "Financial Agent",
      "Benchmark"
    ],
    "key_contributions": [
      "提出EvoCUA模型，将数据生成与策略优化整合为自维持进化循环，突破静态数据扩展瓶颈",
      "设计可验证合成引擎、可扩展异步沙盒rollout及迭代进化学习策略，在OSWorld基准上实现开源新SOTA"
    ],
    "processed_at": "2026-01-23T08:40:21.572833"
  },
  {
    "id": "2601.15802v1",
    "title": "A Beacon Based Solution for Autonomous UUVs GNSS-Denied Stealthy Navigation",
    "abstract": "Autonomous Unmanned Underwater Vehicles (UUVs) enable military and civilian covert operations in coastal areas without relying on support vessels or Global Navigation Satellite Systems (GNSS). Such operations are critical when surface access is not possible and stealthy navigation is required in restricted environments such as protected zones or dangerous areas under access ban. GNSS denied navigation is then essential to maintaining concealment as surfacing could expose UUVs to detection. To ensure a precise fleet positioning a constellation of beacons deployed by aerial or surface drones establish a synthetic landmark network that will guide the fleet of UUVs along an optimized path from the continental shelf to the goal on the shore. These beacons either submerged or floating emit acoustic signals for UUV localisation and navigation. A hierarchical planner generates an adaptive route for the drones executing primitive actions while continuously monitoring and replanning as needed to maintain trajectory accuracy.",
    "authors": [
      "Alexandre Albore",
      "Humbert Fiorino",
      "Damien Pellier"
    ],
    "published": "2026-01-22",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.15802v1",
    "arxiv_url": "https://arxiv.org/abs/2601.15802v1",
    "fetched_at": "2026-01-23T08:36:21.225665",
    "chinese_title": "基于信标的自主水下无人航行器（UUV）无GNSS隐身导航解决方案",
    "chinese_summary": "针对自主水下无人航行器（UUV）在无全球导航卫星系统（GNSS）环境下的隐身导航需求，论文提出通过空中/水面无人机部署信标星座构建合成地标网络，利用声学信号实现UUV定位；同时设计分层规划器生成自适应路径，持续监控并动态重规划以维持轨迹精度，支持UUV从大陆架到海岸目标的精确导航。",
    "tags": [
      "Deep Learning"
    ],
    "key_contributions": [
      "提出信标星座合成地标网络，解决UUV无GNSS隐身定位问题",
      "设计分层自适应规划器，支持动态路径生成与重规划保证轨迹精度"
    ],
    "processed_at": "2026-01-23T08:40:47.573565"
  },
  {
    "id": "2601.15778v1",
    "title": "Agentic Confidence Calibration",
    "abstract": "AI agents are rapidly advancing from passive language models to autonomous systems executing complex, multi-step tasks. Yet their overconfidence in failure remains a fundamental barrier to deployment in high-stakes settings. Existing calibration methods, built for static single-turn outputs, cannot address the unique challenges of agentic systems, such as compounding errors along trajectories, uncertainty from external tools, and opaque failure modes. To address these challenges, we introduce, for the first time, the problem of Agentic Confidence Calibration and propose Holistic Trajectory Calibration (HTC), a novel diagnostic framework that extracts rich process-level features ranging from macro dynamics to micro stability across an agent's entire trajectory. Powered by a simple, interpretable model, HTC consistently surpasses strong baselines in both calibration and discrimination, across eight benchmarks, multiple LLMs, and diverse agent frameworks. Beyond performance, HTC delivers three essential advances: it provides interpretability by revealing the signals behind failure, enables transferability by applying across domains without retraining, and achieves generalization through a General Agent Calibrator (GAC) that achieves the best calibration (lowest ECE) on the out-of-domain GAIA benchmark. Together, these contributions establish a new process-centric paradigm for confidence calibration, providing a framework for diagnosing and enhancing the reliability of AI agents.",
    "authors": [
      "Jiaxin Zhang",
      "Caiming Xiong",
      "Chien-Sheng Wu"
    ],
    "published": "2026-01-22",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.15778v1",
    "arxiv_url": "https://arxiv.org/abs/2601.15778v1",
    "fetched_at": "2026-01-23T08:36:21.225686",
    "chinese_title": "智能体置信度校准",
    "chinese_summary": "本文针对现有静态单轮置信度校准方法无法适配AI智能体（存在轨迹误差累积、外部工具不确定性等特有挑战）的问题，首次提出智能体置信度校准问题，设计Holistic Trajectory Calibration（HTC）框架提取智能体全轨迹过程特征，并提出通用智能体校准器（GAC），在多基准、跨域场景下实现更优校准与判别，建立过程中心的置信度校准新范式。",
    "tags": [
      "LLM",
      "Deep Learning",
      "Benchmark",
      "Financial Agent"
    ],
    "key_contributions": [
      "首次提出智能体置信度校准问题，明确其针对智能体轨迹误差累积、外部工具不确定性等特有挑战的必要性",
      "提出Holistic Trajectory Calibration（HTC）框架与通用智能体校准器（GAC），在多基准、跨域场景下实现优于强基线的校准与判别效果，且具备可解释性、可迁移性与泛化性",
      "建立过程中心的置信度校准新范式，为AI智能体的可靠性诊断与提升提供框架"
    ],
    "processed_at": "2026-01-23T08:41:15.554674"
  },
  {
    "id": "2601.15729v1",
    "title": "DualShield: Safe Model Predictive Diffusion via Reachability Analysis for Interactive Autonomous Driving",
    "abstract": "Diffusion models have emerged as a powerful approach for multimodal motion planning in autonomous driving. However, their practical deployment is typically hindered by the inherent difficulty in enforcing vehicle dynamics and a critical reliance on accurate predictions of other agents, making them prone to safety issues under uncertain interactions. To address these limitations, we introduce DualShield, a planning and control framework that leverages Hamilton-Jacobi (HJ) reachability value functions in a dual capacity. First, the value functions act as proactive guidance, steering the diffusion denoising process towards safe and dynamically feasible regions. Second, they form a reactive safety shield using control barrier-value functions (CBVFs) to modify the executed actions and ensure safety. This dual mechanism preserves the rich exploration capabilities of diffusion models while providing principled safety assurance under uncertain and even adversarial interactions. Simulations in challenging unprotected U-turn scenarios demonstrate that DualShield significantly improves both safety and task efficiency compared to leading methods from different planning paradigms under uncertainty.",
    "authors": [
      "Rui Yang",
      "Lei Zheng",
      "Ruoyu Yao",
      "Jun Ma"
    ],
    "published": "2026-01-22",
    "categories": [
      "cs.RO",
      "cs.AI",
      "eess.SY"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.15729v1",
    "arxiv_url": "https://arxiv.org/abs/2601.15729v1",
    "fetched_at": "2026-01-23T08:36:21.225709",
    "chinese_title": "DualShield：基于可达性分析的交互式自动驾驶安全模型预测扩散",
    "chinese_summary": "针对扩散模型在自动驾驶运动规划中难以满足车辆动力学约束、依赖其他智能体准确预测且易出现安全问题的局限，本文提出DualShield框架，利用HJ可达性价值函数双重作用——既引导扩散去噪过程至安全可行区域，又通过控制障碍价值函数形成反应式安全盾修正执行动作，在保留扩散探索能力的同时保障不确定交互下的安全，仿真验证其在复杂场景下显著提升安全与任务效率。",
    "tags": [
      "Deep Learning",
      "Risk Management"
    ],
    "key_contributions": [
      "解决扩散模型在自动驾驶中动力学约束难满足、不确定交互下安全保障不足的问题，仿真验证其优于现有方法"
    ],
    "processed_at": "2026-01-23T08:41:27.562374"
  },
  {
    "id": "2601.15728v1",
    "title": "Benchmarking Text-to-Python against Text-to-SQL: The Impact of Explicit Logic and Ambiguity",
    "abstract": "While Text-to-SQL remains the dominant approach for database interaction, real-world analytics increasingly require the flexibility of general-purpose programming languages such as Python or Pandas to manage file-based data and complex analytical workflows. Despite this growing need, the reliability of Text-to-Python in core data retrieval remains underexplored relative to the mature SQL ecosystem. To address this gap, we introduce BIRD-Python, a benchmark designed for cross-paradigm evaluation. We systematically refined the original dataset to reduce annotation noise and align execution semantics, thereby establishing a consistent and standardized baseline for comparison. Our analysis reveals a fundamental paradigmatic divergence: whereas SQL leverages implicit DBMS behaviors through its declarative structure, Python requires explicit procedural logic, making it highly sensitive to underspecified user intent. To mitigate this challenge, we propose the Logic Completion Framework (LCF), which resolves ambiguity by incorporating latent domain knowledge into the generation process. Experimental results show that (1) performance differences primarily stem from missing domain context rather than inherent limitations in code generation, and (2) when these gaps are addressed, Text-to-Python achieves performance parity with Text-to-SQL. These findings establish Python as a viable foundation for analytical agents-provided that systems effectively ground ambiguous natural language inputs in executable logical specifications. Resources are available at https://anonymous.4open.science/r/Bird-Python-43B7/.",
    "authors": [
      "Hangle Hu",
      "Chenyu Hou",
      "Bin Cao",
      "Ruizhe Li"
    ],
    "published": "2026-01-22",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.15728v1",
    "arxiv_url": "https://arxiv.org/abs/2601.15728v1",
    "fetched_at": "2026-01-23T08:36:21.225736",
    "chinese_title": "Text-to-Python与Text-to-SQL的基准测试：显式逻辑与歧义的影响",
    "chinese_summary": "本文构建BIRD-Python基准用于Text-to-Python与Text-to-SQL的跨范式标准化评估，分析发现Python因需显式过程逻辑对用户意图歧义更敏感，进而提出逻辑补全框架（LCF）融入领域知识缓解该问题，实验表明补充领域上下文后Text-to-Python性能可与Text-to-SQL相当。",
    "tags": [
      "LLM",
      "NLP",
      "Benchmark",
      "Financial Agent"
    ],
    "key_contributions": [
      "构建BIRD-Python基准，通过优化数据集减少标注噪声、对齐执行语义，建立跨范式评估的标准化基线",
      "提出逻辑补全框架（LCF）缓解Text-to-Python对意图歧义的敏感性，实验证明补充领域上下文后其性能可与Text-to-SQL相当"
    ],
    "processed_at": "2026-01-23T08:41:42.930815"
  },
  {
    "id": "2601.15709v1",
    "title": "AgentSM: Semantic Memory for Agentic Text-to-SQL",
    "abstract": "Recent advances in LLM-based Text-to-SQL have achieved remarkable gains on public benchmarks such as BIRD and Spider. Yet, these systems struggle to scale in realistic enterprise settings with large, complex schemas, diverse SQL dialects, and expensive multi-step reasoning. Emerging agentic approaches show potential for adaptive reasoning but often suffer from inefficiency and instability-repeating interactions with databases, producing inconsistent outputs, and occasionally failing to generate valid answers. To address these challenges, we introduce Agent Semantic Memory (AgentSM), an agentic framework for Text-to-SQL that builds and leverages interpretable semantic memory. Instead of relying on raw scratchpads or vector retrieval, AgentSM captures prior execution traces-or synthesizes curated ones-as structured programs that directly guide future reasoning. This design enables systematic reuse of reasoning paths, which allows agents to scale to larger schemas, more complex questions, and longer trajectories efficiently and reliably. Compared to state-of-the-art systems, AgentSM achieves higher efficiency by reducing average token usage and trajectory length by 25% and 35%, respectively, on the Spider 2.0 benchmark. It also improves execution accuracy, reaching a state-of-the-art accuracy of 44.8% on the Spider 2.0 Lite benchmark.",
    "authors": [
      "Asim Biswal",
      "Chuan Lei",
      "Xiao Qin",
      "Aodong Li",
      "Balakrishnan Narayanaswamy",
      "Tim Kraska"
    ],
    "published": "2026-01-22",
    "categories": [
      "cs.AI",
      "cs.DB",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.15709v1",
    "arxiv_url": "https://arxiv.org/abs/2601.15709v1",
    "fetched_at": "2026-01-23T08:36:21.225763",
    "chinese_title": "AgentSM：面向智能体式Text-to-SQL的语义记忆",
    "chinese_summary": "针对现有LLM-based Text-to-SQL在企业复杂场景（大模式、多样SQL方言等）及智能体方法低效不稳定的问题，论文提出AgentSM框架，通过构建可解释语义记忆，以结构化程序捕获/合成执行轨迹指导推理；在Spider 2.0基准上，该框架平均token和轨迹长度分别减少25%、35%，且在Spider 2.0 Lite上以44.8%执行准确率达当前最优。",
    "tags": [
      "LLM",
      "NLP",
      "Financial Agent",
      "Benchmark"
    ],
    "key_contributions": [
      "提出AgentSM智能体框架，通过可解释语义记忆（结构化程序捕获/合成执行轨迹）解决Text-to-SQL智能体低效不稳定问题",
      "在Spider 2.0基准上显著提升效率（token减少25%、轨迹长度减少35%），并在Spider 2.0 Lite上以44.8%执行准确率达到SOTA"
    ],
    "processed_at": "2026-01-23T08:42:06.486756"
  },
  {
    "id": "2601.15703v1",
    "title": "Agentic Uncertainty Quantification",
    "abstract": "Although AI agents have demonstrated impressive capabilities in long-horizon reasoning, their reliability is severely hampered by the ``Spiral of Hallucination,'' where early epistemic errors propagate irreversibly. Existing methods face a dilemma: uncertainty quantification (UQ) methods typically act as passive sensors, only diagnosing risks without addressing them, while self-reflection mechanisms suffer from continuous or aimless corrections. To bridge this gap, we propose a unified Dual-Process Agentic UQ (AUQ) framework that transforms verbalized uncertainty into active, bi-directional control signals. Our architecture comprises two complementary mechanisms: System 1 (Uncertainty-Aware Memory, UAM), which implicitly propagates verbalized confidence and semantic explanations to prevent blind decision-making; and System 2 (Uncertainty-Aware Reflection, UAR), which utilizes these explanations as rational cues to trigger targeted inference-time resolution only when necessary. This enables the agent to balance efficient execution and deep deliberation dynamically. Extensive experiments on closed-loop benchmarks and open-ended deep research tasks demonstrate that our training-free approach achieves superior performance and trajectory-level calibration. We believe this principled framework AUQ represents a significant step towards reliable agents.",
    "authors": [
      "Jiaxin Zhang",
      "Prafulla Kumar Choubey",
      "Kung-Hsiang Huang",
      "Caiming Xiong",
      "Chien-Sheng Wu"
    ],
    "published": "2026-01-22",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.15703v1",
    "arxiv_url": "https://arxiv.org/abs/2601.15703v1",
    "fetched_at": "2026-01-23T08:36:21.225787",
    "chinese_title": "智能体不确定性量化",
    "chinese_summary": "针对AI智能体“幻觉螺旋”（早期认知错误不可逆传播）问题，现有方法或被动诊断风险或无目的修正，论文提出统一双过程AUQ框架，含不确定性感知记忆（隐式传播置信与解释防盲目决策）和不确定性感知反思（用解释触发必要定向推理），动态平衡执行效率与深度 deliberation；实验显示无训练的AUQ在闭环基准和深度研究任务中表现更优且轨迹级校准好，是可靠智能体的重要进展。",
    "tags": [
      "LLM",
      "Risk Management",
      "Deep Learning",
      "Benchmark"
    ],
    "key_contributions": [
      "提出统一双过程AUQ框架，将口头化不确定性转化为主动双向控制信号，解决现有UQ被动诊断、自我反思无目的修正的困境",
      "设计系统1（不确定性感知记忆）和系统2（不确定性感知反思）互补机制，动态平衡高效执行与深度 deliberation，无训练方法在闭环基准和深度研究任务中表现更优且轨迹级校准好"
    ],
    "processed_at": "2026-01-23T08:42:29.825584"
  },
  {
    "id": "2601.15687v1",
    "title": "FARM: Field-Aware Resolution Model for Intelligent Trigger-Action Automation",
    "abstract": "Trigger-Action Programming (TAP) platforms such as IFTTT and Zapier enable Web of Things (WoT) automation by composing event-driven rules across heterogeneous services. A TAP applet links a trigger to an action and must bind trigger outputs (ingredients) to action inputs (fields) to be executable. Prior work largely treats TAP as service-level prediction from natural language, which often yields non-executable applets that still require manual configuration. We study the function-level configuration problem: generating complete applets with correct ingredient-to-field bindings. We propose FARM (Field-Aware Resolution Model), a two-stage architecture for automated applet generation with full configuration. Stage 1 trains contrastive dual encoders with selective layer freezing over schema-enriched representations, retrieving candidates from 1,724 trigger functions and 1,287 action functions (2.2M possible trigger-action pairs). Stage 2 performs selection and configuration using an LLM-based multi-agent pipeline. It includes intent analysis, trigger selection, action selection via cross-schema scoring, and configuration verification. Agents coordinate through shared state and agreement-based selection. FARM achieves 81% joint accuracy on Gold (62% Noisy, 70% One-shot) at the function level, where both trigger and action functions must match the ground truth. For comparison with service-level baselines, we map functions to their parent services and evaluate at the service level. FARM reaches 81% joint accuracy and improves over TARGE by 23 percentage points. FARM also generates ingredient-to-field bindings, producing executable automation configurations.",
    "authors": [
      "Khusrav Badalov",
      "Young Yoon"
    ],
    "published": "2026-01-22",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.15687v1",
    "arxiv_url": "https://arxiv.org/abs/2601.15687v1",
    "fetched_at": "2026-01-23T08:36:21.225806",
    "chinese_title": "FARM：面向智能触发-动作自动化的字段感知解析模型",
    "chinese_summary": "该文针对触发-动作编程（TAP）平台中函数级配置问题（此前服务级方法易生成不可执行小程序），提出FARM两阶段模型：阶段1用带选择性层冻结的对比双编码器检索候选触发-动作函数对；阶段2通过基于LLM的多智能体 pipeline 完成意图分析、函数选择与配置验证，在函数级联合准确率达81%（Gold数据集）。",
    "tags": [
      "LLM",
      "NLP",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出FARM两阶段架构，解决TAP小程序的函数级配置难题（避免服务级预测的不可执行问题）",
      "阶段1用选择性层冻结的对比双编码器高效检索候选函数对，阶段2通过LLM多智能体实现准确的意图分析、跨schema函数选择与配置验证，提升函数级联合准确率"
    ],
    "processed_at": "2026-01-23T08:42:46.508587"
  },
  {
    "id": "2601.15625v1",
    "title": "Robust Tool Use via Fission-GRPO: Learning to Recover from Execution Errors",
    "abstract": "Large language models (LLMs) can call tools effectively, yet they remain brittle in multi-turn execution: following a tool call error, smaller models often degenerate into repetitive invalid re-invocations, failing to interpret error feedback and self-correct. This brittleness hinders reliable real-world deployment, where the execution errors are inherently inevitable during tool interaction procedures. We identify a key limitation of current approaches: standard reinforcement learning (RL) treats errors as sparse negative rewards, providing no guidance on how to recover, while pre-collected synthetic error-correction datasets suffer from distribution mismatch with the model's on-policy error modes. To bridge this gap, we propose Fission-GRPO, a framework that converts execution errors into corrective supervision within the RL training loop. Our core mechanism fissions each failed trajectory into a new training instance by augmenting it with diagnostic feedback from a finetuned Error Simulator, then resampling recovery rollouts on-policy. This enables the model to learn from the precise errors it makes during exploration, rather than from static, pre-collected error cases. On the BFCL v4 Multi-Turn, Fission-GRPO improves the error recovery rate of Qwen3-8B by 5.7% absolute, crucially, yielding a 4% overall accuracy gain (42.75% to 46.75%) over GRPO and outperforming specialized tool-use agents.",
    "authors": [
      "Zhiwei Zhang",
      "Fei Zhao",
      "Rui Wang",
      "Zezhong Wang",
      "Bin Liang",
      "Jiakang Wang",
      "Yao Hu",
      "Shaosheng Cao",
      "Kam-Fai Wong"
    ],
    "published": "2026-01-22",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.15625v1",
    "arxiv_url": "https://arxiv.org/abs/2601.15625v1",
    "fetched_at": "2026-01-23T08:36:21.225865",
    "chinese_title": "基于Fission-GRPO的鲁棒工具使用：学习从执行错误中恢复",
    "chinese_summary": "针对大语言模型（LLM）多轮工具调用遇错误易重复无效调用的问题，现有强化学习（RL）方法无错误恢复指导、合成数据集分布不匹配，论文提出Fission-GRPO框架——在RL训练循环中用微调错误模拟器的诊断反馈增强失败轨迹，在线重采样恢复滚动，使模型从自身探索的精确错误学习；在BFCL v4多轮任务上，该框架将Qwen3-8B的错误恢复率提升5.7%，整体准确率从42.75%升至46.75%，优于专门工具使用代理。",
    "tags": [
      "LLM",
      "Reinforcement Learning",
      "Execution",
      "Transformer"
    ],
    "key_contributions": [
      "提出Fission-GRPO框架，在RL训练循环中通过错误模拟器增强失败轨迹并在线重采样恢复，解决现有方法的错误恢复指导缺失和分布不匹配问题，使模型从自身探索的错误中学习",
      "在BFCL v4多轮工具调用任务上，显著提升Qwen3-8B的错误恢复率和整体准确率，性能优于现有专门工具使用代理"
    ],
    "processed_at": "2026-01-23T08:43:07.016801"
  },
  {
    "id": "2601.15599v1",
    "title": "Autonomous Business System via Neuro-symbolic AI",
    "abstract": "Current business environments require organizations to continuously reconfigure cross-functional processes, yet enterprise systems are still organized around siloed departments, rigid workflows, and hard-coded automation. Meanwhile large language models (LLMs) excel at interpreting natural language and unstructured data but lack deterministic, verifiable execution of complex business logic. To address this gap, here we introduce AUTOBUS, an Autonomous Business System that integrates LLM-based AI agents, predicate-logic programming, and business-semantics-centric enterprise data into a coherent neuro-symbolic AI architecture for orchestrating end-to-end business initiatives. AUTOBUS models an initiative as a network of tasks with explicit pre/post conditions, required data, evaluation rules, and API-level actions. Enterprise data is organized as a knowledge graph whose entities, relationships, and constraints are translated into logic facts and foundational rules, providing the semantic grounding for task reasoning. Core AI agents synthesize task instructions, enterprise semantics, and available tools into task-specific logic programs, which are executed by a logic engine that enforces constraints, coordinates auxiliary tools, and orchestrate execution of actions and outcomes. Humans define and maintain the semantics, policies and task instructions, curate tools, and supervise high-impact or ambiguous decisions, ensuring accountability and adaptability. We detail the AUTOBUS architecture, the anatomy of the AI agent generated logic programs, and the role of humans and auxiliary tools in the lifecycle of a business initiative.",
    "authors": [
      "Cecil Pang",
      "Hiroki Sayama"
    ],
    "published": "2026-01-22",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.15599v1",
    "arxiv_url": "https://arxiv.org/abs/2601.15599v1",
    "fetched_at": "2026-01-23T08:36:21.225883",
    "chinese_title": "基于神经符号AI的自主业务系统",
    "chinese_summary": "论文提出自主业务系统AUTOBUS，整合LLM代理、谓词逻辑编程与业务语义知识图谱构建神经符号架构；该系统将业务 initiative 建模为带显式条件的数据任务网络，利用逻辑引擎执行约束并协调工具，同时保留人类对语义规则的定义与高影响决策的监督，解决传统企业系统僵化及LLM缺乏确定性执行的问题。",
    "tags": [
      "LLM",
      "NLP",
      "Transformer"
    ],
    "key_contributions": [
      "提出整合LLM、谓词逻辑与业务语义知识图谱的神经符号架构AUTOBUS，弥补传统企业系统僵化与LLM缺乏确定性执行的不足",
      "构建端到端业务initiative的任务网络模型，通过逻辑引擎协调工具执行并保留人类监督，确保可解释性与责任可追溯性"
    ],
    "processed_at": "2026-01-23T08:43:23.170818"
  },
  {
    "id": "2601.15561v1",
    "title": "Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial Optimization Problems",
    "abstract": "This article critically investigates the limitations of the simulated annealing algorithm using probabilistic bits (pSA) in solving large-scale combinatorial optimization problems. The study begins with an in-depth analysis of the pSA process, focusing on the issues resulting from unexpected oscillations among p-bits. These oscillations hinder the energy reduction of the Ising model and thus obstruct the successful execution of pSA in complex tasks. Through detailed simulations, we unravel the root cause of this energy stagnation, identifying the feedback mechanism inherent to the pSA operation as the primary contributor to these disruptive oscillations. To address this challenge, we propose two novel algorithms, time average pSA (TApSA) and stalled pSA (SpSA). These algorithms are designed based on partial deactivation of p-bits and are thoroughly tested using Python simulations on maximum cut benchmarks that are typical combinatorial optimization problems. On the 16 benchmarks from 800 to 5,000 nodes, the proposed methods improve the normalized cut value from 0.8% to 98.4% on average in comparison with the conventional pSA.",
    "authors": [
      "Naoya Onizawa",
      "Takahiro Hanyu"
    ],
    "published": "2026-01-22",
    "categories": [
      "cs.ET",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.15561v1",
    "arxiv_url": "https://arxiv.org/abs/2601.15561v1",
    "fetched_at": "2026-01-23T08:36:21.225902",
    "chinese_title": "基于部分失活的p比特模拟退火算法在大规模组合优化问题中的收敛增强",
    "chinese_summary": "本文分析了基于p比特的模拟退火算法（pSA）因反馈机制导致p比特振荡、能量停滞的问题，提出基于部分失活的时间平均pSA（TApSA）和停滞pSA（SpSA）两种改进算法；在800-5000节点的16个最大割基准测试中，新算法比传统pSA平均提升归一化割值0.8%至98.4%。",
    "tags": [
      "Portfolio Optimization",
      "Benchmark"
    ],
    "key_contributions": [
      "揭示pSA中p比特振荡（源于反馈机制）导致能量停滞的问题根源",
      "提出基于部分失活的TApSA和SpSA算法，显著提升大规模组合优化性能"
    ],
    "processed_at": "2026-01-23T08:43:38.229412"
  },
  {
    "id": "2601.15322v1",
    "title": "Replayable Financial Agents: A Determinism-Faithfulness Assurance Harness for Tool-Using LLM Agents",
    "abstract": "LLM agents struggle with regulatory audit replay: when asked to reproduce a flagged transaction decision with identical inputs, most deployments fail to return consistent results. This paper introduces the Determinism-Faithfulness Assurance Harness (DFAH), a framework for measuring trajectory determinism and evidence-conditioned faithfulness in tool-using agents deployed in financial services.   Across 74 configurations (12 models, 4 providers, 8-24 runs each at T=0.0) in non-agentic baseline experiments, 7-20B parameter models achieved 100% determinism, while 120B+ models required 3.7x larger validation samples to achieve equivalent statistical reliability. Agentic tool-use introduces additional variance (see Tables 4-7). Contrary to the assumed reliability-capability trade-off, a positive Pearson correlation emerged (r = 0.45, p < 0.01, n = 51 at T=0.0) between determinism and faithfulness; models producing consistent outputs also tended to be more evidence-aligned.   Three financial benchmarks are provided (compliance triage, portfolio constraints, DataOps exceptions; 50 cases each) along with an open-source stress-test harness. In these benchmarks and under DFAH evaluation settings, Tier 1 models with schema-first architectures achieved determinism levels consistent with audit replay requirements.",
    "authors": [
      "Raffi Khatchadourian"
    ],
    "published": "2026-01-17",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.15322v1",
    "arxiv_url": "https://arxiv.org/abs/2601.15322v1",
    "fetched_at": "2026-01-23T08:36:58.294565",
    "chinese_title": "可复现金融智能体：面向工具使用型LLM智能体的确定性-忠实性保障框架",
    "chinese_summary": "该论文针对金融服务中工具使用型LLM智能体难以复现交易决策的问题，提出确定性-忠实性保障框架（DFAH）以度量其轨迹确定性与证据条件忠实性；通过多配置实验发现模型确定性与忠实性呈正相关，还提供三个金融基准及开源压力测试工具，验证Tier1模型可满足审计复现要求。",
    "tags": [
      "LLM",
      "Financial Agent",
      "Benchmark"
    ],
    "key_contributions": [
      "提出DFAH框架，用于度量工具使用型LLM智能体的轨迹确定性与证据条件忠实性",
      "提供三个金融基准及开源压力测试工具，验证Tier1模型可满足审计复现要求"
    ],
    "processed_at": "2026-01-23T08:43:48.164985"
  },
  {
    "id": "2601.15597v1",
    "title": "Neural Nonlinear Shrinkage of Covariance Matrices for Minimum Variance Portfolio Optimization",
    "abstract": "This paper introduces a neural network-based nonlinear shrinkage estimator of covariance matrices for the purpose of minimum variance portfolio optimization. It is a hybrid approach that integrates statistical estimation with machine learning. Starting from the Ledoit-Wolf (LW) shrinkage estimator, we decompose the LW covariance matrix into its eigenvalues and eigenvectors, and apply a lightweight transformer-based neural network to learn a nonlinear eigenvalue shrinkage function. Trained with portfolio risk as the loss function, the resulting precision matrix (the inverse covariance matrix) estimator directly targets portfolio risk minimization. By conditioning on the sample-to-dimension ratio, the approach remains scalable across different sample sizes and asset universes. Empirical results on stock daily returns from Standard & Poor's 500 Index (S&P500) demonstrate that the proposed method consistently achieves lower out-of-sample realized risk than benchmark approaches. This highlights the promise of integrating structural statistical models with data-driven learning.",
    "authors": [
      "Liusha Yang",
      "Siqi Zhao",
      "Shuqi Chai"
    ],
    "published": "2026-01-22",
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "pdf_url": "https://arxiv.org/pdf/2601.15597v1",
    "arxiv_url": "https://arxiv.org/abs/2601.15597v1",
    "fetched_at": "2026-01-23T08:38:09.311906",
    "chinese_title": "",
    "chinese_summary": "",
    "tags": [
      "Deep Learning"
    ],
    "key_contributions": [],
    "processed_at": "2026-01-23T08:44:04.656757"
  }
]