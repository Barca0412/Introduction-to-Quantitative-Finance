[
  {
    "id": "2602.12770v1",
    "title": "Efficient Monte Carlo Valuation of Corporate Bonds in Financial Networks",
    "abstract": "Valuing corporate bonds in systemic economies is challenging due to intricate webs of inter-institutional exposures. When a bank defaults, cascading losses propagate through the network, with payments determined by a system of fixed-point equations lacking closed-form solutions. Standard Monte Carlo methods cannot capture rare yet critical default events, while existing rare-event simulation techniques fail to account for higher-order network effects and scale poorly with network size. To overcome these challenges, we propose a novel approach -- Bi-Level Importance Sampling with Splitting -- and characterize individual bank defaults by decoupling them from the network's complex fixed-point dynamics. This separation enables a two-stage estimation process that directly generates samples from the banks' default events. We demonstrate theoretically that the method is both scalable and asymptotically optimal, and validate its effectiveness through numerical studies on empirically observed networks.",
    "authors": [
      "Dohyun Ahn",
      "Agostino Capponi"
    ],
    "published": "2026-02-13",
    "categories": [
      "q-fin.CP",
      "q-fin.PR",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12770v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12770v1",
    "fetched_at": "2026-02-16T08:54:22.957036",
    "chinese_title": "金融网络中企业债券的高效蒙特卡洛估值",
    "chinese_summary": "针对金融网络中企业债券估值因机构间复杂敞口及罕见违约事件难以捕捉的挑战，论文提出双层重要性采样分裂方法，通过解耦单个银行违约与网络不动点动态实现两阶段违约事件样本生成，理论证明其可扩展且渐近最优，实证验证有效。",
    "tags": [
      "Risk Management",
      "Asset Pricing"
    ],
    "key_contributions": [
      "提出双层重要性采样分裂方法，解耦单个银行违约与网络不动点动态，解决金融网络中企业债券估值的罕见违约事件捕捉及高阶网络效应处理难题",
      "理论证明方法可扩展且渐近最优，通过实证网络验证其有效性"
    ],
    "processed_at": "2026-02-16T08:57:19.139868"
  },
  {
    "id": "2602.12490v1",
    "title": "Transformer-based CoVaR: Systemic Risk in Textual Information",
    "abstract": "Conditional Value-at-Risk (CoVaR) quantifies systemic financial risk by measuring the loss quantile of one asset, conditional on another asset experiencing distress. We develop a Transformer-based methodology that integrates financial news articles directly with market data to improve CoVaR estimates. Unlike approaches that use predefined sentiment scores, our method incorporates raw text embeddings generated by a large language model (LLM). We prove explicit error bounds for our Transformer CoVaR estimator, showing that accurate CoVaR learning is possible even with small datasets. Using U.S. market returns and Reuters news items from 2006--2013, our out-of-sample results show that textual information impacts the CoVaR forecasts. With better predictive performance, we identify a pronounced negative dip during market stress periods across several equity assets when comparing the Transformer-based CoVaR to both the CoVaR without text and the CoVaR using traditional sentiment measures. Our results show that textual data can be used to effectively model systemic risk without requiring prohibitively large data sets.",
    "authors": [
      "Junyu Chen",
      "Tom Boot",
      "Lingwei Kong",
      "Weining Wang"
    ],
    "published": "2026-02-13",
    "categories": [
      "econ.EM",
      "q-fin.RM",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12490v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12490v1",
    "fetched_at": "2026-02-16T08:54:22.957077",
    "chinese_title": "基于Transformer的CoVaR：文本信息中的系统性风险",
    "chinese_summary": "本文开发基于Transformer的方法，整合金融新闻文本（LLM生成的原始嵌入而非预定义情感分数）与市场数据改进CoVaR估计；证明其显式误差边界（小数据集可准确学习），样本外结果显示文本信息提升预测性能，能识别市场压力期的显著负向波动且无需超大数据集。",
    "tags": [
      "Transformer",
      "LLM",
      "Risk Management",
      "NLP"
    ],
    "key_contributions": [
      "证明估计器显式误差边界（小数据集可准确学习），样本外验证文本信息提升系统性风险预测性能"
    ],
    "processed_at": "2026-02-16T08:57:30.632567"
  },
  {
    "id": "2602.12976v1",
    "title": "Drift-Aware Variational Autoencoder-based Anomaly Detection with Two-level Ensembling",
    "abstract": "In today's digital world, the generation of vast amounts of streaming data in various domains has become ubiquitous. However, many of these data are unlabeled, making it challenging to identify events, particularly anomalies. This task becomes even more formidable in nonstationary environments where model performance can deteriorate over time due to concept drift. To address these challenges, this paper presents a novel method, VAE++ESDD, which employs incremental learning and two-level ensembling: an ensemble of Variational AutoEncoder(VAEs) for anomaly prediction, along with an ensemble of concept drift detectors. Each drift detector utilizes a statistical-based concept drift mechanism. To evaluate the effectiveness of VAE++ESDD, we conduct a comprehensive experimental study using real-world and synthetic datasets characterized by severely or extremely low anomalous rates and various drift characteristics. Our study reveals that the proposed method significantly outperforms both strong baselines and state-of-the-art methods.",
    "authors": [
      "Jin Li",
      "Kleanthis Malialis",
      "Christos G. Panayiotou",
      "Marios M. Polycarpou"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12976v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12976v1",
    "fetched_at": "2026-02-16T08:54:35.303092",
    "chinese_title": "基于漂移感知变分自编码器和两级集成的异常检测",
    "chinese_summary": "本文提出VAE++ESDD方法，结合增量学习与两级集成（变分自编码器集成用于异常预测、概念漂移检测器集成），每个漂移检测器采用统计机制，针对低异常率及多种漂移特征的真实与合成数据，实验表明其显著优于基线与SOTA方法。",
    "tags": [
      "Anomaly",
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "提出VAE++ESDD方法，通过两级集成（VAE集成+漂移检测器集成）应对非平稳环境下的异常检测挑战",
      "在低异常率及多种漂移特征的真实/合成数据上，方法性能显著优于现有基线与SOTA方法"
    ],
    "processed_at": "2026-02-16T08:57:39.254486"
  },
  {
    "id": "2602.12622v1",
    "title": "Efficient Personalized Federated PCA with Manifold Optimization for IoT Anomaly Detection",
    "abstract": "Internet of things (IoT) networks face increasing security threats due to their distributed nature and resource constraints. Although federated learning (FL) has gained prominence as a privacy-preserving framework for distributed IoT environments, current federated principal component analysis (PCA) methods lack the integration of personalization and robustness, which are critical for effective anomaly detection. To address these limitations, we propose an efficient personalized federated PCA (FedEP) method for anomaly detection in IoT networks. The proposed model achieves personalization through introducing local representations with the $\\ell_1$-norm for element-wise sparsity, while maintaining robustness via enforcing local models with the $\\ell_{2,1}$-norm for row-wise sparsity. To solve this non-convex problem, we develop a manifold optimization algorithm based on the alternating direction method of multipliers (ADMM) with rigorous theoretical convergence guarantees. Experimental results confirm that the proposed FedEP outperforms the state-of-the-art FedPG, achieving excellent F1-scores and accuracy in various IoT security scenarios. Our code will be available at \\href{https://github.com/xianchaoxiu/FedEP}{https://github.com/xianchaoxiu/FedEP}.",
    "authors": [
      "Xianchao Xiu",
      "Chenyi Huang",
      "Wei Zhang",
      "Wanquan Liu"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12622v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12622v1",
    "fetched_at": "2026-02-16T08:54:35.303123",
    "chinese_title": "基于流形优化的高效个性化联邦主成分分析在物联网异常检测中的应用",
    "chinese_summary": "针对物联网（IoT）网络安全威胁下现有联邦主成分分析（PCA）缺乏个性化与鲁棒性的问题，本文提出高效个性化联邦PCA（FedEP）方法：通过ℓ₁范数实现局部表示元素级稀疏以个性化，ℓ₂,₁范数实现行级稀疏以鲁棒性；设计基于交替方向乘子法（ADMM）的流形优化算法求解非凸问题并保证收敛，实验表明其在IoT异常检测中优于SOTA的FedPG。",
    "tags": [
      "Anomaly",
      "Factor Model"
    ],
    "key_contributions": [
      "提出FedEP方法，融合个性化（ℓ₁稀疏）与鲁棒性（ℓ₂,₁行稀疏），适配物联网异常检测场景",
      "构建基于ADMM的流形优化算法，理论保证收敛性，实验验证优于现有方法FedPG"
    ],
    "processed_at": "2026-02-16T08:57:55.542056"
  },
  {
    "id": "2602.12592v1",
    "title": "Power Interpretable Causal ODE Networks: A Unified Model for Explainable Anomaly Detection and Root Cause Analysis in Power Systems",
    "abstract": "Anomaly detection and root cause analysis (RCA) are critical for ensuring the safety and resilience of cyber-physical systems such as power grids. However, existing machine learning models for time series anomaly detection often operate as black boxes, offering only binary outputs without any explanation, such as identifying anomaly type and origin. To address this challenge, we propose Power Interpretable Causality Ordinary Differential Equation (PICODE) Networks, a unified, causality-informed architecture that jointly performs anomaly detection along with the explanation why it is detected as an anomaly, including root cause localization, anomaly type classification, and anomaly shape characterization. Experimental results in power systems demonstrate that PICODE achieves competitive detection performance while offering improved interpretability and reduced reliance on labeled data or external causal graphs. We provide theoretical results demonstrating the alignment between the shape of anomaly functions and the changes in the weights of the extracted causal graphs.",
    "authors": [
      "Yue Sun",
      "Likai Wang",
      "Rick S. Blum",
      "Parv Venkitasubramaniam"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12592v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12592v1",
    "fetched_at": "2026-02-16T08:54:35.303148",
    "chinese_title": "电力可解释因果ODE网络：电力系统中可解释异常检测与根因分析的统一模型",
    "chinese_summary": "针对电力系统等信息物理系统中现有异常检测模型黑箱化、缺乏解释的问题，提出PICODE网络——一种因果感知的统一架构，可联合实现异常检测及多维度解释（根因定位、异常类型分类、异常形状刻画）；实验表明其检测性能具竞争力，解释性提升且减少对标注数据或外部因果图的依赖，还给出异常函数形状与提取的因果图权重变化对齐的理论结果。",
    "tags": [
      "Anomaly",
      "Time Series",
      "Deep Learning",
      "Graph Neural Network"
    ],
    "key_contributions": [
      "提出因果感知的PICODE网络，统一实现电力系统异常检测与多维度解释（根因定位、类型分类、形状刻画）",
      "实验验证检测性能竞争力，解释性提升且减少对标注数据/外部因果图依赖，同时提供异常形状与因果图权重变化对齐的理论支撑"
    ],
    "processed_at": "2026-02-16T08:58:13.815495"
  },
  {
    "id": "2602.13106v1",
    "title": "Which Algorithms Can Graph Neural Networks Learn?",
    "abstract": "In recent years, there has been growing interest in understanding neural architectures' ability to learn to execute discrete algorithms, a line of work often referred to as neural algorithmic reasoning. The goal is to integrate algorithmic reasoning capabilities into larger neural pipelines. Many such architectures are based on (message-passing) graph neural networks (MPNNs), owing to their permutation equivariance and ability to deal with sparsity and variable-sized inputs. However, existing work is either largely empirical and lacks formal guarantees or it focuses solely on expressivity, leaving open the question of when and how such architectures generalize beyond a finite training set. In this work, we propose a general theoretical framework that characterizes the sufficient conditions under which MPNNs can learn an algorithm from a training set of small instances and provably approximate its behavior on inputs of arbitrary size. Our framework applies to a broad class of algorithms, including single-source shortest paths, minimum spanning trees, and general dynamic programming problems, such as the $0$-$1$ knapsack problem. In addition, we establish impossibility results for a wide range of algorithmic tasks, showing that standard MPNNs cannot learn them, and we derive more expressive MPNN-like architectures that overcome these limitations. Finally, we refine our analysis for the Bellman-Ford algorithm, yielding a substantially smaller required training set and significantly extending the recent work of Nerem et al. [2025] by allowing for a differentiable regularization loss. Empirical results largely support our theoretical findings.",
    "authors": [
      "Solveig Wittig",
      "Antonis Vasileiou",
      "Robert R. Nerem",
      "Timo Stoll",
      "Floris Geerts",
      "Yusu Wang",
      "Christopher Morris"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS",
      "cs.NE"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.13106v1",
    "arxiv_url": "https://arxiv.org/abs/2602.13106v1",
    "fetched_at": "2026-02-16T08:55:02.996614",
    "chinese_title": "图神经网络能学习哪些算法？",
    "chinese_summary": "该文提出理论框架刻画消息传递图神经网络（MPNN）从训练小实例学习算法并泛化到任意大小输入的充分条件，覆盖单源最短路径、最小生成树等多类算法；给出标准MPNN无法学习部分任务的不可能结果，推导更具表达力的类MPNN架构；还细化Bellman-Ford算法分析以缩小训练集需求。",
    "tags": [
      "Graph Neural Network",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出理论框架刻画MPNN从训练小实例学习算法并泛化到任意大小输入的充分条件，覆盖多类经典算法",
      "给出标准MPNN无法学习部分任务的不可能结果，推导更具表达力的类MPNN架构"
    ],
    "processed_at": "2026-02-16T08:58:26.588897"
  },
  {
    "id": "2602.13021v1",
    "title": "Prior-Guided Symbolic Regression: Towards Scientific Consistency in Equation Discovery",
    "abstract": "Symbolic Regression (SR) aims to discover interpretable equations from observational data, with the potential to reveal underlying principles behind natural phenomena. However, existing approaches often fall into the Pseudo-Equation Trap: producing equations that fit observations well but remain inconsistent with fundamental scientific principles. A key reason is that these approaches are dominated by empirical risk minimization, lacking explicit constraints to ensure scientific consistency. To bridge this gap, we propose PG-SR, a prior-guided SR framework built upon a three-stage pipeline consisting of warm-up, evolution, and refinement. Throughout the pipeline, PG-SR introduces a prior constraint checker that explicitly encodes domain priors as executable constraint programs, and employs a Prior Annealing Constrained Evaluation (PACE) mechanism during the evolution stage to progressively steer discovery toward scientifically consistent regions. Theoretically, we prove that PG-SR reduces the Rademacher complexity of the hypothesis space, yielding tighter generalization bounds and establishing a guarantee against pseudo-equations. Experimentally, PG-SR outperforms state-of-the-art baselines across diverse domains, maintaining robustness to varying prior quality, noisy data, and data scarcity.",
    "authors": [
      "Jing Xiao",
      "Xinhai Chen",
      "Jiaming Peng",
      "Qinglin Wang",
      "Menghan Jia",
      "Zhiquan Lai",
      "Guangping Yu",
      "Dongsheng Li",
      "Tiejun Li",
      "Jie Liu"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.13021v1",
    "arxiv_url": "https://arxiv.org/abs/2602.13021v1",
    "fetched_at": "2026-02-16T08:55:02.996664",
    "chinese_title": "先验引导的符号回归：迈向方程发现中的科学一致性",
    "chinese_summary": "现有符号回归易陷入伪方程陷阱（拟合好但违背科学原理），本文提出PG-SR框架，通过三阶段 pipeline（预热、进化、精炼）引入先验约束检查器（编码领域先验为可执行约束）和PACE机制（渐进引导进化到科学一致区域）；理论证明其降低假设空间拉德马赫复杂度、提升泛化性并抗伪方程，实验优于SOTA且鲁棒性好。",
    "tags": [
      "Factor Mining",
      "Deep Learning",
      "Time Series"
    ],
    "key_contributions": [
      "提出先验引导的符号回归框架PG-SR，通过显式先验约束与渐进引导机制，解决现有方法的伪方程陷阱问题",
      "理论证明PG-SR降低假设空间复杂度、给出泛化保证，实验验证其优于SOTA且对先验质量、噪声、数据稀缺具有鲁棒性"
    ],
    "processed_at": "2026-02-16T08:58:47.674267"
  },
  {
    "id": "2602.12984v1",
    "title": "SciAgentGym: Benchmarking Multi-Step Scientific Tool-use in LLM Agents",
    "abstract": "Scientific reasoning inherently demands integrating sophisticated toolkits to navigate domain-specific knowledge. Yet, current benchmarks largely overlook agents' ability to orchestrate tools for such rigorous workflows. To bridge this gap, we introduce SciAgentGym, a scalable interactive environment featuring 1,780 domain-specific tools across four natural science disciplines, supported by a robust execution infrastructure. Complementing this, we present SciAgentBench, a tiered evaluation suite designed to stress-test agentic capabilities from elementary actions to long-horizon workflows. Our evaluation identifies a critical bottleneck: state-of-the-art models struggle with complex scientific tool-use. Even for a leading model like GPT-5, success rates drop sharply from 60.6% to 30.9% as interaction horizons extend, primarily due to failures in multi-step workflow execution. To address this, we propose SciForge, a data synthesis method that models the tool action space as a dependency graph to generate logic-aware training trajectories. By fine-tuning on these trajectories, our SciAgent-8B outperforms the significantly larger Qwen3-VL-235B-Instruct while exhibiting positive cross-domain transfer of scientific tool-use capabilities. These results underscore the promising potential of next-generation autonomous scientific agents.",
    "authors": [
      "Yujiong Shen",
      "Yajie Yang",
      "Zhiheng Xi",
      "Binze Hu",
      "Huayu Sha",
      "Jiazheng Zhang",
      "Qiyuan Peng",
      "Junlin Shang",
      "Jixuan Huang",
      "Yutao Fan",
      "Jingqi Tong",
      "Shihan Dou",
      "Ming Zhang",
      "Lei Bai",
      "Zhenfei Yin",
      "Tao Gui",
      "Xingjun Ma",
      "Qi Zhang",
      "Xuanjing Huang",
      "Yu-Gang Jiang"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12984v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12984v1",
    "fetched_at": "2026-02-16T08:55:02.996717",
    "chinese_title": "SciAgentGym：基准测试LLM智能体的多步科学工具使用能力",
    "chinese_summary": "论文提出SciAgentGym（含1780个跨4自然科学领域工具的交互式环境）和SciAgentBench（分层评估套件），发现当前SOTA模型在多步科学工具使用中存在显著瓶颈；进而提出SciForge方法（将工具动作空间建模为依赖图生成逻辑感知训练轨迹），基于此微调的SciAgent-8B性能优于更大规模的Qwen3-VL-235B-Instruct且具备跨域迁移能力。",
    "tags": [
      "LLM",
      "Benchmark",
      "Transformer"
    ],
    "key_contributions": [
      "提出SciAgentGym（含1780个跨4自然科学领域工具的交互式环境）和SciAgentBench（分层评估套件），填补当前基准对智能体科学工具编排能力的空白",
      "提出SciForge数据合成方法（建模工具动作空间为依赖图生成逻辑感知训练轨迹），微调后的SciAgent-8B优于更大模型且具备跨域迁移能力"
    ],
    "processed_at": "2026-02-16T08:59:06.565321"
  },
  {
    "id": "2602.12978v1",
    "title": "Learning Native Continuation for Action Chunking Flow Policies",
    "abstract": "Action chunking enables Vision Language Action (VLA) models to run in real time, but naive chunked execution often exhibits discontinuities at chunk boundaries. Real-Time Chunking (RTC) alleviates this issue but is external to the policy, leading to spurious multimodal switching and trajectories that are not intrinsically smooth. We propose Legato, a training-time continuation method for action-chunked flow-based VLA policies. Specifically, Legato initializes denoising from a schedule-shaped mixture of known actions and noise, exposing the model to partial action information. Moreover, Legato reshapes the learned flow dynamics to ensure that the denoising process remains consistent between training and inference under per-step guidance. Legato further uses randomized schedule condition during training to support varying inference delays and achieve controllable smoothness. Empirically, Legato produces smoother trajectories and reduces spurious multimodal switching during execution, leading to less hesitation and shorter task completion time. Extensive real-world experiments show that Legato consistently outperforms RTC across five manipulation tasks, achieving approximately 10% improvements in both trajectory smoothness and task completion time.",
    "authors": [
      "Yufeng Liu",
      "Hang Yu",
      "Juntu Zhao",
      "Bocheng Li",
      "Di Zhang",
      "Mingzhu Li",
      "Wenxuan Wu",
      "Yingdong Hu",
      "Junyuan Xie",
      "Junliang Guo",
      "Dequan Wang",
      "Yang Gao"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12978v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12978v1",
    "fetched_at": "2026-02-16T08:55:02.996756",
    "chinese_title": "学习动作分块流策略的原生连续性",
    "chinese_summary": "针对视觉语言动作（VLA）模型动作分块执行时的边界不连续及虚假多模态切换问题，提出Legato原生连续性方法，通过调度形状的已知动作与噪声混合初始化去噪、重塑流动力学保证训练推理一致性、随机调度条件支持延迟与可控平滑；实验表明其在5个操作任务中轨迹更平滑、任务完成时间更短，较现有方法RTC提升约10%。",
    "tags": [
      "Deep Learning",
      "Reinforcement Learning",
      "LLM"
    ],
    "key_contributions": [
      "提出Legato训练时原生连续性方法，解决VLA动作分块的边界不连续、虚假多模态切换问题",
      "设计调度形状混合初始化、流动力学重塑、随机调度条件，实现训练推理一致与可控平滑，实验在操作任务中优于RTC约10%"
    ],
    "processed_at": "2026-02-16T08:59:27.620722"
  },
  {
    "id": "2602.12962v1",
    "title": "TriGen: NPU Architecture for End-to-End Acceleration of Large Language Models based on SW-HW Co-Design",
    "abstract": "Recent studies have extensively explored NPU architectures for accelerating AI inference in on-device environments, which are inherently resource-constrained. Meanwhile, transformer-based large language models (LLMs) have become dominant, with rapidly increasing model sizes but low degree of parameter reuse compared to conventional CNNs, making end-to-end execution on resource-limited devices extremely challenging. To address these challenges, we propose TriGen, a novel NPU architecture tailored for resource-constrained environments through software-hardware co-design. Firstly, TriGen adopts low-precision computation using microscaling (MX) to enable additional optimization opportunities while preserving accuracy, and resolves the issues that arise by employing such precision. Secondly, to jointly optimize both nonlinear and linear operations, TriGen eliminates the need for specialized hardware for essential nonlinear operations by using fast and accurate LUT, thereby maximizing performance gains and reducing hardware-cost in on-device environments, and finally, by taking practical hardware constraints into account, further employs scheduling techniques to maximize computational utilization even under limited on-chip memory capacity. We evaluate the performance of TriGen on various LLMs and show that TriGen achieves an average 2.73x performance speedup and 52% less memory transfer over the baseline NPU design with negligible accuracy loss.",
    "authors": [
      "Jonghun Lee",
      "Junghoon Lee",
      "Hyeonjin Kim",
      "Seoho Jeon",
      "Jisup Yoon",
      "Hyunbin Park",
      "Meejeong Park",
      "Heonjae Ha"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12962v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12962v1",
    "fetched_at": "2026-02-16T08:55:02.996787",
    "chinese_title": "TriGen：基于软硬件协同设计的大语言模型端到端加速NPU架构",
    "chinese_summary": "针对资源受限环境下大语言模型（LLM）端到端执行的挑战，本文提出TriGen NPU架构，通过软硬件协同设计实现优化：采用微缩放（MX）低精度计算、LUT替代非线性操作专用硬件、调度技术提升计算利用率；评估显示其较基线平均2.73x加速、减少52%内存传输，精度损失可忽略。",
    "tags": [
      "LLM",
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出TriGen软硬件协同设计的NPU架构，适配资源受限环境下LLM端到端加速的需求",
      "采用低精度计算（MX）、LUT优化非线性操作、调度技术提升利用率，实现显著性能提升与内存优化，精度损失可忽略"
    ],
    "processed_at": "2026-02-16T08:59:38.887328"
  },
  {
    "id": "2602.12691v1",
    "title": "ALOE: Action-Level Off-Policy Evaluation for Vision-Language-Action Model Post-Training",
    "abstract": "We study how to improve large foundation vision-language-action (VLA) systems through online reinforcement learning (RL) in real-world settings. Central to this process is the value function, which provides learning signals to guide VLA learning from experience. In practice, the value function is estimated from trajectory fragments collected from different data sources, including historical policies and intermittent human interventions. Estimating the value function of current behavior quality from the mixture data is inherently an off-policy evaluation problem. However, prior work often adopts conservative on-policy estimation for stability, which avoids direct evaluation of the current high-capacity policy and limits learning effectiveness. In this paper, we propose ALOE, an action-level off-policy evaluation framework for VLA post-training. ALOE applies chunking-based temporal-difference bootstrapping to evaluate individual action sequences instead of predicting final task outcomes. This design improves effective credit assignment to critical action chunks under sparse rewards and supports stable policy improvement. We evaluate our method on three real-world manipulation tasks, including smartphone packing as a high-precision task, laundry folding as a long-horizon deformable-object task, and bimanual pick-and-place involving multi-object perception. Across all tasks, ALOE improves learning efficiency without compromising execution speed, showing that off-policy RL can be reintroduced in a reliable manner for real-world VLA post-training. Videos and additional materials are available at our project website.",
    "authors": [
      "Rushuai Yang",
      "Hecheng Wang",
      "Chiming Liu",
      "Xiaohan Yan",
      "Yunlong Wang",
      "Xuan Du",
      "Shuoyu Yue",
      "Yongcheng Liu",
      "Chuheng Zhang",
      "Lizhe Qi",
      "Yi Chen",
      "Wei Shan",
      "Maoqing Yao"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12691v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12691v1",
    "fetched_at": "2026-02-16T08:55:02.996826",
    "chinese_title": "ALOE：视觉-语言-动作模型后训练的动作级离线策略评估",
    "chinese_summary": "论文针对视觉-语言-动作（VLA）系统在线强化学习中的离线策略评估问题，提出ALOE框架；该框架采用基于分块的时序差分自举方法评估单个动作序列而非最终任务结果，提升稀疏奖励下关键动作分块的信用分配并支持稳定策略改进；在三个真实操作任务上验证了方法能提高学习效率且不影响执行速度。",
    "tags": [
      "Reinforcement Learning",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "提出ALOE动作级离线策略评估框架，解决VLA在线强化学习中混合数据的价值函数估计难题",
      "采用分块时序差分自举评估动作序列，提升稀疏奖励下信用分配并支持稳定策略改进，在真实操作任务上验证有效"
    ],
    "processed_at": "2026-02-16T08:59:58.730500"
  },
  {
    "id": "2602.12684v1",
    "title": "Xiaomi-Robotics-0: An Open-Sourced Vision-Language-Action Model with Real-Time Execution",
    "abstract": "In this report, we introduce Xiaomi-Robotics-0, an advanced vision-language-action (VLA) model optimized for high performance and fast and smooth real-time execution. The key to our method lies in a carefully designed training recipe and deployment strategy. Xiaomi-Robotics-0 is first pre-trained on large-scale cross-embodiment robot trajectories and vision-language data, endowing it with broad and generalizable action-generation capabilities while avoiding catastrophic forgetting of the visual-semantic knowledge of the underlying pre-trained VLM. During post-training, we propose several techniques for training the VLA model for asynchronous execution to address the inference latency during real-robot rollouts. During deployment, we carefully align the timesteps of consecutive predicted action chunks to ensure continuous and seamless real-time rollouts. We evaluate Xiaomi-Robotics-0 extensively in simulation benchmarks and on two challenging real-robot tasks that require precise and dexterous bimanual manipulation. Results show that our method achieves state-of-the-art performance across all simulation benchmarks. Moreover, Xiaomi-Robotics-0 can roll out fast and smoothly on real robots using a consumer-grade GPU, achieving high success rates and throughput on both real-robot tasks. To facilitate future research, code and model checkpoints are open-sourced at https://xiaomi-robotics-0.github.io",
    "authors": [
      "Rui Cai",
      "Jun Guo",
      "Xinze He",
      "Piaopiao Jin",
      "Jie Li",
      "Bingxuan Lin",
      "Futeng Liu",
      "Wei Liu",
      "Fei Ma",
      "Kun Ma",
      "Feng Qiu",
      "Heng Qu",
      "Yifei Su",
      "Qiao Sun",
      "Dong Wang",
      "Donghao Wang",
      "Yunhong Wang",
      "Rujie Wu",
      "Diyun Xiang",
      "Yu Yang",
      "Hangjun Ye",
      "Yuan Zhang",
      "Quanyun Zhou"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12684v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12684v1",
    "fetched_at": "2026-02-16T08:55:02.996887",
    "chinese_title": "Xiaomi-Robotics-0：一种开源的实时执行视觉-语言-动作模型",
    "chinese_summary": "论文提出优化实时执行的视觉-语言-动作（VLA）模型Xiaomi-Robotics-0，通过大规模跨实体机器人轨迹与视觉语言数据预训练，结合异步执行训练及时间步对齐策略，在仿真基准和真实机器人任务中达SOTA性能并开源代码模型。",
    "tags": [
      "Deep Learning",
      "Transformer",
      "Execution",
      "Benchmark"
    ],
    "key_contributions": [
      "提出优化实时执行的VLA模型Xiaomi-Robotics-0，结合预训练与异步执行等技术提升性能",
      "在仿真与真实机器人任务中实现SOTA，开源代码与模型检查点助力研究"
    ],
    "processed_at": "2026-02-16T09:00:11.363918"
  },
  {
    "id": "2602.12662v1",
    "title": "Think Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents",
    "abstract": "Large language models (LLMs) are increasingly deployed as autonomous agents for multi-turn decision-making tasks. However, current agents typically rely on fixed cognitive patterns: non-thinking models generate immediate responses, while thinking models engage in deep reasoning uniformly. This rigidity is inefficient for long-horizon tasks, where cognitive demands vary significantly from step to step, with some requiring strategic planning and others only routine execution. In this paper, we introduce CogRouter, a framework that trains agents to dynamically adapt cognitive depth at each step. Grounded in ACT-R theory, we design four hierarchical cognitive levels ranging from instinctive responses to strategic planning. Our two-stage training approach includes Cognition-aware Supervised Fine-tuning (CoSFT) to instill stable level-specific patterns, and Cognition-aware Policy Optimization (CoPO) for step-level credit assignment via confidence-aware advantage reweighting. The key insight is that appropriate cognitive depth should maximize the confidence of the resulting action. Experiments on ALFWorld and ScienceWorld demonstrate that CogRouter achieves state-of-the-art performance with superior efficiency. With Qwen2.5-7B, it reaches an 82.3% success rate, outperforming GPT-4o (+40.3%), OpenAI-o3 (+18.3%), and GRPO (+14.0%), while using 62% fewer tokens.",
    "authors": [
      "Ruihan Yang",
      "Fanghua Ye",
      "Xiang We",
      "Ruoqing Zhao",
      "Kang Luo",
      "Xinbo Xu",
      "Bo Zhao",
      "Ruotian Ma",
      "Shanyi Wang",
      "Zhaopeng Tu",
      "Xiaolong Li",
      "Deqing Yang",
      " Linus"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12662v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12662v1",
    "fetched_at": "2026-02-16T08:55:02.996926",
    "chinese_title": "快思慢想：面向LLM智能体的步骤级认知深度自适应",
    "chinese_summary": "论文针对当前LLM智能体固定认知模式的低效问题，提出CogRouter框架，基于ACT-R理论设计四层认知层级，通过认知感知监督微调（CoSFT）和认知感知策略优化（CoPO）实现步骤级动态认知深度自适应，在ALFWorld和ScienceWorld任务中取得SOTA性能且大幅减少token使用。",
    "tags": [
      "LLM",
      "Reinforcement Learning",
      "Deep Learning",
      "Transformer"
    ],
    "key_contributions": [
      "设计基于ACT-R理论的四层认知层级及CoSFT、CoPO两阶段训练方法，在提升任务性能的同时显著降低token消耗"
    ],
    "processed_at": "2026-02-16T09:00:20.551791"
  },
  {
    "id": "2602.12630v1",
    "title": "TensorCommitments: A Lightweight Verifiable Inference for Language Models",
    "abstract": "Most large language models (LLMs) run on external clouds: users send a prompt, pay for inference, and must trust that the remote GPU executes the LLM without any adversarial tampering. We critically ask how to achieve verifiable LLM inference, where a prover (the service) must convince a verifier (the client) that an inference was run correctly without rerunning the LLM. Existing cryptographic works are too slow at the LLM scale, while non-cryptographic ones require a strong verifier GPU. We propose TensorCommitments (TCs), a tensor-native proof-of-inference scheme. TC binds the LLM inference to a commitment, an irreversible tag that breaks under tampering, organized in our multivariate Terkle Trees. For LLaMA2, TC adds only 0.97% prover and 0.12% verifier time over inference while improving robustness to tailored LLM attacks by up to 48% over the best prior work requiring a verifier GPU.",
    "authors": [
      "Oguzhan Baser",
      "Elahe Sadeghi",
      "Eric Wang",
      "David Ribeiro Alves",
      "Sam Kazemian",
      "Hong Kang",
      "Sandeep P. Chinchali",
      "Sriram Vishwanath"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12630v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12630v1",
    "fetched_at": "2026-02-16T08:55:02.996956",
    "chinese_title": "TensorCommitments：面向语言模型的轻量级可验证推理",
    "chinese_summary": "针对现有LLM可验证推理方案要么密码学方法效率低、要么非密码学方法依赖强验证GPU的不足，论文提出基于张量原生的TensorCommitments（TC）方案，通过多元Terkle树将LLM推理绑定到抗篡改承诺，在LLaMA2模型上仅增加0.97%的推理方时间和0.12%的验证方时间，且对定制LLM攻击的鲁棒性提升最高达48%。",
    "tags": [
      "LLM",
      "Transformer",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出张量原生的可验证LLM推理方案TensorCommitments（TC），解决现有方案效率或验证资源依赖的问题",
      "在LLaMA2上实现低开销且显著提升对定制LLM攻击的鲁棒性（最高48%）"
    ],
    "processed_at": "2026-02-16T09:00:35.823662"
  },
  {
    "id": "2602.12574v1",
    "title": "Monte Carlo Tree Search with Reasoning Path Refinement for Small Language Models in Conversational Text-to-NoSQL",
    "abstract": "NoSQL databases have been widely adopted in big data analytics, geospatial applications, and healthcare services, due to their flexibility and scalability. However, querying NoSQL databases requires specialized technical expertise, creating a high barrier for users. While recent studies have explored text-to-NoSQL problem, they primarily focus on single-turn interactions, ignoring the conversational nature of real-world queries. To bridge this gap, we introduce the Conversational Text-to-NoSQL task, which generates NoSQL queries given a natural language question, a NoSQL database, and the dialogue history. To address this task, we propose Stage-MCTS, a framework that endows small language models (SLMs) with NoSQL-specific reasoning capabilities by formulating query generation as a search problem. The framework employs Monte Carlo Tree Search (MCTS) guided by a rule-based reward to produce stepwise reasoning data, followed by progressive supervised fine-tuning (SFT) and self-training strategies. We further construct CoNoSQL, a cross-domain dataset with over 2,000 dialogues and 150 databases, to support evaluation. Experiments demonstrate that our approach outperforms state-of-the-art large reasoning models, improving execution value match (EVM) accuracy by up to 7.93%.",
    "authors": [
      "Xubang Xiong",
      "Raymond Chi-Wing Wong",
      "Yuanfeng Song"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12574v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12574v1",
    "fetched_at": "2026-02-16T08:55:02.996977",
    "chinese_title": "用于对话式Text-to-NoSQL中小语言模型的推理路径细化蒙特卡洛树搜索方法",
    "chinese_summary": "该论文提出对话式Text-to-NoSQL任务，针对此任务设计Stage-MCTS框架，通过蒙特卡洛树搜索生成分步推理数据并结合渐进监督微调与自训练策略，同时构建跨领域CoNoSQL数据集，实验表明其性能优于现有SOTA大模型。",
    "tags": [
      "NLP",
      "LLM",
      "Deep Learning"
    ],
    "key_contributions": [
      "提出对话式Text-to-NoSQL任务并构建跨领域CoNoSQL数据集（含2000+对话和150+数据库）",
      "设计Stage-MCTS框架，使小语言模型通过分步推理数据生成与渐进训练在该任务上优于SOTA大模型"
    ],
    "processed_at": "2026-02-16T09:00:54.684554"
  },
  {
    "id": "2602.12426v1",
    "title": "Interference-Robust Non-Coherent Over-the-Air Computation for Decentralized Optimization",
    "abstract": "Non-coherent over-the-air (NCOTA) computation enables low-latency and bandwidth-efficient decentralized optimization by exploiting the average energy superposition property of wireless channels. It has recently been proposed as a powerful tool for executing consensus-based optimization algorithms in fully decentralized systems. A key advantage of NCOTA is that it enables unbiased consensus estimation without channel state information at either transmitters or receivers, requires no transmission scheduling, and scales efficiently to dense network deployments. However, NCOTA is inherently susceptible to external interference, which can bias the consensus estimate and deteriorate the convergence of the underlying decentralized optimization algorithm. In this paper, we propose a novel interference-robust (IR-)NCOTA scheme. The core idea is to apply a coordinated random rotation of the frame of reference across all nodes, and transmit a pseudo-random pilot signal, allowing to transform external interference into a circularly symmetric distribution with zero mean relative to the rotated frame. This ensures that the consensus estimates remain unbiased, preserving the convergence guarantees of the underlying optimization algorithm. Through numerical results on a classification task, it is demonstrated that IR-NCOTA exhibits superior performance over the baseline NCOTA algorithm in the presence of external interference.",
    "authors": [
      "Nicolò Michelusi"
    ],
    "published": "2026-02-12",
    "categories": [
      "eess.SP",
      "cs.LG",
      "cs.MA"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12426v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12426v1",
    "fetched_at": "2026-02-16T08:55:02.996995",
    "chinese_title": "面向分散优化的抗干扰非相干空中计算",
    "chinese_summary": "非相干空中计算（NCOTA）是分散优化的高效工具，但易受外部干扰导致共识估计有偏、优化收敛性下降；论文提出抗干扰IR-NCOTA方案，通过协调随机旋转参考系并传输伪随机导频，将干扰转化为零均值圆对称分布以保持估计无偏，保留优化收敛性；数值实验验证其干扰下性能优于基线NCOTA。",
    "tags": [
      "Algorithmic Trading",
      "Portfolio Optimization",
      "Risk Management"
    ],
    "key_contributions": [
      "提出抗干扰非相干空中计算（IR-NCOTA）方案，解决NCOTA易受外部干扰的问题",
      "设计协调随机旋转参考系+伪随机导频的方法，将干扰转化为零均值圆对称分布，保证共识估计无偏并保留优化收敛性",
      "通过分类任务数值实验验证IR-NCOTA在干扰场景下性能优于基线NCOTA"
    ],
    "processed_at": "2026-02-16T09:01:18.033054"
  },
  {
    "id": "2602.12419v1",
    "title": "Intent-Driven Smart Manufacturing Integrating Knowledge Graphs and Large Language Models",
    "abstract": "The increasing complexity of smart manufacturing environments demands interfaces that can translate high-level human intents into machine-executable actions. This paper presents a unified framework that integrates instruction-tuned Large Language Models (LLMs) with ontology-aligned Knowledge Graphs (KGs) to enable intent-driven interaction in Manufacturing-as-a-Service (MaaS) ecosystems. We fine-tune Mistral-7B-Instruct-V02 on a domain-specific dataset, enabling the translation of natural language intents into structured JSON requirement models. These models are semantically mapped to a Neo4j-based knowledge graph grounded in the ISA-95 standard, ensuring operational alignment with manufacturing processes, resources, and constraints. Our experimental results demonstrate significant performance gains over zero-shot and 3-shots baselines, achieving 89.33\\% exact match accuracy and 97.27\\% overall accuracy. This work lays the foundation for scalable, explainable, and adaptive human-machine",
    "authors": [
      "Takoua Jradi",
      "John Violos",
      "Dimitrios Spatharakis",
      "Lydia Mavraidi",
      "Ioannis Dimolitsas",
      "Aris Leivadeas",
      "Symeon Papavassiliou"
    ],
    "published": "2026-02-12",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12419v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12419v1",
    "fetched_at": "2026-02-16T08:55:02.997024",
    "chinese_title": "融合知识图谱与大语言模型的意图驱动智能制造",
    "chinese_summary": "本文提出融合指令微调大语言模型（Mistral-7B-Instruct-V02）与ISA-95标准Neo4j知识图谱的统一框架，实现自然语言意图到结构化JSON需求模型的转化，支撑制造即服务（MaaS）生态的意图驱动交互；实验显示该框架显著优于零样本和3样本基线，精确匹配准确率达89.33%、整体准确率97.27%，为可扩展、可解释的自适应人机交互奠定基础。",
    "tags": [
      "LLM",
      "Transformer",
      "NLP",
      "Graph Neural Network"
    ],
    "key_contributions": [
      "提出融合指令微调LLM与ISA-95标准知识图谱的统一框架，实现自然语言意图到结构化需求模型的转化，支撑MaaS生态意图驱动交互",
      "实验验证该框架性能显著优于基线，为可扩展、可解释的自适应人机交互奠定基础"
    ],
    "processed_at": "2026-02-16T09:01:34.268094"
  },
  {
    "id": "2602.12322v1",
    "title": "ForeAct: Steering Your VLA with Efficient Visual Foresight Planning",
    "abstract": "Vision-Language-Action (VLA) models convert high-level language instructions into concrete, executable actions, a task that is especially challenging in open-world environments. We present Visual Foresight Planning (ForeAct), a general and efficient planner that guides a VLA step-by-step using imagined future observations and subtask descriptions. With an imagined future observation, the VLA can focus on visuo-motor inference rather than high-level semantic reasoning, leading to improved accuracy and generalization. Our planner comprises a highly efficient foresight image generation module that predicts a high-quality 640$\\times$480 future observation from the current visual input and language instruction within only 0.33s on an H100 GPU, together with a vision-language model that reasons over the task and produces subtask descriptions for both the generator and the VLA. Importantly, state-of-the-art VLAs can integrate our planner seamlessly by simply augmenting their visual inputs, without any architectural modification. The foresight generator is pretrained on over 1 million multi-task, cross-embodiment episodes, enabling it to learn robust embodied dynamics. We evaluate our framework on a benchmark that consists of 11 diverse, multi-step real-world tasks. It achieves an average success rate of 87.4%, demonstrating a +40.9% absolute improvement over the $π_0$ baseline (46.5%) and a +30.3% absolute improvement over $π_0$ augmented with textual subtask guidance (57.1%).",
    "authors": [
      "Zhuoyang Zhang",
      "Shang Yang",
      "Qinghao Hu",
      "Luke J. Huang",
      "James Hou",
      "Yufei Sun",
      "Yao Lu",
      "Song Han"
    ],
    "published": "2026-02-12",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12322v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12322v1",
    "fetched_at": "2026-02-16T08:55:02.997054",
    "chinese_title": "ForeAct：通过高效视觉前瞻规划引导视觉-语言-动作模型",
    "chinese_summary": "论文提出ForeAct，一种通用高效的规划器，通过想象的未来观测和子任务描述逐步引导视觉-语言-动作（VLA）模型；其包含高效前瞻图像生成模块（H100上0.33s生成640×480高质量未来观测）和视觉语言模型，无需修改VLA架构即可集成；在11个真实多步任务上平均成功率达87.4%，较基线显著提升。",
    "tags": [
      "Deep Learning",
      "LLM",
      "Reinforcement Learning"
    ],
    "key_contributions": [
      "提出无需修改VLA架构的ForeAct规划器，通过想象未来观测和子任务描述引导VLA，提升推理效率与准确性",
      "构建高效前瞻图像生成模块（预训练多任务跨实例），在11个真实多步任务上实现87.4%的平均成功率，较基线大幅提升"
    ],
    "processed_at": "2026-02-16T09:01:55.857648"
  }
]