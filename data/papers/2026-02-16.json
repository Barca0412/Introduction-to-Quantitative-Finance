[
  {
    "id": "2602.12770v1",
    "title": "Efficient Monte Carlo Valuation of Corporate Bonds in Financial Networks",
    "abstract": "Valuing corporate bonds in systemic economies is challenging due to intricate webs of inter-institutional exposures. When a bank defaults, cascading losses propagate through the network, with payments determined by a system of fixed-point equations lacking closed-form solutions. Standard Monte Carlo methods cannot capture rare yet critical default events, while existing rare-event simulation techniques fail to account for higher-order network effects and scale poorly with network size. To overcome these challenges, we propose a novel approach -- Bi-Level Importance Sampling with Splitting -- and characterize individual bank defaults by decoupling them from the network's complex fixed-point dynamics. This separation enables a two-stage estimation process that directly generates samples from the banks' default events. We demonstrate theoretically that the method is both scalable and asymptotically optimal, and validate its effectiveness through numerical studies on empirically observed networks.",
    "authors": [
      "Dohyun Ahn",
      "Agostino Capponi"
    ],
    "published": "2026-02-13",
    "categories": [
      "q-fin.CP",
      "q-fin.PR",
      "q-fin.RM"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12770v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12770v1",
    "fetched_at": "2026-02-16T08:54:22.957036"
  },
  {
    "id": "2602.12490v1",
    "title": "Transformer-based CoVaR: Systemic Risk in Textual Information",
    "abstract": "Conditional Value-at-Risk (CoVaR) quantifies systemic financial risk by measuring the loss quantile of one asset, conditional on another asset experiencing distress. We develop a Transformer-based methodology that integrates financial news articles directly with market data to improve CoVaR estimates. Unlike approaches that use predefined sentiment scores, our method incorporates raw text embeddings generated by a large language model (LLM). We prove explicit error bounds for our Transformer CoVaR estimator, showing that accurate CoVaR learning is possible even with small datasets. Using U.S. market returns and Reuters news items from 2006--2013, our out-of-sample results show that textual information impacts the CoVaR forecasts. With better predictive performance, we identify a pronounced negative dip during market stress periods across several equity assets when comparing the Transformer-based CoVaR to both the CoVaR without text and the CoVaR using traditional sentiment measures. Our results show that textual data can be used to effectively model systemic risk without requiring prohibitively large data sets.",
    "authors": [
      "Junyu Chen",
      "Tom Boot",
      "Lingwei Kong",
      "Weining Wang"
    ],
    "published": "2026-02-13",
    "categories": [
      "econ.EM",
      "q-fin.RM",
      "stat.ML"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12490v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12490v1",
    "fetched_at": "2026-02-16T08:54:22.957077"
  },
  {
    "id": "2602.12976v1",
    "title": "Drift-Aware Variational Autoencoder-based Anomaly Detection with Two-level Ensembling",
    "abstract": "In today's digital world, the generation of vast amounts of streaming data in various domains has become ubiquitous. However, many of these data are unlabeled, making it challenging to identify events, particularly anomalies. This task becomes even more formidable in nonstationary environments where model performance can deteriorate over time due to concept drift. To address these challenges, this paper presents a novel method, VAE++ESDD, which employs incremental learning and two-level ensembling: an ensemble of Variational AutoEncoder(VAEs) for anomaly prediction, along with an ensemble of concept drift detectors. Each drift detector utilizes a statistical-based concept drift mechanism. To evaluate the effectiveness of VAE++ESDD, we conduct a comprehensive experimental study using real-world and synthetic datasets characterized by severely or extremely low anomalous rates and various drift characteristics. Our study reveals that the proposed method significantly outperforms both strong baselines and state-of-the-art methods.",
    "authors": [
      "Jin Li",
      "Kleanthis Malialis",
      "Christos G. Panayiotou",
      "Marios M. Polycarpou"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12976v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12976v1",
    "fetched_at": "2026-02-16T08:54:35.303092"
  },
  {
    "id": "2602.12622v1",
    "title": "Efficient Personalized Federated PCA with Manifold Optimization for IoT Anomaly Detection",
    "abstract": "Internet of things (IoT) networks face increasing security threats due to their distributed nature and resource constraints. Although federated learning (FL) has gained prominence as a privacy-preserving framework for distributed IoT environments, current federated principal component analysis (PCA) methods lack the integration of personalization and robustness, which are critical for effective anomaly detection. To address these limitations, we propose an efficient personalized federated PCA (FedEP) method for anomaly detection in IoT networks. The proposed model achieves personalization through introducing local representations with the $\\ell_1$-norm for element-wise sparsity, while maintaining robustness via enforcing local models with the $\\ell_{2,1}$-norm for row-wise sparsity. To solve this non-convex problem, we develop a manifold optimization algorithm based on the alternating direction method of multipliers (ADMM) with rigorous theoretical convergence guarantees. Experimental results confirm that the proposed FedEP outperforms the state-of-the-art FedPG, achieving excellent F1-scores and accuracy in various IoT security scenarios. Our code will be available at \\href{https://github.com/xianchaoxiu/FedEP}{https://github.com/xianchaoxiu/FedEP}.",
    "authors": [
      "Xianchao Xiu",
      "Chenyi Huang",
      "Wei Zhang",
      "Wanquan Liu"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12622v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12622v1",
    "fetched_at": "2026-02-16T08:54:35.303123"
  },
  {
    "id": "2602.12592v1",
    "title": "Power Interpretable Causal ODE Networks: A Unified Model for Explainable Anomaly Detection and Root Cause Analysis in Power Systems",
    "abstract": "Anomaly detection and root cause analysis (RCA) are critical for ensuring the safety and resilience of cyber-physical systems such as power grids. However, existing machine learning models for time series anomaly detection often operate as black boxes, offering only binary outputs without any explanation, such as identifying anomaly type and origin. To address this challenge, we propose Power Interpretable Causality Ordinary Differential Equation (PICODE) Networks, a unified, causality-informed architecture that jointly performs anomaly detection along with the explanation why it is detected as an anomaly, including root cause localization, anomaly type classification, and anomaly shape characterization. Experimental results in power systems demonstrate that PICODE achieves competitive detection performance while offering improved interpretability and reduced reliance on labeled data or external causal graphs. We provide theoretical results demonstrating the alignment between the shape of anomaly functions and the changes in the weights of the extracted causal graphs.",
    "authors": [
      "Yue Sun",
      "Likai Wang",
      "Rick S. Blum",
      "Parv Venkitasubramaniam"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12592v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12592v1",
    "fetched_at": "2026-02-16T08:54:35.303148"
  },
  {
    "id": "2602.13106v1",
    "title": "Which Algorithms Can Graph Neural Networks Learn?",
    "abstract": "In recent years, there has been growing interest in understanding neural architectures' ability to learn to execute discrete algorithms, a line of work often referred to as neural algorithmic reasoning. The goal is to integrate algorithmic reasoning capabilities into larger neural pipelines. Many such architectures are based on (message-passing) graph neural networks (MPNNs), owing to their permutation equivariance and ability to deal with sparsity and variable-sized inputs. However, existing work is either largely empirical and lacks formal guarantees or it focuses solely on expressivity, leaving open the question of when and how such architectures generalize beyond a finite training set. In this work, we propose a general theoretical framework that characterizes the sufficient conditions under which MPNNs can learn an algorithm from a training set of small instances and provably approximate its behavior on inputs of arbitrary size. Our framework applies to a broad class of algorithms, including single-source shortest paths, minimum spanning trees, and general dynamic programming problems, such as the $0$-$1$ knapsack problem. In addition, we establish impossibility results for a wide range of algorithmic tasks, showing that standard MPNNs cannot learn them, and we derive more expressive MPNN-like architectures that overcome these limitations. Finally, we refine our analysis for the Bellman-Ford algorithm, yielding a substantially smaller required training set and significantly extending the recent work of Nerem et al. [2025] by allowing for a differentiable regularization loss. Empirical results largely support our theoretical findings.",
    "authors": [
      "Solveig Wittig",
      "Antonis Vasileiou",
      "Robert R. Nerem",
      "Timo Stoll",
      "Floris Geerts",
      "Yusu Wang",
      "Christopher Morris"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS",
      "cs.NE"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.13106v1",
    "arxiv_url": "https://arxiv.org/abs/2602.13106v1",
    "fetched_at": "2026-02-16T08:55:02.996614"
  },
  {
    "id": "2602.13021v1",
    "title": "Prior-Guided Symbolic Regression: Towards Scientific Consistency in Equation Discovery",
    "abstract": "Symbolic Regression (SR) aims to discover interpretable equations from observational data, with the potential to reveal underlying principles behind natural phenomena. However, existing approaches often fall into the Pseudo-Equation Trap: producing equations that fit observations well but remain inconsistent with fundamental scientific principles. A key reason is that these approaches are dominated by empirical risk minimization, lacking explicit constraints to ensure scientific consistency. To bridge this gap, we propose PG-SR, a prior-guided SR framework built upon a three-stage pipeline consisting of warm-up, evolution, and refinement. Throughout the pipeline, PG-SR introduces a prior constraint checker that explicitly encodes domain priors as executable constraint programs, and employs a Prior Annealing Constrained Evaluation (PACE) mechanism during the evolution stage to progressively steer discovery toward scientifically consistent regions. Theoretically, we prove that PG-SR reduces the Rademacher complexity of the hypothesis space, yielding tighter generalization bounds and establishing a guarantee against pseudo-equations. Experimentally, PG-SR outperforms state-of-the-art baselines across diverse domains, maintaining robustness to varying prior quality, noisy data, and data scarcity.",
    "authors": [
      "Jing Xiao",
      "Xinhai Chen",
      "Jiaming Peng",
      "Qinglin Wang",
      "Menghan Jia",
      "Zhiquan Lai",
      "Guangping Yu",
      "Dongsheng Li",
      "Tiejun Li",
      "Jie Liu"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.13021v1",
    "arxiv_url": "https://arxiv.org/abs/2602.13021v1",
    "fetched_at": "2026-02-16T08:55:02.996664"
  },
  {
    "id": "2602.12984v1",
    "title": "SciAgentGym: Benchmarking Multi-Step Scientific Tool-use in LLM Agents",
    "abstract": "Scientific reasoning inherently demands integrating sophisticated toolkits to navigate domain-specific knowledge. Yet, current benchmarks largely overlook agents' ability to orchestrate tools for such rigorous workflows. To bridge this gap, we introduce SciAgentGym, a scalable interactive environment featuring 1,780 domain-specific tools across four natural science disciplines, supported by a robust execution infrastructure. Complementing this, we present SciAgentBench, a tiered evaluation suite designed to stress-test agentic capabilities from elementary actions to long-horizon workflows. Our evaluation identifies a critical bottleneck: state-of-the-art models struggle with complex scientific tool-use. Even for a leading model like GPT-5, success rates drop sharply from 60.6% to 30.9% as interaction horizons extend, primarily due to failures in multi-step workflow execution. To address this, we propose SciForge, a data synthesis method that models the tool action space as a dependency graph to generate logic-aware training trajectories. By fine-tuning on these trajectories, our SciAgent-8B outperforms the significantly larger Qwen3-VL-235B-Instruct while exhibiting positive cross-domain transfer of scientific tool-use capabilities. These results underscore the promising potential of next-generation autonomous scientific agents.",
    "authors": [
      "Yujiong Shen",
      "Yajie Yang",
      "Zhiheng Xi",
      "Binze Hu",
      "Huayu Sha",
      "Jiazheng Zhang",
      "Qiyuan Peng",
      "Junlin Shang",
      "Jixuan Huang",
      "Yutao Fan",
      "Jingqi Tong",
      "Shihan Dou",
      "Ming Zhang",
      "Lei Bai",
      "Zhenfei Yin",
      "Tao Gui",
      "Xingjun Ma",
      "Qi Zhang",
      "Xuanjing Huang",
      "Yu-Gang Jiang"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12984v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12984v1",
    "fetched_at": "2026-02-16T08:55:02.996717"
  },
  {
    "id": "2602.12978v1",
    "title": "Learning Native Continuation for Action Chunking Flow Policies",
    "abstract": "Action chunking enables Vision Language Action (VLA) models to run in real time, but naive chunked execution often exhibits discontinuities at chunk boundaries. Real-Time Chunking (RTC) alleviates this issue but is external to the policy, leading to spurious multimodal switching and trajectories that are not intrinsically smooth. We propose Legato, a training-time continuation method for action-chunked flow-based VLA policies. Specifically, Legato initializes denoising from a schedule-shaped mixture of known actions and noise, exposing the model to partial action information. Moreover, Legato reshapes the learned flow dynamics to ensure that the denoising process remains consistent between training and inference under per-step guidance. Legato further uses randomized schedule condition during training to support varying inference delays and achieve controllable smoothness. Empirically, Legato produces smoother trajectories and reduces spurious multimodal switching during execution, leading to less hesitation and shorter task completion time. Extensive real-world experiments show that Legato consistently outperforms RTC across five manipulation tasks, achieving approximately 10% improvements in both trajectory smoothness and task completion time.",
    "authors": [
      "Yufeng Liu",
      "Hang Yu",
      "Juntu Zhao",
      "Bocheng Li",
      "Di Zhang",
      "Mingzhu Li",
      "Wenxuan Wu",
      "Yingdong Hu",
      "Junyuan Xie",
      "Junliang Guo",
      "Dequan Wang",
      "Yang Gao"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12978v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12978v1",
    "fetched_at": "2026-02-16T08:55:02.996756"
  },
  {
    "id": "2602.12962v1",
    "title": "TriGen: NPU Architecture for End-to-End Acceleration of Large Language Models based on SW-HW Co-Design",
    "abstract": "Recent studies have extensively explored NPU architectures for accelerating AI inference in on-device environments, which are inherently resource-constrained. Meanwhile, transformer-based large language models (LLMs) have become dominant, with rapidly increasing model sizes but low degree of parameter reuse compared to conventional CNNs, making end-to-end execution on resource-limited devices extremely challenging. To address these challenges, we propose TriGen, a novel NPU architecture tailored for resource-constrained environments through software-hardware co-design. Firstly, TriGen adopts low-precision computation using microscaling (MX) to enable additional optimization opportunities while preserving accuracy, and resolves the issues that arise by employing such precision. Secondly, to jointly optimize both nonlinear and linear operations, TriGen eliminates the need for specialized hardware for essential nonlinear operations by using fast and accurate LUT, thereby maximizing performance gains and reducing hardware-cost in on-device environments, and finally, by taking practical hardware constraints into account, further employs scheduling techniques to maximize computational utilization even under limited on-chip memory capacity. We evaluate the performance of TriGen on various LLMs and show that TriGen achieves an average 2.73x performance speedup and 52% less memory transfer over the baseline NPU design with negligible accuracy loss.",
    "authors": [
      "Jonghun Lee",
      "Junghoon Lee",
      "Hyeonjin Kim",
      "Seoho Jeon",
      "Jisup Yoon",
      "Hyunbin Park",
      "Meejeong Park",
      "Heonjae Ha"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12962v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12962v1",
    "fetched_at": "2026-02-16T08:55:02.996787"
  },
  {
    "id": "2602.12691v1",
    "title": "ALOE: Action-Level Off-Policy Evaluation for Vision-Language-Action Model Post-Training",
    "abstract": "We study how to improve large foundation vision-language-action (VLA) systems through online reinforcement learning (RL) in real-world settings. Central to this process is the value function, which provides learning signals to guide VLA learning from experience. In practice, the value function is estimated from trajectory fragments collected from different data sources, including historical policies and intermittent human interventions. Estimating the value function of current behavior quality from the mixture data is inherently an off-policy evaluation problem. However, prior work often adopts conservative on-policy estimation for stability, which avoids direct evaluation of the current high-capacity policy and limits learning effectiveness. In this paper, we propose ALOE, an action-level off-policy evaluation framework for VLA post-training. ALOE applies chunking-based temporal-difference bootstrapping to evaluate individual action sequences instead of predicting final task outcomes. This design improves effective credit assignment to critical action chunks under sparse rewards and supports stable policy improvement. We evaluate our method on three real-world manipulation tasks, including smartphone packing as a high-precision task, laundry folding as a long-horizon deformable-object task, and bimanual pick-and-place involving multi-object perception. Across all tasks, ALOE improves learning efficiency without compromising execution speed, showing that off-policy RL can be reintroduced in a reliable manner for real-world VLA post-training. Videos and additional materials are available at our project website.",
    "authors": [
      "Rushuai Yang",
      "Hecheng Wang",
      "Chiming Liu",
      "Xiaohan Yan",
      "Yunlong Wang",
      "Xuan Du",
      "Shuoyu Yue",
      "Yongcheng Liu",
      "Chuheng Zhang",
      "Lizhe Qi",
      "Yi Chen",
      "Wei Shan",
      "Maoqing Yao"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12691v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12691v1",
    "fetched_at": "2026-02-16T08:55:02.996826"
  },
  {
    "id": "2602.12684v1",
    "title": "Xiaomi-Robotics-0: An Open-Sourced Vision-Language-Action Model with Real-Time Execution",
    "abstract": "In this report, we introduce Xiaomi-Robotics-0, an advanced vision-language-action (VLA) model optimized for high performance and fast and smooth real-time execution. The key to our method lies in a carefully designed training recipe and deployment strategy. Xiaomi-Robotics-0 is first pre-trained on large-scale cross-embodiment robot trajectories and vision-language data, endowing it with broad and generalizable action-generation capabilities while avoiding catastrophic forgetting of the visual-semantic knowledge of the underlying pre-trained VLM. During post-training, we propose several techniques for training the VLA model for asynchronous execution to address the inference latency during real-robot rollouts. During deployment, we carefully align the timesteps of consecutive predicted action chunks to ensure continuous and seamless real-time rollouts. We evaluate Xiaomi-Robotics-0 extensively in simulation benchmarks and on two challenging real-robot tasks that require precise and dexterous bimanual manipulation. Results show that our method achieves state-of-the-art performance across all simulation benchmarks. Moreover, Xiaomi-Robotics-0 can roll out fast and smoothly on real robots using a consumer-grade GPU, achieving high success rates and throughput on both real-robot tasks. To facilitate future research, code and model checkpoints are open-sourced at https://xiaomi-robotics-0.github.io",
    "authors": [
      "Rui Cai",
      "Jun Guo",
      "Xinze He",
      "Piaopiao Jin",
      "Jie Li",
      "Bingxuan Lin",
      "Futeng Liu",
      "Wei Liu",
      "Fei Ma",
      "Kun Ma",
      "Feng Qiu",
      "Heng Qu",
      "Yifei Su",
      "Qiao Sun",
      "Dong Wang",
      "Donghao Wang",
      "Yunhong Wang",
      "Rujie Wu",
      "Diyun Xiang",
      "Yu Yang",
      "Hangjun Ye",
      "Yuan Zhang",
      "Quanyun Zhou"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12684v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12684v1",
    "fetched_at": "2026-02-16T08:55:02.996887"
  },
  {
    "id": "2602.12662v1",
    "title": "Think Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents",
    "abstract": "Large language models (LLMs) are increasingly deployed as autonomous agents for multi-turn decision-making tasks. However, current agents typically rely on fixed cognitive patterns: non-thinking models generate immediate responses, while thinking models engage in deep reasoning uniformly. This rigidity is inefficient for long-horizon tasks, where cognitive demands vary significantly from step to step, with some requiring strategic planning and others only routine execution. In this paper, we introduce CogRouter, a framework that trains agents to dynamically adapt cognitive depth at each step. Grounded in ACT-R theory, we design four hierarchical cognitive levels ranging from instinctive responses to strategic planning. Our two-stage training approach includes Cognition-aware Supervised Fine-tuning (CoSFT) to instill stable level-specific patterns, and Cognition-aware Policy Optimization (CoPO) for step-level credit assignment via confidence-aware advantage reweighting. The key insight is that appropriate cognitive depth should maximize the confidence of the resulting action. Experiments on ALFWorld and ScienceWorld demonstrate that CogRouter achieves state-of-the-art performance with superior efficiency. With Qwen2.5-7B, it reaches an 82.3% success rate, outperforming GPT-4o (+40.3%), OpenAI-o3 (+18.3%), and GRPO (+14.0%), while using 62% fewer tokens.",
    "authors": [
      "Ruihan Yang",
      "Fanghua Ye",
      "Xiang We",
      "Ruoqing Zhao",
      "Kang Luo",
      "Xinbo Xu",
      "Bo Zhao",
      "Ruotian Ma",
      "Shanyi Wang",
      "Zhaopeng Tu",
      "Xiaolong Li",
      "Deqing Yang",
      " Linus"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12662v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12662v1",
    "fetched_at": "2026-02-16T08:55:02.996926"
  },
  {
    "id": "2602.12630v1",
    "title": "TensorCommitments: A Lightweight Verifiable Inference for Language Models",
    "abstract": "Most large language models (LLMs) run on external clouds: users send a prompt, pay for inference, and must trust that the remote GPU executes the LLM without any adversarial tampering. We critically ask how to achieve verifiable LLM inference, where a prover (the service) must convince a verifier (the client) that an inference was run correctly without rerunning the LLM. Existing cryptographic works are too slow at the LLM scale, while non-cryptographic ones require a strong verifier GPU. We propose TensorCommitments (TCs), a tensor-native proof-of-inference scheme. TC binds the LLM inference to a commitment, an irreversible tag that breaks under tampering, organized in our multivariate Terkle Trees. For LLaMA2, TC adds only 0.97% prover and 0.12% verifier time over inference while improving robustness to tailored LLM attacks by up to 48% over the best prior work requiring a verifier GPU.",
    "authors": [
      "Oguzhan Baser",
      "Elahe Sadeghi",
      "Eric Wang",
      "David Ribeiro Alves",
      "Sam Kazemian",
      "Hong Kang",
      "Sandeep P. Chinchali",
      "Sriram Vishwanath"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12630v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12630v1",
    "fetched_at": "2026-02-16T08:55:02.996956"
  },
  {
    "id": "2602.12574v1",
    "title": "Monte Carlo Tree Search with Reasoning Path Refinement for Small Language Models in Conversational Text-to-NoSQL",
    "abstract": "NoSQL databases have been widely adopted in big data analytics, geospatial applications, and healthcare services, due to their flexibility and scalability. However, querying NoSQL databases requires specialized technical expertise, creating a high barrier for users. While recent studies have explored text-to-NoSQL problem, they primarily focus on single-turn interactions, ignoring the conversational nature of real-world queries. To bridge this gap, we introduce the Conversational Text-to-NoSQL task, which generates NoSQL queries given a natural language question, a NoSQL database, and the dialogue history. To address this task, we propose Stage-MCTS, a framework that endows small language models (SLMs) with NoSQL-specific reasoning capabilities by formulating query generation as a search problem. The framework employs Monte Carlo Tree Search (MCTS) guided by a rule-based reward to produce stepwise reasoning data, followed by progressive supervised fine-tuning (SFT) and self-training strategies. We further construct CoNoSQL, a cross-domain dataset with over 2,000 dialogues and 150 databases, to support evaluation. Experiments demonstrate that our approach outperforms state-of-the-art large reasoning models, improving execution value match (EVM) accuracy by up to 7.93%.",
    "authors": [
      "Xubang Xiong",
      "Raymond Chi-Wing Wong",
      "Yuanfeng Song"
    ],
    "published": "2026-02-13",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12574v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12574v1",
    "fetched_at": "2026-02-16T08:55:02.996977"
  },
  {
    "id": "2602.12426v1",
    "title": "Interference-Robust Non-Coherent Over-the-Air Computation for Decentralized Optimization",
    "abstract": "Non-coherent over-the-air (NCOTA) computation enables low-latency and bandwidth-efficient decentralized optimization by exploiting the average energy superposition property of wireless channels. It has recently been proposed as a powerful tool for executing consensus-based optimization algorithms in fully decentralized systems. A key advantage of NCOTA is that it enables unbiased consensus estimation without channel state information at either transmitters or receivers, requires no transmission scheduling, and scales efficiently to dense network deployments. However, NCOTA is inherently susceptible to external interference, which can bias the consensus estimate and deteriorate the convergence of the underlying decentralized optimization algorithm. In this paper, we propose a novel interference-robust (IR-)NCOTA scheme. The core idea is to apply a coordinated random rotation of the frame of reference across all nodes, and transmit a pseudo-random pilot signal, allowing to transform external interference into a circularly symmetric distribution with zero mean relative to the rotated frame. This ensures that the consensus estimates remain unbiased, preserving the convergence guarantees of the underlying optimization algorithm. Through numerical results on a classification task, it is demonstrated that IR-NCOTA exhibits superior performance over the baseline NCOTA algorithm in the presence of external interference.",
    "authors": [
      "Nicolò Michelusi"
    ],
    "published": "2026-02-12",
    "categories": [
      "eess.SP",
      "cs.LG",
      "cs.MA"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12426v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12426v1",
    "fetched_at": "2026-02-16T08:55:02.996995"
  },
  {
    "id": "2602.12419v1",
    "title": "Intent-Driven Smart Manufacturing Integrating Knowledge Graphs and Large Language Models",
    "abstract": "The increasing complexity of smart manufacturing environments demands interfaces that can translate high-level human intents into machine-executable actions. This paper presents a unified framework that integrates instruction-tuned Large Language Models (LLMs) with ontology-aligned Knowledge Graphs (KGs) to enable intent-driven interaction in Manufacturing-as-a-Service (MaaS) ecosystems. We fine-tune Mistral-7B-Instruct-V02 on a domain-specific dataset, enabling the translation of natural language intents into structured JSON requirement models. These models are semantically mapped to a Neo4j-based knowledge graph grounded in the ISA-95 standard, ensuring operational alignment with manufacturing processes, resources, and constraints. Our experimental results demonstrate significant performance gains over zero-shot and 3-shots baselines, achieving 89.33\\% exact match accuracy and 97.27\\% overall accuracy. This work lays the foundation for scalable, explainable, and adaptive human-machine",
    "authors": [
      "Takoua Jradi",
      "John Violos",
      "Dimitrios Spatharakis",
      "Lydia Mavraidi",
      "Ioannis Dimolitsas",
      "Aris Leivadeas",
      "Symeon Papavassiliou"
    ],
    "published": "2026-02-12",
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12419v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12419v1",
    "fetched_at": "2026-02-16T08:55:02.997024"
  },
  {
    "id": "2602.12322v1",
    "title": "ForeAct: Steering Your VLA with Efficient Visual Foresight Planning",
    "abstract": "Vision-Language-Action (VLA) models convert high-level language instructions into concrete, executable actions, a task that is especially challenging in open-world environments. We present Visual Foresight Planning (ForeAct), a general and efficient planner that guides a VLA step-by-step using imagined future observations and subtask descriptions. With an imagined future observation, the VLA can focus on visuo-motor inference rather than high-level semantic reasoning, leading to improved accuracy and generalization. Our planner comprises a highly efficient foresight image generation module that predicts a high-quality 640$\\times$480 future observation from the current visual input and language instruction within only 0.33s on an H100 GPU, together with a vision-language model that reasons over the task and produces subtask descriptions for both the generator and the VLA. Importantly, state-of-the-art VLAs can integrate our planner seamlessly by simply augmenting their visual inputs, without any architectural modification. The foresight generator is pretrained on over 1 million multi-task, cross-embodiment episodes, enabling it to learn robust embodied dynamics. We evaluate our framework on a benchmark that consists of 11 diverse, multi-step real-world tasks. It achieves an average success rate of 87.4%, demonstrating a +40.9% absolute improvement over the $π_0$ baseline (46.5%) and a +30.3% absolute improvement over $π_0$ augmented with textual subtask guidance (57.1%).",
    "authors": [
      "Zhuoyang Zhang",
      "Shang Yang",
      "Qinghao Hu",
      "Luke J. Huang",
      "James Hou",
      "Yufei Sun",
      "Yao Lu",
      "Song Han"
    ],
    "published": "2026-02-12",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "pdf_url": "https://arxiv.org/pdf/2602.12322v1",
    "arxiv_url": "https://arxiv.org/abs/2602.12322v1",
    "fetched_at": "2026-02-16T08:55:02.997054"
  }
]